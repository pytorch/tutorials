{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# How to use TensorBoard with PyTorch\nTensorBoard is a visualization toolkit for machine learning experimentation. \nTensorBoard allows tracking and visualizing metrics such as loss and accuracy, \nvisualizing the model graph, viewing histograms, displaying images and much more. \nIn this tutorial we are going to cover TensorBoard installation, \nbasic usage with PyTorch, and how to visualize data you logged in TensorBoard UI.\n\n## Installation\nPyTorch should be installed to log models and metrics into TensorBoard log \ndirectory. The following command will install PyTorch 1.4+ via \nAnaconda (recommended):\n\n```sh\n$ conda install pytorch torchvision -c pytorch\n```\nor pip\n\n```sh\n$ pip install torch torchvision\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using TensorBoard in PyTorch\n\nLet\u2019s now try using TensorBoard with PyTorch! Before logging anything, \nwe need to create a ``SummaryWriter`` instance.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Writer will output to ``./runs/`` directory by default.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log scalars\n\nIn machine learning, it\u2019s important to understand key metrics such as \nloss and how they change during training. Scalar helps to save \nthe loss value of each training step, or the accuracy after each epoch. \n\nTo log a scalar value, use \n``add_scalar(tag, scalar_value, global_step=None, walltime=None)``. \nFor example, lets create a simple linear regression training, and \nlog loss value using ``add_scalar``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x = torch.arange(-5, 5, 0.1).view(-1, 1)\ny = -5 * x + 0.1 * torch.randn(x.size())\n\nmodel = torch.nn.Linear(1, 1)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n\ndef train_model(iter):\n    for epoch in range(iter):\n        y1 = model(x)\n        loss = criterion(y1, y)\n        writer.add_scalar(\"Loss/train\", loss, epoch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \ntrain_model(10)\nwriter.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Call ``flush()`` method to make sure that all pending events \nhave been written to disk.\n\nSee [torch.utils.tensorboard tutorials](https://pytorch.org/docs/stable/tensorboard.html) \nto find more TensorBoard visualization types you can log.\n\nIf you do not need the summary writer anymore, call ``close()`` method.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run TensorBoard\n\nInstall TensorBoard through the command line to visualize data you logged\n\n```sh\npip install tensorboard\n```\nNow, start TensorBoard, specifying the root log directory you used above. \nArgument ``logdir`` points to directory where TensorBoard will look to find \nevent files that it can display. TensorBoard will recursively walk \nthe directory structure rooted at ``logdir``, looking for ``.*tfevents.*`` files.\n\n```sh\ntensorboard --logdir=runs\n```\nGo to the URL it provides OR to [http://localhost:6006/](http://localhost:6006/)\n\n<img src=\"file://../../_static/img/thumbnails/tensorboard_scalars.png\" scale=\"40 %\">\n\nThis dashboard shows how the loss and accuracy change with every epoch. \nYou can use it to also track training speed, learning rate, and other \nscalar values. It\u2019s helpful to compare these metrics across different \ntraining runs to improve your model.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learn More\n\n-  [torch.utils.tensorboard](https://pytorch.org/docs/stable/tensorboard.html) docs\n-  [Visualizing models, data, and training with TensorBoard](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) tutorial\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}