{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://docs.pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Compilation Control with `torch.compiler.set_stance`\n",
    "============================================================\n",
    "\n",
    "**Author:** [William Wen](https://github.com/williamwen42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.compiler.set_stance` is a `torch.compiler` API that enables you\n",
    "to change the behavior of `torch.compile` across different calls to your\n",
    "model without having to reapply `torch.compile` to your model.\n",
    "\n",
    "This recipe provides some examples on how to use\n",
    "`torch.compiler.set_stance`.\n",
    "\n",
    "::: {.contents local=\"\"}\n",
    ":::\n",
    "\n",
    "Prerequisites\n",
    "=============\n",
    "\n",
    "-   `torch >= 2.6`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description\n",
    "===========\n",
    "\n",
    "`torch.compile.set_stance` can be used as a decorator, context manager,\n",
    "or raw function to change the behavior of `torch.compile` across\n",
    "different calls to your model.\n",
    "\n",
    "In the example below, the `\"force_eager\"` stance ignores all\n",
    "`torch.compile` directives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def foo(x):\n",
    "    if torch.compiler.is_compiling():\n",
    "        # torch.compile is active\n",
    "        return x + 1\n",
    "    else:\n",
    "        # torch.compile is not active\n",
    "        return x - 1\n",
    "\n",
    "\n",
    "inp = torch.zeros(3)\n",
    "\n",
    "print(foo(inp))  # compiled, prints 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample decorator usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.compiler.set_stance(\"force_eager\")\n",
    "def bar(x):\n",
    "    # force disable the compiler\n",
    "    return foo(x)\n",
    "\n",
    "\n",
    "print(bar(inp))  # not compiled, prints -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample context manager usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.compiler.set_stance(\"force_eager\"):\n",
    "    print(foo(inp))  # not compiled, prints -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample raw function usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.compiler.set_stance(\"force_eager\")\n",
    "print(foo(inp))  # not compiled, prints -1\n",
    "torch.compiler.set_stance(\"default\")\n",
    "\n",
    "print(foo(inp))  # compiled, prints 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.compile` stance can only be changed **outside** of any\n",
    "`torch.compile` region. Attempts to do otherwise will result in an\n",
    "error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def baz(x):\n",
    "    # error!\n",
    "    with torch.compiler.set_stance(\"force_eager\"):\n",
    "        return x + 1\n",
    "\n",
    "\n",
    "try:\n",
    "    baz(inp)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "@torch.compiler.set_stance(\"force_eager\")\n",
    "def inner(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def outer(x):\n",
    "    # error!\n",
    "    return inner(x)\n",
    "\n",
    "\n",
    "try:\n",
    "    outer(inp)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other stances include:\n",
    "\n",
    ":   -   `\"default\"`: The default stance, used for normal compilation.\n",
    "    -   `\"eager_on_recompile\"`: Run code eagerly when a recompile is\n",
    "        necessary. If there is cached compiled code valid for the input,\n",
    "        it will still be used.\n",
    "    -   `\"fail_on_recompile\"`: Raise an error when recompiling a\n",
    "        function.\n",
    "\n",
    "See the `torch.compiler.set_stance` [doc\n",
    "page](https://pytorch.org/docs/main/generated/torch.compiler.set_stance.html#torch.compiler.set_stance)\n",
    "for more stances and options. More stances/options may also be added in\n",
    "the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples\n",
    "========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preventing recompilation\n",
    "========================\n",
    "\n",
    "Some models do not expect any recompilations - for example, you may\n",
    "always have inputs with the same shape. Since recompilations may be\n",
    "expensive, we may wish to error out when we attempt to recompile so we\n",
    "can detect and fix recompilation cases. The `\"fail_on_recompilation\"`\n",
    "stance can be used for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def my_big_model(x):\n",
    "    return torch.relu(x)\n",
    "\n",
    "\n",
    "# first compilation\n",
    "my_big_model(torch.randn(3))\n",
    "\n",
    "with torch.compiler.set_stance(\"fail_on_recompile\"):\n",
    "    my_big_model(torch.randn(3))  # no recompilation - OK\n",
    "    try:\n",
    "        my_big_model(torch.randn(4))  # recompilation - error\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If erroring out is too disruptive, we can use `\"eager_on_recompile\"`\n",
    "instead, which will cause `torch.compile` to fall back to eager instead\n",
    "of erroring out. This may be useful if we don\\'t expect recompilations\n",
    "to happen frequently, but when one is required, we\\'d rather pay the\n",
    "cost of running eagerly over the cost of recompilation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def my_huge_model(x):\n",
    "    if torch.compiler.is_compiling():\n",
    "        return x + 1\n",
    "    else:\n",
    "        return x - 1\n",
    "\n",
    "\n",
    "# first compilation\n",
    "print(my_huge_model(torch.zeros(3)))  # 1\n",
    "\n",
    "with torch.compiler.set_stance(\"eager_on_recompile\"):\n",
    "    print(my_huge_model(torch.zeros(3)))  # 1\n",
    "    print(my_huge_model(torch.zeros(4)))  # -1\n",
    "    print(my_huge_model(torch.zeros(3)))  # 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring performance gains\n",
    "===========================\n",
    "\n",
    "`torch.compiler.set_stance` can be used to compare eager vs. compiled\n",
    "performance without having to define a separate eager model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "\n",
    "@torch.compile\n",
    "def my_gigantic_model(x, y):\n",
    "    x = x @ y\n",
    "    x = x @ y\n",
    "    x = x @ y\n",
    "    return x\n",
    "\n",
    "\n",
    "inps = torch.randn(5, 5), torch.randn(5, 5)\n",
    "\n",
    "with torch.compiler.set_stance(\"force_eager\"):\n",
    "    print(\"eager:\", timed(lambda: my_gigantic_model(*inps))[1])\n",
    "\n",
    "# warmups\n",
    "for _ in range(3):\n",
    "    my_gigantic_model(*inps)\n",
    "\n",
    "print(\"compiled:\", timed(lambda: my_gigantic_model(*inps))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crashing sooner\n",
    "===============\n",
    "\n",
    "Running an eager iteration first before a compiled iteration using the\n",
    "`\"force_eager\"` stance can help us to catch errors unrelated to\n",
    "`torch.compile` before attempting a very long compile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def my_humongous_model(x):\n",
    "    return torch.sin(x, x)\n",
    "\n",
    "\n",
    "try:\n",
    "    with torch.compiler.set_stance(\"force_eager\"):\n",
    "        print(my_humongous_model(torch.randn(3)))\n",
    "    # this call to the compiled model won't run\n",
    "    print(my_humongous_model(torch.randn(3)))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "==========\n",
    "\n",
    "In this recipe, we have learned how to use the\n",
    "`torch.compiler.set_stance` API to modify the behavior of\n",
    "`torch.compile` across different calls to a model without needing to\n",
    "reapply it. The recipe demonstrates using `torch.compiler.set_stance` as\n",
    "a decorator, context manager, or raw function to control compilation\n",
    "stances like `force_eager`, `default`, `eager_on_recompile`, and\n",
    "\\\"fail\\_on\\_recompile.\\\"\n",
    "\n",
    "For more information, see: [torch.compiler.set\\_stance API\n",
    "documentation](https://pytorch.org/docs/main/generated/torch.compiler.set_stance.html#torch.compiler.set_stance).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
