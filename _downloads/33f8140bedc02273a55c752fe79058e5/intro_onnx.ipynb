{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n**Introduction to ONNX**\n\n# Introduction to ONNX\n\nAuthors:\n[Thiago Crepaldi](https://github.com/thiagocrepaldi),\n\n[Open Neural Network eXchange (ONNX)](https://onnx.ai/) is an open standard\nformat for representing machine learning models. The ``torch.onnx`` module provides APIs to\ncapture the computation graph from a native PyTorch :class:`torch.nn.Module` model and convert\nit into an [ONNX graph](https://github.com/onnx/onnx/blob/main/docs/IR.md).\n\nThe exported model can be consumed by any of the many\n[runtimes that support ONNX](https://onnx.ai/supported-tools.html#deployModel),\nincluding Microsoft's [ONNX Runtime](https://www.onnxruntime.ai).\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Currently, there are two flavors of ONNX exporter APIs,\n    but this tutorial will focus on the ``torch.onnx.dynamo_export``.</p></div>\n\nThe TorchDynamo engine is leveraged to hook into Python's frame evaluation API and dynamically rewrite its\nbytecode into an  [FX graph](https://pytorch.org/docs/stable/fx.html).\nThe resulting FX Graph is polished before it is finally translated into an\n[ONNX graph](https://github.com/onnx/onnx/blob/main/docs/IR.md).\n\nThe main advantage of this approach is that the [FX graph](https://pytorch.org/docs/stable/fx.html) is captured using\nbytecode analysis that preserves the dynamic nature of the model instead of using traditional static tracing techniques.\n\n## Dependencies\n\nThe ONNX exporter depends on extra Python packages:\n\n  - [ONNX](https://onnx.ai)\n  - [ONNX Script](https://onnxscript.ai)\n\nThey can be installed through [pip](https://pypi.org/project/pip/):\n\n```bash\npip install --upgrade onnx onnxscript\n```\n.. include:: /beginner_source/basics/onnx_toc.txt\n\n.. toctree::\n   :hidden:\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}