{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n[Introduction to ONNX](intro_onnx.html) ||\n**Exporting a PyTorch model to ONNX** ||\n[Extending the ONNX Registry](onnx_registry_tutorial.html)\n\n# Export a PyTorch model to ONNX\n\n**Author**: [Thiago Crepaldi](https://github.com/thiagocrepaldi)\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>As of PyTorch 2.1, there are two versions of ONNX Exporter.\n\n    * ``torch.onnx.dynamo_export`` is the newest (still in beta) exporter based on the TorchDynamo technology released with PyTorch 2.0\n    * ``torch.onnx.export`` is based on TorchScript backend and has been available since PyTorch 1.2.0</p></div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the [60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html),\nwe had the opportunity to learn about PyTorch at a high level and train a small neural network to classify images.\nIn this tutorial, we are going to expand this to describe how to convert a model defined in PyTorch into the\nONNX format using TorchDynamo and the ``torch.onnx.dynamo_export`` ONNX exporter.\n\nWhile PyTorch is great for iterating on the development of models, the model can be deployed to production\nusing different formats, including [ONNX](https://onnx.ai/) (Open Neural Network Exchange)!\n\nONNX is a flexible open standard format for representing machine learning models which standardized representations\nof machine learning allow them to be executed across a gamut of hardware platforms and runtime environments\nfrom large-scale cloud-based supercomputers to resource-constrained edge devices, such as your web browser and phone.\n\nIn this tutorial, we\u2019ll learn how to:\n\n1. Install the required dependencies.\n2. Author a simple image classifier model.\n3. Export the model to ONNX format.\n4. Save the ONNX model in a file.\n5. Visualize the ONNX model graph using [Netron](https://github.com/lutzroeder/netron).\n6. Execute the ONNX model with `ONNX Runtime`\n7. Compare the PyTorch results with the ones from the ONNX Runtime.\n\n## 1. Install the required dependencies\nBecause the ONNX exporter uses ``onnx`` and ``onnxscript`` to translate PyTorch operators into ONNX operators,\nwe will need to install them.\n\n```bash\npip install onnx\npip install onnxscript\n```\n## 2. Author a simple image classifier model\n\nOnce your environment is set up, let\u2019s start modeling our image classifier with PyTorch,\nexactly like we did in the [60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html).\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass MyModel(nn.Module):\n\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.conv1 = nn.Conv2d(1, 6, 5)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Export the model to ONNX format\n\nNow that we have our model defined, we need to instantiate it and create a random 32x32 input.\nNext, we can export the model to ONNX format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch_model = MyModel()\ntorch_input = torch.randn(1, 1, 32, 32)\nexport_output = torch.onnx.dynamo_export(torch_model, torch_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we didn't need any code change to the model.\nThe resulting ONNX model is stored within ``torch.onnx.ExportOutput`` as a binary protobuf file.\n\n## 4. Save the ONNX model in a file\n\nAlthough having the exported model loaded in memory is useful in many applications,\nwe can save it to disk with the following code:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "export_output.save(\"my_image_classifier.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can load the ONNX file back into memory and check if it is well formed with the following code:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnx\nonnx_model = onnx.load(\"my_image_classifier.onnx\")\nonnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualize the ONNX model graph using Netron\n\nNow that we have our model saved in a file, we can visualize it with [Netron](https://github.com/lutzroeder/netron).\nNetron can either be installed on macos, Linux or Windows computers, or run directly from the browser.\nLet's try the web version by opening the following link: https://netron.app/.\n\n<img src=\"file://../../_static/img/onnx/netron_web_ui.png\" width=\"70%\" align=\"center\">\n\n\nOnce Netron is open, we can drag and drop our ``my_image_classifier.onnx`` file into the browser or select it after\nclicking the **Open model** button.\n\n<img src=\"file://../../_static/img/onnx/image_clossifier_onnx_modelon_netron_web_ui.png\" width=\"50%\">\n\n\nAnd that is it! We have successfully exported our PyTorch model to ONNX format and visualized it with Netron.\n\n## 6. Execute the ONNX model with ONNX Runtime\n\nThe last step is executing the ONNX model with `ONNX Runtime`, but before we do that, let's install ONNX Runtime.\n\n```bash\npip install onnxruntime\n```\nThe ONNX standard does not support all the data structure and types that PyTorch does,\nso we need to adapt PyTorch input's to ONNX format before feeding it to ONNX Runtime.\nIn our example, the input happens to be the same, but it might have more inputs\nthan the original PyTorch model in more complex models.\n\nONNX Runtime requires an additional step that involves converting all PyTorch tensors to Numpy (in CPU)\nand wrap them on a dictionary with keys being a string with the input name as key and the numpy tensor as the value.\n\nNow we can create an *ONNX Runtime Inference Session*, execute the ONNX model with the processed input\nand get the output. In this tutorial, ONNX Runtime is executed on CPU, but it could be executed on GPU as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import onnxruntime\n\nonnx_input = export_output.adapt_torch_inputs_to_onnx(torch_input)\nprint(f\"Input length: {len(onnx_input)}\")\nprint(f\"Sample input: {onnx_input}\")\n\nort_session = onnxruntime.InferenceSession(\"./my_image_classifier.onnx\", providers=['CPUExecutionProvider'])\n\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n\nonnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n\nonnxruntime_outputs = ort_session.run(None, onnxruntime_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compare the PyTorch results with the ones from the ONNX Runtime\n\nThe best way to determine whether the exported model is looking good is through numerical evaluation\nagainst PyTorch, which is our source of truth.\n\nFor that, we need to execute the PyTorch model with the same input and compare the results with ONNX Runtime's.\nBefore comparing the results, we need to convert the PyTorch's output to match ONNX's format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch_outputs = torch_model(torch_input)\ntorch_outputs = export_output.adapt_torch_outputs_to_onnx(torch_outputs)\n\nassert len(torch_outputs) == len(onnxruntime_outputs)\nfor torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n    torch.testing.assert_close(torch_output, torch.tensor(onnxruntime_output))\n\nprint(\"PyTorch and ONNX Runtime output matched!\")\nprint(f\"Output length: {len(onnxruntime_outputs)}\")\nprint(f\"Sample output: {onnxruntime_outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n\nThat is about it! We have successfully exported our PyTorch model to ONNX format,\nsaved the model to disk, viewed it using Netron, executed it with ONNX Runtime\nand finally compared its numerical results with PyTorch's.\n\n## Further reading\n\nThe list below refers to tutorials that ranges from basic examples to advanced scenarios,\nnot necessarily in the order they are listed.\nFeel free to jump directly to specific topics of your interest or\nsit tight and have fun going through all of them to learn all there is about the ONNX exporter.\n\n.. include:: /beginner_source/onnx/onnx_toc.txt\n\n.. toctree::\n   :hidden:\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}