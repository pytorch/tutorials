{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n`Learn the Basics <intro.html>`_ ||\n`Quickstart <quickstart_tutorial.html>`_ || \n`Tensors <tensorqs_tutorial.html>`_ || \n`Datasets & DataLoaders <data_tutorial.html>`_ ||\n`Transforms <transforms_tutorial.html>`_ ||\n`Build Model <buildmodel_tutorial.html>`_ ||\n`Autograd <autogradqs_tutorial.html>`_ ||\n`Optimization <optimization_tutorial.html>`_ ||\n**Save & Load Model**\n\nSave and Load the Model\n============================\n\nIn this section we will look at how to persist model state with saving, loading and running model predictions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.onnx as onnx\nimport torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving and Loading Model Weights\n--------------------------------\nPyTorch models store the learned parameters in an internal\nstate dictionary, called ``state_dict``. These can be persisted via the ``torch.save``\nmethod:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(pretrained=True)\ntorch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To load model weights, you need to create an instance of the same model first, and then load the parameters \nusing ``load_state_dict()`` method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\nmodel.load_state_dict(torch.load('model_weights.pth'))\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>be sure to call ``model.eval()`` method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving and Loading Models with Shapes\n-------------------------------------\nWhen loading model weights, we needed to instantiate the model class first, because the class \ndefines the structure of a network. We might want to save the structure of this class together with \nthe model, in which case we can pass ``model`` (and not ``model.state_dict()``) to the saving function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then load the model like this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = torch.load('model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>This approach uses Python `pickle <https://docs.python.org/3/library/pickle.html>`_ module when serializing the model, thus it relies on the actual class definition to be available when loading the model.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exporting Model to ONNX\n-----------------------\nPyTorch also has native ONNX export support. Given the dynamic nature of the\nPyTorch execution graph, however, the export process must\ntraverse the execution graph to produce a persisted ONNX model. For this reason, a\ntest variable of the appropriate size should be passed in to the\nexport routine (in our case, we will create a dummy zero tensor of the correct size):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "input_image = torch.zeros((1,3,224,224))\nonnx.export(model, input_image, 'model.onnx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are a lot of things you can do with ONNX model, including running inference on different platforms \nand in different programming languages. For more details, we recommend \nvisiting `ONNX tutorial <https://github.com/onnx/tutorials>`_.\n\nCongratulations! You have completed the PyTorch beginner tutorial! Try \n`revisting the first page <quickstart_tutorial.html>`_ to see the tutorial in its entirety\nagain. We hope this tutorial has helped you get started with deep learning on PyTorch. \nGood luck!\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}