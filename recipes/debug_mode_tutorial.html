
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-07-20T23:02:43+00:00" />
    <title>DebugMode: Recording Dispatched Operations and Numerical Debugging &#8212; PyTorch Tutorials 2.10.0+cu128 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=36fba2ff" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=a8d6e986"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/debug_mode_tutorial';</script>
    <link rel="canonical" href="https://docs.pytorch.org/tutorials/recipes/debug_mode_tutorial.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Unstable" href="../unstable_index.html" />
    <link rel="prev" title="Asynchronous Saving with Distributed Checkpoint (DCP)" href="distributed_async_checkpoint_recipe.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.10.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/tutorials" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.10.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../unstable_index.html">
    Unstable
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../unstable_index.html">
    Unstable
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="foreach_map.html">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">DebugMode: Recording Dispatched Operations and Numerical Debugging</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../recipes_index.html" class="nav-link">Recipes</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">DebugMode:...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../recipes_index.html">
        <meta itemprop="name" content="Recipes">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="DebugMode: Recording Dispatched Operations and Numerical Debugging">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/debug_mode_tutorial</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-debug-mode-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="debugmode-recording-dispatched-operations-and-numerical-debugging">
<span id="sphx-glr-recipes-debug-mode-tutorial-py"></span><h1>DebugMode: Recording Dispatched Operations and Numerical Debugging<a class="headerlink" href="#debugmode-recording-dispatched-operations-and-numerical-debugging" title="Link to this heading">#</a></h1>
<p><strong>Authors:</strong> Pian Pawakapan, Shangdi Yu</p>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-2 sd-row-cols-xs-2 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-mortar-board" viewBox="0 0 16 16" aria-hidden="true"><path d="M7.693 1.066a.747.747 0 0 1 .614 0l7.25 3.25a.75.75 0 0 1 0 1.368L13 6.831v2.794c0 1.024-.81 1.749-1.66 2.173-.893.447-2.075.702-3.34.702-.278 0-.55-.012-.816-.036a.75.75 0 0 1 .133-1.494c.22.02.45.03.683.03 1.082 0 2.025-.221 2.67-.543.69-.345.83-.682.83-.832V7.503L8.307 8.934a.747.747 0 0 1-.614 0L4 7.28v1.663c.296.105.575.275.812.512.438.438.688 1.059.688 1.796v3a.75.75 0 0 1-.75.75h-3a.75.75 0 0 1-.75-.75v-3c0-.737.25-1.358.688-1.796.237-.237.516-.407.812-.512V6.606L.443 5.684a.75.75 0 0 1 0-1.368ZM2.583 5 8 7.428 13.416 5 8 2.572ZM2.5 11.25v2.25H4v-2.25c0-.388-.125-.611-.25-.735a.697.697 0 0 0-.5-.203.707.707 0 0 0-.5.203c-.125.124-.25.347-.25.735Z"></path></svg> What you will learn</div>
<ul class="simple">
<li><p class="sd-card-text">How to capture dispatched ops for eager and <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> runs</p></li>
<li><p class="sd-card-text">How to use tensor hashes and stack traces in DebugMode to pinpoint numerical divergence</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<svg version="1.1" width="1.0em" height="1.0em" class="sd-octicon sd-octicon-list-unordered" viewBox="0 0 16 16" aria-hidden="true"><path d="M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg> Prerequisites</div>
<ul class="simple">
<li><p class="sd-card-text">PyTorch 2.10 or later</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">DebugMode</span></code> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils._debug_mode.DebugMode</span></code>) is a
<code class="docutils literal notranslate"><span class="pre">TorchDispatchMode</span></code> that intercepts PyTorch runtime calls and emits a
hierarchical log of operations. It is particularly useful when you need to
understand <em>what</em> actually runs, both in eager mode and under <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>
or when you need to pinpoint numerical divergence between two runs.</p>
<p>Key capabilities:</p>
<ul class="simple">
<li><p><strong>Runtime logging</strong> – Records dispatched operations and TorchInductor compiled
Triton kernels.</p></li>
<li><p><strong>Tensor hashing</strong> – Attaches deterministic hashes to inputs/outputs to enable
diffing runs to locate numerical divergences.</p></li>
<li><p><strong>Dispatch hooks</strong> – Allows registration of custom hooks to annotate calls</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This recipe describes a prototype feature. Prototype features are typically
at an early stage for feedback and testing and are subject to change.</p>
</div>
</section>
<section id="quick-start">
<h2>Quick start<a class="headerlink" href="#quick-start" title="Link to this heading">#</a></h2>
<p>The snippet below captures a small eager workload and prints the debug string:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._inductor.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">decomps_to_exclude</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils._debug_mode</span><span class="w"> </span><span class="kn">import</span> <span class="n">DebugMode</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_once</span><span class="p">():</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.mm.html#torch.mm" title="torch.mm" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">mm</span></a><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

<span class="k">with</span> <span class="n">DebugMode</span><span class="p">()</span> <span class="k">as</span> <span class="n">debug_mode</span><span class="p">:</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">out</span></a> <span class="o">=</span> <span class="n">run_once</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DebugMode output:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">debug_mode</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DebugMode output:
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t: f32[8, 8]
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t: f32[8, 8]
    aten::relu(t: f32[8, 8])  -&gt;  t: f32[8, 8]
    aten::mm(t: f32[8, 8], t: f32[8, 8])  -&gt;  t: f32[8, 8]
</pre></div>
</div>
</section>
<section id="getting-more-metadata">
<h2>Getting more metadata<a class="headerlink" href="#getting-more-metadata" title="Link to this heading">#</a></h2>
<p>For most investigations, you’ll want to enable stack traces, tensor IDs, and tensor hashing.
These features provide metadata to correlate operations back to model code.</p>
<p><code class="docutils literal notranslate"><span class="pre">DebugMode.log_tensor_hashes</span></code> decorates the log with hashes for every call.
The <code class="docutils literal notranslate"><span class="pre">hash_tensor</span></code> hash function uses <code class="docutils literal notranslate"><span class="pre">torch.hash_tensor</span></code>, which returns 0 for tensors whose
elements are all the same. The <code class="docutils literal notranslate"><span class="pre">norm</span></code> hash function uses <code class="docutils literal notranslate"><span class="pre">norm</span></code> with <code class="docutils literal notranslate"><span class="pre">p=1</span></code>.
With both these functions, especially <code class="docutils literal notranslate"><span class="pre">norm</span></code>, tensor closeness in numerics is related to hash closeness,
so it’s rather interpretable. The default <code class="docutils literal notranslate"><span class="pre">hash_fn</span></code> is <code class="docutils literal notranslate"><span class="pre">norm</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="p">(</span>
    <span class="n">DebugMode</span><span class="p">(</span>
        <span class="c1"># record_stack_trace is only supported for eager in pytorch 2.10</span>
        <span class="n">record_stack_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">record_ids</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="k">as</span> <span class="n">debug_mode</span><span class="p">,</span>
    <span class="n">DebugMode</span><span class="o">.</span><span class="n">log_tensor_hashes</span><span class="p">(</span>
        <span class="n">hash_fn</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;norm&quot;</span><span class="p">],</span> <span class="c1"># this is the default</span>
        <span class="n">hash_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">result</span></a> <span class="o">=</span> <span class="n">run_once</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DebugMode output with more metadata:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">debug_mode</span><span class="o">.</span><span class="n">debug_string</span><span class="p">(</span><span class="n">show_stack_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DebugMode output with more metadata:
    # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:59 in run_once, code: x = torch.randn(8, 8)
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t$0: f32[8, 8]  # {&#39;hash&#39;: (51.00151962041855,)}

    # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:60 in run_once, code: y = torch.randn(8, 8)
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t$1: f32[8, 8]  # {&#39;hash&#39;: (53.89346334710717,)}

    # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:61 in run_once, code: return torch.mm(torch.relu(x), y)
    aten::relu(t$0: f32[8, 8])  -&gt;  t$2: f32[8, 8]  # {&#39;input_hash&#39;: (((51.00151962041855,),), {}), &#39;hash&#39;: (24.26631812006235,)}
    aten::mm(t$2: f32[8, 8], t$1: f32[8, 8])  -&gt;  t$3: f32[8, 8]  # {&#39;input_hash&#39;: (((24.26631812006235,), (53.89346334710717,)), {}), &#39;hash&#39;: (95.1554913111031,)}
</pre></div>
</div>
<p>Each line follows <code class="docutils literal notranslate"><span class="pre">op(args)</span> <span class="pre">-&gt;</span> <span class="pre">outputs</span></code>. When <code class="docutils literal notranslate"><span class="pre">record_ids</span></code> is enabled,
tensors are suffixed with <code class="docutils literal notranslate"><span class="pre">$&lt;id&gt;</span></code> and DTensors are labeled <code class="docutils literal notranslate"><span class="pre">dt</span></code>.</p>
</section>
<section id="log-triton-kernels">
<h2>Log Triton kernels<a class="headerlink" href="#log-triton-kernels" title="Link to this heading">#</a></h2>
<p>Though Triton kernels are not dispatched, DebugMode has custom logic that logs their inputs and outputs.</p>
<p>Inductor-generated Triton kernels show up with a <code class="docutils literal notranslate"><span class="pre">[triton]</span></code> prefix.
Pre/post hash annotations report buffer hashes around each kernel call, which
is helpful when isolating incorrect kernels.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.mm.html#torch.mm" title="torch.mm" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">mm</span></a><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">),</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span><span class="o">.</span><span class="n">T</span></a><span class="p">)</span>

<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="p">(</span>
    <span class="n">DebugMode</span><span class="p">(</span><span class="n">record_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">debug_mode</span><span class="p">,</span>
    <span class="n">DebugMode</span><span class="o">.</span><span class="n">log_tensor_hashes</span><span class="p">(</span>
        <span class="n">hash_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">a</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">f</span><span class="p">)(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Triton in DebugMode logs:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">debug_mode</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:321: UserWarning:

TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision(&#39;high&#39;)` for better performance.

Triton in DebugMode logs:
    aten::_to_copy(t: f32[3, 3], dtype=torch.float64)  -&gt;  t: f64[3, 3]  # {&#39;input_hash&#39;: ((9.35049245133996,), {&#39;dtype&#39;: None}), &#39;hash&#39;: 9.35049245133996}
    aten::linalg_vector_norm(t: f64[3, 3], 1)  -&gt;  t: f64[]  # {&#39;input_hash&#39;: ((9.35049245133996, None), {}), &#39;hash&#39;: 9.35049245133996}
    aten::_local_scalar_dense(t: f64[])  -&gt;  9.35049245133996  # {&#39;input_hash&#39;: ((9.35049245133996,), {}), &#39;hash&#39;: None}
    aten::_to_copy(t: f32[3, 3], dtype=torch.float64)  -&gt;  t: f64[3, 3]  # {&#39;input_hash&#39;: ((7.48245083540678,), {&#39;dtype&#39;: None}), &#39;hash&#39;: 7.48245083540678}
    aten::linalg_vector_norm(t: f64[3, 3], 1)  -&gt;  t: f64[]  # {&#39;input_hash&#39;: ((7.48245083540678, None), {}), &#39;hash&#39;: 7.48245083540678}
    aten::_local_scalar_dense(t: f64[])  -&gt;  7.48245083540678  # {&#39;input_hash&#39;: ((7.48245083540678,), {}), &#39;hash&#39;: None}
    [triton] triton_poi_fused_relu_0(in_ptr0=t: f32[3, 3], out_ptr0=t: f32[3, 3], xnumel=9)
    # pre-kernel hashes: {in_ptr0: 9.35049245133996, out_ptr0: 7.48245083540678}
    # post-kernel hashes: {in_ptr0: 9.35049245133996, out_ptr0: 6.005547851324081}

    aten::_to_copy(t: f32[3, 3], dtype=torch.float64)  -&gt;  t: f64[3, 3]  # {&#39;input_hash&#39;: ((9.35049245133996,), {&#39;dtype&#39;: None}), &#39;hash&#39;: 9.35049245133996}
    aten::linalg_vector_norm(t: f64[3, 3], 1)  -&gt;  t: f64[]  # {&#39;input_hash&#39;: ((9.35049245133996, None), {}), &#39;hash&#39;: 9.35049245133996}
    aten::_local_scalar_dense(t: f64[])  -&gt;  9.35049245133996  # {&#39;input_hash&#39;: ((9.35049245133996,), {}), &#39;hash&#39;: None}
    aten::_to_copy(t: f32[3, 3], dtype=torch.float64)  -&gt;  t: f64[3, 3]  # {&#39;input_hash&#39;: ((6.005547851324081,), {&#39;dtype&#39;: None}), &#39;hash&#39;: 6.005547851324081}
    aten::linalg_vector_norm(t: f64[3, 3], 1)  -&gt;  t: f64[]  # {&#39;input_hash&#39;: ((6.005547851324081, None), {}), &#39;hash&#39;: 6.005547851324081}
    aten::_local_scalar_dense(t: f64[])  -&gt;  6.005547851324081  # {&#39;input_hash&#39;: ((6.005547851324081,), {}), &#39;hash&#39;: None}
    aten::mm.out(t: f32[3, 3], t: f32[3, 3], out=t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((6.005547851324081, 9.35049245133996), {&#39;out&#39;: 3.6893488147419103e+19}), &#39;hash&#39;: 22.696724396198988}
</pre></div>
</div>
</section>
<section id="numerical-debugging-with-tensor-hashes">
<h2>Numerical debugging with tensor hashes<a class="headerlink" href="#numerical-debugging-with-tensor-hashes" title="Link to this heading">#</a></h2>
<p>If you have numerical divergence between modes, you can use DebugMode to find where the
numerical divergence originates.
In the example below, you can see that all tensor hashes are the same for eager mode and compiled mode.
If any hash is different, then that’s where the numerical divergence is coming from.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">compile_with</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">compile_with</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">compile_with</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">DebugMode</span><span class="p">(</span><span class="n">record_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">dm</span><span class="p">,</span> <span class="n">DebugMode</span><span class="o">.</span><span class="n">log_tensor_hashes</span><span class="p">(</span>
        <span class="n">hash_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">dm_out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dm</span><span class="p">,</span> <span class="n">dm_out</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Toy</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span><span class="o">.</span><span class="n">T</span></a><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),)</span>
<span class="n">dm_eager</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <span class="n">run_model</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Toy</span></a><span class="p">(),</span> <span class="n">inputs</span><span class="p">)</span>
<span class="n">dm_compiled</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <span class="n">run_model</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Toy</span></a><span class="p">(),</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">compile_with</span><span class="o">=</span><span class="s2">&quot;aot_eager&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eager mode:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dm_eager</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Compiled aot_eager mode:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dm_compiled</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eager mode:
    aten::relu(t: f32[4, 4])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((8.48530788347125,), {}), &#39;hash&#39;: 3.3977268151938915}
    aten::permute(t: f32[4, 4], [1, 0])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((8.48530788347125, [None, None]), {}), &#39;hash&#39;: 8.48530788347125}
    aten::mm(t: f32[4, 4], t: f32[4, 4])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((3.3977268151938915, 8.48530788347125), {}), &#39;hash&#39;: 8.084590770304203}
Compiled aot_eager mode:
    aten::relu(t: f32[4, 4])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((8.48530788347125,), {}), &#39;hash&#39;: 3.3977268151938915}
    aten::permute(t: f32[4, 4], [1, 0])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((8.48530788347125, [None, None]), {}), &#39;hash&#39;: 8.48530788347125}
    aten::mm(t: f32[4, 4], t: f32[4, 4])  -&gt;  t: f32[4, 4]  # {&#39;input_hash&#39;: ((3.3977268151938915, 8.48530788347125), {}), &#39;hash&#39;: 8.084590770304203}
</pre></div>
</div>
<p>Now let’s look at an example where the tensor hashes are different.
I intentionally wrote a wrong decomposition that decomposes cosine to sin.
This will cause numerical divergence.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._dynamo.backends.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">aot_autograd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch._dynamo.backends.debugging</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_nop_func</span>

<span class="k">def</span><span class="w"> </span><span class="nf">wrong_decomp</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>

<span class="n">decomp_table</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">decomp_table</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">cos</span><span class="o">.</span><span class="n">default</span><span class="p">]</span> <span class="o">=</span> <span class="n">wrong_decomp</span>

<span class="n">backend</span> <span class="o">=</span> <span class="n">aot_autograd</span><span class="p">(</span>
    <span class="n">fw_compiler</span><span class="o">=</span><span class="n">get_nop_func</span><span class="p">(),</span>
    <span class="n">bw_compiler</span><span class="o">=</span><span class="n">get_nop_func</span><span class="p">(),</span>
    <span class="n">decompositions</span><span class="o">=</span><span class="n">decomp_table</span>
<span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
    <span class="n">z</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">z</span>

<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">with</span> <span class="n">DebugMode</span><span class="p">(</span><span class="n">record_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">dm_eager</span><span class="p">,</span> <span class="n">DebugMode</span><span class="o">.</span><span class="n">log_tensor_hashes</span><span class="p">(</span>
    <span class="n">hash_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">f</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>

<span class="k">with</span> <span class="n">DebugMode</span><span class="p">(</span><span class="n">record_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">dm_compiled</span><span class="p">,</span> <span class="n">DebugMode</span><span class="o">.</span><span class="n">log_tensor_hashes</span><span class="p">(</span>
    <span class="n">hash_inputs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">)(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Eager:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dm_eager</span><span class="o">.</span><span class="n">debug_string</span><span class="p">(</span><span class="n">show_stack_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Compiled with wrong decomposition:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dm_compiled</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Eager:
    aten::relu(t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((5.864226654171944,), {}), &#39;hash&#39;: 1.867107793688774}
    aten::cos(t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((5.864226654171944,), {}), &#39;hash&#39;: 6.723573297262192}
    aten::add.Tensor(t: f32[3, 3], t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((1.867107793688774, 6.723573297262192), {}), &#39;hash&#39;: 8.590681225061417}

Compiled with wrong decomposition:
    aten::relu(t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((5.864226654171944,), {}), &#39;hash&#39;: 1.867107793688774}
    aten::sin(t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((5.864226654171944,), {}), &#39;hash&#39;: 5.080392405390739}
    aten::add.Tensor(t: f32[3, 3], t: f32[3, 3])  -&gt;  t: f32[3, 3]  # {&#39;input_hash&#39;: ((1.867107793688774, 5.080392405390739), {}), &#39;hash&#39;: 6.947500139474869}
</pre></div>
</div>
<p>In the eager log, we have <code class="docutils literal notranslate"><span class="pre">aten::cos</span></code>, but in the compiled log, we have <code class="docutils literal notranslate"><span class="pre">aten::sin</span></code>.
Moreover, the output hash is different between eager and compiled mode.
Diffing the two logs would show that the first numerical divergence shows up in the <code class="docutils literal notranslate"><span class="pre">aten::cos</span></code> call.</p>
</section>
<section id="custom-dispatch-hooks">
<h2>Custom dispatch hooks<a class="headerlink" href="#custom-dispatch-hooks" title="Link to this heading">#</a></h2>
<p>Hooks allow you to annotate each call with custom metadata such as GPU memory usage. <code class="docutils literal notranslate"><span class="pre">log_hook</span></code> returns a mapping
that is rendered inline with the debug string.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">MB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mf">1024.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">memory_hook</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">result</span></a><span class="p">):</span>
    <span class="n">mem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="n">MB</span> <span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="n">peak</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="n">MB</span> <span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="mf">0.0</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">()</span> <span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available" title="torch.cuda.is_available" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;mem&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mem</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">,</span> <span class="s2">&quot;peak&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">peak</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> MB&quot;</span><span class="p">}</span>

<span class="k">with</span> <span class="p">(</span>
    <span class="n">DebugMode</span><span class="p">()</span> <span class="k">as</span> <span class="n">dm</span><span class="p">,</span>
    <span class="n">DebugMode</span><span class="o">.</span><span class="n">dispatch_hooks</span><span class="p">(</span><span class="n">log_hook</span><span class="o">=</span><span class="n">memory_hook</span><span class="p">),</span>
<span class="p">):</span>
    <span class="n">run_once</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DebugMode output with memory usage:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dm</span><span class="o">.</span><span class="n">debug_string</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DebugMode output with memory usage:
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t: f32[8, 8]  # {&#39;mem&#39;: &#39;8.125 MB&#39;, &#39;peak&#39;: &#39;14.128 MB&#39;}
    aten::randn([8, 8], device=cpu, pin_memory=False)  -&gt;  t: f32[8, 8]  # {&#39;mem&#39;: &#39;8.125 MB&#39;, &#39;peak&#39;: &#39;8.125 MB&#39;}
    aten::relu(t: f32[8, 8])  -&gt;  t: f32[8, 8]  # {&#39;mem&#39;: &#39;8.125 MB&#39;, &#39;peak&#39;: &#39;8.125 MB&#39;}
    aten::mm(t: f32[8, 8], t: f32[8, 8])  -&gt;  t: f32[8, 8]  # {&#39;mem&#39;: &#39;8.125 MB&#39;, &#39;peak&#39;: &#39;8.125 MB&#39;}
</pre></div>
</div>
</section>
<section id="module-boundaries">
<h2>Module boundaries<a class="headerlink" href="#module-boundaries" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">record_nn_module=True</span></code> inserts <code class="docutils literal notranslate"><span class="pre">[nn.Mod]</span></code> markers that show which
module executed each set of operations. As of PyTorch 2.10 it only works in eager mode,
but support for compiled modes is under development.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">l2</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">))</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Bar</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">abc</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Foo</span></a><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xyz</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">xyz</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">abc</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">x</span></a><span class="p">))</span>

<span class="n">mod</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">Bar</span></a><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inp</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">with</span> <span class="n">DebugMode</span><span class="p">(</span><span class="n">record_nn_module</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">record_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">debug_mode</span><span class="p">:</span>
    <a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">inp</span></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DebugMode output with stack traces and module boundaries:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">debug_mode</span><span class="o">.</span><span class="n">debug_string</span><span class="p">(</span><span class="n">show_stack_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DebugMode output with stack traces and module boundaries:
  [nn.Mod] Bar
    [nn.Mod] Bar.abc
      [nn.Mod] Bar.abc.l1
          aten::t(t: f32[4, 4])
          aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4])
      [nn.Mod] Bar.abc.l2
          aten::t(t: f32[4, 4])
          aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4])
    [nn.Mod] Bar.xyz
        aten::t(t: f32[4, 4])
        aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4])
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this tutorial, we saw how DebugMode gives you a lightweight, runtime-only
view of what PyTorch actually executed, whether you are running eager code or
compiled graphs. By layering tensor hashing, Triton logging, and custom
dispatch hooks you can quickly track down numerical differences. This is
especially helpful in debugging bit-wise equivalence between runs.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 2.469 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-debug-mode-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e375168fa13eded0a0693eff61b3e027/debug_mode_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">debug_mode_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7f7fa85318a98807950265add8370195/debug_mode_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">debug_mode_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/e37ca59ecb52d3916829ab3a6d9881a7/debug_mode_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">debug_mode_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="distributed_async_checkpoint_recipe.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Asynchronous Saving with Distributed Checkpoint (DCP)</p>
      </div>
    </a>
    <a class="right-next"
       href="../unstable_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Unstable</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="distributed_async_checkpoint_recipe.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Asynchronous Saving with Distributed Checkpoint (DCP)</p>
      </div>
    </a>
    <a class="right-next"
       href="../unstable_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Unstable</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-start">Quick start</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-more-metadata">Getting more metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#log-triton-kernels">Log Triton kernels</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#numerical-debugging-with-tensor-hashes">Numerical debugging with tensor hashes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-dispatch-hooks">Custom dispatch hooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#module-boundaries">Module boundaries</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "DebugMode: Recording Dispatched Operations and Numerical Debugging",
       "headline": "DebugMode: Recording Dispatched Operations and Numerical Debugging",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/recipes/debug_mode_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. DebugMode: Recording Dispatched Operations and Numerical Debugging# Authors: Pian Pawakapan, Shangdi Yu What you will learn How to capture dispatched ops for eager and torch.compile runs How to use tensor hashes and stack traces in DebugMode to pinpoint numerical divergence Prerequisites PyTorch 2.10 or later Overview# DebugMode (torch.utils._debug_mode.DebugMode) is a TorchDispatchMode that intercepts PyTorch runtime calls and emits a hierarchical log of operations. It is particularly useful when you need to understand what actually runs, both in eager mode and under torch.compile or when you need to pinpoint numerical divergence between two runs. Key capabilities: Runtime logging \u2013 Records dispatched operations and TorchInductor compiled Triton kernels. Tensor hashing \u2013 Attaches deterministic hashes to inputs/outputs to enable diffing runs to locate numerical divergences. Dispatch hooks \u2013 Allows registration of custom hooks to annotate calls Note This recipe describes a prototype feature. Prototype features are typically at an early stage for feedback and testing and are subject to change. Quick start# The snippet below captures a small eager workload and prints the debug string: from torch._inductor.decomposition import decomps_to_exclude import torch from torch.utils._debug_mode import DebugMode def run_once(): x = torch.randn(8, 8) y = torch.randn(8, 8) return torch.mm(torch.relu(x), y) with DebugMode() as debug_mode: out = run_once() print(\"DebugMode output:\") print(debug_mode.debug_string()) DebugMode output: aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t: f32[8, 8] aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t: f32[8, 8] aten::relu(t: f32[8, 8]) -\u003e t: f32[8, 8] aten::mm(t: f32[8, 8], t: f32[8, 8]) -\u003e t: f32[8, 8] Getting more metadata# For most investigations, you\u2019ll want to enable stack traces, tensor IDs, and tensor hashing. These features provide metadata to correlate operations back to model code. DebugMode.log_tensor_hashes decorates the log with hashes for every call. The hash_tensor hash function uses torch.hash_tensor, which returns 0 for tensors whose elements are all the same. The norm hash function uses norm with p=1. With both these functions, especially norm, tensor closeness in numerics is related to hash closeness, so it\u2019s rather interpretable. The default hash_fn is norm. with ( DebugMode( # record_stack_trace is only supported for eager in pytorch 2.10 record_stack_trace=True, record_ids=True, ) as debug_mode, DebugMode.log_tensor_hashes( hash_fn=[\"norm\"], # this is the default hash_inputs=True, ), ): result = run_once() print(\"DebugMode output with more metadata:\") print( debug_mode.debug_string(show_stack_trace=True) ) DebugMode output with more metadata: # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:59 in run_once, code: x = torch.randn(8, 8) aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t$0: f32[8, 8] # {\u0027hash\u0027: (51.00151962041855,)} # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:60 in run_once, code: y = torch.randn(8, 8) aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t$1: f32[8, 8] # {\u0027hash\u0027: (53.89346334710717,)} # File: /var/lib/workspace/recipes_source/debug_mode_tutorial.py:61 in run_once, code: return torch.mm(torch.relu(x), y) aten::relu(t$0: f32[8, 8]) -\u003e t$2: f32[8, 8] # {\u0027input_hash\u0027: (((51.00151962041855,),), {}), \u0027hash\u0027: (24.26631812006235,)} aten::mm(t$2: f32[8, 8], t$1: f32[8, 8]) -\u003e t$3: f32[8, 8] # {\u0027input_hash\u0027: (((24.26631812006235,), (53.89346334710717,)), {}), \u0027hash\u0027: (95.1554913111031,)} Each line follows op(args) -\u003e outputs. When record_ids is enabled, tensors are suffixed with $\u003cid\u003e and DTensors are labeled dt. Log Triton kernels# Though Triton kernels are not dispatched, DebugMode has custom logic that logs their inputs and outputs. Inductor-generated Triton kernels show up with a [triton] prefix. Pre/post hash annotations report buffer hashes around each kernel call, which is helpful when isolating incorrect kernels. def f(x): return torch.mm(torch.relu(x), x.T) x = torch.randn(3, 3, device=\"cuda\") with ( DebugMode(record_output=True) as debug_mode, DebugMode.log_tensor_hashes( hash_inputs=True, ) ): a = torch.compile(f)(x) print(\"Triton in DebugMode logs:\") print(debug_mode.debug_string()) /usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:321: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision(\u0027high\u0027)` for better performance. Triton in DebugMode logs: aten::_to_copy(t: f32[3, 3], dtype=torch.float64) -\u003e t: f64[3, 3] # {\u0027input_hash\u0027: ((9.35049245133996,), {\u0027dtype\u0027: None}), \u0027hash\u0027: 9.35049245133996} aten::linalg_vector_norm(t: f64[3, 3], 1) -\u003e t: f64[] # {\u0027input_hash\u0027: ((9.35049245133996, None), {}), \u0027hash\u0027: 9.35049245133996} aten::_local_scalar_dense(t: f64[]) -\u003e 9.35049245133996 # {\u0027input_hash\u0027: ((9.35049245133996,), {}), \u0027hash\u0027: None} aten::_to_copy(t: f32[3, 3], dtype=torch.float64) -\u003e t: f64[3, 3] # {\u0027input_hash\u0027: ((7.48245083540678,), {\u0027dtype\u0027: None}), \u0027hash\u0027: 7.48245083540678} aten::linalg_vector_norm(t: f64[3, 3], 1) -\u003e t: f64[] # {\u0027input_hash\u0027: ((7.48245083540678, None), {}), \u0027hash\u0027: 7.48245083540678} aten::_local_scalar_dense(t: f64[]) -\u003e 7.48245083540678 # {\u0027input_hash\u0027: ((7.48245083540678,), {}), \u0027hash\u0027: None} [triton] triton_poi_fused_relu_0(in_ptr0=t: f32[3, 3], out_ptr0=t: f32[3, 3], xnumel=9) # pre-kernel hashes: {in_ptr0: 9.35049245133996, out_ptr0: 7.48245083540678} # post-kernel hashes: {in_ptr0: 9.35049245133996, out_ptr0: 6.005547851324081} aten::_to_copy(t: f32[3, 3], dtype=torch.float64) -\u003e t: f64[3, 3] # {\u0027input_hash\u0027: ((9.35049245133996,), {\u0027dtype\u0027: None}), \u0027hash\u0027: 9.35049245133996} aten::linalg_vector_norm(t: f64[3, 3], 1) -\u003e t: f64[] # {\u0027input_hash\u0027: ((9.35049245133996, None), {}), \u0027hash\u0027: 9.35049245133996} aten::_local_scalar_dense(t: f64[]) -\u003e 9.35049245133996 # {\u0027input_hash\u0027: ((9.35049245133996,), {}), \u0027hash\u0027: None} aten::_to_copy(t: f32[3, 3], dtype=torch.float64) -\u003e t: f64[3, 3] # {\u0027input_hash\u0027: ((6.005547851324081,), {\u0027dtype\u0027: None}), \u0027hash\u0027: 6.005547851324081} aten::linalg_vector_norm(t: f64[3, 3], 1) -\u003e t: f64[] # {\u0027input_hash\u0027: ((6.005547851324081, None), {}), \u0027hash\u0027: 6.005547851324081} aten::_local_scalar_dense(t: f64[]) -\u003e 6.005547851324081 # {\u0027input_hash\u0027: ((6.005547851324081,), {}), \u0027hash\u0027: None} aten::mm.out(t: f32[3, 3], t: f32[3, 3], out=t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((6.005547851324081, 9.35049245133996), {\u0027out\u0027: 3.6893488147419103e+19}), \u0027hash\u0027: 22.696724396198988} Numerical debugging with tensor hashes# If you have numerical divergence between modes, you can use DebugMode to find where the numerical divergence originates. In the example below, you can see that all tensor hashes are the same for eager mode and compiled mode. If any hash is different, then that\u2019s where the numerical divergence is coming from. def run_model(model, data, *, compile_with=None): if compile_with is not None: model = torch.compile(model, backend=compile_with) with DebugMode(record_output=True) as dm, DebugMode.log_tensor_hashes( hash_inputs=True, ): dm_out = model(*data) return dm, dm_out class Toy(torch.nn.Module): def forward(self, x): return torch.relu(x).mm(x.T) inputs = (torch.randn(4, 4),) dm_eager, _ = run_model(Toy(), inputs) dm_compiled, _ = run_model(Toy(), inputs, compile_with=\"aot_eager\") print(\"Eager mode:\") print(dm_eager.debug_string()) print(\"Compiled aot_eager mode:\") print(dm_compiled.debug_string()) Eager mode: aten::relu(t: f32[4, 4]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((8.48530788347125,), {}), \u0027hash\u0027: 3.3977268151938915} aten::permute(t: f32[4, 4], [1, 0]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((8.48530788347125, [None, None]), {}), \u0027hash\u0027: 8.48530788347125} aten::mm(t: f32[4, 4], t: f32[4, 4]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((3.3977268151938915, 8.48530788347125), {}), \u0027hash\u0027: 8.084590770304203} Compiled aot_eager mode: aten::relu(t: f32[4, 4]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((8.48530788347125,), {}), \u0027hash\u0027: 3.3977268151938915} aten::permute(t: f32[4, 4], [1, 0]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((8.48530788347125, [None, None]), {}), \u0027hash\u0027: 8.48530788347125} aten::mm(t: f32[4, 4], t: f32[4, 4]) -\u003e t: f32[4, 4] # {\u0027input_hash\u0027: ((3.3977268151938915, 8.48530788347125), {}), \u0027hash\u0027: 8.084590770304203} Now let\u2019s look at an example where the tensor hashes are different. I intentionally wrote a wrong decomposition that decomposes cosine to sin. This will cause numerical divergence. from torch._dynamo.backends.common import aot_autograd from torch._dynamo.backends.debugging import get_nop_func def wrong_decomp(x): return torch.sin(x) decomp_table = {} decomp_table[torch.ops.aten.cos.default] = wrong_decomp backend = aot_autograd( fw_compiler=get_nop_func(), bw_compiler=get_nop_func(), decompositions=decomp_table ) def f(x): y = x.relu() z = torch.cos(x) return y + z x = torch.randn(3, 3) with DebugMode(record_output=True) as dm_eager, DebugMode.log_tensor_hashes( hash_inputs=True, ): f(x) with DebugMode(record_output=True) as dm_compiled, DebugMode.log_tensor_hashes( hash_inputs=True, ): torch.compile(f, backend=backend)(x) print(\"Eager:\") print(dm_eager.debug_string(show_stack_trace=True)) print() print(\"Compiled with wrong decomposition:\") print(dm_compiled.debug_string()) Eager: aten::relu(t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((5.864226654171944,), {}), \u0027hash\u0027: 1.867107793688774} aten::cos(t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((5.864226654171944,), {}), \u0027hash\u0027: 6.723573297262192} aten::add.Tensor(t: f32[3, 3], t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((1.867107793688774, 6.723573297262192), {}), \u0027hash\u0027: 8.590681225061417} Compiled with wrong decomposition: aten::relu(t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((5.864226654171944,), {}), \u0027hash\u0027: 1.867107793688774} aten::sin(t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((5.864226654171944,), {}), \u0027hash\u0027: 5.080392405390739} aten::add.Tensor(t: f32[3, 3], t: f32[3, 3]) -\u003e t: f32[3, 3] # {\u0027input_hash\u0027: ((1.867107793688774, 5.080392405390739), {}), \u0027hash\u0027: 6.947500139474869} In the eager log, we have aten::cos, but in the compiled log, we have aten::sin. Moreover, the output hash is different between eager and compiled mode. Diffing the two logs would show that the first numerical divergence shows up in the aten::cos call. Custom dispatch hooks# Hooks allow you to annotate each call with custom metadata such as GPU memory usage. log_hook returns a mapping that is rendered inline with the debug string. MB = 1024 * 1024.0 def memory_hook(func, types, args, kwargs, result): mem = torch.cuda.memory_allocated() / MB if torch.cuda.is_available() else 0.0 peak = torch.cuda.max_memory_allocated() / MB if torch.cuda.is_available() else 0.0 torch.cuda.reset_peak_memory_stats() if torch.cuda.is_available() else None return {\"mem\": f\"{mem:.3f} MB\", \"peak\": f\"{peak:.3f} MB\"} with ( DebugMode() as dm, DebugMode.dispatch_hooks(log_hook=memory_hook), ): run_once() print(\"DebugMode output with memory usage:\") print(dm.debug_string()) DebugMode output with memory usage: aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t: f32[8, 8] # {\u0027mem\u0027: \u00278.125 MB\u0027, \u0027peak\u0027: \u002714.128 MB\u0027} aten::randn([8, 8], device=cpu, pin_memory=False) -\u003e t: f32[8, 8] # {\u0027mem\u0027: \u00278.125 MB\u0027, \u0027peak\u0027: \u00278.125 MB\u0027} aten::relu(t: f32[8, 8]) -\u003e t: f32[8, 8] # {\u0027mem\u0027: \u00278.125 MB\u0027, \u0027peak\u0027: \u00278.125 MB\u0027} aten::mm(t: f32[8, 8], t: f32[8, 8]) -\u003e t: f32[8, 8] # {\u0027mem\u0027: \u00278.125 MB\u0027, \u0027peak\u0027: \u00278.125 MB\u0027} Module boundaries# record_nn_module=True inserts [nn.Mod] markers that show which module executed each set of operations. As of PyTorch 2.10 it only works in eager mode, but support for compiled modes is under development. class Foo(torch.nn.Module): def __init__(self): super().__init__() self.l1 = torch.nn.Linear(4, 4) self.l2 = torch.nn.Linear(4, 4) def forward(self, x): return self.l2(self.l1(x)) class Bar(torch.nn.Module): def __init__(self): super().__init__() self.abc = Foo() self.xyz = torch.nn.Linear(4, 4) def forward(self, x): return self.xyz(self.abc(x)) mod = Bar() inp = torch.randn(4, 4) with DebugMode(record_nn_module=True, record_output=False) as debug_mode: _ = mod(inp) print(\"DebugMode output with stack traces and module boundaries:\") print(debug_mode.debug_string(show_stack_trace=True)) DebugMode output with stack traces and module boundaries: [nn.Mod] Bar [nn.Mod] Bar.abc [nn.Mod] Bar.abc.l1 aten::t(t: f32[4, 4]) aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4]) [nn.Mod] Bar.abc.l2 aten::t(t: f32[4, 4]) aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4]) [nn.Mod] Bar.xyz aten::t(t: f32[4, 4]) aten::addmm(t: f32[4], t: f32[4, 4], t: f32[4, 4]) Conclusion# In this tutorial, we saw how DebugMode gives you a lightweight, runtime-only view of what PyTorch actually executed, whether you are running eager code or compiled graphs. By layering tensor hashing, Triton logging, and custom dispatch hooks you can quickly track down numerical differences. This is especially helpful in debugging bit-wise equivalence between runs. Total running time of the script: (0 minutes 2.469 seconds) Download Jupyter notebook: debug_mode_tutorial.ipynb Download Python source code: debug_mode_tutorial.py Download zipped: debug_mode_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/debug_mode_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>