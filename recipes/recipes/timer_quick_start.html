
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>Timer quick start — PyTorch Tutorials 2.8.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css?v=c9393ea6" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/documentation_options.js?v=bffbcef7"></script>
<script src="../../_static/doctools.js?v=888ff710"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=f281be69"></script>
<script src="../../_static/katex.min.js?v=be8ff15f"></script>
<script src="../../_static/auto-render.min.js?v=ad136472"></script>
<script src="../../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'recipes/recipes/timer_quick_start';</script>
<link href="https://pytorch.org/tutorials/recipes/recipes/timer_quick_start.html" rel="canonical"/>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../torch_compile_backend_ipex.html" rel="next" title="Intel® Extension for PyTorch* Backend on Intel® CPUs"/>
<link href="tuning_guide.html" rel="prev" title="Performance Tuning Guide"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<link crossorigin="anonymous" href="/recipes/recipes/timer_quick_start.html" rel="canonical"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function() {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
        window.location.hostname === '0.0.0.0' ||
        window.location.hostname === '127.0.0.1' ||
        window.location.hostname === 'docs.pytorch.org' ||
        window.location.hostname === 'docs-preview.pytorch.org' ||
        window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<link crossorigin="anonymous" href="../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
   new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
   j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
   'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
   j.onload = function() {
     window.dispatchEvent(new Event('gtm_loaded'));
     console.log('GTM loaded successfully');
   };
   })(window,document,'script','dataLayer','GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
   !function(f,b,e,v,n,t,s)
   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
   n.callMethod.apply(n,arguments):n.queue.push(arguments)};
   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
   n.queue=[];t=b.createElement(e);t.async=!0;
   t.src=v;s=b.getElementsByTagName(e)[0];
   s.parentNode.insertBefore(t,s)}(window,document,'script',
   'https://connect.facebook.net/en_US/fbevents.js');
   fbq('init', '243028289693773');
   fbq('track', 'PageView');
</script>
<script>
   document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
 </script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
   function gtag() {
    window.dataLayer.push(arguments);
   }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function(e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport">
<meta content="en" name="docsearch:language">
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</meta></meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/pytorch-domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../../index.html">v2.8.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_backend_ipex.html">Intel® Extension for PyTorch* Backend on Intel® CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda_rpc.html">Direct Device-to-Device Communication with TensorPipe CUDA RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../inference_tuning_on_aws_graviton.html">(Beta) PyTorch Inference Performance Tuning on AWS Graviton Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../amx.html">Leverage Intel® Advanced Matrix Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../foreach_map.html">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../recipes_index.html">Recipes</a></li>
<li aria-current="page" class="breadcrumb-item active">Timer quick start</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../../recipes_index.html" itemprop="item"/>
<meta content="Recipes" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Timer quick start" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
      if((window.location.href.indexOf("/unstable/")!= -1) && (window.location.href.indexOf("/unstable/unstable_index")< 1))
        {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function() {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">recipes/recipes/timer_quick_start</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-recipes-timer-quick-start-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="timer-quick-start">
<span id="sphx-glr-recipes-recipes-timer-quick-start-py"></span><h1>Timer quick start<a class="headerlink" href="#timer-quick-start" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Apr 01, 2021 | Last Updated: Jan 19, 2024 | Last Verified: Not Verified</p>
<p>In this tutorial, we’re going to cover the primary APIs of
<cite>torch.utils.benchmark.Timer</cite>. The PyTorch Timer is based on the
<a class="reference external" href="https://docs.python.org/3/library/timeit.html#timeit.Timer">timeit.Timer</a>
API, with several PyTorch specific modifications. Familiarity with the
builtin <cite>Timer</cite> class is not required for this tutorial, however we assume
that the reader is familiar with the fundamentals of performance work.</p>
<p>For a more comprehensive performance tuning tutorial, see
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">PyTorch Benchmark</a>.</p>
<dl class="simple">
<dt><strong>Contents:</strong></dt><dd><ol class="arabic simple">
<li><p><a class="reference external" href="#defining-a-timer">Defining a Timer</a></p></li>
<li><p><a class="reference external" href="#wall-time-timer-blocked-autorange">Wall time: Timer.blocked_autorange(…)</a></p></li>
<li><p><a class="reference external" href="#c-snippets">C++ snippets</a></p></li>
<li><p><a class="reference external" href="#instruction-counts-timer-collect-callgrind">Instruction counts: Timer.collect_callgrind(…)</a></p></li>
<li><p><a class="reference external" href="#instruction-counts-delving-deeper">Instruction counts: Delving deeper</a></p></li>
<li><p><a class="reference external" href="#a-b-testing-with-callgrind">A/B testing with Callgrind</a></p></li>
<li><p><a class="reference external" href="#wrapping-up">Wrapping up</a></p></li>
<li><p><a class="reference external" href="#footnotes">Footnotes</a></p></li>
</ol>
</dd>
</dl>
<section id="defining-a-timer">
<h2>1. Defining a Timer<a class="headerlink" href="#defining-a-timer" title="Link to this heading">#</a></h2>
<p>A <cite>Timer</cite> serves as a task definition.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a>

<span class="n">timer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="c1"># The computation which will be run in a loop and timed.</span>
    <span class="n">stmt</span><span class="o">=</span><span class="s2">"x * y"</span><span class="p">,</span>

    <span class="c1"># `setup` will be run before calling the measurement loop, and is used to</span>
    <span class="c1"># populate any state which is needed by `stmt`</span>
    <span class="n">setup</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">        x = torch.ones((128,))</span>
<span class="s2">        y = torch.ones((128,))</span>
<span class="s2">    """</span><span class="p">,</span>

    <span class="c1"># Alternatively, ``globals`` can be used to pass variables from the outer scope.</span>
    <span class="c1">#</span>
    <span class="c1">#    globals={</span>
    <span class="c1">#        "x": torch.ones((128,)),</span>
    <span class="c1">#        "y": torch.ones((128,)),</span>
    <span class="c1">#    },</span>

    <span class="c1"># Control the number of threads that PyTorch uses. (Default: 1)</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="wall-time-timer-blocked-autorange">
<h2>2. Wall time: <code class="docutils literal notranslate"><span class="pre">Timer.blocked_autorange(...)</span></code><a class="headerlink" href="#wall-time-timer-blocked-autorange" title="Link to this heading">#</a></h2>
<p>This method will handle details such as picking a suitable number if repeats,
fixing the number of threads, and providing a convenient representation of
the results.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Measurement objects store the results of multiple repeats, and provide</span>
<span class="c1"># various utility features.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.Measurement"><span class="n">Measurement</span></a>

<span class="n">m</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.Measurement"><span class="n">Measurement</span></a> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">(</span><span class="n">min_run_time</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text"><strong>Snippet wall time.</strong></span><a class="headerlink" href="#id1" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7f1929a38ed0&gt;
     x * y
     setup:
       x = torch.ones((128,))
       y = torch.ones((128,))

       Median: 2.34 us
       IQR:    0.07 us (2.31 to 2.38)
       424 measurements, 1000 runs per measurement, 1 thread
</pre></div>
</div>
</div>
</section>
<section id="c-snippets">
<h2>3. C++ snippets<a class="headerlink" href="#c-snippets" title="Link to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <span class="n">Language</span>

<span class="n">cpp_timer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="s2">"x * y;"</span><span class="p">,</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">        auto x = torch::ones({128});</span>
<span class="sd">        auto y = torch::ones({128});</span>
<span class="sd">    """</span><span class="p">,</span>
    <span class="n">language</span><span class="o">=</span><span class="n">Language</span><span class="o">.</span><span class="n">CPP</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cpp_timer</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">(</span><span class="n">min_run_time</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text"><strong>C++ snippet wall time.</strong></span><a class="headerlink" href="#id2" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7f192b019ed0&gt;
     x * y;
     setup:
       auto x = torch::ones({128});
       auto y = torch::ones({128});

       Median: 1.21 us
       IQR:    0.03 us (1.20 to 1.23)
       83 measurements, 10000 runs per measurement, 1 thread
</pre></div>
</div>
</div>
<p>Unsurprisingly, the C++ snippet is both faster and has lower variation.</p>
</section>
<section id="instruction-counts-timer-collect-callgrind">
<h2>4. Instruction counts: <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind(...)</span></code><a class="headerlink" href="#instruction-counts-timer-collect-callgrind" title="Link to this heading">#</a></h2>
<p>For deep dive investigations, <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind</span></code> wraps
<a class="reference external" href="https://valgrind.org/docs/manual/cl-manual.html">Callgrind</a> in order to
collect instruction counts. These are useful as they offer fine grained and
deterministic (or very low noise in the case of Python) insights into how a
snippet is run.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.CallgrindStats"><span class="n">CallgrindStats</span></a><span class="p">,</span> <span class="n">FunctionCounts</span>

<span class="n">stats</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.CallgrindStats"><span class="n">CallgrindStats</span></a> <span class="o">=</span> <span class="n">cpp_timer</span><span class="o">.</span><span class="n">collect_callgrind</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text"><strong>C++ Callgrind stats (summary)</strong></span><a class="headerlink" href="#id3" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7f1929a35850&gt;
     x * y;
     setup:
       auto x = torch::ones({128});
       auto y = torch::ones({128});

                             All          Noisy symbols removed
         Instructions:       563600                     563600
         Baseline:                0                          0
     100 runs per measurement, 1 thread
</pre></div>
</div>
</div>
</section>
<section id="instruction-counts-delving-deeper">
<h2>5. Instruction counts: Delving deeper<a class="headerlink" href="#instruction-counts-delving-deeper" title="Link to this heading">#</a></h2>
<p>The string representation of <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code> is similar to that of
Measurement. <cite>Noisy symbols</cite> are a Python concept (removing calls in the
CPython interpreter which are known to be noisy).</p>
<p>For more detailed analysis, however, we will want to look at specific calls.
<code class="docutils literal notranslate"><span class="pre">CallgrindStats.stats()</span></code> returns a <code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code> object to make this easier.
Conceptually, <code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code> can be thought of as a tuple of pairs with some
utility methods, where each pair is <cite>(number of instructions, file path and
function name)</cite>.</p>
<dl class="simple">
<dt>A note on paths:</dt><dd><p>One generally doesn’t care about absolute path. For instance, the full path
and function name for a multiply call is something like:</p>
</dd>
</dl>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>/the/prefix/to/your/pytorch/install/dir/pytorch/build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul<span class="o">(</span>at::Tensor<span class="w"> </span>const<span class="p">&amp;</span><span class="o">)</span><span class="w"> </span>const<span class="w"> </span><span class="o">[</span>/the/path/to/your/conda/install/miniconda3/envs/ab_ref/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so<span class="o">]</span>

when<span class="w"> </span><span class="k">in</span><span class="w"> </span>reality,<span class="w"> </span>all<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>information<span class="w"> </span>that<span class="w"> </span>we<span class="err">'</span>re<span class="w"> </span>interested<span class="w"> </span><span class="k">in</span><span class="w"> </span>can<span class="w"> </span>be
represented<span class="w"> </span><span class="k">in</span>:
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul<span class="o">(</span>at::Tensor<span class="w"> </span>const<span class="p">&amp;</span><span class="o">)</span><span class="w"> </span>const

<span class="sb">``</span>CallgrindStats.as_standardized<span class="o">()</span><span class="sb">``</span><span class="w"> </span>makes<span class="w"> </span>a<span class="w"> </span>best<span class="w"> </span>effort<span class="w"> </span>to<span class="w"> </span>strip<span class="w"> </span>low<span class="w"> </span>signal
portions<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>file<span class="w"> </span>path,<span class="w"> </span>as<span class="w"> </span>well<span class="w"> </span>as<span class="w"> </span>the<span class="w"> </span>shared<span class="w"> </span>object<span class="w"> </span>and<span class="w"> </span>is<span class="w"> </span>generally
recommended.
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">inclusive_stats</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">as_standardized</span><span class="p">()</span><span class="o">.</span><span class="n">stats</span><span class="p">(</span><span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inclusive_stats</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text"><strong>C++ Callgrind stats (detailed)</strong></span><a class="headerlink" href="#id4" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192a6dfd90&gt;
       47264  ???:_int_free
       25963  ???:_int_malloc
       19900  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&amp;)
       18000  ???:__tls_get_addr
       13500  ???:malloc
       11300  build/../c10/util/SmallVector.h:a ... (at::TensorIteratorConfig const&amp;)
       10345  ???:_int_memalign
       10000  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&amp;)
        9200  ???:free
        8000  build/../c10/util/SmallVector.h:a ... IteratorBase::get_strides() const

     Total: 173472
</pre></div>
</div>
</div>
<p>That’s still quite a lot to digest. Let’s use the <cite>FunctionCounts.transform</cite>
method to trim some of the function path, and discard the function called.
When we do, the counts of any collisions (e.g. <cite>foo.h:a()</cite> and <cite>foo.h:b()</cite>
will both map to <cite>foo.h</cite>) will be added together.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="k">def</span><span class="w"> </span><span class="nf">group_by_file</span><span class="p">(</span><span class="n">fn_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">fn_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"???"</span><span class="p">):</span>
        <span class="n">fn_dir</span><span class="p">,</span> <span class="n">fn_file</span> <span class="o">=</span> <span class="n">fn_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fn_dir</span><span class="p">,</span> <span class="n">fn_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">fn_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">fn_dir</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">"^.*build/../"</span><span class="p">,</span> <span class="s2">""</span><span class="p">,</span> <span class="n">fn_dir</span><span class="p">)</span>
        <span class="n">fn_dir</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">"^.*torch/"</span><span class="p">,</span> <span class="s2">"torch/"</span><span class="p">,</span> <span class="n">fn_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">fn_dir</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">fn_file</span><span class="si">}</span><span class="s2">"</span>

<span class="nb">print</span><span class="p">(</span><span class="n">inclusive_stats</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">group_by_file</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text"><strong>Callgrind stats (condensed)</strong></span><a class="headerlink" href="#id5" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750&gt;
       118200  aten/src/ATen   TensorIterator.cpp
        65000  c10/util        SmallVector.h
        47264  ???             _int_free
        25963  ???             _int_malloc
        20900  c10/util        intrusive_ptr.h
        18000  ???             __tls_get_addr
        15900  c10/core        TensorImpl.h
        15100  c10/core        CPUAllocator.cpp
        13500  ???             malloc
        12500  c10/core        TensorImpl.cpp

     Total: 352327
</pre></div>
</div>
</div>
</section>
<section id="a-b-testing-with-callgrind">
<h2>6. A/B testing with <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code><a class="headerlink" href="#a-b-testing-with-callgrind" title="Link to this heading">#</a></h2>
<p>One of the most useful features of instruction counts is they allow fine
grained comparison of computation, which is critical when analyzing
performance.</p>
<p>To see this in action, lets compare our multiplication of two size 128
Tensors with a {128} x {1} multiplication, which will broadcast the second
Tensor:</p>
<blockquote>
<div><p>result = {a0 * b0, a1 * b0, …, a127 * b0}</p>
</div></blockquote>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">broadcasting_stats</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="s2">"x * y;"</span><span class="p">,</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">        auto x = torch::ones({128});</span>
<span class="sd">        auto y = torch::ones({1});</span>
<span class="sd">    """</span><span class="p">,</span>
    <span class="n">language</span><span class="o">=</span><span class="n">Language</span><span class="o">.</span><span class="n">CPP</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">collect_callgrind</span><span class="p">()</span><span class="o">.</span><span class="n">as_standardized</span><span class="p">()</span><span class="o">.</span><span class="n">stats</span><span class="p">(</span><span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Often we want to A/B test two different environments. (e.g. testing a PR, or
experimenting with compile flags.) This is quite simple, as <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code>,
<code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code>, and Measurement are all pickleable. Simply save measurements
from each environment, and load them in a single process for analysis.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>

<span class="c1"># Let's round trip `broadcasting_stats` just to show that we can.</span>
<span class="n">broadcasting_stats</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">broadcasting_stats</span><span class="p">))</span>


<span class="c1"># And now to diff the two tasks:</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">broadcasting_stats</span> <span class="o">-</span> <span class="n">inclusive_stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">extract_fn_name</span><span class="p">(</span><span class="n">fn</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Trim everything except the function name."""</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="s2">":"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\(.+\)"</span><span class="p">,</span> <span class="s2">"(...)"</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>

<span class="c1"># We use `.transform` to make the diff readable:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">delta</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">extract_fn_name</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text"><strong>Instruction count delta</strong></span><a class="headerlink" href="#id6" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750&gt;
         17600  at::TensorIteratorBase::compute_strides(...)
         12700  at::TensorIteratorBase::allocate_or_resize_outputs()
         10200  c10::SmallVectorImpl&lt;long&gt;::operator=(...)
          7400  at::infer_size(...)
          6200  at::TensorIteratorBase::invert_perm(...) const
          6064  _int_free
          5100  at::TensorIteratorBase::reorder_dimensions()
          4300  malloc
          4300  at::TensorIteratorBase::compatible_stride(...) const
           ...
           -28  _int_memalign
          -100  c10::impl::check_tensor_options_and_extract_memory_format(...)
          -300  __memcmp_avx2_movbe
          -400  at::detail::empty_cpu(...)
         -1100  at::TensorIteratorBase::numel() const
         -1300  void at::native::(...)
         -2400  c10::TensorImpl::is_contiguous(...) const
         -6100  at::TensorIteratorBase::compute_fast_setup_type(...)
        -22600  at::TensorIteratorBase::fast_set_up(...)

     Total: 58091
</pre></div>
</div>
</div>
<p>So the broadcasting version takes an extra 580 instructions per call (recall
that we’re collecting 100 runs per sample), or about 10%. There are quite a
few <code class="docutils literal notranslate"><span class="pre">TensorIterator</span></code> calls, so lets drill down to those. <code class="docutils literal notranslate"><span class="pre">FunctionCounts.filter</span></code>
makes this easy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">delta</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">extract_fn_name</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">fn</span><span class="p">:</span> <span class="s2">"TensorIterator"</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text"><strong>Instruction count delta (filter)</strong></span><a class="headerlink" href="#id7" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f19299544d0&gt;
         17600  at::TensorIteratorBase::compute_strides(...)
         12700  at::TensorIteratorBase::allocate_or_resize_outputs()
          6200  at::TensorIteratorBase::invert_perm(...) const
          5100  at::TensorIteratorBase::reorder_dimensions()
          4300  at::TensorIteratorBase::compatible_stride(...) const
          4000  at::TensorIteratorBase::compute_shape(...)
          2300  at::TensorIteratorBase::coalesce_dimensions()
          1600  at::TensorIteratorBase::build(...)
         -1100  at::TensorIteratorBase::numel() const
         -6100  at::TensorIteratorBase::compute_fast_setup_type(...)
        -22600  at::TensorIteratorBase::fast_set_up(...)

     Total: 24000
</pre></div>
</div>
</div>
<p>This makes plain what is going on: there is a fast path in <code class="docutils literal notranslate"><span class="pre">TensorIterator</span></code>
setup, but in the {128} x {1} case we miss it and have to do a more general
analysis which is more expensive. The most prominent call omitted by the
filter is <cite>c10::SmallVectorImpl&lt;long&gt;::operator=(…)</cite>, which is also part
of the more general setup.</p>
</section>
<section id="wrapping-up">
<h2>7. Wrapping up<a class="headerlink" href="#wrapping-up" title="Link to this heading">#</a></h2>
<p>In summary, use <cite>Timer.blocked_autorange</cite> to collect wall times. If timing
variation is too high, increase <cite>min_run_time</cite>, or move to C++ snippets if
convenient.</p>
<p>For fine grained analysis, use <cite>Timer.collect_callgrind</cite> to measure
instruction counts and <cite>FunctionCounts.(__add__ / __sub__ / transform / filter)</cite>
to slice-and-dice them.</p>
</section>
<section id="footnotes">
<h2>8. Footnotes<a class="headerlink" href="#footnotes" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Implied <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">torch</span></code></dt><dd><p>If <cite>globals</cite> does not contain “torch”, Timer will automatically
populate it. This means that <code class="docutils literal notranslate"><span class="pre">Timer("torch.empty(())")</span></code> will work.
(Though other imports should be placed in <cite>setup</cite>,
e.g. <code class="docutils literal notranslate"><span class="pre">Timer("np.zeros(())",</span> <span class="pre">"import</span> <span class="pre">numpy</span> <span class="pre">as</span> <span class="pre">np")</span></code>)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">REL_WITH_DEB_INFO</span></code></dt><dd><p>In order to provide full information about the PyTorch internals which
are executed, <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code> needs access to C++ debug symbols. This is
accomplished by setting <code class="docutils literal notranslate"><span class="pre">REL_WITH_DEB_INFO=1</span></code> when building PyTorch.
Otherwise function calls will be opaque. (The resultant <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code>
will warn if debug symbols are missing.)</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-recipes-timer-quick-start-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c421b7eb91c1baf27a829c1bf3309a42/timer_quick_start.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">timer_quick_start.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c98cce79febbad67b67e99e9aa18a8cf/timer_quick_start.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">timer_quick_start.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a00637bd6fe1ee7bfaa80e7ab5cb1bf4/timer_quick_start.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">timer_quick_start.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="tuning_guide.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Performance Tuning Guide</p>
</div>
</a>
<a class="right-next" href="../torch_compile_backend_ipex.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Intel® Extension for PyTorch* Backend on Intel® CPUs</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="tuning_guide.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Performance Tuning Guide</p>
</div>
</a>
<a class="right-next" href="../torch_compile_backend_ipex.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Intel® Extension for PyTorch* Backend on Intel® CPUs</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-a-timer">1. Defining a Timer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wall-time-timer-blocked-autorange">2. Wall time: <code class="docutils literal notranslate"><span class="pre">Timer.blocked_autorange(...)</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#c-snippets">3. C++ snippets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-counts-timer-collect-callgrind">4. Instruction counts: <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind(...)</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-counts-delving-deeper">5. Instruction counts: Delving deeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-with-callgrind">6. A/B testing with <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">7. Wrapping up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#footnotes">8. Footnotes</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
            hbspt.forms.create({
              region: "na1",
              portalId: "8112310",
              formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
            });
          </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg"><path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg"><path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg"><path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg"><rect fill="currentColor" height="512" rx="0" width="512"></rect><circle cx="142" cy="138" fill="#000" r="37"></circle><path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path></svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg"><path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg"><path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor"></path><path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor"></path></svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
            © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
          </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
      {
         "@context": "https://schema.org",
         "@type": "Article",
         "name": "Timer quick start",
         "headline": "Timer quick start",
         "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
         "url": "/recipes/recipes/timer_quick_start.html",
         "articleBody": "Note Go to the end to download the full example code. Timer quick start# In this tutorial, we\u2019re going to cover the primary APIs of torch.utils.benchmark.Timer. The PyTorch Timer is based on the timeit.Timer API, with several PyTorch specific modifications. Familiarity with the builtin Timer class is not required for this tutorial, however we assume that the reader is familiar with the fundamentals of performance work. For a more comprehensive performance tuning tutorial, see PyTorch Benchmark. Contents: Defining a Timer Wall time: Timer.blocked_autorange(\u2026) C++ snippets Instruction counts: Timer.collect_callgrind(\u2026) Instruction counts: Delving deeper A/B testing with Callgrind Wrapping up Footnotes 1. Defining a Timer# A Timer serves as a task definition. from torch.utils.benchmark import Timer timer = Timer( # The computation which will be run in a loop and timed. stmt=\"x * y\", # `setup` will be run before calling the measurement loop, and is used to # populate any state which is needed by `stmt` setup=\"\"\" x = torch.ones((128,)) y = torch.ones((128,)) \"\"\", # Alternatively, ``globals`` can be used to pass variables from the outer scope. # # globals={ # \"x\": torch.ones((128,)), # \"y\": torch.ones((128,)), # }, # Control the number of threads that PyTorch uses. (Default: 1) num_threads=1, ) 2. Wall time: Timer.blocked_autorange(...)# This method will handle details such as picking a suitable number if repeats, fixing the number of threads, and providing a convenient representation of the results. # Measurement objects store the results of multiple repeats, and provide # various utility features. from torch.utils.benchmark import Measurement m: Measurement = timer.blocked_autorange(min_run_time=1) print(m) Snippet wall time.# \u003ctorch.utils.benchmark.utils.common.Measurement object at 0x7f1929a38ed0\u003e x * y setup: x = torch.ones((128,)) y = torch.ones((128,)) Median: 2.34 us IQR: 0.07 us (2.31 to 2.38) 424 measurements, 1000 runs per measurement, 1 thread 3. C++ snippets# from torch.utils.benchmark import Language cpp_timer = Timer( \"x * y;\", \"\"\" auto x = torch::ones({128}); auto y = torch::ones({128}); \"\"\", language=Language.CPP, ) print(cpp_timer.blocked_autorange(min_run_time=1)) C++ snippet wall time.# \u003ctorch.utils.benchmark.utils.common.Measurement object at 0x7f192b019ed0\u003e x * y; setup: auto x = torch::ones({128}); auto y = torch::ones({128}); Median: 1.21 us IQR: 0.03 us (1.20 to 1.23) 83 measurements, 10000 runs per measurement, 1 thread Unsurprisingly, the C++ snippet is both faster and has lower variation. 4. Instruction counts: Timer.collect_callgrind(...)# For deep dive investigations, Timer.collect_callgrind wraps Callgrind in order to collect instruction counts. These are useful as they offer fine grained and deterministic (or very low noise in the case of Python) insights into how a snippet is run. from torch.utils.benchmark import CallgrindStats, FunctionCounts stats: CallgrindStats = cpp_timer.collect_callgrind() print(stats) C++ Callgrind stats (summary)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7f1929a35850\u003e x * y; setup: auto x = torch::ones({128}); auto y = torch::ones({128}); All Noisy symbols removed Instructions: 563600 563600 Baseline: 0 0 100 runs per measurement, 1 thread 5. Instruction counts: Delving deeper# The string representation of CallgrindStats is similar to that of Measurement. Noisy symbols are a Python concept (removing calls in the CPython interpreter which are known to be noisy). For more detailed analysis, however, we will want to look at specific calls. CallgrindStats.stats() returns a FunctionCounts object to make this easier. Conceptually, FunctionCounts can be thought of as a tuple of pairs with some utility methods, where each pair is (number of instructions, file path and function name). A note on paths:One generally doesn\u2019t care about absolute path. For instance, the full path and function name for a multiply call is something like: /the/prefix/to/your/pytorch/install/dir/pytorch/build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const\u0026) const [/the/path/to/your/conda/install/miniconda3/envs/ab_ref/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so] when in reality, all of the information that we\u0027re interested in can be represented in: build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const\u0026) const ``CallgrindStats.as_standardized()`` makes a best effort to strip low signal portions of the file path, as well as the shared object and is generally recommended. inclusive_stats = stats.as_standardized().stats(inclusive=False) print(inclusive_stats[:10]) C++ Callgrind stats (detailed)# torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192a6dfd90\u003e 47264 ???:_int_free 25963 ???:_int_malloc 19900 build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const\u0026) 18000 ???:__tls_get_addr 13500 ???:malloc 11300 build/../c10/util/SmallVector.h:a ... (at::TensorIteratorConfig const\u0026) 10345 ???:_int_memalign 10000 build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const\u0026) 9200 ???:free 8000 build/../c10/util/SmallVector.h:a ... IteratorBase::get_strides() const Total: 173472 That\u2019s still quite a lot to digest. Let\u2019s use the FunctionCounts.transform method to trim some of the function path, and discard the function called. When we do, the counts of any collisions (e.g. foo.h:a() and foo.h:b() will both map to foo.h) will be added together. import os import re def group_by_file(fn_name: str): if fn_name.startswith(\"???\"): fn_dir, fn_file = fn_name.split(\":\")[:2] else: fn_dir, fn_file = os.path.split(fn_name.split(\":\")[0]) fn_dir = re.sub(\"^.*build/../\", \"\", fn_dir) fn_dir = re.sub(\"^.*torch/\", \"torch/\", fn_dir) return f\"{fn_dir:\u003c15} {fn_file}\" print(inclusive_stats.transform(group_by_file)[:10]) Callgrind stats (condensed)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750\u003e 118200 aten/src/ATen TensorIterator.cpp 65000 c10/util SmallVector.h 47264 ??? _int_free 25963 ??? _int_malloc 20900 c10/util intrusive_ptr.h 18000 ??? __tls_get_addr 15900 c10/core TensorImpl.h 15100 c10/core CPUAllocator.cpp 13500 ??? malloc 12500 c10/core TensorImpl.cpp Total: 352327 6. A/B testing with Callgrind# One of the most useful features of instruction counts is they allow fine grained comparison of computation, which is critical when analyzing performance. To see this in action, lets compare our multiplication of two size 128 Tensors with a {128} x {1} multiplication, which will broadcast the second Tensor: result = {a0 * b0, a1 * b0, \u2026, a127 * b0} broadcasting_stats = Timer( \"x * y;\", \"\"\" auto x = torch::ones({128}); auto y = torch::ones({1}); \"\"\", language=Language.CPP, ).collect_callgrind().as_standardized().stats(inclusive=False) Often we want to A/B test two different environments. (e.g. testing a PR, or experimenting with compile flags.) This is quite simple, as CallgrindStats, FunctionCounts, and Measurement are all pickleable. Simply save measurements from each environment, and load them in a single process for analysis. import pickle # Let\u0027s round trip `broadcasting_stats` just to show that we can. broadcasting_stats = pickle.loads(pickle.dumps(broadcasting_stats)) # And now to diff the two tasks: delta = broadcasting_stats - inclusive_stats def extract_fn_name(fn: str): \"\"\"Trim everything except the function name.\"\"\" fn = \":\".join(fn.split(\":\")[1:]) return re.sub(r\"\\(.+\\)\", \"(...)\", fn) # We use `.transform` to make the diff readable: print(delta.transform(extract_fn_name)) Instruction count delta# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750\u003e 17600 at::TensorIteratorBase::compute_strides(...) 12700 at::TensorIteratorBase::allocate_or_resize_outputs() 10200 c10::SmallVectorImpl\u003clong\u003e::operator=(...) 7400 at::infer_size(...) 6200 at::TensorIteratorBase::invert_perm(...) const 6064 _int_free 5100 at::TensorIteratorBase::reorder_dimensions() 4300 malloc 4300 at::TensorIteratorBase::compatible_stride(...) const ... -28 _int_memalign -100 c10::impl::check_tensor_options_and_extract_memory_format(...) -300 __memcmp_avx2_movbe -400 at::detail::empty_cpu(...) -1100 at::TensorIteratorBase::numel() const -1300 void at::native::(...) -2400 c10::TensorImpl::is_contiguous(...) const -6100 at::TensorIteratorBase::compute_fast_setup_type(...) -22600 at::TensorIteratorBase::fast_set_up(...) Total: 58091 So the broadcasting version takes an extra 580 instructions per call (recall that we\u2019re collecting 100 runs per sample), or about 10%. There are quite a few TensorIterator calls, so lets drill down to those. FunctionCounts.filter makes this easy. print(delta.transform(extract_fn_name).filter(lambda fn: \"TensorIterator\" in fn)) Instruction count delta (filter)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f19299544d0\u003e 17600 at::TensorIteratorBase::compute_strides(...) 12700 at::TensorIteratorBase::allocate_or_resize_outputs() 6200 at::TensorIteratorBase::invert_perm(...) const 5100 at::TensorIteratorBase::reorder_dimensions() 4300 at::TensorIteratorBase::compatible_stride(...) const 4000 at::TensorIteratorBase::compute_shape(...) 2300 at::TensorIteratorBase::coalesce_dimensions() 1600 at::TensorIteratorBase::build(...) -1100 at::TensorIteratorBase::numel() const -6100 at::TensorIteratorBase::compute_fast_setup_type(...) -22600 at::TensorIteratorBase::fast_set_up(...) Total: 24000 This makes plain what is going on: there is a fast path in TensorIterator setup, but in the {128} x {1} case we miss it and have to do a more general analysis which is more expensive. The most prominent call omitted by the filter is c10::SmallVectorImpl\u003clong\u003e::operator=(\u2026), which is also part of the more general setup. 7. Wrapping up# In summary, use Timer.blocked_autorange to collect wall times. If timing variation is too high, increase min_run_time, or move to C++ snippets if convenient. For fine grained analysis, use Timer.collect_callgrind to measure instruction counts and FunctionCounts.(__add__ / __sub__ / transform / filter) to slice-and-dice them. 8. Footnotes# Implied import torchIf globals does not contain \u201ctorch\u201d, Timer will automatically populate it. This means that Timer(\"torch.empty(())\") will work. (Though other imports should be placed in setup, e.g. Timer(\"np.zeros(())\", \"import numpy as np\")) REL_WITH_DEB_INFOIn order to provide full information about the PyTorch internals which are executed, Callgrind needs access to C++ debug symbols. This is accomplished by setting REL_WITH_DEB_INFO=1 when building PyTorch. Otherwise function calls will be opaque. (The resultant CallgrindStats will warn if debug symbols are missing.) Download Jupyter notebook: timer_quick_start.ipynb Download Python source code: timer_quick_start.py Download zipped: timer_quick_start.zip",
         "author": {
           "@type": "Organization",
           "name": "PyTorch Contributors",
           "url": "https://pytorch.org"
         },
         "image": "../../_static/img/pytorch_seo.png",
         "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "/recipes/recipes/timer_quick_start.html"
         },
         "datePublished": "2023-01-01T00:00:00Z",
         "dateModified": "2023-01-01T00:00:00Z"
       }
   </script>
</body>
</body></html>