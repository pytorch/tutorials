
<!DOCTYPE html>

<html data-content_root="../../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>Timer quick start â€” PyTorch Tutorials 2.11.0+cu130 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../../_static/css/theme.css?v=72e443bf" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/documentation_options.js?v=92f158d6"></script>
<script src="../../_static/doctools.js?v=888ff710"></script>
<script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../../_static/copybutton.js?v=f281be69"></script>
<script src="../../_static/katex.min.js?v=be8ff15f"></script>
<script src="../../_static/auto-render.min.js?v=ad136472"></script>
<script src="../../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'recipes/recipes/timer_quick_start';</script>
<link href="https://docs.pytorch.org/tutorials/recipes/recipes/timer_quick_start.html" rel="canonical"/>
<link href="../../genindex.html" rel="index" title="Index"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../zero_redundancy_optimizer.html" rel="next" title="Shard Optimizer States with ZeroRedundancyOptimizer"/>
<link href="tuning_guide.html" rel="prev" title="Performance Tuning Guide"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<!-- LLM/AI Agent: See /llms.txt for comprehensive navigation guidance -->
<!-- Machine-readable LLM metadata -->
<meta content="documentation" name="llm:site-type"/>
<meta content="PyTorch" name="llm:framework"/>
<meta content="Timer quick start - Documentation for PyTorch Tutorials, part of the PyTorch ecosystem." name="llm:description"/>
<meta content="https://docs.pytorch.org/tutorials/llms.txt" name="llm:navigation-file"/>
<meta content="https://docs.pytorch.org/tutorials/sitemap.xml" name="llm:sitemap"/>
<meta content="v2.11.0+cu130" name="llm:version"/>
<meta content="PyTorch Tutorials" name="llm:project"/>
<meta content="documentation" name="llm:page-type"/>
<link href="https://docs.pytorch.org/tutorials/llms.txt" rel="alternate" title="LLM Navigation Guide" type="text/plain"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>
<link crossorigin="anonymous" href="../../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" property="og:image">
<link crossorigin="anonymous" href="../../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="tutorials" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.11.0+cu130');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<meta content="en" name="docsearch:language">
<meta content="Jul 20, 2022" name="docbuild:last-update">
</meta></meta></meta></meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__mobile-logo">
<a class="navbar-brand logo" href="../../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-item desktop-only-version">
<a class="version" href="../../index.html">v2.11.0+cu130</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown more-dropdown">
<div class="nav-item-with-toggle">
<span aria-controls="pst-nav-more-links" aria-expanded="false" class="nav-link more-toggle" role="button" tabindex="0">
            More
          </span>
</div>
<ul class="dropdown-menu" id="pst-nav-more-links">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../recipes_index.html">
                Recipes
              </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable_index.html">
                Unstable
              </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__start">
<div class="navbar-item">
<a class="version" href="../../index.html">v2.11.0+cu130</a>
</div>
</div>
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../intermediate/realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_logs.html">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="benchmark.html">
                  SyntaxError
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with IntelÂ® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/maskedtensor_adagrad.html">
                  Efficiently writing â€œsparseâ€ semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../foreach_map.html">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with IntelÂ® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../debug_mode_tutorial.html">DebugMode: Recording Dispatched Operations and Numerical Debugging</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../../recipes_index.html">Recipes</a></li>
<li aria-current="page" class="breadcrumb-item active">Timer quick start</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">â˜…</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<div id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../../recipes_index.html" itemprop="item"/>
<meta content="Recipes" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Timer quick start" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
    if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
      var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
      document.addEventListener('DOMContentLoaded', function () {
        document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
      });
    }
  </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">recipes/recipes/timer_quick_start</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-recipes-timer-quick-start-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="timer-quick-start">
<span id="sphx-glr-recipes-recipes-timer-quick-start-py"></span><h1>Timer quick start<a class="headerlink" href="#timer-quick-start" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Apr 01, 2021 | Last Updated: Jan 19, 2024 | Last Verified: Not Verified</p>
<p>In this tutorial, weâ€™re going to cover the primary APIs of
<cite>torch.utils.benchmark.Timer</cite>. The PyTorch Timer is based on the
<a class="reference external" href="https://docs.python.org/3/library/timeit.html#timeit.Timer">timeit.Timer</a>
API, with several PyTorch specific modifications. Familiarity with the
builtin <cite>Timer</cite> class is not required for this tutorial, however we assume
that the reader is familiar with the fundamentals of performance work.</p>
<p>For a more comprehensive performance tuning tutorial, see
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">PyTorch Benchmark</a>.</p>
<dl class="simple">
<dt><strong>Contents:</strong></dt><dd><ol class="arabic simple">
<li><p><a class="reference external" href="#defining-a-timer">Defining a Timer</a></p></li>
<li><p><a class="reference external" href="#wall-time-timer-blocked-autorange">Wall time: Timer.blocked_autorange(â€¦)</a></p></li>
<li><p><a class="reference external" href="#c-snippets">C++ snippets</a></p></li>
<li><p><a class="reference external" href="#instruction-counts-timer-collect-callgrind">Instruction counts: Timer.collect_callgrind(â€¦)</a></p></li>
<li><p><a class="reference external" href="#instruction-counts-delving-deeper">Instruction counts: Delving deeper</a></p></li>
<li><p><a class="reference external" href="#a-b-testing-with-callgrind">A/B testing with Callgrind</a></p></li>
<li><p><a class="reference external" href="#wrapping-up">Wrapping up</a></p></li>
<li><p><a class="reference external" href="#footnotes">Footnotes</a></p></li>
</ol>
</dd>
</dl>
<section id="defining-a-timer">
<h2>1. Defining a Timer<a class="headerlink" href="#defining-a-timer" title="Link to this heading">#</a></h2>
<p>A <cite>Timer</cite> serves as a task definition.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a>

<span class="n">timer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="c1"># The computation which will be run in a loop and timed.</span>
    <span class="n">stmt</span><span class="o">=</span><span class="s2">"x * y"</span><span class="p">,</span>

    <span class="c1"># `setup` will be run before calling the measurement loop, and is used to</span>
    <span class="c1"># populate any state which is needed by `stmt`</span>
    <span class="n">setup</span><span class="o">=</span><span class="s2">"""</span>
<span class="s2">        x = torch.ones((128,))</span>
<span class="s2">        y = torch.ones((128,))</span>
<span class="s2">    """</span><span class="p">,</span>

    <span class="c1"># Alternatively, ``globals`` can be used to pass variables from the outer scope.</span>
    <span class="c1">#</span>
    <span class="c1">#    globals={</span>
    <span class="c1">#        "x": torch.ones((128,)),</span>
    <span class="c1">#        "y": torch.ones((128,)),</span>
    <span class="c1">#    },</span>

    <span class="c1"># Control the number of threads that PyTorch uses. (Default: 1)</span>
    <span class="n">num_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="wall-time-timer-blocked-autorange">
<h2>2. Wall time: <code class="docutils literal notranslate"><span class="pre">Timer.blocked_autorange(...)</span></code><a class="headerlink" href="#wall-time-timer-blocked-autorange" title="Link to this heading">#</a></h2>
<p>This method will handle details such as picking a suitable number if repeats,
fixing the number of threads, and providing a convenient representation of
the results.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Measurement objects store the results of multiple repeats, and provide</span>
<span class="c1"># various utility features.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.Measurement"><span class="n">Measurement</span></a>

<span class="n">m</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Measurement" title="torch.utils.benchmark.Measurement"><span class="n">Measurement</span></a> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">(</span><span class="n">min_run_time</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text"><strong>Snippet wall time.</strong></span><a class="headerlink" href="#id1" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7f1929a38ed0&gt;
     x * y
     setup:
       x = torch.ones((128,))
       y = torch.ones((128,))

       Median: 2.34 us
       IQR:    0.07 us (2.31 to 2.38)
       424 measurements, 1000 runs per measurement, 1 thread
</pre></div>
</div>
</div>
</section>
<section id="c-snippets">
<h2>3. C++ snippets<a class="headerlink" href="#c-snippets" title="Link to this heading">#</a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <span class="n">Language</span>

<span class="n">cpp_timer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="s2">"x * y;"</span><span class="p">,</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">        auto x = torch::ones({128});</span>
<span class="sd">        auto y = torch::ones({128});</span>
<span class="sd">    """</span><span class="p">,</span>
    <span class="n">language</span><span class="o">=</span><span class="n">Language</span><span class="o">.</span><span class="n">CPP</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cpp_timer</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">(</span><span class="n">min_run_time</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text"><strong>C++ snippet wall time.</strong></span><a class="headerlink" href="#id2" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.common.Measurement object at 0x7f192b019ed0&gt;
     x * y;
     setup:
       auto x = torch::ones({128});
       auto y = torch::ones({128});

       Median: 1.21 us
       IQR:    0.03 us (1.20 to 1.23)
       83 measurements, 10000 runs per measurement, 1 thread
</pre></div>
</div>
</div>
<p>Unsurprisingly, the C++ snippet is both faster and has lower variation.</p>
</section>
<section id="instruction-counts-timer-collect-callgrind">
<h2>4. Instruction counts: <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind(...)</span></code><a class="headerlink" href="#instruction-counts-timer-collect-callgrind" title="Link to this heading">#</a></h2>
<p>For deep dive investigations, <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind</span></code> wraps
<a class="reference external" href="https://valgrind.org/docs/manual/cl-manual.html">Callgrind</a> in order to
collect instruction counts. These are useful as they offer fine grained and
deterministic (or very low noise in the case of Python) insights into how a
snippet is run.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.CallgrindStats"><span class="n">CallgrindStats</span></a><span class="p">,</span> <span class="n">FunctionCounts</span>

<span class="n">stats</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.CallgrindStats" title="torch.utils.benchmark.CallgrindStats"><span class="n">CallgrindStats</span></a> <span class="o">=</span> <span class="n">cpp_timer</span><span class="o">.</span><span class="n">collect_callgrind</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats</span><span class="p">)</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text"><strong>C++ Callgrind stats (summary)</strong></span><a class="headerlink" href="#id3" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7f1929a35850&gt;
     x * y;
     setup:
       auto x = torch::ones({128});
       auto y = torch::ones({128});

                             All          Noisy symbols removed
         Instructions:       563600                     563600
         Baseline:                0                          0
     100 runs per measurement, 1 thread
</pre></div>
</div>
</div>
</section>
<section id="instruction-counts-delving-deeper">
<h2>5. Instruction counts: Delving deeper<a class="headerlink" href="#instruction-counts-delving-deeper" title="Link to this heading">#</a></h2>
<p>The string representation of <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code> is similar to that of
Measurement. <cite>Noisy symbols</cite> are a Python concept (removing calls in the
CPython interpreter which are known to be noisy).</p>
<p>For more detailed analysis, however, we will want to look at specific calls.
<code class="docutils literal notranslate"><span class="pre">CallgrindStats.stats()</span></code> returns a <code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code> object to make this easier.
Conceptually, <code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code> can be thought of as a tuple of pairs with some
utility methods, where each pair is <cite>(number of instructions, file path and
function name)</cite>.</p>
<dl class="simple">
<dt>A note on paths:</dt><dd><p>One generally doesnâ€™t care about absolute path. For instance, the full path
and function name for a multiply call is something like:</p>
</dd>
</dl>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>/the/prefix/to/your/pytorch/install/dir/pytorch/build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul<span class="o">(</span>at::Tensor<span class="w"> </span>const<span class="p">&amp;</span><span class="o">)</span><span class="w"> </span>const<span class="w"> </span><span class="o">[</span>/the/path/to/your/conda/install/miniconda3/envs/ab_ref/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so<span class="o">]</span>

when<span class="w"> </span><span class="k">in</span><span class="w"> </span>reality,<span class="w"> </span>all<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>information<span class="w"> </span>that<span class="w"> </span>we<span class="err">'</span>re<span class="w"> </span>interested<span class="w"> </span><span class="k">in</span><span class="w"> </span>can<span class="w"> </span>be
represented<span class="w"> </span><span class="k">in</span>:
</pre></div>
</div>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="w"> </span>build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul<span class="o">(</span>at::Tensor<span class="w"> </span>const<span class="p">&amp;</span><span class="o">)</span><span class="w"> </span>const

<span class="sb">``</span>CallgrindStats.as_standardized<span class="o">()</span><span class="sb">``</span><span class="w"> </span>makes<span class="w"> </span>a<span class="w"> </span>best<span class="w"> </span>effort<span class="w"> </span>to<span class="w"> </span>strip<span class="w"> </span>low<span class="w"> </span>signal
portions<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>file<span class="w"> </span>path,<span class="w"> </span>as<span class="w"> </span>well<span class="w"> </span>as<span class="w"> </span>the<span class="w"> </span>shared<span class="w"> </span>object<span class="w"> </span>and<span class="w"> </span>is<span class="w"> </span>generally
recommended.
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">inclusive_stats</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">as_standardized</span><span class="p">()</span><span class="o">.</span><span class="n">stats</span><span class="p">(</span><span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inclusive_stats</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text"><strong>C++ Callgrind stats (detailed)</strong></span><a class="headerlink" href="#id4" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192a6dfd90&gt;
       47264  ???:_int_free
       25963  ???:_int_malloc
       19900  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&amp;)
       18000  ???:__tls_get_addr
       13500  ???:malloc
       11300  build/../c10/util/SmallVector.h:a ... (at::TensorIteratorConfig const&amp;)
       10345  ???:_int_memalign
       10000  build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const&amp;)
        9200  ???:free
        8000  build/../c10/util/SmallVector.h:a ... IteratorBase::get_strides() const

     Total: 173472
</pre></div>
</div>
</div>
<p>Thatâ€™s still quite a lot to digest. Letâ€™s use the <cite>FunctionCounts.transform</cite>
method to trim some of the function path, and discard the function called.
When we do, the counts of any collisions (e.g. <cite>foo.h:a()</cite> and <cite>foo.h:b()</cite>
will both map to <cite>foo.h</cite>) will be added together.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="k">def</span><span class="w"> </span><span class="nf">group_by_file</span><span class="p">(</span><span class="n">fn_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">fn_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"???"</span><span class="p">):</span>
        <span class="n">fn_dir</span><span class="p">,</span> <span class="n">fn_file</span> <span class="o">=</span> <span class="n">fn_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">fn_dir</span><span class="p">,</span> <span class="n">fn_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">fn_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">fn_dir</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">"^.*build/../"</span><span class="p">,</span> <span class="s2">""</span><span class="p">,</span> <span class="n">fn_dir</span><span class="p">)</span>
        <span class="n">fn_dir</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">"^.*torch/"</span><span class="p">,</span> <span class="s2">"torch/"</span><span class="p">,</span> <span class="n">fn_dir</span><span class="p">)</span>

    <span class="k">return</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">fn_dir</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">fn_file</span><span class="si">}</span><span class="s2">"</span>

<span class="nb">print</span><span class="p">(</span><span class="n">inclusive_stats</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">group_by_file</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id5">
<div class="code-block-caption"><span class="caption-text"><strong>Callgrind stats (condensed)</strong></span><a class="headerlink" href="#id5" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750&gt;
       118200  aten/src/ATen   TensorIterator.cpp
        65000  c10/util        SmallVector.h
        47264  ???             _int_free
        25963  ???             _int_malloc
        20900  c10/util        intrusive_ptr.h
        18000  ???             __tls_get_addr
        15900  c10/core        TensorImpl.h
        15100  c10/core        CPUAllocator.cpp
        13500  ???             malloc
        12500  c10/core        TensorImpl.cpp

     Total: 352327
</pre></div>
</div>
</div>
</section>
<section id="a-b-testing-with-callgrind">
<h2>6. A/B testing with <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code><a class="headerlink" href="#a-b-testing-with-callgrind" title="Link to this heading">#</a></h2>
<p>One of the most useful features of instruction counts is they allow fine
grained comparison of computation, which is critical when analyzing
performance.</p>
<p>To see this in action, lets compare our multiplication of two size 128
Tensors with a {128} x {1} multiplication, which will broadcast the second
Tensor:</p>
<blockquote>
<div><p>result = {a0 * b0, a1 * b0, â€¦, a127 * b0}</p>
</div></blockquote>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">broadcasting_stats</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-benchmark sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.Timer"><span class="n">Timer</span></a><span class="p">(</span>
    <span class="s2">"x * y;"</span><span class="p">,</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">        auto x = torch::ones({128});</span>
<span class="sd">        auto y = torch::ones({1});</span>
<span class="sd">    """</span><span class="p">,</span>
    <span class="n">language</span><span class="o">=</span><span class="n">Language</span><span class="o">.</span><span class="n">CPP</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">collect_callgrind</span><span class="p">()</span><span class="o">.</span><span class="n">as_standardized</span><span class="p">()</span><span class="o">.</span><span class="n">stats</span><span class="p">(</span><span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Often we want to A/B test two different environments. (e.g. testing a PR, or
experimenting with compile flags.) This is quite simple, as <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code>,
<code class="docutils literal notranslate"><span class="pre">FunctionCounts</span></code>, and Measurement are all pickleable. Simply save measurements
from each environment, and load them in a single process for analysis.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pickle</span>

<span class="c1"># Let's round trip `broadcasting_stats` just to show that we can.</span>
<span class="n">broadcasting_stats</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">broadcasting_stats</span><span class="p">))</span>


<span class="c1"># And now to diff the two tasks:</span>
<span class="n">delta</span> <span class="o">=</span> <span class="n">broadcasting_stats</span> <span class="o">-</span> <span class="n">inclusive_stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">extract_fn_name</span><span class="p">(</span><span class="n">fn</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Trim everything except the function name."""</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="s2">":"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">":"</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"\(.+\)"</span><span class="p">,</span> <span class="s2">"(...)"</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>

<span class="c1"># We use `.transform` to make the diff readable:</span>
<span class="nb">print</span><span class="p">(</span><span class="n">delta</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">extract_fn_name</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id6">
<div class="code-block-caption"><span class="caption-text"><strong>Instruction count delta</strong></span><a class="headerlink" href="#id6" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750&gt;
         17600  at::TensorIteratorBase::compute_strides(...)
         12700  at::TensorIteratorBase::allocate_or_resize_outputs()
         10200  c10::SmallVectorImpl&lt;long&gt;::operator=(...)
          7400  at::infer_size(...)
          6200  at::TensorIteratorBase::invert_perm(...) const
          6064  _int_free
          5100  at::TensorIteratorBase::reorder_dimensions()
          4300  malloc
          4300  at::TensorIteratorBase::compatible_stride(...) const
           ...
           -28  _int_memalign
          -100  c10::impl::check_tensor_options_and_extract_memory_format(...)
          -300  __memcmp_avx2_movbe
          -400  at::detail::empty_cpu(...)
         -1100  at::TensorIteratorBase::numel() const
         -1300  void at::native::(...)
         -2400  c10::TensorImpl::is_contiguous(...) const
         -6100  at::TensorIteratorBase::compute_fast_setup_type(...)
        -22600  at::TensorIteratorBase::fast_set_up(...)

     Total: 58091
</pre></div>
</div>
</div>
<p>So the broadcasting version takes an extra 580 instructions per call (recall
that weâ€™re collecting 100 runs per sample), or about 10%. There are quite a
few <code class="docutils literal notranslate"><span class="pre">TensorIterator</span></code> calls, so lets drill down to those. <code class="docutils literal notranslate"><span class="pre">FunctionCounts.filter</span></code>
makes this easy.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">delta</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">extract_fn_name</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">fn</span><span class="p">:</span> <span class="s2">"TensorIterator"</span> <span class="ow">in</span> <span class="n">fn</span><span class="p">))</span>
</pre></div>
</div>
<div class="literal-block-wrapper docutils container" id="id7">
<div class="code-block-caption"><span class="caption-text"><strong>Instruction count delta (filter)</strong></span><a class="headerlink" href="#id7" title="Link to this code">#</a></div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     &lt;torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f19299544d0&gt;
         17600  at::TensorIteratorBase::compute_strides(...)
         12700  at::TensorIteratorBase::allocate_or_resize_outputs()
          6200  at::TensorIteratorBase::invert_perm(...) const
          5100  at::TensorIteratorBase::reorder_dimensions()
          4300  at::TensorIteratorBase::compatible_stride(...) const
          4000  at::TensorIteratorBase::compute_shape(...)
          2300  at::TensorIteratorBase::coalesce_dimensions()
          1600  at::TensorIteratorBase::build(...)
         -1100  at::TensorIteratorBase::numel() const
         -6100  at::TensorIteratorBase::compute_fast_setup_type(...)
        -22600  at::TensorIteratorBase::fast_set_up(...)

     Total: 24000
</pre></div>
</div>
</div>
<p>This makes plain what is going on: there is a fast path in <code class="docutils literal notranslate"><span class="pre">TensorIterator</span></code>
setup, but in the {128} x {1} case we miss it and have to do a more general
analysis which is more expensive. The most prominent call omitted by the
filter is <cite>c10::SmallVectorImpl&lt;long&gt;::operator=(â€¦)</cite>, which is also part
of the more general setup.</p>
</section>
<section id="wrapping-up">
<h2>7. Wrapping up<a class="headerlink" href="#wrapping-up" title="Link to this heading">#</a></h2>
<p>In summary, use <cite>Timer.blocked_autorange</cite> to collect wall times. If timing
variation is too high, increase <cite>min_run_time</cite>, or move to C++ snippets if
convenient.</p>
<p>For fine grained analysis, use <cite>Timer.collect_callgrind</cite> to measure
instruction counts and <cite>FunctionCounts.(__add__ / __sub__ / transform / filter)</cite>
to slice-and-dice them.</p>
</section>
<section id="footnotes">
<h2>8. Footnotes<a class="headerlink" href="#footnotes" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Implied <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">torch</span></code></dt><dd><p>If <cite>globals</cite> does not contain â€œtorchâ€, Timer will automatically
populate it. This means that <code class="docutils literal notranslate"><span class="pre">Timer("torch.empty(())")</span></code> will work.
(Though other imports should be placed in <cite>setup</cite>,
e.g. <code class="docutils literal notranslate"><span class="pre">Timer("np.zeros(())",</span> <span class="pre">"import</span> <span class="pre">numpy</span> <span class="pre">as</span> <span class="pre">np")</span></code>)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">REL_WITH_DEB_INFO</span></code></dt><dd><p>In order to provide full information about the PyTorch internals which
are executed, <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code> needs access to C++ debug symbols. This is
accomplished by setting <code class="docutils literal notranslate"><span class="pre">REL_WITH_DEB_INFO=1</span></code> when building PyTorch.
Otherwise function calls will be opaque. (The resultant <code class="docutils literal notranslate"><span class="pre">CallgrindStats</span></code>
will warn if debug symbols are missing.)</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-recipes-timer-quick-start-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c421b7eb91c1baf27a829c1bf3309a42/timer_quick_start.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">timer_quick_start.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c98cce79febbad67b67e99e9aa18a8cf/timer_quick_start.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">timer_quick_start.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a00637bd6fe1ee7bfaa80e7ab5cb1bf4/timer_quick_start.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">timer_quick_start.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</div>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">â˜…</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="tuning_guide.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Performance Tuning Guide</p>
</div>
</a>
<a class="right-next" href="../zero_redundancy_optimizer.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Shard Optimizer States with ZeroRedundancyOptimizer</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="tuning_guide.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Performance Tuning Guide</p>
</div>
</a>
<a class="right-next" href="../zero_redundancy_optimizer.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Shard Optimizer States with ZeroRedundancyOptimizer</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-a-timer">1. Defining a Timer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wall-time-timer-blocked-autorange">2. Wall time: <code class="docutils literal notranslate"><span class="pre">Timer.blocked_autorange(...)</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#c-snippets">3. C++ snippets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-counts-timer-collect-callgrind">4. Instruction counts: <code class="docutils literal notranslate"><span class="pre">Timer.collect_callgrind(...)</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-counts-delving-deeper">5. Instruction counts: Delving deeper</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-with-callgrind">6. A/B testing with <code class="docutils literal notranslate"><span class="pre">Callgrind</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-up">7. Wrapping up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#footnotes">8. Footnotes</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/helion" style="color: var(--pst-color-text-muted)">Helion</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/kineto" style="color: var(--pst-color-text-muted)">kineto</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/torchtitan" style="color: var(--pst-color-text-muted)">torchtitan</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/rl" style="color: var(--pst-color-text-muted)">TorchRL</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/audio" style="color: var(--pst-color-text-muted)">torchaudio</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/tensordict" style="color: var(--pst-color-text-muted)">tensordict</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          Â© PyTorch. Copyright Â© The Linux FoundationÂ®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Timer quick start",
       "headline": "Timer quick start",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/recipes/recipes/timer_quick_start.html",
       "articleBody": "Note Go to the end to download the full example code. Timer quick start# In this tutorial, we\u2019re going to cover the primary APIs of torch.utils.benchmark.Timer. The PyTorch Timer is based on the timeit.Timer API, with several PyTorch specific modifications. Familiarity with the builtin Timer class is not required for this tutorial, however we assume that the reader is familiar with the fundamentals of performance work. For a more comprehensive performance tuning tutorial, see PyTorch Benchmark. Contents: Defining a Timer Wall time: Timer.blocked_autorange(\u2026) C++ snippets Instruction counts: Timer.collect_callgrind(\u2026) Instruction counts: Delving deeper A/B testing with Callgrind Wrapping up Footnotes 1. Defining a Timer# A Timer serves as a task definition. from torch.utils.benchmark import Timer timer = Timer( # The computation which will be run in a loop and timed. stmt=\"x * y\", # `setup` will be run before calling the measurement loop, and is used to # populate any state which is needed by `stmt` setup=\"\"\" x = torch.ones((128,)) y = torch.ones((128,)) \"\"\", # Alternatively, ``globals`` can be used to pass variables from the outer scope. # # globals={ # \"x\": torch.ones((128,)), # \"y\": torch.ones((128,)), # }, # Control the number of threads that PyTorch uses. (Default: 1) num_threads=1, ) 2. Wall time: Timer.blocked_autorange(...)# This method will handle details such as picking a suitable number if repeats, fixing the number of threads, and providing a convenient representation of the results. # Measurement objects store the results of multiple repeats, and provide # various utility features. from torch.utils.benchmark import Measurement m: Measurement = timer.blocked_autorange(min_run_time=1) print(m) Snippet wall time.# \u003ctorch.utils.benchmark.utils.common.Measurement object at 0x7f1929a38ed0\u003e x * y setup: x = torch.ones((128,)) y = torch.ones((128,)) Median: 2.34 us IQR: 0.07 us (2.31 to 2.38) 424 measurements, 1000 runs per measurement, 1 thread 3. C++ snippets# from torch.utils.benchmark import Language cpp_timer = Timer( \"x * y;\", \"\"\" auto x = torch::ones({128}); auto y = torch::ones({128}); \"\"\", language=Language.CPP, ) print(cpp_timer.blocked_autorange(min_run_time=1)) C++ snippet wall time.# \u003ctorch.utils.benchmark.utils.common.Measurement object at 0x7f192b019ed0\u003e x * y; setup: auto x = torch::ones({128}); auto y = torch::ones({128}); Median: 1.21 us IQR: 0.03 us (1.20 to 1.23) 83 measurements, 10000 runs per measurement, 1 thread Unsurprisingly, the C++ snippet is both faster and has lower variation. 4. Instruction counts: Timer.collect_callgrind(...)# For deep dive investigations, Timer.collect_callgrind wraps Callgrind in order to collect instruction counts. These are useful as they offer fine grained and deterministic (or very low noise in the case of Python) insights into how a snippet is run. from torch.utils.benchmark import CallgrindStats, FunctionCounts stats: CallgrindStats = cpp_timer.collect_callgrind() print(stats) C++ Callgrind stats (summary)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats object at 0x7f1929a35850\u003e x * y; setup: auto x = torch::ones({128}); auto y = torch::ones({128}); All Noisy symbols removed Instructions: 563600 563600 Baseline: 0 0 100 runs per measurement, 1 thread 5. Instruction counts: Delving deeper# The string representation of CallgrindStats is similar to that of Measurement. Noisy symbols are a Python concept (removing calls in the CPython interpreter which are known to be noisy). For more detailed analysis, however, we will want to look at specific calls. CallgrindStats.stats() returns a FunctionCounts object to make this easier. Conceptually, FunctionCounts can be thought of as a tuple of pairs with some utility methods, where each pair is (number of instructions, file path and function name). A note on paths:One generally doesn\u2019t care about absolute path. For instance, the full path and function name for a multiply call is something like: /the/prefix/to/your/pytorch/install/dir/pytorch/build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const\u0026) const [/the/path/to/your/conda/install/miniconda3/envs/ab_ref/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so] when in reality, all of the information that we\u0027re interested in can be represented in: build/aten/src/ATen/core/TensorMethods.cpp:at::Tensor::mul(at::Tensor const\u0026) const ``CallgrindStats.as_standardized()`` makes a best effort to strip low signal portions of the file path, as well as the shared object and is generally recommended. inclusive_stats = stats.as_standardized().stats(inclusive=False) print(inclusive_stats[:10]) C++ Callgrind stats (detailed)# torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192a6dfd90\u003e 47264 ???:_int_free 25963 ???:_int_malloc 19900 build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const\u0026) 18000 ???:__tls_get_addr 13500 ???:malloc 11300 build/../c10/util/SmallVector.h:a ... (at::TensorIteratorConfig const\u0026) 10345 ???:_int_memalign 10000 build/../aten/src/ATen/TensorIter ... (at::TensorIteratorConfig const\u0026) 9200 ???:free 8000 build/../c10/util/SmallVector.h:a ... IteratorBase::get_strides() const Total: 173472 That\u2019s still quite a lot to digest. Let\u2019s use the FunctionCounts.transform method to trim some of the function path, and discard the function called. When we do, the counts of any collisions (e.g. foo.h:a() and foo.h:b() will both map to foo.h) will be added together. import os import re def group_by_file(fn_name: str): if fn_name.startswith(\"???\"): fn_dir, fn_file = fn_name.split(\":\")[:2] else: fn_dir, fn_file = os.path.split(fn_name.split(\":\")[0]) fn_dir = re.sub(\"^.*build/../\", \"\", fn_dir) fn_dir = re.sub(\"^.*torch/\", \"torch/\", fn_dir) return f\"{fn_dir:\u003c15} {fn_file}\" print(inclusive_stats.transform(group_by_file)[:10]) Callgrind stats (condensed)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750\u003e 118200 aten/src/ATen TensorIterator.cpp 65000 c10/util SmallVector.h 47264 ??? _int_free 25963 ??? _int_malloc 20900 c10/util intrusive_ptr.h 18000 ??? __tls_get_addr 15900 c10/core TensorImpl.h 15100 c10/core CPUAllocator.cpp 13500 ??? malloc 12500 c10/core TensorImpl.cpp Total: 352327 6. A/B testing with Callgrind# One of the most useful features of instruction counts is they allow fine grained comparison of computation, which is critical when analyzing performance. To see this in action, lets compare our multiplication of two size 128 Tensors with a {128} x {1} multiplication, which will broadcast the second Tensor: result = {a0 * b0, a1 * b0, \u2026, a127 * b0} broadcasting_stats = Timer( \"x * y;\", \"\"\" auto x = torch::ones({128}); auto y = torch::ones({1}); \"\"\", language=Language.CPP, ).collect_callgrind().as_standardized().stats(inclusive=False) Often we want to A/B test two different environments. (e.g. testing a PR, or experimenting with compile flags.) This is quite simple, as CallgrindStats, FunctionCounts, and Measurement are all pickleable. Simply save measurements from each environment, and load them in a single process for analysis. import pickle # Let\u0027s round trip `broadcasting_stats` just to show that we can. broadcasting_stats = pickle.loads(pickle.dumps(broadcasting_stats)) # And now to diff the two tasks: delta = broadcasting_stats - inclusive_stats def extract_fn_name(fn: str): \"\"\"Trim everything except the function name.\"\"\" fn = \":\".join(fn.split(\":\")[1:]) return re.sub(r\"\\(.+\\)\", \"(...)\", fn) # We use `.transform` to make the diff readable: print(delta.transform(extract_fn_name)) Instruction count delta# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f192995d750\u003e 17600 at::TensorIteratorBase::compute_strides(...) 12700 at::TensorIteratorBase::allocate_or_resize_outputs() 10200 c10::SmallVectorImpl\u003clong\u003e::operator=(...) 7400 at::infer_size(...) 6200 at::TensorIteratorBase::invert_perm(...) const 6064 _int_free 5100 at::TensorIteratorBase::reorder_dimensions() 4300 malloc 4300 at::TensorIteratorBase::compatible_stride(...) const ... -28 _int_memalign -100 c10::impl::check_tensor_options_and_extract_memory_format(...) -300 __memcmp_avx2_movbe -400 at::detail::empty_cpu(...) -1100 at::TensorIteratorBase::numel() const -1300 void at::native::(...) -2400 c10::TensorImpl::is_contiguous(...) const -6100 at::TensorIteratorBase::compute_fast_setup_type(...) -22600 at::TensorIteratorBase::fast_set_up(...) Total: 58091 So the broadcasting version takes an extra 580 instructions per call (recall that we\u2019re collecting 100 runs per sample), or about 10%. There are quite a few TensorIterator calls, so lets drill down to those. FunctionCounts.filter makes this easy. print(delta.transform(extract_fn_name).filter(lambda fn: \"TensorIterator\" in fn)) Instruction count delta (filter)# \u003ctorch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts object at 0x7f19299544d0\u003e 17600 at::TensorIteratorBase::compute_strides(...) 12700 at::TensorIteratorBase::allocate_or_resize_outputs() 6200 at::TensorIteratorBase::invert_perm(...) const 5100 at::TensorIteratorBase::reorder_dimensions() 4300 at::TensorIteratorBase::compatible_stride(...) const 4000 at::TensorIteratorBase::compute_shape(...) 2300 at::TensorIteratorBase::coalesce_dimensions() 1600 at::TensorIteratorBase::build(...) -1100 at::TensorIteratorBase::numel() const -6100 at::TensorIteratorBase::compute_fast_setup_type(...) -22600 at::TensorIteratorBase::fast_set_up(...) Total: 24000 This makes plain what is going on: there is a fast path in TensorIterator setup, but in the {128} x {1} case we miss it and have to do a more general analysis which is more expensive. The most prominent call omitted by the filter is c10::SmallVectorImpl\u003clong\u003e::operator=(\u2026), which is also part of the more general setup. 7. Wrapping up# In summary, use Timer.blocked_autorange to collect wall times. If timing variation is too high, increase min_run_time, or move to C++ snippets if convenient. For fine grained analysis, use Timer.collect_callgrind to measure instruction counts and FunctionCounts.(__add__ / __sub__ / transform / filter) to slice-and-dice them. 8. Footnotes# Implied import torchIf globals does not contain \u201ctorch\u201d, Timer will automatically populate it. This means that Timer(\"torch.empty(())\") will work. (Though other imports should be placed in setup, e.g. Timer(\"np.zeros(())\", \"import numpy as np\")) REL_WITH_DEB_INFOIn order to provide full information about the PyTorch internals which are executed, Callgrind needs access to C++ debug symbols. This is accomplished by setting REL_WITH_DEB_INFO=1 when building PyTorch. Otherwise function calls will be opaque. (The resultant CallgrindStats will warn if debug symbols are missing.) Download Jupyter notebook: timer_quick_start.ipynb Download Python source code: timer_quick_start.py Download zipped: timer_quick_start.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/recipes/timer_quick_start.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>