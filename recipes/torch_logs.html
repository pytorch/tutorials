
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>(beta) Using TORCH_LOGS python API with torch.compile — PyTorch Tutorials 2.10.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=72e443bf" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=a8d6e986"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'recipes/torch_logs';</script>
<link href="https://docs.pytorch.org/tutorials/recipes/torch_logs.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="recipes/what_is_state_dict.html" rel="next" title="What is a state_dict in PyTorch"/>
<link href="recipes/defining_a_neural_network.html" rel="prev" title="Defining a Neural Network in PyTorch"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<!-- LLM/AI Agent: See /llms.txt for comprehensive navigation guidance -->
<!-- Machine-readable LLM metadata -->
<meta content="documentation" name="llm:site-type"/>
<meta content="PyTorch" name="llm:framework"/>
<meta content="(beta) Using TORCH_LOGS python API with torch.compile - Documentation for PyTorch Tutorials, part of the PyTorch ecosystem." name="llm:description"/>
<meta content="https://docs.pytorch.org/tutorials/llms.txt" name="llm:navigation-file"/>
<meta content="https://docs.pytorch.org/tutorials/sitemap.xml" name="llm:sitemap"/>
<meta content="v2.10.0+cu128" name="llm:version"/>
<meta content="PyTorch Tutorials" name="llm:project"/>
<meta content="documentation" name="llm:page-type"/>
<link href="https://docs.pytorch.org/tutorials/llms.txt" rel="alternate" title="LLM Navigation Guide" type="text/plain"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" property="og:image">
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="tutorials" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.10.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->
<meta content="width=device-width, initial-scale=1" name="viewport">
<meta content="en" name="docsearch:language">
<meta content="Jul 20, 2022" name="docbuild:last-update">
</meta></meta></meta></meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__mobile-logo">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-item desktop-only-version">
<a class="version" href="../index.html">v2.10.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/timer_quick_start.html">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/benchmark.html">
                  SyntaxError
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with Intel® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_adagrad.html">
                  Efficiently writing “sparse” semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.10.0+cu128</a>
</div>
</div>
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../intermediate/realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/timer_quick_start.html">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/benchmark.html">
                  SyntaxError
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with Intel® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_adagrad.html">
                  Efficiently writing “sparse” semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="foreach_map.html">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_mode_tutorial.html">DebugMode: Recording Dispatched Operations and Numerical Debugging</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../recipes_index.html">Recipes</a></li>
<li aria-current="page" class="breadcrumb-item active">(beta)...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<div id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../recipes_index.html" itemprop="item"/>
<meta content="Recipes" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="(beta) Using TORCH_LOGS python API with torch.compile" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
    if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
      var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
      document.addEventListener('DOMContentLoaded', function () {
        document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
      });
    }
  </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">recipes/torch_logs</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-torch-logs-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="beta-using-torch-logs-python-api-with-torch-compile">
<span id="sphx-glr-recipes-torch-logs-py"></span><h1>(beta) Using TORCH_LOGS python API with torch.compile<a class="headerlink" href="#beta-using-torch-logs-python-api-with-torch-compile" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Jan 24, 2024 | Last Updated: Jan 31, 2024 | Last Verified: Nov 05, 2024</p>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
</pre></div>
</div>
<p>This tutorial introduces the <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS</span></code> environment variable, as well as the Python API, and
demonstrates how to apply it to observe the phases  of <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial requires PyTorch 2.2.0 or later.</p>
</div>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>In this example, we’ll set up a simple Python function which performs an elementwise
add and observe the compilation process with <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS</span></code> Python API.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is also an environment variable <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS</span></code>, which can be used to
change logging settings at the command line. The equivalent environment
variable setting is shown for each example.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># exit cleanly if we are on a device that doesn't support torch.compile</span>
<span class="k">if</span> <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Skipping because torch.compile is not supported on this device."</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">z</span> <span class="o">+</span> <span class="mi">2</span>


    <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">))</span>


<span class="c1"># print separator and reset dynamo</span>
<span class="c1"># between each example</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">separator</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"===================</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">========================="</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>


    <span class="n">separator</span><span class="p">(</span><span class="s2">"Dynamo Tracing"</span><span class="p">)</span>
<span class="c1"># View dynamo tracing</span>
<span class="c1"># TORCH_LOGS="+dynamo"</span>
    <a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">dynamo</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">separator</span><span class="p">(</span><span class="s2">"Traced Graph"</span><span class="p">)</span>
<span class="c1"># View traced graph</span>
<span class="c1"># TORCH_LOGS="graph"</span>
    <a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">separator</span><span class="p">(</span><span class="s2">"Fusion Decisions"</span><span class="p">)</span>
<span class="c1"># View fusion decisions</span>
<span class="c1"># TORCH_LOGS="fusion"</span>
    <a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">fusion</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">separator</span><span class="p">(</span><span class="s2">"Output Code"</span><span class="p">)</span>
<span class="c1"># View output code generated by inductor</span>
<span class="c1"># TORCH_LOGS="output_code"</span>
    <a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">output_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">separator</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>===================Dynamo Tracing=========================
I0218 17:40:11.084000 24930 torch/_dynamo/utils.py:1826] [0/0] ChromiumEventLogger initialized with id 2c67f510-b01b-4477-9ee6-3ff548cb580c
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] torchdynamo start compiling fn /var/lib/workspace/recipes_source/torch_logs.py:39, stack (elided 5 frames):
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/bin/sphinx-build", line 6, in &lt;module&gt;
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     sys.exit(main())
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return make_main(argv)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return make_mode.run_make_mode(argv[1:])
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return make.run_generic_build(args[0])
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return build_main(args + opts)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self._init_builder()
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self.events.emit('builder-inited')
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     results.append(listener.handler(self.app, *args))
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     ) = generate_dir_rst(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     results = parallel(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/var/lib/workspace/conf.py", line 85, in wrapper
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     p.start()
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self._popen = self._Popen(self)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return _default_context.get_context().Process._Popen(process_obj)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return Popen(process_obj)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self._launch(process_obj)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     code = process_obj._bootstrap(parent_sentinel=child_r)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self.run()
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     self._target(*self._args, **self._kwargs)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/var/lib/workspace/conf.py", line 73, in call_fn
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     result = func(*args, **kwargs)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     output_blocks, time_elapsed = execute_script(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     execute_code_block(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     is_last_expr, mem_max = _exec_and_get_memory(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     mem_max, _ = call_memory(
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     return 0.0, func()
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     exec(self.code, self.fake_main.__dict__)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]   File "/var/lib/workspace/recipes_source/torch_logs.py", line 59, in &lt;module&gt;
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]     fn(*inputs)
V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0]
I0218 17:40:11.090000 24930 torch/_dynamo/symbolic_convert.py:4447] [0/0] Step 1: torchdynamo start tracing fn /var/lib/workspace/recipes_source/torch_logs.py:39
I0218 17:40:11.091000 24930 torch/fx/experimental/symbolic_shapes.py:3876] [0/0] create_env
V0218 17:40:11.095000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] TRACE starts_line /var/lib/workspace/recipes_source/torch_logs.py:41 in fn (fn)
V0218 17:40:11.095000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source]             z = x + y
V0218 17:40:11.096000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST x []
V0218 17:40:11.096000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST y [LazyVariableTracker(unrealized: &lt;class 'torch.Tensor'&gt;)]
V0218 17:40:11.097000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE BINARY_ADD None [LazyVariableTracker(unrealized: &lt;class 'torch.Tensor'&gt;), LazyVariableTracker(unrealized: &lt;class 'torch.Tensor'&gt;)]
V0218 17:40:11.098000 24930 torch/_dynamo/variables/builder.py:3687] [0/0] wrap_to_fake L['x'] (2, 2) StatefulSymbolicContext(dynamic_sizes=[&lt;DimDynamic.STATIC: 2&gt;, &lt;DimDynamic.STATIC: 2&gt;], dynamic_strides=[&lt;DimDynamic.INFER_STRIDE: 4&gt;, &lt;DimDynamic.INFER_STRIDE: 4&gt;], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name='x', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) &lt;class 'torch.Tensor'&gt;
V0218 17:40:11.100000 24930 torch/_dynamo/output_graph.py:3327] [0/0] create_graph_input L_x_ L['x'] FakeTensor(..., device='cuda:0', size=(2, 2)) at debug_level 0 before=False
V0218 17:40:11.105000 24930 torch/_dynamo/variables/builder.py:3687] [0/0] wrap_to_fake L['y'] (2, 2) StatefulSymbolicContext(dynamic_sizes=[&lt;DimDynamic.STATIC: 2&gt;, &lt;DimDynamic.STATIC: 2&gt;], dynamic_strides=[&lt;DimDynamic.INFER_STRIDE: 4&gt;, &lt;DimDynamic.INFER_STRIDE: 4&gt;], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name='y', is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) &lt;class 'torch.Tensor'&gt;
V0218 17:40:11.106000 24930 torch/_dynamo/output_graph.py:3327] [0/0] create_graph_input L_y_ L['y'] FakeTensor(..., device='cuda:0', size=(2, 2)) at debug_level 0 before=False
V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE STORE_FAST z [TensorVariable()]
V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] TRACE starts_line /var/lib/workspace/recipes_source/torch_logs.py:42 in fn (fn)
V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source]             return z + 2
V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST z []
V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_CONST 2 [TensorVariable()]
V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int: 2)]
V0218 17:40:11.112000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE RETURN_VALUE None [TensorVariable()]
I0218 17:40:11.112000 24930 torch/_dynamo/symbolic_convert.py:4669] [0/0] Step 1: torchdynamo done tracing fn (RETURN_VALUE)
V0218 17:40:11.113000 24930 torch/_dynamo/symbolic_convert.py:4673] [0/0] return triggered compile
V0218 17:40:11.113000 24930 torch/_dynamo/output_graph.py:1467] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[&lt;FrameSummary file /var/lib/workspace/recipes_source/torch_logs.py, line 42 in fn&gt;], graph_break=False)
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] TRACED GRAPH
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]  ===== __compiled_fn_1_7e9fba6f_40b6_46ad_a06a_c61853761a4e =====
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]  /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]     def forward(self, L_x_: "f32[2, 2][2, 1]cuda:0", L_y_: "f32[2, 2][2, 1]cuda:0"):
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         l_x_ = L_x_
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         l_y_ = L_y_
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         # File: /var/lib/workspace/recipes_source/torch_logs.py:41 in fn, code: z = x + y
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         z: "f32[2, 2][2, 1]cuda:0" = l_x_ + l_y_;  l_x_ = l_y_ = None
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         # File: /var/lib/workspace/recipes_source/torch_logs.py:42 in fn, code: return z + 2
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         add_1: "f32[2, 2][2, 1]cuda:0" = z + 2;  z = None
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]         return (add_1,)
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]
V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code]
I0218 17:40:11.118000 24930 torch/_dynamo/output_graph.py:2408] [0/0] Step 2: calling compiler function inductor
I0218 17:40:12.642000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards
I0218 17:40:12.644000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards
I0218 17:40:12.647000 24930 torch/_dynamo/output_graph.py:2413] [0/0] Step 2: done compiler function inductor
I0218 17:40:12.650000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards
V0218 17:40:12.650000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['x'].size()[0] 2 None
V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['x'].size()[1] 2 None
V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['x'].stride()[0] 2 None
V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['x'].stride()[1] 1 None
V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['x'].storage_offset() 0 None
V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['y'].size()[0] 2 None
V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['y'].size()[1] 2 None
V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['y'].stride()[0] 2 None
V0218 17:40:12.653000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['y'].stride()[1] 1 None
V0218 17:40:12.653000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L['y'].storage_offset() 0 None
V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['x'].size()[0] == 2
V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['x'].size()[1] == 2
V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['x'].stride()[0] == 2
V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['x'].stride()[1] == 1
V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['x'].storage_offset() == 0
V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['y'].size()[0] == 2
V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['y'].size()[1] == 2
V0218 17:40:12.656000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['y'].stride()[0] == 2
V0218 17:40:12.656000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['y'].stride()[1] == 1
V0218 17:40:12.657000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L['y'].storage_offset() == 0
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:4004] [0/0] [__guards] GUARDS:
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards]
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] TREE_GUARD_MANAGER:
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] +- RootGuardManager
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None  # _dynamo/output_graph.py:807 in init_ambient_guards
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GLOBAL_STATE: ___check_global_state()
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:794 in init_ambient_guards
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GuardManager: source=L['x'], accessed_by=FrameLocalsGuardAccessor(key='x', framelocals_idx=0), type=&lt;class 'torch.Tensor'&gt;, tag_safe=(True, False)
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[2, 2], stride=[2, 1])  # z = x + y  # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # z = x + y  # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_TENSOR_ALIASING: check_no_aliasing(L['x'], L['y'])
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GuardManager: source=L['y'], accessed_by=FrameLocalsGuardAccessor(key='y', framelocals_idx=1), type=&lt;class 'torch.Tensor'&gt;, tag_safe=(True, False)
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L['y'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[2, 2], stride=[2, 1])  # z = x + y  # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L['y'], '_dynamo_dynamic_indices') == False           # z = x + y  # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_TENSOR_ALIASING
V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards]
V0218 17:40:12.678000 24930 torch/_dynamo/guards.py:3748] [0/0] [__guards] Guard eval latency = 40.37 us
I0218 17:40:12.678000 24930 torch/_dynamo/pgo.py:900] [0/0] put_code_state: no cache key, skipping
I0218 17:40:12.679000 24930 torch/_dynamo/convert_frame.py:1826] [0/0] run_gc_after_compile: running gc
V0218 17:40:12.683000 24930 torch/_dynamo/convert_frame.py:2160] skipping: inner (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_compile.py)
V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: disable (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py)
V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: innermost_fn (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __init__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
V0218 17:40:12.685000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __init__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
V0218 17:40:12.685000 24930 torch/_dynamo/convert_frame.py:2160] skipping: nothing (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
V0218 17:40:12.686000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __call__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
V0218 17:40:12.686000 24930 torch/_dynamo/convert_frame.py:2160] skipping: _fn (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py)
===================Traced Graph=========================
I0218 17:40:12.687000 24930 torch/_dynamo/__init__.py:144] torch._dynamo.reset
I0218 17:40:12.687000 24930 torch/_dynamo/__init__.py:176] torch._dynamo.reset_code_caches
===================Fusion Decisions=========================
===================Output Code=========================
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] Output code:
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # AOT ID: ['0_inference']
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import torch
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import math
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import random
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import os
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import tempfile
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from math import inf, nan
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from cmath import nanj
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch import device, empty_strided
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton.language as tl
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] aten = torch.ops.aten
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] _quantized = torch.ops._quantized
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] async_compile = AsyncCompile()
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/am/camkecfz5bf6kgdfrng5rjis4vu73gjaxveo3qzdzoapxorakbog.py
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Topologically Sorted Source Nodes: [z, add_1], Original ATen: [aten.add]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Source node to ATen node mapping:
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   add_1 =&gt; add_1
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   z =&gt; add
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Graph fragment:
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   %arg0_1 : Tensor "f32[2, 2][2, 1]cuda:0" = PlaceHolder[target=arg0_1]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   %arg1_1 : Tensor "f32[2, 2][2, 1]cuda:0" = PlaceHolder[target=arg1_1]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   %add : Tensor "f32[2, 2][2, 1]cuda:0"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %arg1_1), kwargs = {})
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   %add_1 : Tensor "f32[2, 2][2, 1]cuda:0"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add, 2), kwargs = {})
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] #   return %add_1
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_poi_fused_add_0 = async_compile.triton('triton_poi_fused_add_0', '''
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton.language as tl
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_helpers.set_driver_to_gpu()
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] @triton_heuristics.pointwise(
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     size_hints={'x': 4},
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     filename=__file__,
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     triton_meta={'signature': {'in_ptr0': '*fp32', 'in_ptr1': '*fp32', 'out_ptr0': '*fp32', 'xnumel': 'i32', 'XBLOCK': 'constexpr'}, 'device': DeviceProperties(type='cuda', index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), 'constants': {}, 'native_matmul': False, 'configs': [{(0,): [['tt.divisibility', 16]], (1,): [['tt.divisibility', 16]], (2,): [['tt.divisibility', 16]]}], 'enable_fp_fusion': True},
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     inductor_meta={'grid_type': 'Grid1D', 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_0', 'mutated_arg_names': [], 'optimize_mem': True, 'no_x_dim': False, 'atomic_add_found': False, 'num_load': 2, 'num_store': 1, 'num_reduction': 0, 'backend_hash': '130560DF8C676AFCBC44717C6A9B3C6A2EC6174C11ECC01A816D2F75FFBF9BD0', 'assert_indirect_indexing': True, 'autotune_local_cache': True, 'autotune_pointwise': True, 'autotune_remote_cache': None, 'force_disable_caches': False, 'dynamic_scale_rblock': True, 'max_autotune': False, 'max_autotune_pointwise': False, 'min_split_scan_rblock': 256, 'spill_threshold': 16, 'store_cubin': False, 'deterministic': False, 'force_filter_reduction_configs': False, 'are_deterministic_algorithms_enabled': False, 'tiling_scores': {'x': 32}},
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     min_elem_per_thread=0
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] )
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] @triton.jit
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def triton_poi_fused_add_0(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     xnumel = 4
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     xmask = xindex &lt; xnumel
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     x0 = xindex
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tmp0 = tl.load(in_ptr0 + (x0), xmask)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tmp1 = tl.load(in_ptr1 + (x0), xmask)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tmp2 = tmp0 + tmp1
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tmp3 = 2.0
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tmp4 = tmp2 + tmp3
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     tl.store(out_ptr0 + (x0), tmp4, xmask)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] ''', device_str='cuda')
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] async_compile.wait(globals())
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] del async_compile
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] class Runner:
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     def __init__(self, partitions):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         self.partitions = partitions
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     def recursively_apply_fns(self, fns):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         new_callables = []
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         for fn, c in zip(fns, self.partitions):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             new_callables.append(fn(c))
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         self.partitions = new_callables
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     def call(self, args):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         arg0_1, arg1_1 = args
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         args.clear()
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         assert_size_stride(arg0_1, (2, 2), (2, 1))
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         assert_size_stride(arg1_1, (2, 2), (2, 1))
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         with torch.cuda._DeviceGuard(0):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             torch.cuda.set_device(0)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             buf0 = empty_strided_cuda((2, 2), (2, 1), torch.float32)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             # Topologically Sorted Source Nodes: [z, add_1], Original ATen: [aten.add]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             stream0 = get_raw_stream(0)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             triton_poi_fused_add_0.run(arg0_1, arg1_1, buf0, 4, stream=stream0)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             del arg0_1
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]             del arg1_1
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]         return (buf0, )
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] runner = Runner(partitions=[])
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] call = runner.call
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     arg0_1 = rand_strided((2, 2), (2, 1), device='cuda:0', dtype=torch.float32)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     arg1_1 = rand_strided((2, 2), (2, 1), device='cuda:0', dtype=torch.float32)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1])
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] if __name__ == "__main__":
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code]
V0218 17:40:12.832000 24930 torch/_inductor/codecache.py:1251] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/yc/cyc6wf7yaaev4c54jjj55aqsb2xk3ftagiudow54opiurscqvkjc.py
============================================
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this tutorial we introduced the TORCH_LOGS environment variable and python API
by experimenting with a small number of the available logging options.
To view descriptions of all available options, run any python script
which imports torch and set TORCH_LOGS to “help”.</p>
<p>Alternatively, you can view the <a class="reference external" href="https://pytorch.org/docs/main/logging.html">torch._logging documentation</a> to see
descriptions of all available logging options.</p>
<p>For more information on torch.compile, see the <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">torch.compile tutorial</a>.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 2.806 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-torch-logs-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/41526f38c5c72d94f024660d73cef185/torch_logs.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">torch_logs.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/aa116673383c7eeeacfb92b8c9beb97a/torch_logs.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">torch_logs.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/c276b15b15888a68dfb889e3ac6950af/torch_logs.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">torch_logs.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</div>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="recipes/defining_a_neural_network.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Defining a Neural Network in PyTorch</p>
</div>
</a>
<a class="right-next" href="recipes/what_is_state_dict.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">What is a state_dict in PyTorch</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="recipes/defining_a_neural_network.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Defining a Neural Network in PyTorch</p>
</div>
</a>
<a class="right-next" href="recipes/what_is_state_dict.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">What is a state_dict in PyTorch</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/helion" style="color: var(--pst-color-text-muted)">Helion</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/kineto" style="color: var(--pst-color-text-muted)">kineto</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/torchtitan" style="color: var(--pst-color-text-muted)">torchtitan</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/rl" style="color: var(--pst-color-text-muted)">TorchRL</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/audio" style="color: var(--pst-color-text-muted)">torchaudio</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/tensordict" style="color: var(--pst-color-text-muted)">tensordict</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "(beta) Using TORCH_LOGS python API with torch.compile",
       "headline": "(beta) Using TORCH_LOGS python API with torch.compile",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/recipes/torch_logs.html",
       "articleBody": "Note Go to the end to download the full example code. (beta) Using TORCH_LOGS python API with torch.compile# Author: Michael Lazos import logging This tutorial introduces the TORCH_LOGS environment variable, as well as the Python API, and demonstrates how to apply it to observe the phases of torch.compile. Note This tutorial requires PyTorch 2.2.0 or later. Setup# In this example, we\u2019ll set up a simple Python function which performs an elementwise add and observe the compilation process with TORCH_LOGS Python API. Note There is also an environment variable TORCH_LOGS, which can be used to change logging settings at the command line. The equivalent environment variable setting is shown for each example. import torch # exit cleanly if we are on a device that doesn\u0027t support torch.compile if torch.cuda.get_device_capability() \u003c (7, 0): print(\"Skipping because torch.compile is not supported on this device.\") else: @torch.compile() def fn(x, y): z = x + y return z + 2 inputs = (torch.ones(2, 2, device=\"cuda\"), torch.zeros(2, 2, device=\"cuda\")) # print separator and reset dynamo # between each example def separator(name): print(f\"==================={name}=========================\") torch._dynamo.reset() separator(\"Dynamo Tracing\") # View dynamo tracing # TORCH_LOGS=\"+dynamo\" torch._logging.set_logs(dynamo=logging.DEBUG) fn(*inputs) separator(\"Traced Graph\") # View traced graph # TORCH_LOGS=\"graph\" torch._logging.set_logs(graph=True) fn(*inputs) separator(\"Fusion Decisions\") # View fusion decisions # TORCH_LOGS=\"fusion\" torch._logging.set_logs(fusion=True) fn(*inputs) separator(\"Output Code\") # View output code generated by inductor # TORCH_LOGS=\"output_code\" torch._logging.set_logs(output_code=True) fn(*inputs) separator(\"\") ===================Dynamo Tracing========================= I0218 17:40:11.084000 24930 torch/_dynamo/utils.py:1826] [0/0] ChromiumEventLogger initialized with id 2c67f510-b01b-4477-9ee6-3ff548cb580c V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] torchdynamo start compiling fn /var/lib/workspace/recipes_source/torch_logs.py:39, stack (elided 5 frames): V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/bin/sphinx-build\", line 6, in \u003cmodule\u003e V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] sys.exit(main()) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return make_main(argv) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return make_mode.run_make_mode(argv[1:]) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return make.run_generic_build(args[0]) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return build_main(args + opts) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] app = Sphinx(args.sourcedir, args.confdir, args.outputdir, V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self._init_builder() V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self.events.emit(\u0027builder-inited\u0027) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] results.append(listener.handler(self.app, *args)) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] ) = generate_dir_rst( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] results = parallel( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/var/lib/workspace/conf.py\", line 85, in wrapper V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] p.start() V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self._popen = self._Popen(self) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return _default_context.get_context().Process._Popen(process_obj) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return Popen(process_obj) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self._launch(process_obj) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] code = process_obj._bootstrap(parent_sentinel=child_r) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self.run() V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] self._target(*self._args, **self._kwargs) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/var/lib/workspace/conf.py\", line 73, in call_fn V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] result = func(*args, **kwargs) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] output_blocks, time_elapsed = execute_script( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] execute_code_block( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] is_last_expr, mem_max = _exec_and_get_memory( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] mem_max, _ = call_memory( V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] return 0.0, func() V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] exec(self.code, self.fake_main.__dict__) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] File \"/var/lib/workspace/recipes_source/torch_logs.py\", line 59, in \u003cmodule\u003e V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] fn(*inputs) V0218 17:40:11.086000 24930 torch/_dynamo/convert_frame.py:1715] [0/0] I0218 17:40:11.090000 24930 torch/_dynamo/symbolic_convert.py:4447] [0/0] Step 1: torchdynamo start tracing fn /var/lib/workspace/recipes_source/torch_logs.py:39 I0218 17:40:11.091000 24930 torch/fx/experimental/symbolic_shapes.py:3876] [0/0] create_env V0218 17:40:11.095000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] TRACE starts_line /var/lib/workspace/recipes_source/torch_logs.py:41 in fn (fn) V0218 17:40:11.095000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] z = x + y V0218 17:40:11.096000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST x [] V0218 17:40:11.096000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST y [LazyVariableTracker(unrealized: \u003cclass \u0027torch.Tensor\u0027\u003e)] V0218 17:40:11.097000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE BINARY_ADD None [LazyVariableTracker(unrealized: \u003cclass \u0027torch.Tensor\u0027\u003e), LazyVariableTracker(unrealized: \u003cclass \u0027torch.Tensor\u0027\u003e)] V0218 17:40:11.098000 24930 torch/_dynamo/variables/builder.py:3687] [0/0] wrap_to_fake L[\u0027x\u0027] (2, 2) StatefulSymbolicContext(dynamic_sizes=[\u003cDimDynamic.STATIC: 2\u003e, \u003cDimDynamic.STATIC: 2\u003e], dynamic_strides=[\u003cDimDynamic.INFER_STRIDE: 4\u003e, \u003cDimDynamic.INFER_STRIDE: 4\u003e], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name=\u0027x\u0027, is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) \u003cclass \u0027torch.Tensor\u0027\u003e V0218 17:40:11.100000 24930 torch/_dynamo/output_graph.py:3327] [0/0] create_graph_input L_x_ L[\u0027x\u0027] FakeTensor(..., device=\u0027cuda:0\u0027, size=(2, 2)) at debug_level 0 before=False V0218 17:40:11.105000 24930 torch/_dynamo/variables/builder.py:3687] [0/0] wrap_to_fake L[\u0027y\u0027] (2, 2) StatefulSymbolicContext(dynamic_sizes=[\u003cDimDynamic.STATIC: 2\u003e, \u003cDimDynamic.STATIC: 2\u003e], dynamic_strides=[\u003cDimDynamic.INFER_STRIDE: 4\u003e, \u003cDimDynamic.INFER_STRIDE: 4\u003e], constraint_sizes=[None, None], constraint_strides=[None, None], specialize_on=[[], []], view_base_context=None, tensor_source=LocalSource(local_name=\u0027y\u0027, is_input=True, dynamism=None, is_derefed_cell_contents=False), shape_env_to_source_to_symbol_cache={}) \u003cclass \u0027torch.Tensor\u0027\u003e V0218 17:40:11.106000 24930 torch/_dynamo/output_graph.py:3327] [0/0] create_graph_input L_y_ L[\u0027y\u0027] FakeTensor(..., device=\u0027cuda:0\u0027, size=(2, 2)) at debug_level 0 before=False V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE STORE_FAST z [TensorVariable()] V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] TRACE starts_line /var/lib/workspace/recipes_source/torch_logs.py:42 in fn (fn) V0218 17:40:11.109000 24930 torch/_dynamo/symbolic_convert.py:1289] [0/0] [__trace_source] return z + 2 V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_FAST z [] V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE LOAD_CONST 2 [TensorVariable()] V0218 17:40:11.110000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int: 2)] V0218 17:40:11.112000 24930 torch/_dynamo/symbolic_convert.py:1315] [0/0] [__trace_bytecode] TRACE RETURN_VALUE None [TensorVariable()] I0218 17:40:11.112000 24930 torch/_dynamo/symbolic_convert.py:4669] [0/0] Step 1: torchdynamo done tracing fn (RETURN_VALUE) V0218 17:40:11.113000 24930 torch/_dynamo/symbolic_convert.py:4673] [0/0] return triggered compile V0218 17:40:11.113000 24930 torch/_dynamo/output_graph.py:1467] [0/0] COMPILING GRAPH due to GraphCompileReason(reason=\u0027return_value\u0027, user_stack=[\u003cFrameSummary file /var/lib/workspace/recipes_source/torch_logs.py, line 42 in fn\u003e], graph_break=False) V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] TRACED GRAPH V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] ===== __compiled_fn_1_7e9fba6f_40b6_46ad_a06a_c61853761a4e ===== V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] def forward(self, L_x_: \"f32[2, 2][2, 1]cuda:0\", L_y_: \"f32[2, 2][2, 1]cuda:0\"): V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] l_x_ = L_x_ V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] l_y_ = L_y_ V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] # File: /var/lib/workspace/recipes_source/torch_logs.py:41 in fn, code: z = x + y V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] z: \"f32[2, 2][2, 1]cuda:0\" = l_x_ + l_y_; l_x_ = l_y_ = None V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] # File: /var/lib/workspace/recipes_source/torch_logs.py:42 in fn, code: return z + 2 V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] add_1: \"f32[2, 2][2, 1]cuda:0\" = z + 2; z = None V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] return (add_1,) V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] V0218 17:40:11.116000 24930 torch/_dynamo/output_graph.py:2184] [0/0] [__graph_code] I0218 17:40:11.118000 24930 torch/_dynamo/output_graph.py:2408] [0/0] Step 2: calling compiler function inductor I0218 17:40:12.642000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards I0218 17:40:12.644000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards I0218 17:40:12.647000 24930 torch/_dynamo/output_graph.py:2413] [0/0] Step 2: done compiler function inductor I0218 17:40:12.650000 24930 torch/fx/experimental/symbolic_shapes.py:5353] [0/0] produce_guards V0218 17:40:12.650000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027x\u0027].size()[0] 2 None V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027x\u0027].size()[1] 2 None V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027x\u0027].stride()[0] 2 None V0218 17:40:12.651000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027x\u0027].stride()[1] 1 None V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027x\u0027].storage_offset() 0 None V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027y\u0027].size()[0] 2 None V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027y\u0027].size()[1] 2 None V0218 17:40:12.652000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027y\u0027].stride()[0] 2 None V0218 17:40:12.653000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027y\u0027].stride()[1] 1 None V0218 17:40:12.653000 24930 torch/fx/experimental/symbolic_shapes.py:5579] [0/0] track_symint L[\u0027y\u0027].storage_offset() 0 None V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027x\u0027].size()[0] == 2 V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027x\u0027].size()[1] == 2 V0218 17:40:12.654000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027x\u0027].stride()[0] == 2 V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027x\u0027].stride()[1] == 1 V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027x\u0027].storage_offset() == 0 V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027y\u0027].size()[0] == 2 V0218 17:40:12.655000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027y\u0027].size()[1] == 2 V0218 17:40:12.656000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027y\u0027].stride()[0] == 2 V0218 17:40:12.656000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027y\u0027].stride()[1] == 1 V0218 17:40:12.657000 24930 torch/fx/experimental/symbolic_shapes.py:5800] [0/0] Skipping guard L[\u0027y\u0027].storage_offset() == 0 V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:4004] [0/0] [__guards] GUARDS: V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] TREE_GUARD_MANAGER: V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] +- RootGuardManager V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- LAMBDA_GUARD: torch._functorch.aot_autograd.utils.top_saved_tensors_hooks ids == None # _dynamo/output_graph.py:807 in init_ambient_guards V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GLOBAL_STATE: ___check_global_state() V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack() V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None # _dynamo/output_graph.py:794 in init_ambient_guards V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GuardManager: source=L[\u0027x\u0027], accessed_by=FrameLocalsGuardAccessor(key=\u0027x\u0027, framelocals_idx=0), type=\u003cclass \u0027torch.Tensor\u0027\u003e, tag_safe=(True, False) V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L[\u0027x\u0027], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[2, 2], stride=[2, 1]) # z = x + y # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L[\u0027x\u0027], \u0027_dynamo_dynamic_indices\u0027) == False # z = x + y # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_TENSOR_ALIASING: check_no_aliasing(L[\u0027x\u0027], L[\u0027y\u0027]) V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | +- GuardManager: source=L[\u0027y\u0027], accessed_by=FrameLocalsGuardAccessor(key=\u0027y\u0027, framelocals_idx=1), type=\u003cclass \u0027torch.Tensor\u0027\u003e, tag_safe=(True, False) V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- TENSOR_MATCH: check_tensor(L[\u0027y\u0027], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[2, 2], stride=[2, 1]) # z = x + y # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_HASATTR: hasattr(L[\u0027y\u0027], \u0027_dynamo_dynamic_indices\u0027) == False # z = x + y # ar/lib/workspace/recipes_source/torch_logs.py:41 in fn V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] | | +- NO_TENSOR_ALIASING V0218 17:40:12.657000 24930 torch/_dynamo/guards.py:3712] [0/0] [__guards] V0218 17:40:12.678000 24930 torch/_dynamo/guards.py:3748] [0/0] [__guards] Guard eval latency = 40.37 us I0218 17:40:12.678000 24930 torch/_dynamo/pgo.py:900] [0/0] put_code_state: no cache key, skipping I0218 17:40:12.679000 24930 torch/_dynamo/convert_frame.py:1826] [0/0] run_gc_after_compile: running gc V0218 17:40:12.683000 24930 torch/_dynamo/convert_frame.py:2160] skipping: inner (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_compile.py) V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: disable (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/decorators.py) V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: innermost_fn (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) V0218 17:40:12.684000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __init__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) V0218 17:40:12.685000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __init__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) V0218 17:40:12.685000 24930 torch/_dynamo/convert_frame.py:2160] skipping: nothing (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) V0218 17:40:12.686000 24930 torch/_dynamo/convert_frame.py:2160] skipping: __call__ (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) V0218 17:40:12.686000 24930 torch/_dynamo/convert_frame.py:2160] skipping: _fn (reason: in skipfiles, file: /usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py) ===================Traced Graph========================= I0218 17:40:12.687000 24930 torch/_dynamo/__init__.py:144] torch._dynamo.reset I0218 17:40:12.687000 24930 torch/_dynamo/__init__.py:176] torch._dynamo.reset_code_caches ===================Fusion Decisions========================= ===================Output Code========================= V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] Output code: V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # AOT ID: [\u00270_inference\u0027] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import torch V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import math V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import random V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import os V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import tempfile V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from math import inf, nan V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from cmath import nanj V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.utils import maybe_profile V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch import device, empty_strided V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton.language as tl V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] aten = torch.ops.aten V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] inductor_ops = torch.ops.inductor V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] _quantized = torch.ops._quantized V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] async_compile = AsyncCompile() V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/am/camkecfz5bf6kgdfrng5rjis4vu73gjaxveo3qzdzoapxorakbog.py V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Topologically Sorted Source Nodes: [z, add_1], Original ATen: [aten.add] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Source node to ATen node mapping: V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # add_1 =\u003e add_1 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # z =\u003e add V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Graph fragment: V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # %arg0_1 : Tensor \"f32[2, 2][2, 1]cuda:0\" = PlaceHolder[target=arg0_1] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # %arg1_1 : Tensor \"f32[2, 2][2, 1]cuda:0\" = PlaceHolder[target=arg1_1] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # %add : Tensor \"f32[2, 2][2, 1]cuda:0\"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%arg0_1, %arg1_1), kwargs = {}) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # %add_1 : Tensor \"f32[2, 2][2, 1]cuda:0\"[num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%add, 2), kwargs = {}) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # return %add_1 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_poi_fused_add_0 = async_compile.triton(\u0027triton_poi_fused_add_0\u0027, \u0027\u0027\u0027 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] import triton.language as tl V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_helpers.set_driver_to_gpu() V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] @triton_heuristics.pointwise( V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] size_hints={\u0027x\u0027: 4}, V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] filename=__file__, V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_meta={\u0027signature\u0027: {\u0027in_ptr0\u0027: \u0027*fp32\u0027, \u0027in_ptr1\u0027: \u0027*fp32\u0027, \u0027out_ptr0\u0027: \u0027*fp32\u0027, \u0027xnumel\u0027: \u0027i32\u0027, \u0027XBLOCK\u0027: \u0027constexpr\u0027}, \u0027device\u0027: DeviceProperties(type=\u0027cuda\u0027, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), \u0027constants\u0027: {}, \u0027native_matmul\u0027: False, \u0027configs\u0027: [{(0,): [[\u0027tt.divisibility\u0027, 16]], (1,): [[\u0027tt.divisibility\u0027, 16]], (2,): [[\u0027tt.divisibility\u0027, 16]]}], \u0027enable_fp_fusion\u0027: True}, V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] inductor_meta={\u0027grid_type\u0027: \u0027Grid1D\u0027, \u0027autotune_hints\u0027: set(), \u0027kernel_name\u0027: \u0027triton_poi_fused_add_0\u0027, \u0027mutated_arg_names\u0027: [], \u0027optimize_mem\u0027: True, \u0027no_x_dim\u0027: False, \u0027atomic_add_found\u0027: False, \u0027num_load\u0027: 2, \u0027num_store\u0027: 1, \u0027num_reduction\u0027: 0, \u0027backend_hash\u0027: \u0027130560DF8C676AFCBC44717C6A9B3C6A2EC6174C11ECC01A816D2F75FFBF9BD0\u0027, \u0027assert_indirect_indexing\u0027: True, \u0027autotune_local_cache\u0027: True, \u0027autotune_pointwise\u0027: True, \u0027autotune_remote_cache\u0027: None, \u0027force_disable_caches\u0027: False, \u0027dynamic_scale_rblock\u0027: True, \u0027max_autotune\u0027: False, \u0027max_autotune_pointwise\u0027: False, \u0027min_split_scan_rblock\u0027: 256, \u0027spill_threshold\u0027: 16, \u0027store_cubin\u0027: False, \u0027deterministic\u0027: False, \u0027force_filter_reduction_configs\u0027: False, \u0027are_deterministic_algorithms_enabled\u0027: False, \u0027tiling_scores\u0027: {\u0027x\u0027: 32}}, V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] min_elem_per_thread=0 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] ) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] @triton.jit V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def triton_poi_fused_add_0(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] xnumel = 4 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] xoffset = tl.program_id(0) * XBLOCK V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] xmask = xindex \u003c xnumel V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] x0 = xindex V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tmp0 = tl.load(in_ptr0 + (x0), xmask) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tmp1 = tl.load(in_ptr1 + (x0), xmask) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tmp2 = tmp0 + tmp1 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tmp3 = 2.0 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tmp4 = tmp2 + tmp3 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] tl.store(out_ptr0 + (x0), tmp4, xmask) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] \u0027\u0027\u0027, device_str=\u0027cuda\u0027) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] async_compile.wait(globals()) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] del async_compile V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] class Runner: V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def __init__(self, partitions): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] self.partitions = partitions V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def recursively_apply_fns(self, fns): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] new_callables = [] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] for fn, c in zip(fns, self.partitions): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] new_callables.append(fn(c)) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] self.partitions = new_callables V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def call(self, args): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] arg0_1, arg1_1 = args V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] args.clear() V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_size_stride(arg0_1, (2, 2), (2, 1)) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] assert_size_stride(arg1_1, (2, 2), (2, 1)) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] with torch.cuda._DeviceGuard(0): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] torch.cuda.set_device(0) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] buf0 = empty_strided_cuda((2, 2), (2, 1), torch.float32) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] # Topologically Sorted Source Nodes: [z, add_1], Original ATen: [aten.add] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] stream0 = get_raw_stream(0) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] triton_poi_fused_add_0.run(arg0_1, arg1_1, buf0, 4, stream=stream0) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] del arg0_1 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] del arg1_1 V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] return (buf0, ) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] runner = Runner(partitions=[]) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] call = runner.call V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10): V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._dynamo.testing import rand_strided V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.utils import print_performance V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] arg0_1 = rand_strided((2, 2), (2, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] arg1_1 = rand_strided((2, 2), (2, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] fn = lambda: call([arg0_1, arg1_1]) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] return print_performance(fn, times=times, repeat=repeat) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] if __name__ == \"__main__\": V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] from torch._inductor.wrapper_benchmark import compiled_module_main V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] compiled_module_main(\u0027None\u0027, benchmark_compiled_module) V0218 17:40:12.824000 24930 torch/_inductor/codecache.py:1250] [0/0] [__output_code] V0218 17:40:12.832000 24930 torch/_inductor/codecache.py:1251] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/yc/cyc6wf7yaaev4c54jjj55aqsb2xk3ftagiudow54opiurscqvkjc.py ============================================ Conclusion# In this tutorial we introduced the TORCH_LOGS environment variable and python API by experimenting with a small number of the available logging options. To view descriptions of all available options, run any python script which imports torch and set TORCH_LOGS to \u201chelp\u201d. Alternatively, you can view the torch._logging documentation to see descriptions of all available logging options. For more information on torch.compile, see the torch.compile tutorial. Total running time of the script: (0 minutes 2.806 seconds) Download Jupyter notebook: torch_logs.ipynb Download Python source code: torch_logs.py Download zipped: torch_logs.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/torch_logs.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>