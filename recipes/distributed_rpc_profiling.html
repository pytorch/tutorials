


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Profiling PyTorch RPC-Based Workloads &mdash; PyTorch Tutorials 1.13.0+cu117 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Shard Optimizer States with ZeroRedundancyOptimizer" href="zero_redundancy_optimizer.html" />
    <link rel="prev" title="Deploying with Flask" href="deployment_with_flask.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.13.0+cu117
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_command_classification_with_torchaudio_tutorial.html">Speech Command Classification with torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transformer_tutorial.html">Language Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torch_compile_tutorial.html">torch.compile Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pipeline_tutorial.html">Training Transformer models using Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_android.html">Image Segmentation DeepLabV3 on Android</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
          <li><a href="recipes_index.html">PyTorch Recipes</a> &gt;</li>
        
      <li>Profiling PyTorch RPC-Based Workloads</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/recipes/distributed_rpc_profiling.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">recipes/distributed_rpc_profiling</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        

          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="profiling-pytorch-rpc-based-workloads">
<h1>Profiling PyTorch RPC-Based Workloads<a class="headerlink" href="#profiling-pytorch-rpc-based-workloads" title="Permalink to this heading">¶</a></h1>
<p>In this recipe, you will learn:</p>
<ul class="simple">
<li><p>An overview of the <a class="reference external" href="https://pytorch.org/docs/stable/rpc.html">Distributed RPC Framework</a>.</p></li>
<li><p>An overview of the <a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#profiler">PyTorch Profiler</a>.</p></li>
<li><p>How to use the profiler to profile RPC-based workloads.</p></li>
<li><p>A short example showcasing how to use the profiler to tune RPC parameters.</p></li>
</ul>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>PyTorch 1.6+</p></li>
</ul>
<p>The instructions for installing PyTorch are
available at <a class="reference external" href="https://pytorch.org/">pytorch.org</a>.</p>
</div>
<div class="section" id="what-is-the-distributed-rpc-framework">
<h2>What is the Distributed RPC Framework?<a class="headerlink" href="#what-is-the-distributed-rpc-framework" title="Permalink to this heading">¶</a></h2>
<p>The <strong>Distributed RPC Framework</strong> provides mechanisms for multi-machine model
training through a set of primitives to allow for remote communication, and a
higher-level API to automatically differentiate models split across several machines.
For this recipe, it would be helpful to be familiar with the <a class="reference external" href="https://pytorch.org/docs/stable/rpc.html">Distributed RPC Framework</a>
as well as the <a class="reference external" href="https://pytorch.org/tutorials/intermediate/rpc_tutorial.html">RPC Tutorials</a>.</p>
</div>
<div class="section" id="what-is-the-pytorch-profiler">
<h2>What is the PyTorch Profiler?<a class="headerlink" href="#what-is-the-pytorch-profiler" title="Permalink to this heading">¶</a></h2>
<p>The profiler is a context manager based API that allows for on-demand profiling of
operators in a model’s workload. The profiler can be used to analyze various aspects
of a model including execution time, operators invoked, and memory consumption. For a
detailed tutorial on using the profiler to profile a single-node model, please see the
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/profiler.html">Profiler Recipe</a>.</p>
</div>
<div class="section" id="how-to-use-the-profiler-for-rpc-based-workloads">
<h2>How to use the Profiler for RPC-based workloads<a class="headerlink" href="#how-to-use-the-profiler-for-rpc-based-workloads" title="Permalink to this heading">¶</a></h2>
<p>The profiler supports profiling of calls made of RPC and allows the user to have a
detailed view into the operations that take place on different nodes. To demonstrate an
example of this, let’s first set up the RPC framework. The below code snippet will initialize
two RPC workers on the same host, named <code class="docutils literal notranslate"><span class="pre">worker0</span></code> and <code class="docutils literal notranslate"><span class="pre">worker1</span></code> respectively. The workers will
be spawned as subprocesses, and we set some environment variables required for proper
initialization.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="kn">import</span> <span class="nn">torch.autograd.profiler</span> <span class="k">as</span> <span class="nn">profiler</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">random_tensor</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;localhost&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;29500&quot;</span>
    <span class="n">worker_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="c1"># Initialize RPC framework.</span>
    <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">worker_name</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span>
    <span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">worker_name</span><span class="si">}</span><span class="s2"> successfully initialized RPC.&quot;</span><span class="p">)</span>

    <span class="k">pass</span> <span class="c1"># to be continued below</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> waiting for workers and shutting down RPC&quot;</span><span class="p">)</span>
    <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> shutdown RPC&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># Run 2 RPC workers.</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">worker</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,),</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
</pre></div>
</div>
<p>Running the above program should present you with the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">worker1</span> <span class="n">successfully</span> <span class="n">initialized</span> <span class="n">RPC</span><span class="o">.</span>
<span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">worker0</span> <span class="n">successfully</span> <span class="n">initialized</span> <span class="n">RPC</span><span class="o">.</span>
<span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Rank</span> <span class="mi">0</span> <span class="n">waiting</span> <span class="k">for</span> <span class="n">workers</span> <span class="ow">and</span> <span class="n">shutting</span> <span class="n">down</span> <span class="n">RPC</span>
<span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Rank</span> <span class="mi">1</span> <span class="n">waiting</span> <span class="k">for</span> <span class="n">workers</span> <span class="ow">and</span> <span class="n">shutting</span> <span class="n">down</span> <span class="n">RPC</span>
<span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Rank</span> <span class="mi">1</span> <span class="n">shutdown</span> <span class="n">RPC</span>
<span class="n">DEBUG</span><span class="p">:</span><span class="n">root</span><span class="p">:</span><span class="n">Rank</span> <span class="mi">0</span> <span class="n">shutdown</span> <span class="n">RPC</span>
</pre></div>
</div>
<p>Now that we have a skeleton setup of our RPC framework, we can move on to
sending RPCs back and forth and using the profiler to obtain a view of what’s
happening under the hood. Let’s add to the above <code class="docutils literal notranslate"><span class="pre">worker</span></code> function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="c1"># Above code omitted...</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">dst_worker_rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span>
        <span class="n">dst_worker_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">dst_worker_rank</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">random_tensor</span><span class="p">(),</span> <span class="n">random_tensor</span><span class="p">()</span>
        <span class="c1"># Send and wait RPC completion under profiling scope.</span>
        <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">()</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
            <span class="n">fut1</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span>
            <span class="n">fut2</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span>
            <span class="c1"># RPCs must be awaited within profiling scope.</span>
            <span class="n">fut1</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
            <span class="n">fut2</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">())</span>
</pre></div>
</div>
<p>The aforementioned code creates 2 RPCs, specifying <code class="docutils literal notranslate"><span class="pre">torch.add</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.mul</span></code>, respectively,
to be run with two random input tensors on worker 1. Since we use the <code class="docutils literal notranslate"><span class="pre">rpc_async</span></code> API,
we are returned a <code class="docutils literal notranslate"><span class="pre">torch.futures.Future</span></code> object, which must be awaited for the result
of the computation. Note that this wait must take place within the scope created by
the profiling context manager in order for the RPC to be accurately profiled. Running
the code with this new worker function should result in the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some columns are omitted for brevity, exact output subject to randomness</span>
<span class="o">----------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
<span class="n">Name</span>                                                              <span class="n">Self</span> <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>  <span class="n">Self</span> <span class="n">CPU</span> <span class="n">total</span>   <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>      <span class="n">CPU</span> <span class="n">total</span>        <span class="n">CPU</span> <span class="n">time</span> <span class="n">avg</span>     <span class="n">Number</span> <span class="n">of</span> <span class="n">Calls</span>  <span class="n">Node</span> <span class="n">ID</span>
<span class="o">----------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
<span class="n">rpc_async</span><span class="c1">#aten::add(worker0 -&gt; worker1)                           0.00%            0.000us          0                20.462ms         20.462ms         1                0</span>
<span class="n">rpc_async</span><span class="c1">#aten::mul(worker0 -&gt; worker1)                           0.00%            0.000us          0                5.712ms          5.712ms          1                0</span>
<span class="n">rpc_async</span><span class="c1">#aten::mul(worker0 -&gt; worker1)#remote_op: mul            1.84%            206.864us        2.69%            302.162us        151.081us        2                1</span>
<span class="n">rpc_async</span><span class="c1">#aten::add(worker0 -&gt; worker1)#remote_op: add            1.41%            158.501us        1.57%            176.924us        176.924us        1                1</span>
<span class="n">rpc_async</span><span class="c1">#aten::mul(worker0 -&gt; worker1)#remote_op: output_nr      0.04%            4.980us          0.04%            4.980us          2.490us          2                1</span>
<span class="n">rpc_async</span><span class="c1">#aten::mul(worker0 -&gt; worker1)#remote_op: is_leaf        0.07%            7.806us          0.07%            7.806us          1.952us          4                1</span>
<span class="n">rpc_async</span><span class="c1">#aten::add(worker0 -&gt; worker1)#remote_op: empty          0.16%            18.423us         0.16%            18.423us         18.423us         1                1</span>
<span class="n">rpc_async</span><span class="c1">#aten::mul(worker0 -&gt; worker1)#remote_op: empty          0.14%            15.712us         0.14%            15.712us         15.712us         1                1</span>
<span class="o">----------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
<span class="n">Self</span> <span class="n">CPU</span> <span class="n">time</span> <span class="n">total</span><span class="p">:</span> <span class="mf">11.237</span><span class="n">ms</span>
</pre></div>
</div>
<p>Here we can see that the profiler has profiled our <code class="docutils literal notranslate"><span class="pre">rpc_async</span></code> calls made to <code class="docutils literal notranslate"><span class="pre">worker1</span></code>
from <code class="docutils literal notranslate"><span class="pre">worker0</span></code>. In particular, the first 2 entries in the table show details (such as
the operator name, originating worker, and destination worker) about each RPC call made
and the <code class="docutils literal notranslate"><span class="pre">CPU</span> <span class="pre">total</span></code> column indicates the end-to-end latency of the RPC call.</p>
<p>We also have visibility into the actual operators invoked remotely on worker 1 due to RPC.
We can see operations that took place on <code class="docutils literal notranslate"><span class="pre">worker1</span></code> by checking the <code class="docutils literal notranslate"><span class="pre">Node</span> <span class="pre">ID</span></code> column. For
example, we can interpret the row with name <code class="docutils literal notranslate"><span class="pre">rpc_async#aten::mul(worker0</span> <span class="pre">-&gt;</span> <span class="pre">worker1)#remote_op:</span> <span class="pre">mul</span></code>
as a <code class="docutils literal notranslate"><span class="pre">mul</span></code> operation taking place on the remote node, as a result of the RPC sent to <code class="docutils literal notranslate"><span class="pre">worker1</span></code>
from <code class="docutils literal notranslate"><span class="pre">worker0</span></code>, specifying <code class="docutils literal notranslate"><span class="pre">worker1</span></code> to run the builtin <code class="docutils literal notranslate"><span class="pre">mul</span></code> operator on the input tensors.
Note that names of remote operations are prefixed with the name of the RPC event that resulted
in them. For example, remote operations corresponding to the <code class="docutils literal notranslate"><span class="pre">rpc.rpc_async(dst_worker_name,</span> <span class="pre">torch.add,</span> <span class="pre">args=(t1,</span> <span class="pre">t2))</span></code>
call are prefixed with <code class="docutils literal notranslate"><span class="pre">rpc_async#aten::mul(worker0</span> <span class="pre">-&gt;</span> <span class="pre">worker1)</span></code>.</p>
<p>We can also use the profiler to gain insight into user-defined functions that are executed over RPC.
For example, let’s add the following to the above <code class="docutils literal notranslate"><span class="pre">worker</span></code> function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define somewhere outside of worker() func.</span>
<span class="k">def</span> <span class="nf">udf_with_ops</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">time</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">random_tensor</span><span class="p">(),</span> <span class="n">random_tensor</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="c1"># Above code omitted</span>
    <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">()</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
        <span class="n">fut</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">udf_with_ops</span><span class="p">)</span>
        <span class="n">fut</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">())</span>
</pre></div>
</div>
<p>The above code creates a user-defined function that sleeps for 1 second, and then executes various
operators. Similar to what we’ve done above, we send an RPC to the remote worker, specifying it to
run our user-defined function. Running this code should result in the following output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Exact output subject to randomness</span>
<span class="o">--------------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
<span class="n">Name</span>                                                                  <span class="n">Self</span> <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>  <span class="n">Self</span> <span class="n">CPU</span> <span class="n">total</span>   <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>      <span class="n">CPU</span> <span class="n">total</span>        <span class="n">CPU</span> <span class="n">time</span> <span class="n">avg</span>     <span class="n">Number</span> <span class="n">of</span> <span class="n">Calls</span>  <span class="n">Node</span> <span class="n">ID</span>
<span class="o">--------------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)                            0.00%            0.000us          0                1.008s           1.008s           1                0</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: rand            12.58%           80.037us         47.09%           299.589us        149.795us        2                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: empty           15.40%           98.013us         15.40%           98.013us         24.503us         4                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: uniform_        22.85%           145.358us        23.87%           151.870us        75.935us         2                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: is_complex      1.02%            6.512us          1.02%            6.512us          3.256us          2                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: add             25.80%           164.179us        28.43%           180.867us        180.867us        1                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: mul             20.48%           130.293us        31.43%           199.949us        99.975us         2                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: output_nr       0.71%            4.506us          0.71%            4.506us          2.253us          2                1</span>
<span class="n">rpc_async</span><span class="c1">#udf_with_ops(worker0 -&gt; worker1)#remote_op: is_leaf         1.16%            7.367us          1.16%            7.367us          1.842us          4                1</span>
<span class="o">--------------------------------------------------------------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>  <span class="o">---------------</span>
</pre></div>
</div>
<p>Here we can see that the user-defined function has successfully been profiled with its name
<code class="docutils literal notranslate"><span class="pre">(rpc_async#udf_with_ops(worker0</span> <span class="pre">-&gt;</span> <span class="pre">worker1))</span></code>, and has the CPU total time we would roughly expect
(slightly greater than 1s given the <code class="docutils literal notranslate"><span class="pre">sleep</span></code>). Similar to the above profiling output, we can see the
remote operators that have been executed on worker 1 as part of executing this RPC request.</p>
<p>In addition, we can visualize remote execution using the tracing functionality provided by the profiler.
Let’s add the following code to the above <code class="docutils literal notranslate"><span class="pre">worker</span></code> function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
    <span class="c1"># Above code omitted</span>
    <span class="c1"># Will generate trace for above profiling output</span>
    <span class="n">trace_file</span> <span class="o">=</span> <span class="s2">&quot;/tmp/trace.json&quot;</span>
    <span class="n">prof</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">trace_file</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote trace to </span><span class="si">{</span><span class="n">trace_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, we can load the trace file in Chrome (<code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code>). We should see output similar to
the following:</p>
<a class="reference internal image-reference" href="../_images/rpc_trace_img.png"><img alt="../_images/rpc_trace_img.png" src="../_images/rpc_trace_img.png" style="width: 840.0px; height: 253.5px;" /></a>
<p>As we can see, we have traced our RPC requests and can also visualize traces of the remote operations,
in this case, given in the trace row for <code class="docutils literal notranslate"><span class="pre">node_id:</span> <span class="pre">1</span></code>.</p>
</div>
<div class="section" id="example-using-profiler-to-tune-rpc-initialization-parameters">
<h2>Example: Using profiler to tune RPC initialization parameters<a class="headerlink" href="#example-using-profiler-to-tune-rpc-initialization-parameters" title="Permalink to this heading">¶</a></h2>
<p>The following exercise is intended to be a simple example into how one can use statistics and traces
from the profiler to guide tuning RPC initialization parameters. In particular, we will focus on tuning
the <code class="docutils literal notranslate"><span class="pre">num_worker_threads</span></code> parameter used during RPC initialization. First, we modify our <code class="docutils literal notranslate"><span class="pre">rpc.init_rpc</span></code>
call to the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize RPC framework.</span>
<span class="n">num_worker_threads</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="n">worker_name</span><span class="p">,</span>
  <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
  <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
  <span class="n">rpc_backend_options</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span><span class="n">num_worker_threads</span><span class="o">=</span><span class="n">num_worker_threads</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>This will initialize the [TensorPipe RPC backend](<a class="reference external" href="https://pytorch.org/docs/stable/rpc.html#tensorpipe-backend">https://pytorch.org/docs/stable/rpc.html#tensorpipe-backend</a>) with only one thread for processing RPC requests. Next, add
the following function somewhere outside of the <code class="docutils literal notranslate"><span class="pre">worker</span></code> main function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">num_workers_udf_with_ops</span><span class="p">():</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">t</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">t</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
<span class="k">return</span> <span class="n">t</span>
</pre></div>
</div>
<p>This function is mainly intended to be a dummy CPU-intensive function for demonstration purposes. Next, we add the
following RPC and profiling code to our main <code class="docutils literal notranslate"><span class="pre">worker</span></code> function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">()</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
  <span class="n">futs</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">fut</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">num_workers_udf_with_ops</span><span class="p">)</span>
    <span class="n">futs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fut</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">futs</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">())</span>

<span class="n">trace_file</span> <span class="o">=</span> <span class="s2">&quot;/tmp/trace.json&quot;</span>
<span class="c1"># Export the trace.</span>
<span class="n">p</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">trace_file</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote trace to </span><span class="si">{</span><span class="n">trace_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Running the code should return the following profiling statistics (exact output subject to randomness):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-------------------------------------------------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>
                                               <span class="n">Name</span>    <span class="n">Self</span> <span class="n">CPU</span> <span class="o">%</span>      <span class="n">Self</span> <span class="n">CPU</span>   <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>     <span class="n">CPU</span> <span class="n">total</span>  <span class="n">CPU</span> <span class="n">time</span> <span class="n">avg</span>    <span class="c1"># of Calls       Node ID</span>
<span class="o">-------------------------------------------------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">zeros</span>         <span class="mf">0.33</span><span class="o">%</span>     <span class="mf">143.557</span><span class="n">us</span>         <span class="mf">0.47</span><span class="o">%</span>     <span class="mf">203.125</span><span class="n">us</span>      <span class="mf">50.781</span><span class="n">us</span>             <span class="mi">4</span>             <span class="mi">0</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">empty</span>         <span class="mf">0.24</span><span class="o">%</span>     <span class="mf">101.487</span><span class="n">us</span>         <span class="mf">0.24</span><span class="o">%</span>     <span class="mf">101.487</span><span class="n">us</span>      <span class="mf">12.686</span><span class="n">us</span>             <span class="mi">8</span>             <span class="mi">0</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">zero_</span>         <span class="mf">0.04</span><span class="o">%</span>      <span class="mf">17.758</span><span class="n">us</span>         <span class="mf">0.04</span><span class="o">%</span>      <span class="mf">17.758</span><span class="n">us</span>       <span class="mf">4.439</span><span class="n">us</span>             <span class="mi">4</span>             <span class="mi">0</span>
<span class="n">rpc_async</span><span class="c1">#num_workers_udf_with_ops(worker0 -&gt; worker...         0.00%       0.000us             0     189.757ms      47.439ms             4             0</span>
<span class="c1"># additional columns omitted for brevity</span>
<span class="o">-------------------------------------------------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>
</pre></div>
</div>
<p>We can see that there were 4 RPC calls as expected taking a total of 190ms. Let’s now tune the <code class="docutils literal notranslate"><span class="pre">num_worker_threads</span></code>
parameter we set earlier, by changing it to <code class="docutils literal notranslate"><span class="pre">num_worker_threads</span> <span class="pre">=</span> <span class="pre">8</span></code>. Running the code with that change should return
the following profiling statistics (exact output subject to randomness):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-------------------------------------------------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>
                                               <span class="n">Name</span>    <span class="n">Self</span> <span class="n">CPU</span> <span class="o">%</span>      <span class="n">Self</span> <span class="n">CPU</span>   <span class="n">CPU</span> <span class="n">total</span> <span class="o">%</span>     <span class="n">CPU</span> <span class="n">total</span>  <span class="n">CPU</span> <span class="n">time</span> <span class="n">avg</span>    <span class="c1"># of Calls       Node ID</span>
<span class="o">-------------------------------------------------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>  <span class="o">------------</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">zeros</span>         <span class="mf">0.31</span><span class="o">%</span>     <span class="mf">127.320</span><span class="n">us</span>         <span class="mf">0.53</span><span class="o">%</span>     <span class="mf">217.203</span><span class="n">us</span>      <span class="mf">54.301</span><span class="n">us</span>             <span class="mi">4</span>             <span class="mi">0</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">empty</span>         <span class="mf">0.27</span><span class="o">%</span>     <span class="mf">113.529</span><span class="n">us</span>         <span class="mf">0.27</span><span class="o">%</span>     <span class="mf">113.529</span><span class="n">us</span>      <span class="mf">14.191</span><span class="n">us</span>             <span class="mi">8</span>             <span class="mi">0</span>
                                            <span class="n">aten</span><span class="p">::</span><span class="n">zero_</span>         <span class="mf">0.04</span><span class="o">%</span>      <span class="mf">18.032</span><span class="n">us</span>         <span class="mf">0.04</span><span class="o">%</span>      <span class="mf">18.032</span><span class="n">us</span>       <span class="mf">4.508</span><span class="n">us</span>             <span class="mi">4</span>             <span class="mi">0</span>
<span class="n">rpc_async</span><span class="c1">#num_workers_udf_with_ops(worker0 -&gt; worker...         0.00%       0.000us             0      94.776ms      23.694ms             4             0</span>
</pre></div>
</div>
<p>We see a clear ~2x speedup, and hypothesize that this speedup is due to exploiting parallelism on the server due
to the additional cores available. However, how can we ensure that this speedup is due to the increase in cores?
Taking a look at the trace visualization helps with this. Below is the trace when we set <code class="docutils literal notranslate"><span class="pre">num_worker_threads=1</span></code>:</p>
<a class="reference internal image-reference" href="../_images/oneworker.png"><img alt="../_images/oneworker.png" src="../_images/oneworker.png" style="width: 825.0px; height: 97.0px;" /></a>
<p>Focusing on the trace for <code class="docutils literal notranslate"><span class="pre">node</span> <span class="pre">1</span></code>, we can see that the RPCs are ran serially on the server.</p>
<p>Next, the following is the trace where we set <code class="docutils literal notranslate"><span class="pre">num_worker_threads=8</span></code>:</p>
<a class="reference internal image-reference" href="../_images/8_workers.png"><img alt="../_images/8_workers.png" src="../_images/8_workers.png" style="width: 827.5px; height: 180.0px;" /></a>
<p>Based on the latter trace, we can see <code class="docutils literal notranslate"><span class="pre">node</span> <span class="pre">1</span></code> was able to execute the RPCs in parallel on the server, due to having additional
worker threads. To summarize, we were able to leverage both the profiler’s output report and trace to pick an appropriate
<code class="docutils literal notranslate"><span class="pre">num_worker_threads</span></code> parameter for RPC initialization in this simple exercise.</p>
<p>Putting it all together, we have the following code for this recipe:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="nn">rpc</span>
<span class="kn">import</span> <span class="nn">torch.autograd.profiler</span> <span class="k">as</span> <span class="nn">profiler</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">stream</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">random_tensor</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">udf_with_ops</span><span class="p">():</span>
  <span class="kn">import</span> <span class="nn">time</span>
  <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">random_tensor</span><span class="p">(),</span> <span class="n">random_tensor</span><span class="p">()</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">num_workers_udf_with_ops</span><span class="p">():</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
      <span class="n">t</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
      <span class="n">t</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
      <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">relu</span><span class="p">()</span>
      <span class="n">t</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">t</span>

<span class="k">def</span> <span class="nf">worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;localhost&quot;</span>
  <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;29500&quot;</span>
  <span class="n">worker_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span>

  <span class="c1"># Initialize RPC framework.</span>
  <span class="n">num_worker_threads</span> <span class="o">=</span><span class="mi">8</span>
  <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="n">worker_name</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
    <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
    <span class="n">rpc_backend_options</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span><span class="n">num_worker_threads</span><span class="o">=</span><span class="n">num_worker_threads</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">worker_name</span><span class="si">}</span><span class="s2"> successfully initialized RPC.&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">dst_worker_rank</span> <span class="o">=</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">world_size</span>
    <span class="n">dst_worker_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;worker</span><span class="si">{</span><span class="n">dst_worker_rank</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">random_tensor</span><span class="p">(),</span> <span class="n">random_tensor</span><span class="p">()</span>
    <span class="c1"># Send and wait RPC completion under profiling scope.</span>
    <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">()</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
      <span class="n">fut1</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span>
      <span class="n">fut2</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">))</span>
      <span class="c1"># RPCs must be awaited within profiling scope.</span>
      <span class="n">fut1</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
      <span class="n">fut2</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">prof</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">())</span>

    <span class="k">with</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">()</span> <span class="k">as</span> <span class="n">p</span><span class="p">:</span>
      <span class="n">futs</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">fut</span> <span class="o">=</span> <span class="n">rpc</span><span class="o">.</span><span class="n">rpc_async</span><span class="p">(</span><span class="n">dst_worker_name</span><span class="p">,</span> <span class="n">num_workers_udf_with_ops</span><span class="p">)</span>
        <span class="n">futs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fut</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">futs</span><span class="p">:</span>
          <span class="n">f</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">key_averages</span><span class="p">()</span><span class="o">.</span><span class="n">table</span><span class="p">())</span>

    <span class="n">trace_file</span> <span class="o">=</span> <span class="s2">&quot;/tmp/trace.json&quot;</span>
    <span class="c1"># Export the trace.</span>
    <span class="n">p</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">trace_file</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Wrote trace to </span><span class="si">{</span><span class="n">trace_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> waiting for workers and shutting down RPC&quot;</span><span class="p">)</span>
  <span class="n">rpc</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
  <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2"> shutdown RPC&quot;</span><span class="p">)</span>



<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
  <span class="c1"># Run 2 RPC workers.</span>
  <span class="n">world_size</span> <span class="o">=</span> <span class="mi">2</span>
  <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">worker</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,),</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="learn-more">
<h2>Learn More<a class="headerlink" href="#learn-more" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/">pytorch.org</a> for installation instructions, and more documentation
and tutorials.</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/rpc.html">Distributed RPC Framework</a> for RPC framework and API reference.</p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/stable/autograd.html#profiler">Full profiler documentation</a> for profiler documentation.</p></li>
</ul>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="zero_redundancy_optimizer.html" class="btn btn-neutral float-right" title="Shard Optimizer States with ZeroRedundancyOptimizer" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="deployment_with_flask.html" class="btn btn-neutral" title="Deploying with Flask" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr class="rating-hr hr-top">
      <div class="rating-container">
        <div class="rating-prompt">Rate this Tutorial</div>
        <div class="stars-outer">
          <i class="far fa-star" title="1 Star" data-behavior="tutorial-rating" data-count="1"></i>
          <i class="far fa-star" title="2 Stars" data-behavior="tutorial-rating" data-count="2"></i>
          <i class="far fa-star" title="3 Stars" data-behavior="tutorial-rating" data-count="3"></i>
          <i class="far fa-star" title="4 Stars" data-behavior="tutorial-rating" data-count="4"></i>
          <i class="far fa-star" title="5 Stars" data-behavior="tutorial-rating" data-count="5"></i>
        </div>
      </div>
    <hr class="rating-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Profiling PyTorch RPC-Based Workloads</a><ul>
<li><a class="reference internal" href="#requirements">Requirements</a></li>
<li><a class="reference internal" href="#what-is-the-distributed-rpc-framework">What is the Distributed RPC Framework?</a></li>
<li><a class="reference internal" href="#what-is-the-pytorch-profiler">What is the PyTorch Profiler?</a></li>
<li><a class="reference internal" href="#how-to-use-the-profiler-for-rpc-based-workloads">How to use the Profiler for RPC-based workloads</a></li>
<li><a class="reference internal" href="#example-using-profiler-to-tune-rpc-initialization-parameters">Example: Using profiler to tune RPC initialization parameters</a></li>
<li><a class="reference internal" href="#learn-more">Learn More</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/katex.min.js"></script>
         <script src="../_static/auto-render.min.js"></script>
         <script src="../_static/katex_autorenderer.js"></script>
         <script src="../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>

  
//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; isplay: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });

    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Mobile'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>