
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-07-20T23:02:43+00:00" />
    <title>Explicit horizontal fusion with foreach_map and torch.compile &#8212; PyTorch Tutorials 2.7.0+cu126 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=c9393ea6" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=07b0cd76"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/foreach_map';</script>
    <link rel="canonical" href="https://pytorch.org/tutorials/recipes/foreach_map.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compile Time Caching Configuration" href="torch_compile_caching_configuration_tutorial.html" />
    <link rel="prev" title="(beta) Utilizing Torch Function modes with torch.compile" href="torch_compile_torch_function_modes.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>
<link rel="canonical" href="/recipes/foreach_map.html" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects.
  document.addEventListener('DOMContentLoaded', function() {
    // Hide cookie banner on local environments
    if (window.location.hostname === 'localhost' ||
        window.location.hostname === '0.0.0.0' ||
        window.location.hostname === '127.0.0.1' ||
        window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy" content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
   height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
   <!-- End Google Tag Manager (noscript) -->
   <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
   new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
   j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
   'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
   j.onload = function() {
     window.dispatchEvent(new Event('gtm_loaded'));
     console.log('GTM loaded successfully');
   };
   })(window,document,'script','dataLayer','GTM-T8XT4PS');
</script>
 <!-- End Google Tag Manager -->
 <!-- Facebook Pixel Code -->
<script>
   !function(f,b,e,v,n,t,s)
   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
   n.callMethod.apply(n,arguments):n.queue.push(arguments)};
   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
   n.queue=[];t=b.createElement(e);t.async=!0;
   t.src=v;s=b.getElementsByTagName(e)[0];
   s.parentNode.insertBefore(t,s)}(window,document,'script',
   'https://connect.facebook.net/en_US/fbevents.js');
   fbq('init', '243028289693773');
   fbq('track', 'PageView');
</script>
<script>
   document.documentElement.setAttribute('data-version', 'v2.7.0+cu126');
 </script>
<noscript>
   <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1"/>
</noscript>
<script>
   function gtag() {
    window.dataLayer.push(arguments);
   }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function(e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>

  </head>
<body data-feedback-url="https://github.com/pytorch/tutorials" class="pytorch-body">
     <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started">Get Started</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/pytorch-domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
   
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.7.0+cu126</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../unstable_index.html">
    Unstable
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../unstable_index.html">
    Unstable
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_backend_ipex.html">Intel® Extension for PyTorch* Backend on Intel® CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda_rpc.html">Direct Device-to-Device Communication with TensorPipe CUDA RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference_tuning_on_aws_graviton.html">(Beta) PyTorch Inference Performance Tuning on AWS Graviton Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="amx.html">Leverage Intel® Advanced Matrix Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../recipes_index.html" class="nav-link">Recipes</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Explicit...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article"id="pytorch-article">
   <!-- Hidden breadcrumb schema for SEO only -->
   <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
        <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <link itemprop="item" href="../recipes_index.html">
          <meta itemprop="name" content="Recipes">
          <meta itemprop="position" content="1">
        </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Explicit horizontal fusion with foreach_map and torch.compile">
        <meta itemprop="position" content="2">
      </div>
   </div>

    
    <script>
      if((window.location.href.indexOf("/unstable/")!= -1) && (window.location.href.indexOf("/unstable/unstable_index")< 1))
        {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function() {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/foreach_map</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
         <div id="google-colab-link">
         <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
         <div class="call-to-action-desktop-view">Run in Google Colab</div>
         <div class="call-to-action-mobile-view">Colab</div>
         </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
         <div id="download-notebook-link">
         <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
         <div class="call-to-action-desktop-view">Download Notebook</div>
         <div class="call-to-action-mobile-view">Notebook</div>
         </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
         <div id="github-view-link">
         <img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
         <div class="call-to-action-desktop-view">View on GitHub</div>
         <div class="call-to-action-mobile-view">GitHub</div>
         </div>
      </a>
    </div>
    
    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-foreach-map-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="explicit-horizontal-fusion-with-foreach-map-and-torch-compile">
<span id="sphx-glr-recipes-foreach-map-py"></span><h1>Explicit horizontal fusion with foreach_map and torch.compile<a class="headerlink" href="#explicit-horizontal-fusion-with-foreach-map-and-torch-compile" title="Link to this heading">#</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<dl class="simple">
<dt>Horizontal fusion is a key optimization in ML compilers. In eager,</dt><dd><p>this is typically expressed using the torch._foreach* ops which parallelizes
operations across a list of tensors. However, supporting all possible permutations
of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map
allows conversion of any pointwise op in <code class="docutils literal notranslate"><span class="pre">torch</span></code> to a horiztonally fused foreach
variant. In this tutorial, we will demonstrate how to implement the Adam optimizer
with <code class="docutils literal notranslate"><span class="pre">foreach_map</span></code> to generate a fully fused kernel.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This recipe describes a prototype feature. Prototype features are typically
at an early stage for feedback and testing and are subject to change.</p>
</div>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>PyTorch v2.7.0 or later</p></li>
</ul>
<section id="model-setup">
<h3>Model Setup<a class="headerlink" href="#model-setup" title="Link to this heading">#</a></h3>
<p>For this example, we’ll use a simple sequence of linear layers.
We instantiate an independent copy to compare the two optimizer implementations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># exit cleanly if we are on a device that doesn&#39;t support ``torch.compile``</span>
<span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because torch.compile is not supported on this device.&quot;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create simple model</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># run forward pass</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># run backward to populate the grads for our optimizer below</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="helper-functions-for-foreach-map-implementation">
<h3>Helper functions for foreach_map implementation<a class="headerlink" href="#helper-functions-for-foreach-map-implementation" title="Link to this heading">#</a></h3>
<p>In this section, we’ll begin our implementation of the Adam optimizer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._higher_order_ops.foreach_map</span><span class="w"> </span><span class="kn">import</span> <span class="n">foreach_map</span>

<span class="c1"># Helper function to extract optimizer states from a torch.optim.Adam instance</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_inputs</span><span class="p">(</span><span class="n">optim</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optim</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
            <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg&quot;</span><span class="p">])</span>
            <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg_sq&quot;</span><span class="p">])</span>
            <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">steps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avg_sqs</span>


<span class="c1"># Functions to update the different optimizer states</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_exp_avg_sq</span><span class="p">(</span><span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">beta2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">exp_avg</span><span class="p">,</span> <span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">bias_correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="n">bias_correction2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta2</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">lr</span> <span class="o">/</span> <span class="n">bias_correction1</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">bias_correction2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">))</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">eps</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">(</span><span class="n">param</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">div</span></a><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">))</span>

<span class="c1"># Our full Adam implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">foreach_map_adam</span><span class="p">(</span>
    <span class="n">steps</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">exp_avgs</span><span class="p">,</span>
    <span class="n">exp_avg_sqs</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">with</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
        <span class="c1"># update step</span>
        <span class="n">updated_steps</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">updated_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weight_decay</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">,</span> <span class="p">(</span><span class="n">grads</span><span class="p">,),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="c1"># Higher-order operators (HOPs) cannot have multiple outputs at the moment</span>
        <span class="c1"># need to call foreach_map once for each output</span>
        <span class="n">exp_avgs_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp" title="torch.lerp" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span></a><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
        <span class="n">exp_avgs_sq_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="n">update_exp_avg_sq</span><span class="p">,</span> <span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">beta2</span><span class="p">)</span>
        <span class="n">params_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span>
            <span class="n">update_param</span><span class="p">,</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">steps</span><span class="p">,</span>
            <span class="n">exp_avgs_updated</span><span class="p">,</span>
            <span class="n">exp_avgs_sq_updated</span><span class="p">,</span>
            <span class="n">beta1</span><span class="p">,</span>
            <span class="n">beta2</span><span class="p">,</span>
            <span class="n">lr</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Higher-order operators (HOPs) don&#39;t support input mutation today</span>
        <span class="c1"># so manually  update the states in-place</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avgs_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">exp_avgs_sq_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">params_updated</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</section>
<section id="setting-up-and-running-the-compiled-kernel">
<h3>Setting up and running the compiled kernel<a class="headerlink" href="#setting-up-and-running-the-compiled-kernel" title="Link to this heading">#</a></h3>
<p>In this section, we’ll run our Adam optimizer
and compare the results</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is only supported on CUDA devices that have a compute capability of 7.0 or higher.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model_copy</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># warm up the optimizer state dict</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager_copy</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="p">)</span>
<span class="n">compiled_adam</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foreach_map_adam</span><span class="p">)</span>

<span class="c1"># optionally view the output code</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs" class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">output_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Warmup runs to compile the function</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
    <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">for</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">],</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a><span class="p">)</span>

<span class="c1"># Benchmark performance</span>

 <span class="c1"># Let&#39;s define a helpful benchmarking function:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">benchmark</span>

<span class="k">def</span><span class="w"> </span><span class="nf">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">benchmark</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span>
        <span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;f(*args, **kwargs)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span> <span class="n">f</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">t0</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mf">1e6</span>

<span class="n">eager_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">)</span>
<span class="n">compiled_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">eager_runtime</span> <span class="o">&gt;</span> <span class="n">compiled_runtime</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;eager runtime: </span><span class="si">{</span><span class="n">eager_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;compiled runtime: </span><span class="si">{</span><span class="n">compiled_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] Output code:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] # AOT ID: [&#39;0_inference&#39;]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import torch
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import math
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import random
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import os
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import tempfile
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from math import inf, nan
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from cmath import nanj
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch import device, empty_strided
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import triton
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import triton.language as tl
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] aten = torch.ops.aten
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] _quantized = torch.ops._quantized
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] async_compile = AsyncCompile()
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/ej/cejr7t4zzqo7llcoxga7clgyc6gs3676lsm4dvilpfw64kudp2ns.py
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] # Source node to ATen node mapping:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] triton_for_fused_0 = async_compile.triton(&#39;triton_for_fused_0&#39;, &#39;&#39;&#39;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import triton
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] import triton.language as tl
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] @triton_heuristics.foreach(
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_warps=8,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr6&#39;: &#39;*fp32&#39;, &#39;out_ptr7&#39;: &#39;*fp32&#39;, &#39;out_ptr8&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr24&#39;: &#39;*fp32&#39;, &#39;out_ptr25&#39;: &#39;*fp32&#39;, &#39;out_ptr26&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr42&#39;: &#39;*fp32&#39;, &#39;out_ptr43&#39;: &#39;*fp32&#39;, &#39;out_ptr44&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr60&#39;: &#39;*fp32&#39;, &#39;out_ptr61&#39;: &#39;*fp32&#39;, &#39;out_ptr62&#39;: &#39;*fp32&#39;, &#39;out_ptr69&#39;: &#39;*fp32&#39;, &#39;out_ptr70&#39;: &#39;*fp32&#39;, &#39;out_ptr71&#39;: &#39;*fp32&#39;, &#39;out_ptr78&#39;: &#39;*fp32&#39;, &#39;out_ptr79&#39;: &#39;*fp32&#39;, &#39;out_ptr80&#39;: &#39;*fp32&#39;, &#39;out_ptr87&#39;: &#39;*fp32&#39;, &#39;out_ptr88&#39;: &#39;*fp32&#39;, &#39;out_ptr89&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_0&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr24&#39;, &#39;out_ptr25&#39;, &#39;out_ptr26&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr42&#39;, &#39;out_ptr43&#39;, &#39;out_ptr44&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr6&#39;, &#39;out_ptr60&#39;, &#39;out_ptr61&#39;, &#39;out_ptr62&#39;, &#39;out_ptr69&#39;, &#39;out_ptr7&#39;, &#39;out_ptr70&#39;, &#39;out_ptr71&#39;, &#39;out_ptr78&#39;, &#39;out_ptr79&#39;, &#39;out_ptr8&#39;, &#39;out_ptr80&#39;, &#39;out_ptr87&#39;, &#39;out_ptr88&#39;, &#39;out_ptr89&#39;], &#39;backend_hash&#39;: &#39;1E2C16421D4C3DBA4AD92BFC4278A3CB24C43DEDA6EE7FF9E3FBB1DBB80802DB&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] )
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] @triton.jit
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] def triton_for_fused_0(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr6, out_ptr7, out_ptr8, out_ptr15, out_ptr16, out_ptr17, out_ptr24, out_ptr25, out_ptr26, out_ptr33, out_ptr34, out_ptr35, out_ptr42, out_ptr43, out_ptr44, out_ptr51, out_ptr52, out_ptr53, out_ptr60, out_ptr61, out_ptr62, out_ptr69, out_ptr70, out_ptr71, out_ptr78, out_ptr79, out_ptr80, out_ptr87, out_ptr88, out_ptr89):
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     pid = tl.program_id(0)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1024
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     if pid &lt; num_xblocks_0:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x0 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp5 = tl.load(in_ptr0 + (x0), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp6 = tl.load(in_ptr1 + (x0), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp11 = tl.load(in_ptr2 + (x0), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp18 = tl.load(in_ptr3 + (x0), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp20 = in_ptr4
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp0 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp1 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp2 = tmp0 &gt;= tmp1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp3 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp4 = tl.where(tmp2, tmp3, tmp0)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp7 = tmp5 - tmp6
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp8 = tmp4 * tmp7
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp9 = tl.where(tmp2, tmp5, tmp6)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp10 = tmp8 + tmp9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp12 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp13 = tmp11 * tmp12
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp14 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp15 = tmp5 * tmp14
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp16 = tmp15 * tmp5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp17 = tmp13 + tmp16
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp19 = libdevice.sqrt(tmp17)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp21 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp22 = tmp20 + tmp21
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp23 = libdevice.pow(tmp12, tmp22)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp24 = tmp21 - tmp23
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp25 = libdevice.sqrt(tmp24)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp26 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp27 = libdevice.pow(tmp26, tmp22)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp28 = tmp21 - tmp27
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp29 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp30 = (tmp29 / tmp28)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp31 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp32 = tmp30 * tmp31
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp33 = -tmp32
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp34 = tmp25 * tmp33
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp35 = (tmp19 / tmp34)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp36 = (tmp29 / tmp33)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp37 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp38 = tmp36 * tmp37
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp39 = tmp35 + tmp38
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp40 = (tmp10 / tmp39)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp41 = tmp18 + tmp40
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr6 + (x0), tmp41, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr7 + (x0), tmp10, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr8 + (x0), tmp17, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_1:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x1 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp47 = tl.load(in_ptr5 + (x1), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp48 = tl.load(in_ptr6 + (x1), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp53 = tl.load(in_ptr7 + (x1), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp60 = tl.load(in_ptr8 + (x1), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp62 = in_ptr9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp42 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp43 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp44 = tmp42 &gt;= tmp43
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp45 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp46 = tl.where(tmp44, tmp45, tmp42)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp49 = tmp47 - tmp48
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp50 = tmp46 * tmp49
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp51 = tl.where(tmp44, tmp47, tmp48)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp52 = tmp50 + tmp51
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp54 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp55 = tmp53 * tmp54
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp56 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp57 = tmp47 * tmp56
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp58 = tmp57 * tmp47
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp59 = tmp55 + tmp58
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp61 = libdevice.sqrt(tmp59)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp63 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp64 = tmp62 + tmp63
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp65 = libdevice.pow(tmp54, tmp64)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp66 = tmp63 - tmp65
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp67 = libdevice.sqrt(tmp66)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp68 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp69 = libdevice.pow(tmp68, tmp64)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp70 = tmp63 - tmp69
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp71 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp72 = (tmp71 / tmp70)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp73 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp74 = tmp72 * tmp73
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp75 = -tmp74
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp76 = tmp67 * tmp75
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp77 = (tmp61 / tmp76)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp78 = (tmp71 / tmp75)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp79 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp80 = tmp78 * tmp79
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp81 = tmp77 + tmp80
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp82 = (tmp52 / tmp81)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp83 = tmp60 + tmp82
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr15 + (x1), tmp83, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr16 + (x1), tmp52, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr17 + (x1), tmp59, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_2:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x2 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp89 = tl.load(in_ptr10 + (x2), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp90 = tl.load(in_ptr11 + (x2), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp95 = tl.load(in_ptr12 + (x2), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp102 = tl.load(in_ptr13 + (x2), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp104 = in_ptr14
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp84 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp85 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp86 = tmp84 &gt;= tmp85
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp87 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp88 = tl.where(tmp86, tmp87, tmp84)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp91 = tmp89 - tmp90
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp92 = tmp88 * tmp91
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp93 = tl.where(tmp86, tmp89, tmp90)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp94 = tmp92 + tmp93
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp96 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp97 = tmp95 * tmp96
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp98 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp99 = tmp89 * tmp98
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp100 = tmp99 * tmp89
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp101 = tmp97 + tmp100
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp103 = libdevice.sqrt(tmp101)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp105 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp106 = tmp104 + tmp105
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp107 = libdevice.pow(tmp96, tmp106)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp108 = tmp105 - tmp107
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp109 = libdevice.sqrt(tmp108)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp110 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp111 = libdevice.pow(tmp110, tmp106)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp112 = tmp105 - tmp111
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp113 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp114 = (tmp113 / tmp112)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp115 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp116 = tmp114 * tmp115
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp117 = -tmp116
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp118 = tmp109 * tmp117
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp119 = (tmp103 / tmp118)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp120 = (tmp113 / tmp117)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp121 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp122 = tmp120 * tmp121
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp123 = tmp119 + tmp122
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp124 = (tmp94 / tmp123)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp125 = tmp102 + tmp124
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr24 + (x2), tmp125, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr25 + (x2), tmp94, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr26 + (x2), tmp101, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_3:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_2
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x3 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp131 = tl.load(in_ptr15 + (x3), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp132 = tl.load(in_ptr16 + (x3), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp137 = tl.load(in_ptr17 + (x3), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp144 = tl.load(in_ptr18 + (x3), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp146 = in_ptr19
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp126 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp127 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp128 = tmp126 &gt;= tmp127
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp129 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp130 = tl.where(tmp128, tmp129, tmp126)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp133 = tmp131 - tmp132
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp134 = tmp130 * tmp133
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp135 = tl.where(tmp128, tmp131, tmp132)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp136 = tmp134 + tmp135
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp138 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp139 = tmp137 * tmp138
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp140 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp141 = tmp131 * tmp140
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp142 = tmp141 * tmp131
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp143 = tmp139 + tmp142
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp145 = libdevice.sqrt(tmp143)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp147 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp148 = tmp146 + tmp147
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp149 = libdevice.pow(tmp138, tmp148)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp150 = tmp147 - tmp149
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp151 = libdevice.sqrt(tmp150)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp152 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp153 = libdevice.pow(tmp152, tmp148)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp154 = tmp147 - tmp153
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp155 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp156 = (tmp155 / tmp154)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp157 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp158 = tmp156 * tmp157
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp159 = -tmp158
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp160 = tmp151 * tmp159
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp161 = (tmp145 / tmp160)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp162 = (tmp155 / tmp159)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp163 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp164 = tmp162 * tmp163
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp165 = tmp161 + tmp164
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp166 = (tmp136 / tmp165)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp167 = tmp144 + tmp166
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr33 + (x3), tmp167, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr34 + (x3), tmp136, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr35 + (x3), tmp143, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_4:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_3
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x4 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp173 = tl.load(in_ptr20 + (x4), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp174 = tl.load(in_ptr21 + (x4), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp179 = tl.load(in_ptr22 + (x4), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp186 = tl.load(in_ptr23 + (x4), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp188 = in_ptr24
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp168 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp169 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp170 = tmp168 &gt;= tmp169
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp171 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp172 = tl.where(tmp170, tmp171, tmp168)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp175 = tmp173 - tmp174
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp176 = tmp172 * tmp175
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp177 = tl.where(tmp170, tmp173, tmp174)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp178 = tmp176 + tmp177
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp180 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp181 = tmp179 * tmp180
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp182 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp183 = tmp173 * tmp182
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp184 = tmp183 * tmp173
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp185 = tmp181 + tmp184
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp187 = libdevice.sqrt(tmp185)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp189 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp190 = tmp188 + tmp189
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp191 = libdevice.pow(tmp180, tmp190)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp192 = tmp189 - tmp191
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp193 = libdevice.sqrt(tmp192)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp194 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp195 = libdevice.pow(tmp194, tmp190)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp196 = tmp189 - tmp195
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp197 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp198 = (tmp197 / tmp196)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp199 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp200 = tmp198 * tmp199
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp201 = -tmp200
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp202 = tmp193 * tmp201
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp203 = (tmp187 / tmp202)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp204 = (tmp197 / tmp201)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp205 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp206 = tmp204 * tmp205
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp207 = tmp203 + tmp206
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp208 = (tmp178 / tmp207)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp209 = tmp186 + tmp208
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr42 + (x4), tmp209, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr43 + (x4), tmp178, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr44 + (x4), tmp185, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_5:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_4
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x5 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp215 = tl.load(in_ptr25 + (x5), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp216 = tl.load(in_ptr26 + (x5), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp221 = tl.load(in_ptr27 + (x5), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp228 = tl.load(in_ptr28 + (x5), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp230 = in_ptr29
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp210 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp211 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp212 = tmp210 &gt;= tmp211
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp213 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp214 = tl.where(tmp212, tmp213, tmp210)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp217 = tmp215 - tmp216
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp218 = tmp214 * tmp217
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp219 = tl.where(tmp212, tmp215, tmp216)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp220 = tmp218 + tmp219
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp222 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp223 = tmp221 * tmp222
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp224 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp225 = tmp215 * tmp224
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp226 = tmp225 * tmp215
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp227 = tmp223 + tmp226
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp229 = libdevice.sqrt(tmp227)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp231 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp232 = tmp230 + tmp231
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp233 = libdevice.pow(tmp222, tmp232)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp234 = tmp231 - tmp233
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp235 = libdevice.sqrt(tmp234)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp236 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp237 = libdevice.pow(tmp236, tmp232)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp238 = tmp231 - tmp237
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp239 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp240 = (tmp239 / tmp238)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp241 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp242 = tmp240 * tmp241
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp243 = -tmp242
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp244 = tmp235 * tmp243
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp245 = (tmp229 / tmp244)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp246 = (tmp239 / tmp243)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp247 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp248 = tmp246 * tmp247
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp249 = tmp245 + tmp248
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp250 = (tmp220 / tmp249)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp251 = tmp228 + tmp250
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr51 + (x5), tmp251, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr52 + (x5), tmp220, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr53 + (x5), tmp227, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_6:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x6 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp257 = tl.load(in_ptr30 + (x6), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp258 = tl.load(in_ptr31 + (x6), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp263 = tl.load(in_ptr32 + (x6), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp270 = tl.load(in_ptr33 + (x6), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp272 = in_ptr34
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp252 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp253 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp254 = tmp252 &gt;= tmp253
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp255 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp256 = tl.where(tmp254, tmp255, tmp252)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp259 = tmp257 - tmp258
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp260 = tmp256 * tmp259
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp261 = tl.where(tmp254, tmp257, tmp258)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp262 = tmp260 + tmp261
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp264 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp265 = tmp263 * tmp264
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp266 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp267 = tmp257 * tmp266
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp268 = tmp267 * tmp257
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp269 = tmp265 + tmp268
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp271 = libdevice.sqrt(tmp269)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp273 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp274 = tmp272 + tmp273
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp275 = libdevice.pow(tmp264, tmp274)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp276 = tmp273 - tmp275
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp277 = libdevice.sqrt(tmp276)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp278 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp279 = libdevice.pow(tmp278, tmp274)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp280 = tmp273 - tmp279
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp281 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp282 = (tmp281 / tmp280)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp283 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp284 = tmp282 * tmp283
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp285 = -tmp284
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp286 = tmp277 * tmp285
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp287 = (tmp271 / tmp286)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp288 = (tmp281 / tmp285)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp289 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp290 = tmp288 * tmp289
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp291 = tmp287 + tmp290
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp292 = (tmp262 / tmp291)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp293 = tmp270 + tmp292
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr60 + (x6), tmp293, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr61 + (x6), tmp262, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr62 + (x6), tmp269, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_7:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_6
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x7 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp299 = tl.load(in_ptr35 + (x7), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp300 = tl.load(in_ptr36 + (x7), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp305 = tl.load(in_ptr37 + (x7), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp312 = tl.load(in_ptr38 + (x7), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp314 = in_ptr39
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp294 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp295 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp296 = tmp294 &gt;= tmp295
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp297 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp298 = tl.where(tmp296, tmp297, tmp294)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp301 = tmp299 - tmp300
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp302 = tmp298 * tmp301
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp303 = tl.where(tmp296, tmp299, tmp300)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp304 = tmp302 + tmp303
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp306 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp307 = tmp305 * tmp306
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp308 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp309 = tmp299 * tmp308
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp310 = tmp309 * tmp299
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp311 = tmp307 + tmp310
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp313 = libdevice.sqrt(tmp311)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp315 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp316 = tmp314 + tmp315
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp317 = libdevice.pow(tmp306, tmp316)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp318 = tmp315 - tmp317
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp319 = libdevice.sqrt(tmp318)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp320 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp321 = libdevice.pow(tmp320, tmp316)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp322 = tmp315 - tmp321
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp323 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp324 = (tmp323 / tmp322)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp325 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp326 = tmp324 * tmp325
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp327 = -tmp326
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp328 = tmp319 * tmp327
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp329 = (tmp313 / tmp328)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp330 = (tmp323 / tmp327)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp331 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp332 = tmp330 * tmp331
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp333 = tmp329 + tmp332
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp334 = (tmp304 / tmp333)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp335 = tmp312 + tmp334
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr69 + (x7), tmp335, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr70 + (x7), tmp304, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr71 + (x7), tmp311, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_8:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_7
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x8 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp341 = tl.load(in_ptr40 + (x8), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp342 = tl.load(in_ptr41 + (x8), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp347 = tl.load(in_ptr42 + (x8), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp354 = tl.load(in_ptr43 + (x8), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp356 = in_ptr44
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp336 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp337 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp338 = tmp336 &gt;= tmp337
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp339 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp340 = tl.where(tmp338, tmp339, tmp336)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp343 = tmp341 - tmp342
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp344 = tmp340 * tmp343
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp345 = tl.where(tmp338, tmp341, tmp342)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp346 = tmp344 + tmp345
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp348 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp349 = tmp347 * tmp348
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp350 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp351 = tmp341 * tmp350
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp352 = tmp351 * tmp341
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp353 = tmp349 + tmp352
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp355 = libdevice.sqrt(tmp353)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp357 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp358 = tmp356 + tmp357
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp359 = libdevice.pow(tmp348, tmp358)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp360 = tmp357 - tmp359
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp361 = libdevice.sqrt(tmp360)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp362 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp363 = libdevice.pow(tmp362, tmp358)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp364 = tmp357 - tmp363
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp365 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp366 = (tmp365 / tmp364)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp367 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp368 = tmp366 * tmp367
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp369 = -tmp368
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp370 = tmp361 * tmp369
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp371 = (tmp355 / tmp370)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp372 = (tmp365 / tmp369)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp373 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp374 = tmp372 * tmp373
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp375 = tmp371 + tmp374
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp376 = (tmp346 / tmp375)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp377 = tmp354 + tmp376
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr78 + (x8), tmp377, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr79 + (x8), tmp346, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr80 + (x8), tmp353, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     elif pid &lt; num_xblocks_9:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pid_offset = pid - num_xblocks_8
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xnumel = 1048576
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         r0_numel = 1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         x9 = xindex
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp383 = tl.load(in_ptr45 + (x9), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp384 = tl.load(in_ptr46 + (x9), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp389 = tl.load(in_ptr47 + (x9), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp396 = tl.load(in_ptr48 + (x9), None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp398 = in_ptr49
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp378 = 0.09999999999999998
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp379 = 0.5
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp380 = tmp378 &gt;= tmp379
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp381 = -0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp382 = tl.where(tmp380, tmp381, tmp378)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp385 = tmp383 - tmp384
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp386 = tmp382 * tmp385
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp387 = tl.where(tmp380, tmp383, tmp384)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp388 = tmp386 + tmp387
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp390 = 0.999
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp391 = tmp389 * tmp390
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp392 = 0.0010000000000000009
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp393 = tmp383 * tmp392
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp394 = tmp393 * tmp383
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp395 = tmp391 + tmp394
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp397 = libdevice.sqrt(tmp395)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp399 = 1.0
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp400 = tmp398 + tmp399
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp401 = libdevice.pow(tmp390, tmp400)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp402 = tmp399 - tmp401
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp403 = libdevice.sqrt(tmp402)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp404 = 0.9
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp405 = libdevice.pow(tmp404, tmp400)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp406 = tmp399 - tmp405
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp407 = tl.full([1], 1, tl.int32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp408 = (tmp407 / tmp406)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp409 = 0.001
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp410 = tmp408 * tmp409
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp411 = -tmp410
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp412 = tmp403 * tmp411
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp413 = (tmp397 / tmp412)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp414 = (tmp407 / tmp411)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp415 = 1e-08
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp416 = tmp414 * tmp415
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp417 = tmp413 + tmp416
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp418 = (tmp388 / tmp417)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tmp419 = tmp396 + tmp418
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr87 + (x9), tmp419, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr88 + (x9), tmp388, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         tl.store(out_ptr89 + (x9), tmp395, None)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     else:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         pass
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] cpp_fused__foreach_copy_1 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] #include &quot;/tmp/torchinductor_ci-user/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h&quot;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] extern &quot;C&quot;  void kernel(const float* in_ptr0,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr1,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr2,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr3,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr4,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr5,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr6,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr7,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr8,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        const float* in_ptr9,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr1,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr3,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr5,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr7,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr9,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr11,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr13,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr15,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr17,
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                        float* out_ptr19)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr11[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr13[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr15[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr17[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             {
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]                 out_ptr19[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]             }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] }
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] &#39;&#39;&#39;)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] async_compile.wait(globals())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] del async_compile
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] def call(args):
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     args.clear()
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg10_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg11_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg12_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg13_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg14_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg15_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg16_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg17_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg18_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg19_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg20_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg21_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg22_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg23_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg24_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg25_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg26_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg27_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg28_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg29_1, (), ())
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         torch.cuda.set_device(0)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         triton_for_fused_0.run(arg1_1, arg30_1, arg40_1, arg0_1, arg20_1.item(), arg3_1, arg31_1, arg41_1, arg2_1, arg21_1.item(), arg5_1, arg32_1, arg42_1, arg4_1, arg22_1.item(), arg7_1, arg33_1, arg43_1, arg6_1, arg23_1.item(), arg9_1, arg34_1, arg44_1, arg8_1, arg24_1.item(), arg11_1, arg35_1, arg45_1, arg10_1, arg25_1.item(), arg13_1, arg36_1, arg46_1, arg12_1, arg26_1.item(), arg15_1, arg37_1, arg47_1, arg14_1, arg27_1.item(), arg17_1, arg38_1, arg48_1, arg16_1, arg28_1.item(), arg19_1, arg39_1, arg49_1, arg18_1, arg29_1.item(), arg0_1, arg30_1, arg40_1, arg2_1, arg31_1, arg41_1, arg4_1, arg32_1, arg42_1, arg6_1, arg33_1, arg43_1, arg8_1, arg34_1, arg44_1, arg10_1, arg35_1, arg45_1, arg12_1, arg36_1, arg46_1, arg14_1, arg37_1, arg47_1, arg16_1, arg38_1, arg48_1, arg18_1, arg39_1, arg49_1, stream=stream0)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg0_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg10_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg11_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg12_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg13_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg14_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg15_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg16_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg17_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg18_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg19_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg1_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg2_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg30_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg31_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg32_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg33_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg34_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg35_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg36_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg37_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg38_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg39_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg3_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg40_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg41_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg42_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg43_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg44_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg45_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg46_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg47_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg48_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg49_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg4_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg5_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg6_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg7_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg8_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]         del arg9_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     cpp_fused__foreach_copy_1(arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg20_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg21_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg22_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg23_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg24_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg25_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg26_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg27_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg28_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     del arg29_1
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     return ()
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg10_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg11_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg12_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg13_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg14_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg15_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg16_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg17_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg18_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg19_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg20_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg21_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg22_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg23_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg24_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg25_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg26_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg27_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg28_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg29_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code] if __name__ == &quot;__main__&quot;:
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0806 16:44:49.534000 22411 torch/_inductor/graph.py:2104] [0/0] [__output_code]
V0806 16:44:49.581000 22411 torch/_inductor/graph.py:2115] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/bx/cbxwuspm7iljtlkypwgm5a6rrandaew4wqmdmng4lzas4ogomxpw.py
I0806 16:44:51.104000 22411 torch/_inductor/graph.py:2149] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/bx/cbxwuspm7iljtlkypwgm5a6rrandaew4wqmdmng4lzas4ogomxpw.py
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] Output code:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] # AOT ID: [&#39;1_inference&#39;]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import torch
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import math
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import random
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import os
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import tempfile
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from math import inf, nan
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from cmath import nanj
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.utils import maybe_profile
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch import device, empty_strided
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import triton
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import triton.language as tl
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] aten = torch.ops.aten
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] inductor_ops = torch.ops.inductor
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] _quantized = torch.ops._quantized
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] async_compile = AsyncCompile()
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/ej/cejr7t4zzqo7llcoxga7clgyc6gs3676lsm4dvilpfw64kudp2ns.py
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] # Source node to ATen node mapping:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] triton_for_fused_0 = async_compile.triton(&#39;triton_for_fused_0&#39;, &#39;&#39;&#39;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import triton
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] import triton.language as tl
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] @triton_heuristics.foreach(
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_warps=8,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr6&#39;: &#39;*fp32&#39;, &#39;out_ptr7&#39;: &#39;*fp32&#39;, &#39;out_ptr8&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr24&#39;: &#39;*fp32&#39;, &#39;out_ptr25&#39;: &#39;*fp32&#39;, &#39;out_ptr26&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr42&#39;: &#39;*fp32&#39;, &#39;out_ptr43&#39;: &#39;*fp32&#39;, &#39;out_ptr44&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr60&#39;: &#39;*fp32&#39;, &#39;out_ptr61&#39;: &#39;*fp32&#39;, &#39;out_ptr62&#39;: &#39;*fp32&#39;, &#39;out_ptr69&#39;: &#39;*fp32&#39;, &#39;out_ptr70&#39;: &#39;*fp32&#39;, &#39;out_ptr71&#39;: &#39;*fp32&#39;, &#39;out_ptr78&#39;: &#39;*fp32&#39;, &#39;out_ptr79&#39;: &#39;*fp32&#39;, &#39;out_ptr80&#39;: &#39;*fp32&#39;, &#39;out_ptr87&#39;: &#39;*fp32&#39;, &#39;out_ptr88&#39;: &#39;*fp32&#39;, &#39;out_ptr89&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_0&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr24&#39;, &#39;out_ptr25&#39;, &#39;out_ptr26&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr42&#39;, &#39;out_ptr43&#39;, &#39;out_ptr44&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr6&#39;, &#39;out_ptr60&#39;, &#39;out_ptr61&#39;, &#39;out_ptr62&#39;, &#39;out_ptr69&#39;, &#39;out_ptr7&#39;, &#39;out_ptr70&#39;, &#39;out_ptr71&#39;, &#39;out_ptr78&#39;, &#39;out_ptr79&#39;, &#39;out_ptr8&#39;, &#39;out_ptr80&#39;, &#39;out_ptr87&#39;, &#39;out_ptr88&#39;, &#39;out_ptr89&#39;], &#39;backend_hash&#39;: &#39;1E2C16421D4C3DBA4AD92BFC4278A3CB24C43DEDA6EE7FF9E3FBB1DBB80802DB&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] )
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] @triton.jit
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] def triton_for_fused_0(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr6, out_ptr7, out_ptr8, out_ptr15, out_ptr16, out_ptr17, out_ptr24, out_ptr25, out_ptr26, out_ptr33, out_ptr34, out_ptr35, out_ptr42, out_ptr43, out_ptr44, out_ptr51, out_ptr52, out_ptr53, out_ptr60, out_ptr61, out_ptr62, out_ptr69, out_ptr70, out_ptr71, out_ptr78, out_ptr79, out_ptr80, out_ptr87, out_ptr88, out_ptr89):
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     pid = tl.program_id(0)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     XBLOCK: tl.constexpr = 1024
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     if pid &lt; num_xblocks_0:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x0 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp5 = tl.load(in_ptr0 + (x0), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp6 = tl.load(in_ptr1 + (x0), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp11 = tl.load(in_ptr2 + (x0), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp18 = tl.load(in_ptr3 + (x0), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp20 = in_ptr4
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp0 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp1 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp2 = tmp0 &gt;= tmp1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp3 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp4 = tl.where(tmp2, tmp3, tmp0)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp7 = tmp5 - tmp6
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp8 = tmp4 * tmp7
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp9 = tl.where(tmp2, tmp5, tmp6)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp10 = tmp8 + tmp9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp12 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp13 = tmp11 * tmp12
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp14 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp15 = tmp5 * tmp14
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp16 = tmp15 * tmp5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp17 = tmp13 + tmp16
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp19 = libdevice.sqrt(tmp17)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp21 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp22 = tmp20 + tmp21
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp23 = libdevice.pow(tmp12, tmp22)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp24 = tmp21 - tmp23
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp25 = libdevice.sqrt(tmp24)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp26 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp27 = libdevice.pow(tmp26, tmp22)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp28 = tmp21 - tmp27
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp29 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp30 = (tmp29 / tmp28)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp31 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp32 = tmp30 * tmp31
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp33 = -tmp32
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp34 = tmp25 * tmp33
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp35 = (tmp19 / tmp34)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp36 = (tmp29 / tmp33)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp37 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp38 = tmp36 * tmp37
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp39 = tmp35 + tmp38
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp40 = (tmp10 / tmp39)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp41 = tmp18 + tmp40
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr6 + (x0), tmp41, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr7 + (x0), tmp10, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr8 + (x0), tmp17, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_1:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x1 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp47 = tl.load(in_ptr5 + (x1), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp48 = tl.load(in_ptr6 + (x1), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp53 = tl.load(in_ptr7 + (x1), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp60 = tl.load(in_ptr8 + (x1), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp62 = in_ptr9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp42 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp43 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp44 = tmp42 &gt;= tmp43
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp45 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp46 = tl.where(tmp44, tmp45, tmp42)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp49 = tmp47 - tmp48
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp50 = tmp46 * tmp49
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp51 = tl.where(tmp44, tmp47, tmp48)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp52 = tmp50 + tmp51
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp54 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp55 = tmp53 * tmp54
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp56 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp57 = tmp47 * tmp56
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp58 = tmp57 * tmp47
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp59 = tmp55 + tmp58
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp61 = libdevice.sqrt(tmp59)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp63 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp64 = tmp62 + tmp63
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp65 = libdevice.pow(tmp54, tmp64)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp66 = tmp63 - tmp65
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp67 = libdevice.sqrt(tmp66)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp68 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp69 = libdevice.pow(tmp68, tmp64)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp70 = tmp63 - tmp69
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp71 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp72 = (tmp71 / tmp70)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp73 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp74 = tmp72 * tmp73
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp75 = -tmp74
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp76 = tmp67 * tmp75
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp77 = (tmp61 / tmp76)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp78 = (tmp71 / tmp75)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp79 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp80 = tmp78 * tmp79
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp81 = tmp77 + tmp80
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp82 = (tmp52 / tmp81)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp83 = tmp60 + tmp82
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr15 + (x1), tmp83, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr16 + (x1), tmp52, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr17 + (x1), tmp59, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_2:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x2 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp89 = tl.load(in_ptr10 + (x2), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp90 = tl.load(in_ptr11 + (x2), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp95 = tl.load(in_ptr12 + (x2), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp102 = tl.load(in_ptr13 + (x2), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp104 = in_ptr14
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp84 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp85 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp86 = tmp84 &gt;= tmp85
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp87 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp88 = tl.where(tmp86, tmp87, tmp84)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp91 = tmp89 - tmp90
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp92 = tmp88 * tmp91
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp93 = tl.where(tmp86, tmp89, tmp90)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp94 = tmp92 + tmp93
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp96 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp97 = tmp95 * tmp96
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp98 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp99 = tmp89 * tmp98
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp100 = tmp99 * tmp89
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp101 = tmp97 + tmp100
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp103 = libdevice.sqrt(tmp101)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp105 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp106 = tmp104 + tmp105
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp107 = libdevice.pow(tmp96, tmp106)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp108 = tmp105 - tmp107
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp109 = libdevice.sqrt(tmp108)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp110 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp111 = libdevice.pow(tmp110, tmp106)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp112 = tmp105 - tmp111
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp113 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp114 = (tmp113 / tmp112)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp115 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp116 = tmp114 * tmp115
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp117 = -tmp116
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp118 = tmp109 * tmp117
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp119 = (tmp103 / tmp118)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp120 = (tmp113 / tmp117)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp121 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp122 = tmp120 * tmp121
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp123 = tmp119 + tmp122
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp124 = (tmp94 / tmp123)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp125 = tmp102 + tmp124
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr24 + (x2), tmp125, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr25 + (x2), tmp94, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr26 + (x2), tmp101, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_3:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_2
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x3 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp131 = tl.load(in_ptr15 + (x3), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp132 = tl.load(in_ptr16 + (x3), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp137 = tl.load(in_ptr17 + (x3), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp144 = tl.load(in_ptr18 + (x3), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp146 = in_ptr19
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp126 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp127 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp128 = tmp126 &gt;= tmp127
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp129 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp130 = tl.where(tmp128, tmp129, tmp126)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp133 = tmp131 - tmp132
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp134 = tmp130 * tmp133
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp135 = tl.where(tmp128, tmp131, tmp132)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp136 = tmp134 + tmp135
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp138 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp139 = tmp137 * tmp138
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp140 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp141 = tmp131 * tmp140
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp142 = tmp141 * tmp131
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp143 = tmp139 + tmp142
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp145 = libdevice.sqrt(tmp143)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp147 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp148 = tmp146 + tmp147
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp149 = libdevice.pow(tmp138, tmp148)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp150 = tmp147 - tmp149
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp151 = libdevice.sqrt(tmp150)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp152 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp153 = libdevice.pow(tmp152, tmp148)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp154 = tmp147 - tmp153
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp155 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp156 = (tmp155 / tmp154)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp157 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp158 = tmp156 * tmp157
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp159 = -tmp158
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp160 = tmp151 * tmp159
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp161 = (tmp145 / tmp160)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp162 = (tmp155 / tmp159)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp163 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp164 = tmp162 * tmp163
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp165 = tmp161 + tmp164
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp166 = (tmp136 / tmp165)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp167 = tmp144 + tmp166
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr33 + (x3), tmp167, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr34 + (x3), tmp136, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr35 + (x3), tmp143, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_4:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_3
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x4 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp173 = tl.load(in_ptr20 + (x4), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp174 = tl.load(in_ptr21 + (x4), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp179 = tl.load(in_ptr22 + (x4), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp186 = tl.load(in_ptr23 + (x4), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp188 = in_ptr24
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp168 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp169 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp170 = tmp168 &gt;= tmp169
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp171 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp172 = tl.where(tmp170, tmp171, tmp168)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp175 = tmp173 - tmp174
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp176 = tmp172 * tmp175
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp177 = tl.where(tmp170, tmp173, tmp174)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp178 = tmp176 + tmp177
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp180 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp181 = tmp179 * tmp180
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp182 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp183 = tmp173 * tmp182
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp184 = tmp183 * tmp173
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp185 = tmp181 + tmp184
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp187 = libdevice.sqrt(tmp185)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp189 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp190 = tmp188 + tmp189
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp191 = libdevice.pow(tmp180, tmp190)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp192 = tmp189 - tmp191
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp193 = libdevice.sqrt(tmp192)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp194 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp195 = libdevice.pow(tmp194, tmp190)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp196 = tmp189 - tmp195
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp197 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp198 = (tmp197 / tmp196)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp199 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp200 = tmp198 * tmp199
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp201 = -tmp200
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp202 = tmp193 * tmp201
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp203 = (tmp187 / tmp202)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp204 = (tmp197 / tmp201)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp205 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp206 = tmp204 * tmp205
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp207 = tmp203 + tmp206
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp208 = (tmp178 / tmp207)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp209 = tmp186 + tmp208
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr42 + (x4), tmp209, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr43 + (x4), tmp178, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr44 + (x4), tmp185, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_5:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_4
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x5 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp215 = tl.load(in_ptr25 + (x5), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp216 = tl.load(in_ptr26 + (x5), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp221 = tl.load(in_ptr27 + (x5), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp228 = tl.load(in_ptr28 + (x5), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp230 = in_ptr29
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp210 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp211 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp212 = tmp210 &gt;= tmp211
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp213 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp214 = tl.where(tmp212, tmp213, tmp210)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp217 = tmp215 - tmp216
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp218 = tmp214 * tmp217
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp219 = tl.where(tmp212, tmp215, tmp216)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp220 = tmp218 + tmp219
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp222 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp223 = tmp221 * tmp222
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp224 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp225 = tmp215 * tmp224
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp226 = tmp225 * tmp215
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp227 = tmp223 + tmp226
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp229 = libdevice.sqrt(tmp227)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp231 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp232 = tmp230 + tmp231
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp233 = libdevice.pow(tmp222, tmp232)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp234 = tmp231 - tmp233
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp235 = libdevice.sqrt(tmp234)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp236 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp237 = libdevice.pow(tmp236, tmp232)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp238 = tmp231 - tmp237
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp239 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp240 = (tmp239 / tmp238)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp241 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp242 = tmp240 * tmp241
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp243 = -tmp242
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp244 = tmp235 * tmp243
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp245 = (tmp229 / tmp244)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp246 = (tmp239 / tmp243)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp247 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp248 = tmp246 * tmp247
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp249 = tmp245 + tmp248
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp250 = (tmp220 / tmp249)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp251 = tmp228 + tmp250
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr51 + (x5), tmp251, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr52 + (x5), tmp220, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr53 + (x5), tmp227, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_6:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x6 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp257 = tl.load(in_ptr30 + (x6), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp258 = tl.load(in_ptr31 + (x6), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp263 = tl.load(in_ptr32 + (x6), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp270 = tl.load(in_ptr33 + (x6), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp272 = in_ptr34
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp252 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp253 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp254 = tmp252 &gt;= tmp253
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp255 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp256 = tl.where(tmp254, tmp255, tmp252)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp259 = tmp257 - tmp258
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp260 = tmp256 * tmp259
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp261 = tl.where(tmp254, tmp257, tmp258)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp262 = tmp260 + tmp261
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp264 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp265 = tmp263 * tmp264
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp266 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp267 = tmp257 * tmp266
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp268 = tmp267 * tmp257
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp269 = tmp265 + tmp268
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp271 = libdevice.sqrt(tmp269)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp273 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp274 = tmp272 + tmp273
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp275 = libdevice.pow(tmp264, tmp274)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp276 = tmp273 - tmp275
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp277 = libdevice.sqrt(tmp276)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp278 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp279 = libdevice.pow(tmp278, tmp274)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp280 = tmp273 - tmp279
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp281 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp282 = (tmp281 / tmp280)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp283 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp284 = tmp282 * tmp283
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp285 = -tmp284
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp286 = tmp277 * tmp285
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp287 = (tmp271 / tmp286)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp288 = (tmp281 / tmp285)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp289 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp290 = tmp288 * tmp289
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp291 = tmp287 + tmp290
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp292 = (tmp262 / tmp291)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp293 = tmp270 + tmp292
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr60 + (x6), tmp293, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr61 + (x6), tmp262, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr62 + (x6), tmp269, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_7:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_6
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x7 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp299 = tl.load(in_ptr35 + (x7), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp300 = tl.load(in_ptr36 + (x7), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp305 = tl.load(in_ptr37 + (x7), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp312 = tl.load(in_ptr38 + (x7), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp314 = in_ptr39
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp294 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp295 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp296 = tmp294 &gt;= tmp295
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp297 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp298 = tl.where(tmp296, tmp297, tmp294)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp301 = tmp299 - tmp300
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp302 = tmp298 * tmp301
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp303 = tl.where(tmp296, tmp299, tmp300)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp304 = tmp302 + tmp303
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp306 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp307 = tmp305 * tmp306
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp308 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp309 = tmp299 * tmp308
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp310 = tmp309 * tmp299
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp311 = tmp307 + tmp310
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp313 = libdevice.sqrt(tmp311)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp315 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp316 = tmp314 + tmp315
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp317 = libdevice.pow(tmp306, tmp316)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp318 = tmp315 - tmp317
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp319 = libdevice.sqrt(tmp318)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp320 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp321 = libdevice.pow(tmp320, tmp316)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp322 = tmp315 - tmp321
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp323 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp324 = (tmp323 / tmp322)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp325 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp326 = tmp324 * tmp325
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp327 = -tmp326
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp328 = tmp319 * tmp327
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp329 = (tmp313 / tmp328)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp330 = (tmp323 / tmp327)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp331 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp332 = tmp330 * tmp331
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp333 = tmp329 + tmp332
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp334 = (tmp304 / tmp333)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp335 = tmp312 + tmp334
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr69 + (x7), tmp335, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr70 + (x7), tmp304, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr71 + (x7), tmp311, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_8:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_7
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x8 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp341 = tl.load(in_ptr40 + (x8), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp342 = tl.load(in_ptr41 + (x8), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp347 = tl.load(in_ptr42 + (x8), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp354 = tl.load(in_ptr43 + (x8), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp356 = in_ptr44
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp336 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp337 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp338 = tmp336 &gt;= tmp337
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp339 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp340 = tl.where(tmp338, tmp339, tmp336)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp343 = tmp341 - tmp342
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp344 = tmp340 * tmp343
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp345 = tl.where(tmp338, tmp341, tmp342)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp346 = tmp344 + tmp345
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp348 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp349 = tmp347 * tmp348
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp350 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp351 = tmp341 * tmp350
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp352 = tmp351 * tmp341
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp353 = tmp349 + tmp352
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp355 = libdevice.sqrt(tmp353)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp357 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp358 = tmp356 + tmp357
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp359 = libdevice.pow(tmp348, tmp358)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp360 = tmp357 - tmp359
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp361 = libdevice.sqrt(tmp360)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp362 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp363 = libdevice.pow(tmp362, tmp358)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp364 = tmp357 - tmp363
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp365 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp366 = (tmp365 / tmp364)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp367 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp368 = tmp366 * tmp367
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp369 = -tmp368
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp370 = tmp361 * tmp369
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp371 = (tmp355 / tmp370)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp372 = (tmp365 / tmp369)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp373 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp374 = tmp372 * tmp373
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp375 = tmp371 + tmp374
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp376 = (tmp346 / tmp375)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp377 = tmp354 + tmp376
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr78 + (x8), tmp377, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr79 + (x8), tmp346, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr80 + (x8), tmp353, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     elif pid &lt; num_xblocks_9:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pid_offset = pid - num_xblocks_8
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xnumel = 1048576
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         r0_numel = 1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         x9 = xindex
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp383 = tl.load(in_ptr45 + (x9), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp384 = tl.load(in_ptr46 + (x9), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp389 = tl.load(in_ptr47 + (x9), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp396 = tl.load(in_ptr48 + (x9), None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp398 = in_ptr49
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp378 = 0.09999999999999998
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp379 = 0.5
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp380 = tmp378 &gt;= tmp379
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp381 = -0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp382 = tl.where(tmp380, tmp381, tmp378)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp385 = tmp383 - tmp384
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp386 = tmp382 * tmp385
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp387 = tl.where(tmp380, tmp383, tmp384)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp388 = tmp386 + tmp387
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp390 = 0.999
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp391 = tmp389 * tmp390
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp392 = 0.0010000000000000009
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp393 = tmp383 * tmp392
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp394 = tmp393 * tmp383
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp395 = tmp391 + tmp394
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp397 = libdevice.sqrt(tmp395)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp399 = 1.0
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp400 = tmp398 + tmp399
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp401 = libdevice.pow(tmp390, tmp400)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp402 = tmp399 - tmp401
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp403 = libdevice.sqrt(tmp402)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp404 = 0.9
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp405 = libdevice.pow(tmp404, tmp400)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp406 = tmp399 - tmp405
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp407 = tl.full([1], 1, tl.int32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp408 = (tmp407 / tmp406)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp409 = 0.001
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp410 = tmp408 * tmp409
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp411 = -tmp410
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp412 = tmp403 * tmp411
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp413 = (tmp397 / tmp412)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp414 = (tmp407 / tmp411)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp415 = 1e-08
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp416 = tmp414 * tmp415
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp417 = tmp413 + tmp416
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp418 = (tmp388 / tmp417)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tmp419 = tmp396 + tmp418
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr87 + (x9), tmp419, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr88 + (x9), tmp388, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         tl.store(out_ptr89 + (x9), tmp395, None)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     else:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         pass
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] cpp_fused__foreach_copy_1 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] #include &quot;/tmp/torchinductor_ci-user/pi/cpicxudqmdsjh5cm4klbtbrvy2cxwr7whxl3md2zzdjdf3orvfdf.h&quot;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] extern &quot;C&quot;  void kernel(const float* in_ptr0,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr1,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr2,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr3,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr4,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr5,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr6,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr7,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr8,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        const float* in_ptr9,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr1,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr3,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr5,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr7,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr9,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr11,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr13,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr15,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr17,
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                        float* out_ptr19)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr11[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr13[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr15[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr17[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             {
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 auto tmp2 = decltype(tmp0)(tmp0 + tmp1);
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]                 out_ptr19[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]             }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] }
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] &#39;&#39;&#39;)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] async_compile.wait(globals())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] del async_compile
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] def call(args):
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     args.clear()
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg10_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg11_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg12_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg13_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg14_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg15_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg16_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg17_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg18_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg19_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg20_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg21_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg22_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg23_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg24_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg25_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg26_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg27_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg28_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg29_1, (), ())
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         torch.cuda.set_device(0)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         stream0 = get_raw_stream(0)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         triton_for_fused_0.run(arg1_1, arg30_1, arg40_1, arg0_1, arg20_1.item(), arg3_1, arg31_1, arg41_1, arg2_1, arg21_1.item(), arg5_1, arg32_1, arg42_1, arg4_1, arg22_1.item(), arg7_1, arg33_1, arg43_1, arg6_1, arg23_1.item(), arg9_1, arg34_1, arg44_1, arg8_1, arg24_1.item(), arg11_1, arg35_1, arg45_1, arg10_1, arg25_1.item(), arg13_1, arg36_1, arg46_1, arg12_1, arg26_1.item(), arg15_1, arg37_1, arg47_1, arg14_1, arg27_1.item(), arg17_1, arg38_1, arg48_1, arg16_1, arg28_1.item(), arg19_1, arg39_1, arg49_1, arg18_1, arg29_1.item(), arg0_1, arg30_1, arg40_1, arg2_1, arg31_1, arg41_1, arg4_1, arg32_1, arg42_1, arg6_1, arg33_1, arg43_1, arg8_1, arg34_1, arg44_1, arg10_1, arg35_1, arg45_1, arg12_1, arg36_1, arg46_1, arg14_1, arg37_1, arg47_1, arg16_1, arg38_1, arg48_1, arg18_1, arg39_1, arg49_1, stream=stream0)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg0_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg10_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg11_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg12_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg13_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg14_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg15_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg16_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg17_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg18_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg19_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg1_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg2_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg30_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg31_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg32_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg33_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg34_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg35_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg36_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg37_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg38_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg39_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg3_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg40_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg41_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg42_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg43_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg44_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg45_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg46_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg47_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg48_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg49_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg4_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg5_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg6_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg7_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg8_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]         del arg9_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     cpp_fused__foreach_copy_1(arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg20_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg21_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg22_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg23_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg24_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg25_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg26_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg27_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg28_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     del arg29_1
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     return ()
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     from torch._dynamo.testing import rand_strided
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     from torch._inductor.utils import print_performance
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg10_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg11_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg12_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg13_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg14_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg15_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg16_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg17_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg18_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg19_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg20_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg21_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg22_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg23_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg24_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg25_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg26_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg27_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg28_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg29_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code] if __name__ == &quot;__main__&quot;:
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0806 16:44:53.699000 22411 torch/_inductor/graph.py:2104] [0/1] [__output_code]
V0806 16:44:53.747000 22411 torch/_inductor/graph.py:2115] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/65/c655isihixkazmceuwbfqagiscwkui2zsppjfrucnr3s5l4gahqw.py
I0806 16:44:53.787000 22411 torch/_inductor/graph.py:2149] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/65/c655isihixkazmceuwbfqagiscwkui2zsppjfrucnr3s5l4gahqw.py
eager runtime: 1213.1350599997859us
compiled runtime: 755.4586415059227us
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map.
By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam
optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide
on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a
valuable resource for developers looking to improve the performance of their models with horizontal fusion.</p>
<p>See also:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/compiling_optimizer.html">Compiled optimizer tutorial</a> - an intro into the compiled optimizer.</p></li>
<li><p><a class="reference external" href="https://dev-discuss.pytorch.org/t/compiling-the-optimizer-with-pt2/1669">Compiling the optimizer with PT2</a> - deeper technical details on the compiled optimizer.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 12.434 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-foreach-map-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/162cf335b789dd055d4192f77cb0251c/foreach_map.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">foreach_map.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bcb9aa4fd3968b85310b970dbd86bbc3/foreach_map.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">foreach_map.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/faee5eeb51c8f314872395cc1b776677/foreach_map.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">foreach_map.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
  </article>

              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-setup">Model Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions-for-foreach-map-implementation">Helper functions for foreach_map implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-and-running-the-compiled-kernel">Setting up and running the compiled kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
          </div>

          <div class="col-md-4">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
          </div>

          <div class="col-md-4">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">

          
      <div class="newsletter" id="newsletter">
  
        <p
          class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
      
      
          <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
          <script>
            hbspt.forms.create({
              region: "na1",
              portalId: "8112310",
              formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
            });
          </script>
          
      
        <p
          class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
          
      </div>
      
  
  
      <div class="lf-grid">  
        <ul class="social-links">
          <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
          </a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
          </a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
          </a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
          </a></li>
          <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack"><path fill="currentColor" d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z"></path></svg>
          </a></li>
          <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat"><path fill="currentColor" d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z"></path><path fill="currentColor" d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z"></path></svg>
          </a></li>
        </ul>
      </div>
  
      <div class="privacy-policy">
        <div class="copyright">
          <p>
            &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
          </p>
        </div>
      </div>


       </div>
 </footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>

   
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
   <script type="application/ld+json">
      {
         "@context": "https://schema.org",
         "@type": "Article",
         "headline": "Explicit horizontal fusion with foreach_map and torch.compile",
         "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
         "url": "/recipes/foreach_map.html",
         "author": {
           "@type": "Organization",
           "name": "PyTorch Contributors",
           "url": "https://pytorch.org"
         },
         "image": "../_static/img/pytorch_seo.png",
         "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "/recipes/foreach_map.html"
         },
        "datePublished": "",
         "dateModified": "",
         "articleBody": "Note Go to the end to download the full example code. Explicit horizontal fusion with foreach_map and torch.compile# Author: Michael Lazos Horizontal fusion is a key optimization in ML compilers. In eager,this is typically expressed using the torch._foreach* ops which parallelizes operations across a list of tensors. However, supporting all possible permutations of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map allows conversion of any pointwise op in torch to a horiztonally fused foreach variant. In this tutorial, we will demonstrate how to implement the Adam optimizer with foreach_map to generate a fully fused kernel. Note This recipe describes a prototype feature. Prototype features are typically at an early stage for feedback and testing and are subject to change. Prerequisites# PyTorch v2.7.0 or later Model Setup# For this example, we’ll use a simple sequence of linear layers. We instantiate an independent copy to compare the two optimizer implementations. import torch # exit cleanly if we are on a device that doesn&#39;t support ``torch.compile`` if torch.cuda.get_device_capability() &lt; (7, 0): print(\&#34;Exiting because torch.compile is not supported on this device.\&#34;) import sys sys.exit(0) # Create simple model model = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\&#34;cuda\&#34;) for _ in range(10)] ) model_copy = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\&#34;cuda\&#34;) for _ in range(10)] ) input = torch.rand(1024, device=\&#34;cuda\&#34;) # run forward pass output = model(input) output_copy = model_copy(input) # run backward to populate the grads for our optimizer below output.sum().backward() output_copy.sum().backward() Helper functions for foreach_map implementation# In this section, we’ll begin our implementation of the Adam optimizer. from torch._higher_order_ops.foreach_map import foreach_map # Helper function to extract optimizer states from a torch.optim.Adam instance def get_inputs(optim): steps = [] params = [] grads = [] exp_avgs = [] exp_avg_sqs = [] for group in optim.param_groups: for p in group[\&#34;params\&#34;]: params.append(p) grads.append(p.grad) state = optim.state[p] exp_avgs.append(state[\&#34;exp_avg\&#34;]) exp_avg_sqs.append(state[\&#34;exp_avg_sq\&#34;]) steps.append(state[\&#34;step\&#34;]) return steps, params, exp_avgs, exp_avg_sqs # Functions to update the different optimizer states def update_exp_avg_sq(exp_avg_sq, grad, beta2): return exp_avg_sq.mul(beta2).addcmul(grad, grad, value=1 - beta2) def update_param(param, step, exp_avg, exp_avg_sq, beta1, beta2, lr, eps): bias_correction1 = 1 - torch.pow(beta1, step) bias_correction2 = (1 - torch.pow(beta2, step)).sqrt() step_size = (lr / bias_correction1).neg() denom = (exp_avg_sq.sqrt() / (bias_correction2 * step_size)).add(eps / step_size) return torch.add(param, torch.div(exp_avg, denom)) # Our full Adam implementation def foreach_map_adam( steps, params, exp_avgs, exp_avg_sqs, weight_decay=0, beta1=0.9, beta2=0.999, lr=1e-3, eps=1e-8, ): with torch.no..."
       }
   </script>

  </body>
</html>