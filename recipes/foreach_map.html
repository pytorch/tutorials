
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-07-20T23:02:43+00:00" />
    <title>Explicit horizontal fusion with foreach_map and torch.compile &#8212; PyTorch Tutorials 2.9.0+cu128 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=047068a3" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=c2809cec"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/foreach_map';</script>
    <link rel="canonical" href="https://docs.pytorch.org/tutorials/recipes/foreach_map.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compile Time Caching Configuration" href="torch_compile_caching_configuration_tutorial.html" />
    <link rel="prev" title="(beta) Utilizing Torch Function modes with torch.compile" href="torch_compile_torch_function_modes.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.9.0+cu128');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/tutorials" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.9.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../recipes_index.html" class="nav-link">Recipes</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Explicit...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../recipes_index.html">
        <meta itemprop="name" content="Recipes">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Explicit horizontal fusion with foreach_map and torch.compile">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/foreach_map</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-foreach-map-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="explicit-horizontal-fusion-with-foreach-map-and-torch-compile">
<span id="sphx-glr-recipes-foreach-map-py"></span><h1>Explicit horizontal fusion with foreach_map and torch.compile<a class="headerlink" href="#explicit-horizontal-fusion-with-foreach-map-and-torch-compile" title="Link to this heading">#</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<dl class="simple">
<dt>Horizontal fusion is a key optimization in ML compilers. In eager,</dt><dd><p>this is typically expressed using the torch._foreach* ops which parallelizes
operations across a list of tensors. However, supporting all possible permutations
of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map
allows conversion of any pointwise op in <code class="docutils literal notranslate"><span class="pre">torch</span></code> to a horiztonally fused foreach
variant. In this tutorial, we will demonstrate how to implement the Adam optimizer
with <code class="docutils literal notranslate"><span class="pre">foreach_map</span></code> to generate a fully fused kernel.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This recipe describes a prototype feature. Prototype features are typically
at an early stage for feedback and testing and are subject to change.</p>
</div>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>PyTorch v2.7.0 or later</p></li>
</ul>
<section id="model-setup">
<h3>Model Setup<a class="headerlink" href="#model-setup" title="Link to this heading">#</a></h3>
<p>For this example, we’ll use a simple sequence of linear layers.
We instantiate an independent copy to compare the two optimizer implementations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># exit cleanly if we are on a device that doesn&#39;t support ``torch.compile``</span>
<span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because torch.compile is not supported on this device.&quot;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create simple model</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># run forward pass</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># run backward to populate the grads for our optimizer below</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="helper-functions-for-foreach-map-implementation">
<h3>Helper functions for foreach_map implementation<a class="headerlink" href="#helper-functions-for-foreach-map-implementation" title="Link to this heading">#</a></h3>
<p>In this section, we’ll begin our implementation of the Adam optimizer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._higher_order_ops.foreach_map</span><span class="w"> </span><span class="kn">import</span> <span class="n">foreach_map</span>

<span class="c1"># Helper function to extract optimizer states from a torch.optim.Adam instance</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_inputs</span><span class="p">(</span><span class="n">optim</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optim</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
            <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg&quot;</span><span class="p">])</span>
            <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg_sq&quot;</span><span class="p">])</span>
            <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">steps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avg_sqs</span>


<span class="c1"># Functions to update the different optimizer states</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_exp_avg_sq</span><span class="p">(</span><span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">beta2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">exp_avg</span><span class="p">,</span> <span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">bias_correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="n">bias_correction2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta2</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">lr</span> <span class="o">/</span> <span class="n">bias_correction1</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">bias_correction2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">))</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">eps</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">(</span><span class="n">param</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">div</span></a><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">))</span>

<span class="c1"># Our full Adam implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">foreach_map_adam</span><span class="p">(</span>
    <span class="n">steps</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">exp_avgs</span><span class="p">,</span>
    <span class="n">exp_avg_sqs</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">with</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
        <span class="c1"># update step</span>
        <span class="n">updated_steps</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">updated_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weight_decay</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">,</span> <span class="p">(</span><span class="n">grads</span><span class="p">,),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="c1"># Higher-order operators (HOPs) cannot have multiple outputs at the moment</span>
        <span class="c1"># need to call foreach_map once for each output</span>
        <span class="n">exp_avgs_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp" title="torch.lerp" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span></a><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
        <span class="n">exp_avgs_sq_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="n">update_exp_avg_sq</span><span class="p">,</span> <span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">beta2</span><span class="p">)</span>
        <span class="n">params_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span>
            <span class="n">update_param</span><span class="p">,</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">steps</span><span class="p">,</span>
            <span class="n">exp_avgs_updated</span><span class="p">,</span>
            <span class="n">exp_avgs_sq_updated</span><span class="p">,</span>
            <span class="n">beta1</span><span class="p">,</span>
            <span class="n">beta2</span><span class="p">,</span>
            <span class="n">lr</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Higher-order operators (HOPs) don&#39;t support input mutation today</span>
        <span class="c1"># so manually  update the states in-place</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avgs_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">exp_avgs_sq_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">params_updated</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</section>
<section id="setting-up-and-running-the-compiled-kernel">
<h3>Setting up and running the compiled kernel<a class="headerlink" href="#setting-up-and-running-the-compiled-kernel" title="Link to this heading">#</a></h3>
<p>In this section, we’ll run our Adam optimizer
and compare the results</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is only supported on CUDA devices that have a compute capability of 7.0 or higher.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model_copy</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># warm up the optimizer state dict</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager_copy</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="p">)</span>
<span class="n">compiled_adam</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foreach_map_adam</span><span class="p">)</span>

<span class="c1"># optionally view the output code</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs" class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">output_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Warmup runs to compile the function</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
    <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">for</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">],</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a><span class="p">)</span>

<span class="c1"># Benchmark performance</span>

 <span class="c1"># Let&#39;s define a helpful benchmarking function:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">benchmark</span>

<span class="k">def</span><span class="w"> </span><span class="nf">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">benchmark</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span>
        <span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;f(*args, **kwargs)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span> <span class="n">f</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">t0</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mf">1e6</span>

<span class="n">eager_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">)</span>
<span class="n">compiled_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">eager_runtime</span> <span class="o">&gt;</span> <span class="n">compiled_runtime</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;eager runtime: </span><span class="si">{</span><span class="n">eager_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;compiled runtime: </span><span class="si">{</span><span class="n">compiled_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] Output code:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # AOT ID: [&#39;0_inference&#39;]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import torch
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import math
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import random
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import os
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import tempfile
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from math import inf, nan
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from cmath import nanj
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch import device, empty_strided
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton.language as tl
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] aten = torch.ops.aten
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] _quantized = torch.ops._quantized
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] async_compile = AsyncCompile()
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] extern &quot;C&quot;  void  kernel(const float* in_ptr0,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr1,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr2,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr3,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr4,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr5,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr6,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr7,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr8,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        const float* in_ptr9,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr0,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr1,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr2,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr3,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr4,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr5,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr6,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr7,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr8,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                        float* out_ptr9)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr0[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr2[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr4[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr6[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr8[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             {
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] }
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] &#39;&#39;&#39;)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/zr/czr3lns75kwntdd4kbv7cuobqrmx4orie2lal4gttw4y5fiq4ii3.py
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # Source node to ATen node mapping:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] triton_for_fused_1 = async_compile.triton(&#39;triton_for_fused_1&#39;, &#39;&#39;&#39;
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton.language as tl
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] @triton_heuristics.foreach(
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_warps=8,
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr3&#39;: &#39;*fp32&#39;, &#39;out_ptr4&#39;: &#39;*fp32&#39;, &#39;out_ptr5&#39;: &#39;*fp32&#39;, &#39;out_ptr9&#39;: &#39;*fp32&#39;, &#39;out_ptr10&#39;: &#39;*fp32&#39;, &#39;out_ptr11&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr21&#39;: &#39;*fp32&#39;, &#39;out_ptr22&#39;: &#39;*fp32&#39;, &#39;out_ptr23&#39;: &#39;*fp32&#39;, &#39;out_ptr27&#39;: &#39;*fp32&#39;, &#39;out_ptr28&#39;: &#39;*fp32&#39;, &#39;out_ptr29&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr39&#39;: &#39;*fp32&#39;, &#39;out_ptr40&#39;: &#39;*fp32&#39;, &#39;out_ptr41&#39;: &#39;*fp32&#39;, &#39;out_ptr45&#39;: &#39;*fp32&#39;, &#39;out_ptr46&#39;: &#39;*fp32&#39;, &#39;out_ptr47&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr57&#39;: &#39;*fp32&#39;, &#39;out_ptr58&#39;: &#39;*fp32&#39;, &#39;out_ptr59&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_1&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr10&#39;, &#39;out_ptr11&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr21&#39;, &#39;out_ptr22&#39;, &#39;out_ptr23&#39;, &#39;out_ptr27&#39;, &#39;out_ptr28&#39;, &#39;out_ptr29&#39;, &#39;out_ptr3&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr39&#39;, &#39;out_ptr4&#39;, &#39;out_ptr40&#39;, &#39;out_ptr41&#39;, &#39;out_ptr45&#39;, &#39;out_ptr46&#39;, &#39;out_ptr47&#39;, &#39;out_ptr5&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr57&#39;, &#39;out_ptr58&#39;, &#39;out_ptr59&#39;, &#39;out_ptr9&#39;], &#39;backend_hash&#39;: &#39;5C4E406C711B3861DF9C100323E0EC398E2F633BD8802E2E564CD4776AA7ED44&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] )
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] @triton.jit
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     pid = tl.program_id(0)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1024
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     if pid &lt; num_xblocks_0:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x0 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp17 = in_ptr4
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp2 = tmp0 - tmp1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp3 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp4 = tmp3 * tmp2
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp7 = tmp4 + tmp6
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp9 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp11 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp12 = tmp0 * tmp11
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp13 = tmp12 * tmp0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp14 = tmp10 + tmp13
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp16 = libdevice.sqrt(tmp14)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp18 = libdevice.pow(tmp9, tmp17)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp19 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp20 = tmp19 - tmp18
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp21 = libdevice.sqrt(tmp20)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp22 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp23 = libdevice.pow(tmp22, tmp17)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp24 = tmp19 - tmp23
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp25 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp26 = (tmp25 / tmp24)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp27 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp28 = tmp26 * tmp27
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp29 = -tmp28
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp30 = tmp21 * tmp29
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp31 = (tmp16 / tmp30)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp32 = (tmp25 / tmp29)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp33 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp34 = tmp32 * tmp33
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp35 = tmp31 + tmp34
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp36 = (tmp7 / tmp35)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp37 = tmp15 + tmp36
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr3 + (x0), tmp7, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr4 + (x0), tmp14, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr5 + (x0), tmp37, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_1:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x1 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp38 = tl.load(in_ptr5 + (x1), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp39 = tl.load(in_ptr6 + (x1), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp46 = tl.load(in_ptr7 + (x1), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp53 = tl.load(in_ptr8 + (x1), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp55 = in_ptr9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp40 = tmp38 - tmp39
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp41 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp42 = tmp41 * tmp40
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp43 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp44 = tl.where(tmp43, tmp38, tmp39)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp45 = tmp42 + tmp44
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp47 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp48 = tmp46 * tmp47
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp49 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp50 = tmp38 * tmp49
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp51 = tmp50 * tmp38
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp52 = tmp48 + tmp51
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp54 = libdevice.sqrt(tmp52)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp56 = libdevice.pow(tmp47, tmp55)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp57 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp58 = tmp57 - tmp56
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp59 = libdevice.sqrt(tmp58)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp60 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp61 = libdevice.pow(tmp60, tmp55)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp62 = tmp57 - tmp61
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp63 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp64 = (tmp63 / tmp62)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp65 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp66 = tmp64 * tmp65
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp67 = -tmp66
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp68 = tmp59 * tmp67
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp69 = (tmp54 / tmp68)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp70 = (tmp63 / tmp67)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp71 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp72 = tmp70 * tmp71
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp73 = tmp69 + tmp72
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp74 = (tmp45 / tmp73)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp75 = tmp53 + tmp74
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr9 + (x1), tmp45, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr10 + (x1), tmp52, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr11 + (x1), tmp75, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_2:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x2 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp76 = tl.load(in_ptr10 + (x2), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp77 = tl.load(in_ptr11 + (x2), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp84 = tl.load(in_ptr12 + (x2), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp91 = tl.load(in_ptr13 + (x2), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp93 = in_ptr14
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp78 = tmp76 - tmp77
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp79 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp80 = tmp79 * tmp78
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp81 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp82 = tl.where(tmp81, tmp76, tmp77)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp83 = tmp80 + tmp82
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp85 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp86 = tmp84 * tmp85
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp87 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp88 = tmp76 * tmp87
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp89 = tmp88 * tmp76
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp90 = tmp86 + tmp89
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp92 = libdevice.sqrt(tmp90)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp94 = libdevice.pow(tmp85, tmp93)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp95 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp96 = tmp95 - tmp94
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp97 = libdevice.sqrt(tmp96)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp98 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp99 = libdevice.pow(tmp98, tmp93)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp100 = tmp95 - tmp99
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp101 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp102 = (tmp101 / tmp100)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp103 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp104 = tmp102 * tmp103
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp105 = -tmp104
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp106 = tmp97 * tmp105
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp107 = (tmp92 / tmp106)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp108 = (tmp101 / tmp105)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp109 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp110 = tmp108 * tmp109
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp111 = tmp107 + tmp110
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp112 = (tmp83 / tmp111)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp113 = tmp91 + tmp112
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr15 + (x2), tmp83, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr16 + (x2), tmp90, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr17 + (x2), tmp113, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_3:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_2
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x3 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp114 = tl.load(in_ptr15 + (x3), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp115 = tl.load(in_ptr16 + (x3), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp122 = tl.load(in_ptr17 + (x3), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp129 = tl.load(in_ptr18 + (x3), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp131 = in_ptr19
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp116 = tmp114 - tmp115
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp117 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp118 = tmp117 * tmp116
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp119 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp120 = tl.where(tmp119, tmp114, tmp115)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp121 = tmp118 + tmp120
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp123 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp124 = tmp122 * tmp123
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp125 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp126 = tmp114 * tmp125
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp127 = tmp126 * tmp114
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp128 = tmp124 + tmp127
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp130 = libdevice.sqrt(tmp128)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp132 = libdevice.pow(tmp123, tmp131)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp133 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp134 = tmp133 - tmp132
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp135 = libdevice.sqrt(tmp134)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp136 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp137 = libdevice.pow(tmp136, tmp131)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp138 = tmp133 - tmp137
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp139 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp140 = (tmp139 / tmp138)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp141 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp142 = tmp140 * tmp141
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp143 = -tmp142
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp144 = tmp135 * tmp143
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp145 = (tmp130 / tmp144)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp146 = (tmp139 / tmp143)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp147 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp148 = tmp146 * tmp147
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp149 = tmp145 + tmp148
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp150 = (tmp121 / tmp149)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp151 = tmp129 + tmp150
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr21 + (x3), tmp121, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr22 + (x3), tmp128, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr23 + (x3), tmp151, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_4:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_3
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x4 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp152 = tl.load(in_ptr20 + (x4), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp153 = tl.load(in_ptr21 + (x4), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp160 = tl.load(in_ptr22 + (x4), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp167 = tl.load(in_ptr23 + (x4), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp169 = in_ptr24
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp154 = tmp152 - tmp153
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp155 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp156 = tmp155 * tmp154
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp157 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp158 = tl.where(tmp157, tmp152, tmp153)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp159 = tmp156 + tmp158
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp161 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp162 = tmp160 * tmp161
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp163 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp164 = tmp152 * tmp163
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp165 = tmp164 * tmp152
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp166 = tmp162 + tmp165
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp168 = libdevice.sqrt(tmp166)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp170 = libdevice.pow(tmp161, tmp169)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp171 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp172 = tmp171 - tmp170
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp173 = libdevice.sqrt(tmp172)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp174 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp175 = libdevice.pow(tmp174, tmp169)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp176 = tmp171 - tmp175
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp177 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp178 = (tmp177 / tmp176)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp179 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp180 = tmp178 * tmp179
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp181 = -tmp180
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp182 = tmp173 * tmp181
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp183 = (tmp168 / tmp182)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp184 = (tmp177 / tmp181)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp185 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp186 = tmp184 * tmp185
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp187 = tmp183 + tmp186
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp188 = (tmp159 / tmp187)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp189 = tmp167 + tmp188
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr27 + (x4), tmp159, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr28 + (x4), tmp166, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr29 + (x4), tmp189, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_5:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_4
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x5 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp190 = tl.load(in_ptr25 + (x5), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp191 = tl.load(in_ptr26 + (x5), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp198 = tl.load(in_ptr27 + (x5), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp205 = tl.load(in_ptr28 + (x5), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp207 = in_ptr29
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp192 = tmp190 - tmp191
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp193 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp194 = tmp193 * tmp192
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp195 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp196 = tl.where(tmp195, tmp190, tmp191)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp197 = tmp194 + tmp196
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp199 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp200 = tmp198 * tmp199
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp201 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp202 = tmp190 * tmp201
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp203 = tmp202 * tmp190
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp204 = tmp200 + tmp203
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp206 = libdevice.sqrt(tmp204)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp208 = libdevice.pow(tmp199, tmp207)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp209 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp210 = tmp209 - tmp208
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp211 = libdevice.sqrt(tmp210)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp212 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp213 = libdevice.pow(tmp212, tmp207)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp214 = tmp209 - tmp213
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp215 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp216 = (tmp215 / tmp214)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp217 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp218 = tmp216 * tmp217
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp219 = -tmp218
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp220 = tmp211 * tmp219
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp221 = (tmp206 / tmp220)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp222 = (tmp215 / tmp219)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp223 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp224 = tmp222 * tmp223
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp225 = tmp221 + tmp224
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp226 = (tmp197 / tmp225)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp227 = tmp205 + tmp226
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr33 + (x5), tmp197, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr34 + (x5), tmp204, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr35 + (x5), tmp227, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_6:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_5
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x6 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp228 = tl.load(in_ptr30 + (x6), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp229 = tl.load(in_ptr31 + (x6), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp236 = tl.load(in_ptr32 + (x6), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp243 = tl.load(in_ptr33 + (x6), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp245 = in_ptr34
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp230 = tmp228 - tmp229
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp231 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp232 = tmp231 * tmp230
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp233 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp234 = tl.where(tmp233, tmp228, tmp229)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp235 = tmp232 + tmp234
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp237 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp238 = tmp236 * tmp237
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp239 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp240 = tmp228 * tmp239
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp241 = tmp240 * tmp228
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp242 = tmp238 + tmp241
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp244 = libdevice.sqrt(tmp242)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp246 = libdevice.pow(tmp237, tmp245)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp247 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp248 = tmp247 - tmp246
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp249 = libdevice.sqrt(tmp248)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp250 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp251 = libdevice.pow(tmp250, tmp245)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp252 = tmp247 - tmp251
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp253 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp254 = (tmp253 / tmp252)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp255 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp256 = tmp254 * tmp255
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp257 = -tmp256
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp258 = tmp249 * tmp257
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp259 = (tmp244 / tmp258)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp260 = (tmp253 / tmp257)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp261 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp262 = tmp260 * tmp261
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp263 = tmp259 + tmp262
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp264 = (tmp235 / tmp263)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp265 = tmp243 + tmp264
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr39 + (x6), tmp235, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr40 + (x6), tmp242, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr41 + (x6), tmp265, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_7:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_6
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x7 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp266 = tl.load(in_ptr35 + (x7), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp267 = tl.load(in_ptr36 + (x7), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp274 = tl.load(in_ptr37 + (x7), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp281 = tl.load(in_ptr38 + (x7), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp283 = in_ptr39
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp268 = tmp266 - tmp267
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp269 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp270 = tmp269 * tmp268
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp271 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp272 = tl.where(tmp271, tmp266, tmp267)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp273 = tmp270 + tmp272
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp275 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp276 = tmp274 * tmp275
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp277 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp278 = tmp266 * tmp277
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp279 = tmp278 * tmp266
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp280 = tmp276 + tmp279
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp282 = libdevice.sqrt(tmp280)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp284 = libdevice.pow(tmp275, tmp283)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp285 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp286 = tmp285 - tmp284
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp287 = libdevice.sqrt(tmp286)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp288 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp289 = libdevice.pow(tmp288, tmp283)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp290 = tmp285 - tmp289
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp291 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp292 = (tmp291 / tmp290)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp293 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp294 = tmp292 * tmp293
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp295 = -tmp294
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp296 = tmp287 * tmp295
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp297 = (tmp282 / tmp296)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp298 = (tmp291 / tmp295)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp299 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp300 = tmp298 * tmp299
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp301 = tmp297 + tmp300
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp302 = (tmp273 / tmp301)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp303 = tmp281 + tmp302
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr45 + (x7), tmp273, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr46 + (x7), tmp280, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr47 + (x7), tmp303, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_8:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_7
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x8 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp304 = tl.load(in_ptr40 + (x8), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp305 = tl.load(in_ptr41 + (x8), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp312 = tl.load(in_ptr42 + (x8), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp319 = tl.load(in_ptr43 + (x8), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp321 = in_ptr44
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp306 = tmp304 - tmp305
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp307 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp308 = tmp307 * tmp306
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp309 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp310 = tl.where(tmp309, tmp304, tmp305)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp311 = tmp308 + tmp310
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp313 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp314 = tmp312 * tmp313
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp315 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp316 = tmp304 * tmp315
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp317 = tmp316 * tmp304
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp318 = tmp314 + tmp317
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp320 = libdevice.sqrt(tmp318)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp322 = libdevice.pow(tmp313, tmp321)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp323 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp324 = tmp323 - tmp322
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp325 = libdevice.sqrt(tmp324)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp326 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp327 = libdevice.pow(tmp326, tmp321)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp328 = tmp323 - tmp327
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp329 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp330 = (tmp329 / tmp328)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp331 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp332 = tmp330 * tmp331
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp333 = -tmp332
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp334 = tmp325 * tmp333
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp335 = (tmp320 / tmp334)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp336 = (tmp329 / tmp333)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp337 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp338 = tmp336 * tmp337
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp339 = tmp335 + tmp338
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp340 = (tmp311 / tmp339)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp341 = tmp319 + tmp340
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr51 + (x8), tmp311, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr52 + (x8), tmp318, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr53 + (x8), tmp341, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     elif pid &lt; num_xblocks_9:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pid_offset = pid - num_xblocks_8
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xnumel = 1048576
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         r0_numel = 1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         x9 = xindex
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp342 = tl.load(in_ptr45 + (x9), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp343 = tl.load(in_ptr46 + (x9), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp350 = tl.load(in_ptr47 + (x9), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp357 = tl.load(in_ptr48 + (x9), None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp359 = in_ptr49
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp344 = tmp342 - tmp343
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp345 = 0.10000000149011612
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp346 = tmp345 * tmp344
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp347 = tl.full([1], False, tl.int1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp348 = tl.where(tmp347, tmp342, tmp343)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp349 = tmp346 + tmp348
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp351 = 0.999
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp352 = tmp350 * tmp351
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp353 = 0.0010000000000000009
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp354 = tmp342 * tmp353
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp355 = tmp354 * tmp342
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp356 = tmp352 + tmp355
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp358 = libdevice.sqrt(tmp356)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp360 = libdevice.pow(tmp351, tmp359)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp361 = 1.0
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp362 = tmp361 - tmp360
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp363 = libdevice.sqrt(tmp362)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp364 = 0.9
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp365 = libdevice.pow(tmp364, tmp359)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp366 = tmp361 - tmp365
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp367 = tl.full([1], 1, tl.int32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp368 = (tmp367 / tmp366)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp369 = 0.001
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp370 = tmp368 * tmp369
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp371 = -tmp370
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp372 = tmp363 * tmp371
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp373 = (tmp358 / tmp372)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp374 = (tmp367 / tmp371)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp375 = 1e-08
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp376 = tmp374 * tmp375
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp377 = tmp373 + tmp376
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp378 = (tmp349 / tmp377)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tmp379 = tmp357 + tmp378
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr57 + (x9), tmp349, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr58 + (x9), tmp356, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         tl.store(out_ptr59 + (x9), tmp379, None)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     else:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         pass
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] async_compile.wait(globals())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del async_compile
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] class Runner:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     def __init__(self, partitions):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         self.partitions = partitions
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     def recursively_apply_fns(self, fns):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         new_callables = []
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         for fn, c in zip(fns, self.partitions):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             new_callables.append(fn(c))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         self.partitions = new_callables
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     def call(self, args):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         args.clear()
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg10_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg11_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg12_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg13_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg14_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg15_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg16_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg17_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg18_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg19_1, (), ())
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         with torch.cuda._DeviceGuard(0):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             torch.cuda.set_device(0)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             # Unsorted Source Nodes: [], Original ATen: []
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             stream0 = get_raw_stream(0)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg0_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg10_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg11_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg12_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg13_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg14_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg15_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg16_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg17_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg18_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg19_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg1_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg20_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg21_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg22_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg23_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg24_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg25_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg26_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg27_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg28_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg29_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg2_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg30_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg31_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg32_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg33_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg34_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg35_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg36_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg37_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg38_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg39_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg3_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg40_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg41_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg42_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg43_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg44_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg45_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg46_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg47_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg48_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg49_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg4_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg5_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg6_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg7_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg8_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]             del arg9_1
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]         return ()
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] runner = Runner(partitions=[])
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] call = runner.call
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] if __name__ == &quot;__main__&quot;:
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code]
V1015 19:13:55.618000 22460 torch/_inductor/graph.py:2382] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/3z/c3zx36tk4abtxhogfchf72ivehsipq4lsckled4kz5c533zx2apc.py
I1015 19:13:59.637000 22460 torch/_inductor/graph.py:2343] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/3z/c3zx36tk4abtxhogfchf72ivehsipq4lsckled4kz5c533zx2apc.py
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] Output code:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # AOT ID: [&#39;1_inference&#39;]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import torch
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import math
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import random
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import os
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import tempfile
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from math import inf, nan
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from cmath import nanj
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.utils import maybe_profile
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch import device, empty_strided
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton.language as tl
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] aten = torch.ops.aten
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] inductor_ops = torch.ops.inductor
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] _quantized = torch.ops._quantized
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] async_compile = AsyncCompile()
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] extern &quot;C&quot;  void  kernel(const float* in_ptr0,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr1,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr2,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr3,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr4,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr5,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr6,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr7,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr8,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        const float* in_ptr9,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr0,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr1,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr2,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr3,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr4,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr5,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr6,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr7,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr8,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                        float* out_ptr9)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr0[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr2[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr4[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr6[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr8[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             {
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] }
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] &#39;&#39;&#39;)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/zr/czr3lns75kwntdd4kbv7cuobqrmx4orie2lal4gttw4y5fiq4ii3.py
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # Source node to ATen node mapping:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] triton_for_fused_1 = async_compile.triton(&#39;triton_for_fused_1&#39;, &#39;&#39;&#39;
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton.language as tl
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] @triton_heuristics.foreach(
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_warps=8,
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr3&#39;: &#39;*fp32&#39;, &#39;out_ptr4&#39;: &#39;*fp32&#39;, &#39;out_ptr5&#39;: &#39;*fp32&#39;, &#39;out_ptr9&#39;: &#39;*fp32&#39;, &#39;out_ptr10&#39;: &#39;*fp32&#39;, &#39;out_ptr11&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr21&#39;: &#39;*fp32&#39;, &#39;out_ptr22&#39;: &#39;*fp32&#39;, &#39;out_ptr23&#39;: &#39;*fp32&#39;, &#39;out_ptr27&#39;: &#39;*fp32&#39;, &#39;out_ptr28&#39;: &#39;*fp32&#39;, &#39;out_ptr29&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr39&#39;: &#39;*fp32&#39;, &#39;out_ptr40&#39;: &#39;*fp32&#39;, &#39;out_ptr41&#39;: &#39;*fp32&#39;, &#39;out_ptr45&#39;: &#39;*fp32&#39;, &#39;out_ptr46&#39;: &#39;*fp32&#39;, &#39;out_ptr47&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr57&#39;: &#39;*fp32&#39;, &#39;out_ptr58&#39;: &#39;*fp32&#39;, &#39;out_ptr59&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_1&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr10&#39;, &#39;out_ptr11&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr21&#39;, &#39;out_ptr22&#39;, &#39;out_ptr23&#39;, &#39;out_ptr27&#39;, &#39;out_ptr28&#39;, &#39;out_ptr29&#39;, &#39;out_ptr3&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr39&#39;, &#39;out_ptr4&#39;, &#39;out_ptr40&#39;, &#39;out_ptr41&#39;, &#39;out_ptr45&#39;, &#39;out_ptr46&#39;, &#39;out_ptr47&#39;, &#39;out_ptr5&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr57&#39;, &#39;out_ptr58&#39;, &#39;out_ptr59&#39;, &#39;out_ptr9&#39;], &#39;backend_hash&#39;: &#39;5C4E406C711B3861DF9C100323E0EC398E2F633BD8802E2E564CD4776AA7ED44&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] )
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] @triton.jit
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     pid = tl.program_id(0)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     XBLOCK: tl.constexpr = 1024
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     if pid &lt; num_xblocks_0:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x0 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp17 = in_ptr4
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp2 = tmp0 - tmp1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp3 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp4 = tmp3 * tmp2
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp7 = tmp4 + tmp6
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp9 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp10 = tmp8 * tmp9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp11 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp12 = tmp0 * tmp11
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp13 = tmp12 * tmp0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp14 = tmp10 + tmp13
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp16 = libdevice.sqrt(tmp14)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp18 = libdevice.pow(tmp9, tmp17)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp19 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp20 = tmp19 - tmp18
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp21 = libdevice.sqrt(tmp20)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp22 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp23 = libdevice.pow(tmp22, tmp17)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp24 = tmp19 - tmp23
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp25 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp26 = (tmp25 / tmp24)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp27 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp28 = tmp26 * tmp27
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp29 = -tmp28
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp30 = tmp21 * tmp29
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp31 = (tmp16 / tmp30)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp32 = (tmp25 / tmp29)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp33 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp34 = tmp32 * tmp33
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp35 = tmp31 + tmp34
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp36 = (tmp7 / tmp35)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp37 = tmp15 + tmp36
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr3 + (x0), tmp7, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr4 + (x0), tmp14, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr5 + (x0), tmp37, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_1:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x1 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp38 = tl.load(in_ptr5 + (x1), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp39 = tl.load(in_ptr6 + (x1), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp46 = tl.load(in_ptr7 + (x1), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp53 = tl.load(in_ptr8 + (x1), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp55 = in_ptr9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp40 = tmp38 - tmp39
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp41 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp42 = tmp41 * tmp40
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp43 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp44 = tl.where(tmp43, tmp38, tmp39)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp45 = tmp42 + tmp44
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp47 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp48 = tmp46 * tmp47
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp49 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp50 = tmp38 * tmp49
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp51 = tmp50 * tmp38
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp52 = tmp48 + tmp51
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp54 = libdevice.sqrt(tmp52)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp56 = libdevice.pow(tmp47, tmp55)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp57 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp58 = tmp57 - tmp56
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp59 = libdevice.sqrt(tmp58)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp60 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp61 = libdevice.pow(tmp60, tmp55)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp62 = tmp57 - tmp61
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp63 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp64 = (tmp63 / tmp62)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp65 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp66 = tmp64 * tmp65
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp67 = -tmp66
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp68 = tmp59 * tmp67
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp69 = (tmp54 / tmp68)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp70 = (tmp63 / tmp67)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp71 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp72 = tmp70 * tmp71
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp73 = tmp69 + tmp72
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp74 = (tmp45 / tmp73)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp75 = tmp53 + tmp74
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr9 + (x1), tmp45, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr10 + (x1), tmp52, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr11 + (x1), tmp75, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_2:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x2 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp76 = tl.load(in_ptr10 + (x2), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp77 = tl.load(in_ptr11 + (x2), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp84 = tl.load(in_ptr12 + (x2), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp91 = tl.load(in_ptr13 + (x2), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp93 = in_ptr14
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp78 = tmp76 - tmp77
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp79 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp80 = tmp79 * tmp78
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp81 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp82 = tl.where(tmp81, tmp76, tmp77)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp83 = tmp80 + tmp82
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp85 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp86 = tmp84 * tmp85
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp87 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp88 = tmp76 * tmp87
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp89 = tmp88 * tmp76
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp90 = tmp86 + tmp89
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp92 = libdevice.sqrt(tmp90)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp94 = libdevice.pow(tmp85, tmp93)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp95 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp96 = tmp95 - tmp94
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp97 = libdevice.sqrt(tmp96)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp98 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp99 = libdevice.pow(tmp98, tmp93)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp100 = tmp95 - tmp99
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp101 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp102 = (tmp101 / tmp100)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp103 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp104 = tmp102 * tmp103
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp105 = -tmp104
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp106 = tmp97 * tmp105
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp107 = (tmp92 / tmp106)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp108 = (tmp101 / tmp105)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp109 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp110 = tmp108 * tmp109
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp111 = tmp107 + tmp110
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp112 = (tmp83 / tmp111)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp113 = tmp91 + tmp112
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr15 + (x2), tmp83, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr16 + (x2), tmp90, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr17 + (x2), tmp113, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_3:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_2
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x3 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp114 = tl.load(in_ptr15 + (x3), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp115 = tl.load(in_ptr16 + (x3), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp122 = tl.load(in_ptr17 + (x3), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp129 = tl.load(in_ptr18 + (x3), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp131 = in_ptr19
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp116 = tmp114 - tmp115
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp117 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp118 = tmp117 * tmp116
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp119 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp120 = tl.where(tmp119, tmp114, tmp115)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp121 = tmp118 + tmp120
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp123 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp124 = tmp122 * tmp123
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp125 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp126 = tmp114 * tmp125
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp127 = tmp126 * tmp114
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp128 = tmp124 + tmp127
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp130 = libdevice.sqrt(tmp128)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp132 = libdevice.pow(tmp123, tmp131)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp133 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp134 = tmp133 - tmp132
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp135 = libdevice.sqrt(tmp134)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp136 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp137 = libdevice.pow(tmp136, tmp131)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp138 = tmp133 - tmp137
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp139 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp140 = (tmp139 / tmp138)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp141 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp142 = tmp140 * tmp141
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp143 = -tmp142
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp144 = tmp135 * tmp143
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp145 = (tmp130 / tmp144)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp146 = (tmp139 / tmp143)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp147 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp148 = tmp146 * tmp147
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp149 = tmp145 + tmp148
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp150 = (tmp121 / tmp149)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp151 = tmp129 + tmp150
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr21 + (x3), tmp121, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr22 + (x3), tmp128, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr23 + (x3), tmp151, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_4:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_3
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x4 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp152 = tl.load(in_ptr20 + (x4), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp153 = tl.load(in_ptr21 + (x4), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp160 = tl.load(in_ptr22 + (x4), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp167 = tl.load(in_ptr23 + (x4), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp169 = in_ptr24
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp154 = tmp152 - tmp153
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp155 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp156 = tmp155 * tmp154
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp157 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp158 = tl.where(tmp157, tmp152, tmp153)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp159 = tmp156 + tmp158
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp161 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp162 = tmp160 * tmp161
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp163 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp164 = tmp152 * tmp163
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp165 = tmp164 * tmp152
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp166 = tmp162 + tmp165
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp168 = libdevice.sqrt(tmp166)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp170 = libdevice.pow(tmp161, tmp169)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp171 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp172 = tmp171 - tmp170
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp173 = libdevice.sqrt(tmp172)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp174 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp175 = libdevice.pow(tmp174, tmp169)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp176 = tmp171 - tmp175
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp177 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp178 = (tmp177 / tmp176)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp179 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp180 = tmp178 * tmp179
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp181 = -tmp180
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp182 = tmp173 * tmp181
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp183 = (tmp168 / tmp182)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp184 = (tmp177 / tmp181)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp185 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp186 = tmp184 * tmp185
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp187 = tmp183 + tmp186
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp188 = (tmp159 / tmp187)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp189 = tmp167 + tmp188
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr27 + (x4), tmp159, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr28 + (x4), tmp166, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr29 + (x4), tmp189, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_5:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_4
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x5 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp190 = tl.load(in_ptr25 + (x5), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp191 = tl.load(in_ptr26 + (x5), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp198 = tl.load(in_ptr27 + (x5), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp205 = tl.load(in_ptr28 + (x5), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp207 = in_ptr29
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp192 = tmp190 - tmp191
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp193 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp194 = tmp193 * tmp192
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp195 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp196 = tl.where(tmp195, tmp190, tmp191)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp197 = tmp194 + tmp196
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp199 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp200 = tmp198 * tmp199
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp201 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp202 = tmp190 * tmp201
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp203 = tmp202 * tmp190
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp204 = tmp200 + tmp203
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp206 = libdevice.sqrt(tmp204)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp208 = libdevice.pow(tmp199, tmp207)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp209 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp210 = tmp209 - tmp208
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp211 = libdevice.sqrt(tmp210)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp212 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp213 = libdevice.pow(tmp212, tmp207)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp214 = tmp209 - tmp213
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp215 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp216 = (tmp215 / tmp214)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp217 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp218 = tmp216 * tmp217
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp219 = -tmp218
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp220 = tmp211 * tmp219
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp221 = (tmp206 / tmp220)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp222 = (tmp215 / tmp219)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp223 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp224 = tmp222 * tmp223
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp225 = tmp221 + tmp224
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp226 = (tmp197 / tmp225)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp227 = tmp205 + tmp226
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr33 + (x5), tmp197, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr34 + (x5), tmp204, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr35 + (x5), tmp227, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_6:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_5
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x6 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp228 = tl.load(in_ptr30 + (x6), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp229 = tl.load(in_ptr31 + (x6), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp236 = tl.load(in_ptr32 + (x6), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp243 = tl.load(in_ptr33 + (x6), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp245 = in_ptr34
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp230 = tmp228 - tmp229
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp231 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp232 = tmp231 * tmp230
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp233 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp234 = tl.where(tmp233, tmp228, tmp229)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp235 = tmp232 + tmp234
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp237 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp238 = tmp236 * tmp237
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp239 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp240 = tmp228 * tmp239
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp241 = tmp240 * tmp228
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp242 = tmp238 + tmp241
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp244 = libdevice.sqrt(tmp242)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp246 = libdevice.pow(tmp237, tmp245)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp247 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp248 = tmp247 - tmp246
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp249 = libdevice.sqrt(tmp248)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp250 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp251 = libdevice.pow(tmp250, tmp245)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp252 = tmp247 - tmp251
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp253 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp254 = (tmp253 / tmp252)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp255 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp256 = tmp254 * tmp255
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp257 = -tmp256
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp258 = tmp249 * tmp257
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp259 = (tmp244 / tmp258)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp260 = (tmp253 / tmp257)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp261 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp262 = tmp260 * tmp261
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp263 = tmp259 + tmp262
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp264 = (tmp235 / tmp263)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp265 = tmp243 + tmp264
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr39 + (x6), tmp235, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr40 + (x6), tmp242, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr41 + (x6), tmp265, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_7:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_6
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x7 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp266 = tl.load(in_ptr35 + (x7), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp267 = tl.load(in_ptr36 + (x7), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp274 = tl.load(in_ptr37 + (x7), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp281 = tl.load(in_ptr38 + (x7), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp283 = in_ptr39
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp268 = tmp266 - tmp267
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp269 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp270 = tmp269 * tmp268
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp271 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp272 = tl.where(tmp271, tmp266, tmp267)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp273 = tmp270 + tmp272
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp275 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp276 = tmp274 * tmp275
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp277 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp278 = tmp266 * tmp277
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp279 = tmp278 * tmp266
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp280 = tmp276 + tmp279
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp282 = libdevice.sqrt(tmp280)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp284 = libdevice.pow(tmp275, tmp283)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp285 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp286 = tmp285 - tmp284
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp287 = libdevice.sqrt(tmp286)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp288 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp289 = libdevice.pow(tmp288, tmp283)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp290 = tmp285 - tmp289
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp291 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp292 = (tmp291 / tmp290)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp293 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp294 = tmp292 * tmp293
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp295 = -tmp294
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp296 = tmp287 * tmp295
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp297 = (tmp282 / tmp296)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp298 = (tmp291 / tmp295)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp299 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp300 = tmp298 * tmp299
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp301 = tmp297 + tmp300
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp302 = (tmp273 / tmp301)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp303 = tmp281 + tmp302
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr45 + (x7), tmp273, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr46 + (x7), tmp280, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr47 + (x7), tmp303, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_8:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_7
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x8 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp304 = tl.load(in_ptr40 + (x8), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp305 = tl.load(in_ptr41 + (x8), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp312 = tl.load(in_ptr42 + (x8), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp319 = tl.load(in_ptr43 + (x8), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp321 = in_ptr44
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp306 = tmp304 - tmp305
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp307 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp308 = tmp307 * tmp306
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp309 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp310 = tl.where(tmp309, tmp304, tmp305)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp311 = tmp308 + tmp310
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp313 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp314 = tmp312 * tmp313
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp315 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp316 = tmp304 * tmp315
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp317 = tmp316 * tmp304
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp318 = tmp314 + tmp317
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp320 = libdevice.sqrt(tmp318)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp322 = libdevice.pow(tmp313, tmp321)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp323 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp324 = tmp323 - tmp322
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp325 = libdevice.sqrt(tmp324)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp326 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp327 = libdevice.pow(tmp326, tmp321)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp328 = tmp323 - tmp327
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp329 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp330 = (tmp329 / tmp328)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp331 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp332 = tmp330 * tmp331
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp333 = -tmp332
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp334 = tmp325 * tmp333
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp335 = (tmp320 / tmp334)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp336 = (tmp329 / tmp333)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp337 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp338 = tmp336 * tmp337
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp339 = tmp335 + tmp338
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp340 = (tmp311 / tmp339)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp341 = tmp319 + tmp340
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr51 + (x8), tmp311, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr52 + (x8), tmp318, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr53 + (x8), tmp341, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     elif pid &lt; num_xblocks_9:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pid_offset = pid - num_xblocks_8
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xnumel = 1048576
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         r0_numel = 1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         x9 = xindex
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp342 = tl.load(in_ptr45 + (x9), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp343 = tl.load(in_ptr46 + (x9), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp350 = tl.load(in_ptr47 + (x9), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp357 = tl.load(in_ptr48 + (x9), None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp359 = in_ptr49
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp344 = tmp342 - tmp343
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp345 = 0.10000000149011612
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp346 = tmp345 * tmp344
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp347 = tl.full([1], False, tl.int1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp348 = tl.where(tmp347, tmp342, tmp343)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp349 = tmp346 + tmp348
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp351 = 0.999
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp352 = tmp350 * tmp351
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp353 = 0.0010000000000000009
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp354 = tmp342 * tmp353
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp355 = tmp354 * tmp342
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp356 = tmp352 + tmp355
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp358 = libdevice.sqrt(tmp356)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp360 = libdevice.pow(tmp351, tmp359)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp361 = 1.0
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp362 = tmp361 - tmp360
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp363 = libdevice.sqrt(tmp362)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp364 = 0.9
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp365 = libdevice.pow(tmp364, tmp359)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp366 = tmp361 - tmp365
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp367 = tl.full([1], 1, tl.int32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp368 = (tmp367 / tmp366)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp369 = 0.001
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp370 = tmp368 * tmp369
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp371 = -tmp370
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp372 = tmp363 * tmp371
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp373 = (tmp358 / tmp372)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp374 = (tmp367 / tmp371)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp375 = 1e-08
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp376 = tmp374 * tmp375
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp377 = tmp373 + tmp376
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp378 = (tmp349 / tmp377)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tmp379 = tmp357 + tmp378
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr57 + (x9), tmp349, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr58 + (x9), tmp356, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         tl.store(out_ptr59 + (x9), tmp379, None)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     else:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         pass
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] async_compile.wait(globals())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del async_compile
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] class Runner:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     def __init__(self, partitions):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         self.partitions = partitions
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     def recursively_apply_fns(self, fns):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         new_callables = []
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         for fn, c in zip(fns, self.partitions):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             new_callables.append(fn(c))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         self.partitions = new_callables
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     def call(self, args):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         args.clear()
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg10_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg11_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg12_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg13_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg14_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg15_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg16_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg17_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg18_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg19_1, (), ())
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         with torch.cuda._DeviceGuard(0):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             torch.cuda.set_device(0)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             # Unsorted Source Nodes: [], Original ATen: []
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             stream0 = get_raw_stream(0)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg0_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg10_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg11_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg12_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg13_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg14_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg15_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg16_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg17_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg18_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg19_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg1_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg20_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg21_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg22_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg23_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg24_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg25_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg26_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg27_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg28_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg29_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg2_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg30_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg31_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg32_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg33_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg34_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg35_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg36_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg37_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg38_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg39_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg3_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg40_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg41_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg42_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg43_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg44_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg45_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg46_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg47_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg48_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg49_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg4_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg5_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg6_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg7_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg8_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]             del arg9_1
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]         return ()
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] runner = Runner(partitions=[])
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] call = runner.call
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     from torch._dynamo.testing import rand_strided
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     from torch._inductor.utils import print_performance
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] if __name__ == &quot;__main__&quot;:
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code]
V1015 19:14:02.472000 22460 torch/_inductor/graph.py:2382] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/rm/crmhpjxzwenotqwjwl3d7kmcop4uprfxdwzvnddzkch3uomol3gu.py
I1015 19:14:02.600000 22460 torch/_inductor/graph.py:2343] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/rm/crmhpjxzwenotqwjwl3d7kmcop4uprfxdwzvnddzkch3uomol3gu.py
eager runtime: 1203.8487999996053us
compiled runtime: 785.2021686176158us
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map.
By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam
optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide
on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a
valuable resource for developers looking to improve the performance of their models with horizontal fusion.</p>
<p>See also:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/compiling_optimizer.html">Compiled optimizer tutorial</a> - an intro into the compiled optimizer.</p></li>
<li><p><a class="reference external" href="https://dev-discuss.pytorch.org/t/compiling-the-optimizer-with-pt2/1669">Compiling the optimizer with PT2</a> - deeper technical details on the compiled optimizer.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 16.082 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-foreach-map-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/162cf335b789dd055d4192f77cb0251c/foreach_map.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">foreach_map.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bcb9aa4fd3968b85310b970dbd86bbc3/foreach_map.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">foreach_map.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/faee5eeb51c8f314872395cc1b776677/foreach_map.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">foreach_map.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-setup">Model Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions-for-foreach-map-implementation">Helper functions for foreach_map implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-and-running-the-compiled-kernel">Setting up and running the compiled kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    
    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>
    

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Explicit horizontal fusion with foreach_map and torch.compile",
       "headline": "Explicit horizontal fusion with foreach_map and torch.compile",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/recipes/foreach_map.html",
       "articleBody": "Note Go to the end to download the full example code. Explicit horizontal fusion with foreach_map and torch.compile# Author: Michael Lazos Horizontal fusion is a key optimization in ML compilers. In eager,this is typically expressed using the torch._foreach* ops which parallelizes operations across a list of tensors. However, supporting all possible permutations of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map allows conversion of any pointwise op in torch to a horiztonally fused foreach variant. In this tutorial, we will demonstrate how to implement the Adam optimizer with foreach_map to generate a fully fused kernel. Note This recipe describes a prototype feature. Prototype features are typically at an early stage for feedback and testing and are subject to change. Prerequisites# PyTorch v2.7.0 or later Model Setup# For this example, we\u2019ll use a simple sequence of linear layers. We instantiate an independent copy to compare the two optimizer implementations. import torch # exit cleanly if we are on a device that doesn\u0027t support ``torch.compile`` if torch.cuda.get_device_capability() \u003c (7, 0): print(\"Exiting because torch.compile is not supported on this device.\") import sys sys.exit(0) # Create simple model model = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\"cuda\") for _ in range(10)] ) model_copy = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\"cuda\") for _ in range(10)] ) input = torch.rand(1024, device=\"cuda\") # run forward pass output = model(input) output_copy = model_copy(input) # run backward to populate the grads for our optimizer below output.sum().backward() output_copy.sum().backward() Helper functions for foreach_map implementation# In this section, we\u2019ll begin our implementation of the Adam optimizer. from torch._higher_order_ops.foreach_map import foreach_map # Helper function to extract optimizer states from a torch.optim.Adam instance def get_inputs(optim): steps = [] params = [] grads = [] exp_avgs = [] exp_avg_sqs = [] for group in optim.param_groups: for p in group[\"params\"]: params.append(p) grads.append(p.grad) state = optim.state[p] exp_avgs.append(state[\"exp_avg\"]) exp_avg_sqs.append(state[\"exp_avg_sq\"]) steps.append(state[\"step\"]) return steps, params, exp_avgs, exp_avg_sqs # Functions to update the different optimizer states def update_exp_avg_sq(exp_avg_sq, grad, beta2): return exp_avg_sq.mul(beta2).addcmul(grad, grad, value=1 - beta2) def update_param(param, step, exp_avg, exp_avg_sq, beta1, beta2, lr, eps): bias_correction1 = 1 - torch.pow(beta1, step) bias_correction2 = (1 - torch.pow(beta2, step)).sqrt() step_size = (lr / bias_correction1).neg() denom = (exp_avg_sq.sqrt() / (bias_correction2 * step_size)).add(eps / step_size) return torch.add(param, torch.div(exp_avg, denom)) # Our full Adam implementation def foreach_map_adam( steps, params, exp_avgs, exp_avg_sqs, weight_decay=0, beta1=0.9, beta2=0.999, lr=1e-3, eps=1e-8, ): with torch.no_grad(): grads = [param.grad for param in params] # update step updated_steps = foreach_map(lambda x: x + 1, steps) torch._foreach_copy_(steps, updated_steps) if weight_decay != 0: foreach_map(torch.add, (grads,), alpha=weight_decay) # Higher-order operators (HOPs) cannot have multiple outputs at the moment # need to call foreach_map once for each output exp_avgs_updated = foreach_map(torch.lerp, exp_avgs, grads, 1 - beta1) exp_avgs_sq_updated = foreach_map(update_exp_avg_sq, exp_avg_sqs, grads, beta2) params_updated = foreach_map( update_param, params, steps, exp_avgs_updated, exp_avgs_sq_updated, beta1, beta2, lr, eps, ) # Higher-order operators (HOPs) don\u0027t support input mutation today # so manually update the states in-place torch._foreach_copy_(exp_avgs, exp_avgs_updated) torch._foreach_copy_(exp_avg_sqs, exp_avgs_sq_updated) torch._foreach_copy_(params, params_updated) return Setting up and running the compiled kernel# In this section, we\u2019ll run our Adam optimizer and compare the results Note torch.compile is only supported on CUDA devices that have a compute capability of 7.0 or higher. opt_eager = torch.optim.Adam(model.parameters(), lr=torch.tensor(0.01)) opt_eager_copy = torch.optim.Adam(model_copy.parameters(), lr=torch.tensor(0.01)) # warm up the optimizer state dict opt_eager.step() opt_eager_copy.step() inputs = get_inputs(opt_eager_copy) compiled_adam = torch.compile(foreach_map_adam) # optionally view the output code torch._logging.set_logs(output_code=True) # Warmup runs to compile the function for _ in range(5): opt_eager.step() compiled_adam(*inputs) for eager_p, compile_p in zip(opt_eager.param_groups[0][\"params\"], opt_eager_copy.param_groups[0][\"params\"]): torch.allclose(eager_p, compile_p) # Benchmark performance # Let\u0027s define a helpful benchmarking function: import torch.utils.benchmark as benchmark def benchmark_torch_function_in_microseconds(f, *args, **kwargs): t0 = benchmark.Timer( stmt=\"f(*args, **kwargs)\", globals={\"args\": args, \"kwargs\": kwargs, \"f\": f} ) return t0.blocked_autorange().mean * 1e6 eager_runtime = benchmark_torch_function_in_microseconds(opt_eager.step) compiled_runtime = benchmark_torch_function_in_microseconds(lambda: compiled_adam(*inputs)) assert eager_runtime \u003e compiled_runtime print(f\"eager runtime: {eager_runtime}us\") print(f\"compiled runtime: {compiled_runtime}us\") V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] Output code: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # AOT ID: [\u00270_inference\u0027] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import torch V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import math V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import random V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import os V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import tempfile V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from math import inf, nan V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from cmath import nanj V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.utils import maybe_profile V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch import device, empty_strided V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton.language as tl V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] aten = torch.ops.aten V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] inductor_ops = torch.ops.inductor V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] _quantized = torch.ops._quantized V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] async_compile = AsyncCompile() V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([\u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027], \u0027\u0027\u0027 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] #include \u003ctorch/csrc/inductor/cpp_prefix.h\u003e V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] extern \"C\" void kernel(const float* in_ptr0, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr1, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr2, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr3, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr4, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr5, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr6, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr7, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr8, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] const float* in_ptr9, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr0, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr1, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr2, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr3, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr4, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr5, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr6, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr7, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr8, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] float* out_ptr9) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr0[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr0[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr1[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr1[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr2[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr2[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr3[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr3[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr4[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr4[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr5[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr5[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr6[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr6[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr7[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr7[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr8[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr8[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] { V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp0 = in_ptr9[static_cast\u003cint64_t\u003e(0L)]; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] out_ptr9[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] } V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] \u0027\u0027\u0027) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/zr/czr3lns75kwntdd4kbv7cuobqrmx4orie2lal4gttw4y5fiq4ii3.py V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # Source node to ATen node mapping: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] triton_for_fused_1 = async_compile.triton(\u0027triton_for_fused_1\u0027, \u0027\u0027\u0027 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] import triton.language as tl V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] @triton_heuristics.foreach( V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_warps=8, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] triton_meta={\u0027signature\u0027: {\u0027in_ptr0\u0027: \u0027*fp32\u0027, \u0027in_ptr1\u0027: \u0027*fp32\u0027, \u0027in_ptr2\u0027: \u0027*fp32\u0027, \u0027in_ptr3\u0027: \u0027*fp32\u0027, \u0027in_ptr4\u0027: \u0027fp32\u0027, \u0027in_ptr5\u0027: \u0027*fp32\u0027, \u0027in_ptr6\u0027: \u0027*fp32\u0027, \u0027in_ptr7\u0027: \u0027*fp32\u0027, \u0027in_ptr8\u0027: \u0027*fp32\u0027, \u0027in_ptr9\u0027: \u0027fp32\u0027, \u0027in_ptr10\u0027: \u0027*fp32\u0027, \u0027in_ptr11\u0027: \u0027*fp32\u0027, \u0027in_ptr12\u0027: \u0027*fp32\u0027, \u0027in_ptr13\u0027: \u0027*fp32\u0027, \u0027in_ptr14\u0027: \u0027fp32\u0027, \u0027in_ptr15\u0027: \u0027*fp32\u0027, \u0027in_ptr16\u0027: \u0027*fp32\u0027, \u0027in_ptr17\u0027: \u0027*fp32\u0027, \u0027in_ptr18\u0027: \u0027*fp32\u0027, \u0027in_ptr19\u0027: \u0027fp32\u0027, \u0027in_ptr20\u0027: \u0027*fp32\u0027, \u0027in_ptr21\u0027: \u0027*fp32\u0027, \u0027in_ptr22\u0027: \u0027*fp32\u0027, \u0027in_ptr23\u0027: \u0027*fp32\u0027, \u0027in_ptr24\u0027: \u0027fp32\u0027, \u0027in_ptr25\u0027: \u0027*fp32\u0027, \u0027in_ptr26\u0027: \u0027*fp32\u0027, \u0027in_ptr27\u0027: \u0027*fp32\u0027, \u0027in_ptr28\u0027: \u0027*fp32\u0027, \u0027in_ptr29\u0027: \u0027fp32\u0027, \u0027in_ptr30\u0027: \u0027*fp32\u0027, \u0027in_ptr31\u0027: \u0027*fp32\u0027, \u0027in_ptr32\u0027: \u0027*fp32\u0027, \u0027in_ptr33\u0027: \u0027*fp32\u0027, \u0027in_ptr34\u0027: \u0027fp32\u0027, \u0027in_ptr35\u0027: \u0027*fp32\u0027, \u0027in_ptr36\u0027: \u0027*fp32\u0027, \u0027in_ptr37\u0027: \u0027*fp32\u0027, \u0027in_ptr38\u0027: \u0027*fp32\u0027, \u0027in_ptr39\u0027: \u0027fp32\u0027, \u0027in_ptr40\u0027: \u0027*fp32\u0027, \u0027in_ptr41\u0027: \u0027*fp32\u0027, \u0027in_ptr42\u0027: \u0027*fp32\u0027, \u0027in_ptr43\u0027: \u0027*fp32\u0027, \u0027in_ptr44\u0027: \u0027fp32\u0027, \u0027in_ptr45\u0027: \u0027*fp32\u0027, \u0027in_ptr46\u0027: \u0027*fp32\u0027, \u0027in_ptr47\u0027: \u0027*fp32\u0027, \u0027in_ptr48\u0027: \u0027*fp32\u0027, \u0027in_ptr49\u0027: \u0027fp32\u0027, \u0027out_ptr3\u0027: \u0027*fp32\u0027, \u0027out_ptr4\u0027: \u0027*fp32\u0027, \u0027out_ptr5\u0027: \u0027*fp32\u0027, \u0027out_ptr9\u0027: \u0027*fp32\u0027, \u0027out_ptr10\u0027: \u0027*fp32\u0027, \u0027out_ptr11\u0027: \u0027*fp32\u0027, \u0027out_ptr15\u0027: \u0027*fp32\u0027, \u0027out_ptr16\u0027: \u0027*fp32\u0027, \u0027out_ptr17\u0027: \u0027*fp32\u0027, \u0027out_ptr21\u0027: \u0027*fp32\u0027, \u0027out_ptr22\u0027: \u0027*fp32\u0027, \u0027out_ptr23\u0027: \u0027*fp32\u0027, \u0027out_ptr27\u0027: \u0027*fp32\u0027, \u0027out_ptr28\u0027: \u0027*fp32\u0027, \u0027out_ptr29\u0027: \u0027*fp32\u0027, \u0027out_ptr33\u0027: \u0027*fp32\u0027, \u0027out_ptr34\u0027: \u0027*fp32\u0027, \u0027out_ptr35\u0027: \u0027*fp32\u0027, \u0027out_ptr39\u0027: \u0027*fp32\u0027, \u0027out_ptr40\u0027: \u0027*fp32\u0027, \u0027out_ptr41\u0027: \u0027*fp32\u0027, \u0027out_ptr45\u0027: \u0027*fp32\u0027, \u0027out_ptr46\u0027: \u0027*fp32\u0027, \u0027out_ptr47\u0027: \u0027*fp32\u0027, \u0027out_ptr51\u0027: \u0027*fp32\u0027, \u0027out_ptr52\u0027: \u0027*fp32\u0027, \u0027out_ptr53\u0027: \u0027*fp32\u0027, \u0027out_ptr57\u0027: \u0027*fp32\u0027, \u0027out_ptr58\u0027: \u0027*fp32\u0027, \u0027out_ptr59\u0027: \u0027*fp32\u0027}, \u0027device\u0027: DeviceProperties(type=\u0027cuda\u0027, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), \u0027constants\u0027: {}, \u0027configs\u0027: [{(0,): [[\u0027tt.divisibility\u0027, 16]], (1,): [[\u0027tt.divisibility\u0027, 16]], (2,): [[\u0027tt.divisibility\u0027, 16]], (3,): [[\u0027tt.divisibility\u0027, 16]], (5,): [[\u0027tt.divisibility\u0027, 16]], (6,): [[\u0027tt.divisibility\u0027, 16]], (7,): [[\u0027tt.divisibility\u0027, 16]], (8,): [[\u0027tt.divisibility\u0027, 16]], (10,): [[\u0027tt.divisibility\u0027, 16]], (11,): [[\u0027tt.divisibility\u0027, 16]], (12,): [[\u0027tt.divisibility\u0027, 16]], (13,): [[\u0027tt.divisibility\u0027, 16]], (15,): [[\u0027tt.divisibility\u0027, 16]], (16,): [[\u0027tt.divisibility\u0027, 16]], (17,): [[\u0027tt.divisibility\u0027, 16]], (18,): [[\u0027tt.divisibility\u0027, 16]], (20,): [[\u0027tt.divisibility\u0027, 16]], (21,): [[\u0027tt.divisibility\u0027, 16]], (22,): [[\u0027tt.divisibility\u0027, 16]], (23,): [[\u0027tt.divisibility\u0027, 16]], (25,): [[\u0027tt.divisibility\u0027, 16]], (26,): [[\u0027tt.divisibility\u0027, 16]], (27,): [[\u0027tt.divisibility\u0027, 16]], (28,): [[\u0027tt.divisibility\u0027, 16]], (30,): [[\u0027tt.divisibility\u0027, 16]], (31,): [[\u0027tt.divisibility\u0027, 16]], (32,): [[\u0027tt.divisibility\u0027, 16]], (33,): [[\u0027tt.divisibility\u0027, 16]], (35,): [[\u0027tt.divisibility\u0027, 16]], (36,): [[\u0027tt.divisibility\u0027, 16]], (37,): [[\u0027tt.divisibility\u0027, 16]], (38,): [[\u0027tt.divisibility\u0027, 16]], (40,): [[\u0027tt.divisibility\u0027, 16]], (41,): [[\u0027tt.divisibility\u0027, 16]], (42,): [[\u0027tt.divisibility\u0027, 16]], (43,): [[\u0027tt.divisibility\u0027, 16]], (45,): [[\u0027tt.divisibility\u0027, 16]], (46,): [[\u0027tt.divisibility\u0027, 16]], (47,): [[\u0027tt.divisibility\u0027, 16]], (48,): [[\u0027tt.divisibility\u0027, 16]], (50,): [[\u0027tt.divisibility\u0027, 16]], (51,): [[\u0027tt.divisibility\u0027, 16]], (52,): [[\u0027tt.divisibility\u0027, 16]], (53,): [[\u0027tt.divisibility\u0027, 16]], (54,): [[\u0027tt.divisibility\u0027, 16]], (55,): [[\u0027tt.divisibility\u0027, 16]], (56,): [[\u0027tt.divisibility\u0027, 16]], (57,): [[\u0027tt.divisibility\u0027, 16]], (58,): [[\u0027tt.divisibility\u0027, 16]], (59,): [[\u0027tt.divisibility\u0027, 16]], (60,): [[\u0027tt.divisibility\u0027, 16]], (61,): [[\u0027tt.divisibility\u0027, 16]], (62,): [[\u0027tt.divisibility\u0027, 16]], (63,): [[\u0027tt.divisibility\u0027, 16]], (64,): [[\u0027tt.divisibility\u0027, 16]], (65,): [[\u0027tt.divisibility\u0027, 16]], (66,): [[\u0027tt.divisibility\u0027, 16]], (67,): [[\u0027tt.divisibility\u0027, 16]], (68,): [[\u0027tt.divisibility\u0027, 16]], (69,): [[\u0027tt.divisibility\u0027, 16]], (70,): [[\u0027tt.divisibility\u0027, 16]], (71,): [[\u0027tt.divisibility\u0027, 16]], (72,): [[\u0027tt.divisibility\u0027, 16]], (73,): [[\u0027tt.divisibility\u0027, 16]], (74,): [[\u0027tt.divisibility\u0027, 16]], (75,): [[\u0027tt.divisibility\u0027, 16]], (76,): [[\u0027tt.divisibility\u0027, 16]], (77,): [[\u0027tt.divisibility\u0027, 16]], (78,): [[\u0027tt.divisibility\u0027, 16]], (79,): [[\u0027tt.divisibility\u0027, 16]]}]}, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] inductor_meta={\u0027grid_type\u0027: \u0027SequentialComboKernelGrid\u0027, \u0027combo_grid_meta\u0027: {\u0027num_kernels\u0027: 10, \u0027min_blocks\u0027: 0, \u0027default_config\u0027: {\u0027XBLOCK\u0027: 1024}, \u0027no_x_dim_0\u0027: False, \u0027xnumel_0\u0027: 1048576, \u0027no_x_dim_1\u0027: False, \u0027xnumel_1\u0027: 1048576, \u0027no_x_dim_2\u0027: False, \u0027xnumel_2\u0027: 1048576, \u0027no_x_dim_3\u0027: False, \u0027xnumel_3\u0027: 1048576, \u0027no_x_dim_4\u0027: False, \u0027xnumel_4\u0027: 1048576, \u0027no_x_dim_5\u0027: False, \u0027xnumel_5\u0027: 1048576, \u0027no_x_dim_6\u0027: False, \u0027xnumel_6\u0027: 1048576, \u0027no_x_dim_7\u0027: False, \u0027xnumel_7\u0027: 1048576, \u0027no_x_dim_8\u0027: False, \u0027xnumel_8\u0027: 1048576, \u0027no_x_dim_9\u0027: False, \u0027xnumel_9\u0027: 1048576}, \u0027kernel_name\u0027: \u0027triton_for_fused_1\u0027, \u0027mutated_arg_names\u0027: [\u0027in_ptr1\u0027, \u0027in_ptr11\u0027, \u0027in_ptr12\u0027, \u0027in_ptr13\u0027, \u0027in_ptr16\u0027, \u0027in_ptr17\u0027, \u0027in_ptr18\u0027, \u0027in_ptr2\u0027, \u0027in_ptr21\u0027, \u0027in_ptr22\u0027, \u0027in_ptr23\u0027, \u0027in_ptr26\u0027, \u0027in_ptr27\u0027, \u0027in_ptr28\u0027, \u0027in_ptr3\u0027, \u0027in_ptr31\u0027, \u0027in_ptr32\u0027, \u0027in_ptr33\u0027, \u0027in_ptr36\u0027, \u0027in_ptr37\u0027, \u0027in_ptr38\u0027, \u0027in_ptr41\u0027, \u0027in_ptr42\u0027, \u0027in_ptr43\u0027, \u0027in_ptr46\u0027, \u0027in_ptr47\u0027, \u0027in_ptr48\u0027, \u0027in_ptr6\u0027, \u0027in_ptr7\u0027, \u0027in_ptr8\u0027, \u0027out_ptr10\u0027, \u0027out_ptr11\u0027, \u0027out_ptr15\u0027, \u0027out_ptr16\u0027, \u0027out_ptr17\u0027, \u0027out_ptr21\u0027, \u0027out_ptr22\u0027, \u0027out_ptr23\u0027, \u0027out_ptr27\u0027, \u0027out_ptr28\u0027, \u0027out_ptr29\u0027, \u0027out_ptr3\u0027, \u0027out_ptr33\u0027, \u0027out_ptr34\u0027, \u0027out_ptr35\u0027, \u0027out_ptr39\u0027, \u0027out_ptr4\u0027, \u0027out_ptr40\u0027, \u0027out_ptr41\u0027, \u0027out_ptr45\u0027, \u0027out_ptr46\u0027, \u0027out_ptr47\u0027, \u0027out_ptr5\u0027, \u0027out_ptr51\u0027, \u0027out_ptr52\u0027, \u0027out_ptr53\u0027, \u0027out_ptr57\u0027, \u0027out_ptr58\u0027, \u0027out_ptr59\u0027, \u0027out_ptr9\u0027], \u0027backend_hash\u0027: \u00275C4E406C711B3861DF9C100323E0EC398E2F633BD8802E2E564CD4776AA7ED44\u0027, \u0027are_deterministic_algorithms_enabled\u0027: False, \u0027assert_indirect_indexing\u0027: True, \u0027autotune_local_cache\u0027: True, \u0027autotune_pointwise\u0027: True, \u0027autotune_remote_cache\u0027: None, \u0027force_disable_caches\u0027: False, \u0027dynamic_scale_rblock\u0027: True, \u0027max_autotune\u0027: False, \u0027max_autotune_pointwise\u0027: False, \u0027min_split_scan_rblock\u0027: 256, \u0027spill_threshold\u0027: 16, \u0027store_cubin\u0027: False}, V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] ) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] @triton.jit V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid = tl.program_id(0) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] XBLOCK: tl.constexpr = 1024 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_0 = tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] if pid \u003c num_xblocks_0: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x0 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp0 = tl.load(in_ptr0 + (x0), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp1 = tl.load(in_ptr1 + (x0), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp8 = tl.load(in_ptr2 + (x0), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp15 = tl.load(in_ptr3 + (x0), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp17 = in_ptr4 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp2 = tmp0 - tmp1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp3 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp4 = tmp3 * tmp2 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp5 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp6 = tl.where(tmp5, tmp0, tmp1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp7 = tmp4 + tmp6 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp9 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp10 = tmp8 * tmp9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp11 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp12 = tmp0 * tmp11 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp13 = tmp12 * tmp0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp14 = tmp10 + tmp13 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp16 = libdevice.sqrt(tmp14) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp18 = libdevice.pow(tmp9, tmp17) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp19 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp20 = tmp19 - tmp18 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp21 = libdevice.sqrt(tmp20) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp22 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp23 = libdevice.pow(tmp22, tmp17) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp24 = tmp19 - tmp23 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp25 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp26 = (tmp25 / tmp24) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp27 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp28 = tmp26 * tmp27 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp29 = -tmp28 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp30 = tmp21 * tmp29 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp31 = (tmp16 / tmp30) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp32 = (tmp25 / tmp29) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp33 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp34 = tmp32 * tmp33 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp35 = tmp31 + tmp34 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp36 = (tmp7 / tmp35) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp37 = tmp15 + tmp36 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr3 + (x0), tmp7, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr4 + (x0), tmp14, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr5 + (x0), tmp37, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_1: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x1 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp38 = tl.load(in_ptr5 + (x1), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp39 = tl.load(in_ptr6 + (x1), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp46 = tl.load(in_ptr7 + (x1), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp53 = tl.load(in_ptr8 + (x1), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp55 = in_ptr9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp40 = tmp38 - tmp39 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp41 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp42 = tmp41 * tmp40 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp43 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp44 = tl.where(tmp43, tmp38, tmp39) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp45 = tmp42 + tmp44 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp47 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp48 = tmp46 * tmp47 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp49 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp50 = tmp38 * tmp49 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp51 = tmp50 * tmp38 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp52 = tmp48 + tmp51 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp54 = libdevice.sqrt(tmp52) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp56 = libdevice.pow(tmp47, tmp55) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp57 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp58 = tmp57 - tmp56 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp59 = libdevice.sqrt(tmp58) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp60 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp61 = libdevice.pow(tmp60, tmp55) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp62 = tmp57 - tmp61 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp63 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp64 = (tmp63 / tmp62) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp65 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp66 = tmp64 * tmp65 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp67 = -tmp66 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp68 = tmp59 * tmp67 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp69 = (tmp54 / tmp68) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp70 = (tmp63 / tmp67) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp71 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp72 = tmp70 * tmp71 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp73 = tmp69 + tmp72 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp74 = (tmp45 / tmp73) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp75 = tmp53 + tmp74 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr9 + (x1), tmp45, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr10 + (x1), tmp52, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr11 + (x1), tmp75, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_2: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x2 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp76 = tl.load(in_ptr10 + (x2), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp77 = tl.load(in_ptr11 + (x2), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp84 = tl.load(in_ptr12 + (x2), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp91 = tl.load(in_ptr13 + (x2), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp93 = in_ptr14 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp78 = tmp76 - tmp77 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp79 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp80 = tmp79 * tmp78 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp81 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp82 = tl.where(tmp81, tmp76, tmp77) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp83 = tmp80 + tmp82 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp85 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp86 = tmp84 * tmp85 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp87 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp88 = tmp76 * tmp87 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp89 = tmp88 * tmp76 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp90 = tmp86 + tmp89 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp92 = libdevice.sqrt(tmp90) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp94 = libdevice.pow(tmp85, tmp93) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp95 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp96 = tmp95 - tmp94 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp97 = libdevice.sqrt(tmp96) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp98 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp99 = libdevice.pow(tmp98, tmp93) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp100 = tmp95 - tmp99 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp101 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp102 = (tmp101 / tmp100) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp103 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp104 = tmp102 * tmp103 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp105 = -tmp104 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp106 = tmp97 * tmp105 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp107 = (tmp92 / tmp106) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp108 = (tmp101 / tmp105) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp109 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp110 = tmp108 * tmp109 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp111 = tmp107 + tmp110 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp112 = (tmp83 / tmp111) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp113 = tmp91 + tmp112 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr15 + (x2), tmp83, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr16 + (x2), tmp90, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr17 + (x2), tmp113, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_3: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_2 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x3 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp114 = tl.load(in_ptr15 + (x3), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp115 = tl.load(in_ptr16 + (x3), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp122 = tl.load(in_ptr17 + (x3), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp129 = tl.load(in_ptr18 + (x3), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp131 = in_ptr19 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp116 = tmp114 - tmp115 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp117 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp118 = tmp117 * tmp116 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp119 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp120 = tl.where(tmp119, tmp114, tmp115) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp121 = tmp118 + tmp120 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp123 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp124 = tmp122 * tmp123 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp125 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp126 = tmp114 * tmp125 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp127 = tmp126 * tmp114 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp128 = tmp124 + tmp127 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp130 = libdevice.sqrt(tmp128) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp132 = libdevice.pow(tmp123, tmp131) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp133 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp134 = tmp133 - tmp132 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp135 = libdevice.sqrt(tmp134) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp136 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp137 = libdevice.pow(tmp136, tmp131) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp138 = tmp133 - tmp137 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp139 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp140 = (tmp139 / tmp138) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp141 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp142 = tmp140 * tmp141 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp143 = -tmp142 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp144 = tmp135 * tmp143 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp145 = (tmp130 / tmp144) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp146 = (tmp139 / tmp143) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp147 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp148 = tmp146 * tmp147 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp149 = tmp145 + tmp148 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp150 = (tmp121 / tmp149) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp151 = tmp129 + tmp150 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr21 + (x3), tmp121, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr22 + (x3), tmp128, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr23 + (x3), tmp151, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_4: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_3 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x4 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp152 = tl.load(in_ptr20 + (x4), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp153 = tl.load(in_ptr21 + (x4), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp160 = tl.load(in_ptr22 + (x4), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp167 = tl.load(in_ptr23 + (x4), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp169 = in_ptr24 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp154 = tmp152 - tmp153 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp155 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp156 = tmp155 * tmp154 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp157 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp158 = tl.where(tmp157, tmp152, tmp153) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp159 = tmp156 + tmp158 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp161 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp162 = tmp160 * tmp161 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp163 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp164 = tmp152 * tmp163 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp165 = tmp164 * tmp152 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp166 = tmp162 + tmp165 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp168 = libdevice.sqrt(tmp166) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp170 = libdevice.pow(tmp161, tmp169) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp171 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp172 = tmp171 - tmp170 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp173 = libdevice.sqrt(tmp172) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp174 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp175 = libdevice.pow(tmp174, tmp169) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp176 = tmp171 - tmp175 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp177 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp178 = (tmp177 / tmp176) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp179 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp180 = tmp178 * tmp179 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp181 = -tmp180 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp182 = tmp173 * tmp181 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp183 = (tmp168 / tmp182) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp184 = (tmp177 / tmp181) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp185 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp186 = tmp184 * tmp185 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp187 = tmp183 + tmp186 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp188 = (tmp159 / tmp187) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp189 = tmp167 + tmp188 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr27 + (x4), tmp159, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr28 + (x4), tmp166, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr29 + (x4), tmp189, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_5: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_4 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x5 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp190 = tl.load(in_ptr25 + (x5), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp191 = tl.load(in_ptr26 + (x5), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp198 = tl.load(in_ptr27 + (x5), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp205 = tl.load(in_ptr28 + (x5), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp207 = in_ptr29 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp192 = tmp190 - tmp191 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp193 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp194 = tmp193 * tmp192 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp195 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp196 = tl.where(tmp195, tmp190, tmp191) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp197 = tmp194 + tmp196 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp199 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp200 = tmp198 * tmp199 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp201 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp202 = tmp190 * tmp201 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp203 = tmp202 * tmp190 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp204 = tmp200 + tmp203 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp206 = libdevice.sqrt(tmp204) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp208 = libdevice.pow(tmp199, tmp207) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp209 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp210 = tmp209 - tmp208 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp211 = libdevice.sqrt(tmp210) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp212 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp213 = libdevice.pow(tmp212, tmp207) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp214 = tmp209 - tmp213 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp215 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp216 = (tmp215 / tmp214) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp217 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp218 = tmp216 * tmp217 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp219 = -tmp218 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp220 = tmp211 * tmp219 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp221 = (tmp206 / tmp220) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp222 = (tmp215 / tmp219) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp223 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp224 = tmp222 * tmp223 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp225 = tmp221 + tmp224 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp226 = (tmp197 / tmp225) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp227 = tmp205 + tmp226 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr33 + (x5), tmp197, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr34 + (x5), tmp204, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr35 + (x5), tmp227, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_6: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_5 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x6 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp228 = tl.load(in_ptr30 + (x6), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp229 = tl.load(in_ptr31 + (x6), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp236 = tl.load(in_ptr32 + (x6), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp243 = tl.load(in_ptr33 + (x6), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp245 = in_ptr34 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp230 = tmp228 - tmp229 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp231 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp232 = tmp231 * tmp230 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp233 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp234 = tl.where(tmp233, tmp228, tmp229) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp235 = tmp232 + tmp234 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp237 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp238 = tmp236 * tmp237 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp239 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp240 = tmp228 * tmp239 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp241 = tmp240 * tmp228 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp242 = tmp238 + tmp241 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp244 = libdevice.sqrt(tmp242) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp246 = libdevice.pow(tmp237, tmp245) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp247 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp248 = tmp247 - tmp246 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp249 = libdevice.sqrt(tmp248) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp250 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp251 = libdevice.pow(tmp250, tmp245) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp252 = tmp247 - tmp251 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp253 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp254 = (tmp253 / tmp252) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp255 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp256 = tmp254 * tmp255 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp257 = -tmp256 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp258 = tmp249 * tmp257 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp259 = (tmp244 / tmp258) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp260 = (tmp253 / tmp257) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp261 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp262 = tmp260 * tmp261 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp263 = tmp259 + tmp262 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp264 = (tmp235 / tmp263) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp265 = tmp243 + tmp264 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr39 + (x6), tmp235, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr40 + (x6), tmp242, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr41 + (x6), tmp265, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_7: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_6 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x7 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp266 = tl.load(in_ptr35 + (x7), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp267 = tl.load(in_ptr36 + (x7), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp274 = tl.load(in_ptr37 + (x7), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp281 = tl.load(in_ptr38 + (x7), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp283 = in_ptr39 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp268 = tmp266 - tmp267 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp269 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp270 = tmp269 * tmp268 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp271 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp272 = tl.where(tmp271, tmp266, tmp267) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp273 = tmp270 + tmp272 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp275 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp276 = tmp274 * tmp275 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp277 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp278 = tmp266 * tmp277 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp279 = tmp278 * tmp266 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp280 = tmp276 + tmp279 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp282 = libdevice.sqrt(tmp280) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp284 = libdevice.pow(tmp275, tmp283) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp285 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp286 = tmp285 - tmp284 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp287 = libdevice.sqrt(tmp286) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp288 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp289 = libdevice.pow(tmp288, tmp283) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp290 = tmp285 - tmp289 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp291 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp292 = (tmp291 / tmp290) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp293 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp294 = tmp292 * tmp293 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp295 = -tmp294 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp296 = tmp287 * tmp295 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp297 = (tmp282 / tmp296) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp298 = (tmp291 / tmp295) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp299 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp300 = tmp298 * tmp299 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp301 = tmp297 + tmp300 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp302 = (tmp273 / tmp301) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp303 = tmp281 + tmp302 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr45 + (x7), tmp273, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr46 + (x7), tmp280, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr47 + (x7), tmp303, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_8: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_7 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x8 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp304 = tl.load(in_ptr40 + (x8), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp305 = tl.load(in_ptr41 + (x8), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp312 = tl.load(in_ptr42 + (x8), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp319 = tl.load(in_ptr43 + (x8), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp321 = in_ptr44 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp306 = tmp304 - tmp305 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp307 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp308 = tmp307 * tmp306 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp309 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp310 = tl.where(tmp309, tmp304, tmp305) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp311 = tmp308 + tmp310 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp313 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp314 = tmp312 * tmp313 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp315 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp316 = tmp304 * tmp315 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp317 = tmp316 * tmp304 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp318 = tmp314 + tmp317 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp320 = libdevice.sqrt(tmp318) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp322 = libdevice.pow(tmp313, tmp321) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp323 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp324 = tmp323 - tmp322 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp325 = libdevice.sqrt(tmp324) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp326 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp327 = libdevice.pow(tmp326, tmp321) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp328 = tmp323 - tmp327 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp329 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp330 = (tmp329 / tmp328) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp331 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp332 = tmp330 * tmp331 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp333 = -tmp332 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp334 = tmp325 * tmp333 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp335 = (tmp320 / tmp334) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp336 = (tmp329 / tmp333) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp337 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp338 = tmp336 * tmp337 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp339 = tmp335 + tmp338 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp340 = (tmp311 / tmp339) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp341 = tmp319 + tmp340 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr51 + (x8), tmp311, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr52 + (x8), tmp318, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr53 + (x8), tmp341, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] elif pid \u003c num_xblocks_9: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pid_offset = pid - num_xblocks_8 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xnumel = 1048576 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] r0_numel = 1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] x9 = xindex V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp342 = tl.load(in_ptr45 + (x9), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp343 = tl.load(in_ptr46 + (x9), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp350 = tl.load(in_ptr47 + (x9), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp357 = tl.load(in_ptr48 + (x9), None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp359 = in_ptr49 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp344 = tmp342 - tmp343 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp345 = 0.10000000149011612 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp346 = tmp345 * tmp344 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp347 = tl.full([1], False, tl.int1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp348 = tl.where(tmp347, tmp342, tmp343) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp349 = tmp346 + tmp348 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp351 = 0.999 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp352 = tmp350 * tmp351 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp353 = 0.0010000000000000009 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp354 = tmp342 * tmp353 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp355 = tmp354 * tmp342 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp356 = tmp352 + tmp355 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp358 = libdevice.sqrt(tmp356) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp360 = libdevice.pow(tmp351, tmp359) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp361 = 1.0 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp362 = tmp361 - tmp360 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp363 = libdevice.sqrt(tmp362) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp364 = 0.9 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp365 = libdevice.pow(tmp364, tmp359) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp366 = tmp361 - tmp365 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp367 = tl.full([1], 1, tl.int32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp368 = (tmp367 / tmp366) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp369 = 0.001 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp370 = tmp368 * tmp369 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp371 = -tmp370 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp372 = tmp363 * tmp371 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp373 = (tmp358 / tmp372) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp374 = (tmp367 / tmp371) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp375 = 1e-08 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp376 = tmp374 * tmp375 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp377 = tmp373 + tmp376 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp378 = (tmp349 / tmp377) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tmp379 = tmp357 + tmp378 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr57 + (x9), tmp349, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr58 + (x9), tmp356, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] tl.store(out_ptr59 + (x9), tmp379, None) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] else: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] pass V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] \u0027\u0027\u0027, device_str=\u0027cuda\u0027) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] async_compile.wait(globals()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del async_compile V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] class Runner: V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def __init__(self, partitions): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] self.partitions = partitions V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def recursively_apply_fns(self, fns): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] new_callables = [] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] for fn, c in zip(fns, self.partitions): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] new_callables.append(fn(c)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] self.partitions = new_callables V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def call(self, args): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] args.clear() V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg0_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg1_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg2_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg3_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg4_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg5_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg6_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg7_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg8_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg9_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg10_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg11_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg12_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg13_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg14_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg15_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg16_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg17_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg18_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg19_1, (), ()) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg20_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg21_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg22_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg23_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg24_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg25_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg26_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg27_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg28_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg29_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg30_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg31_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg32_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg33_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg34_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg35_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg36_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg37_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg38_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg39_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg40_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg41_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg42_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg43_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg44_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg45_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg46_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg47_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg48_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] assert_size_stride(arg49_1, (1024, 1024), (1024, 1)) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] with torch.cuda._DeviceGuard(0): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] torch.cuda.set_device(0) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] stream0 = get_raw_stream(0) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg0_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg10_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg11_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg12_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg13_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg14_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg15_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg16_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg17_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg18_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg19_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg1_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg20_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg21_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg22_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg23_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg24_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg25_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg26_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg27_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg28_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg29_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg2_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg30_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg31_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg32_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg33_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg34_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg35_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg36_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg37_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg38_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg39_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg3_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg40_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg41_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg42_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg43_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg44_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg45_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg46_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg47_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg48_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg49_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg4_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg5_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg6_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg7_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg8_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] del arg9_1 V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] return () V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] runner = Runner(partitions=[]) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] call = runner.call V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10): V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._dynamo.testing import rand_strided V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.utils import print_performance V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg0_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg1_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg2_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg3_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg4_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg5_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg6_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg7_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg8_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg9_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg10_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg11_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg12_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg13_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg14_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg15_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg16_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg17_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg18_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg19_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg20_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg21_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg22_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg23_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg24_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg25_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg26_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg27_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg28_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg29_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg30_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg31_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg32_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg33_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg34_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg35_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg36_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg37_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg38_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg39_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg40_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg41_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg42_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg43_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg44_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg45_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg46_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg47_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg48_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] arg49_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1]) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] return print_performance(fn, times=times, repeat=repeat) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] if __name__ == \"__main__\": V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] from torch._inductor.wrapper_benchmark import compiled_module_main V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] compiled_module_main(\u0027None\u0027, benchmark_compiled_module) V1015 19:13:55.568000 22460 torch/_inductor/graph.py:2371] [0/0] [__output_code] V1015 19:13:55.618000 22460 torch/_inductor/graph.py:2382] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/3z/c3zx36tk4abtxhogfchf72ivehsipq4lsckled4kz5c533zx2apc.py I1015 19:13:59.637000 22460 torch/_inductor/graph.py:2343] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/3z/c3zx36tk4abtxhogfchf72ivehsipq4lsckled4kz5c533zx2apc.py V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] Output code: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # AOT ID: [\u00271_inference\u0027] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import torch V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import math V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import random V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import os V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import tempfile V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from math import inf, nan V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from cmath import nanj V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.utils import maybe_profile V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch import device, empty_strided V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton.language as tl V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] aten = torch.ops.aten V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] inductor_ops = torch.ops.inductor V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] _quantized = torch.ops._quantized V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] async_compile = AsyncCompile() V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([\u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027], \u0027\u0027\u0027 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] #include \u003ctorch/csrc/inductor/cpp_prefix.h\u003e V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] extern \"C\" void kernel(const float* in_ptr0, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr1, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr2, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr3, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr4, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr5, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr6, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr7, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr8, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] const float* in_ptr9, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr0, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr1, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr2, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr3, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr4, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr5, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr6, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr7, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr8, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] float* out_ptr9) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr0[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr0[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr1[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr1[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr2[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr2[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr3[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr3[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr4[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr4[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr5[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr5[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr6[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr6[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr7[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr7[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr8[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr8[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] { V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp0 = in_ptr9[static_cast\u003cint64_t\u003e(0L)]; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] out_ptr9[static_cast\u003cint64_t\u003e(0L)] = tmp2; V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] } V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] \u0027\u0027\u0027) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/zr/czr3lns75kwntdd4kbv7cuobqrmx4orie2lal4gttw4y5fiq4ii3.py V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # Source node to ATen node mapping: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] triton_for_fused_1 = async_compile.triton(\u0027triton_for_fused_1\u0027, \u0027\u0027\u0027 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] import triton.language as tl V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] @triton_heuristics.foreach( V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_warps=8, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] triton_meta={\u0027signature\u0027: {\u0027in_ptr0\u0027: \u0027*fp32\u0027, \u0027in_ptr1\u0027: \u0027*fp32\u0027, \u0027in_ptr2\u0027: \u0027*fp32\u0027, \u0027in_ptr3\u0027: \u0027*fp32\u0027, \u0027in_ptr4\u0027: \u0027fp32\u0027, \u0027in_ptr5\u0027: \u0027*fp32\u0027, \u0027in_ptr6\u0027: \u0027*fp32\u0027, \u0027in_ptr7\u0027: \u0027*fp32\u0027, \u0027in_ptr8\u0027: \u0027*fp32\u0027, \u0027in_ptr9\u0027: \u0027fp32\u0027, \u0027in_ptr10\u0027: \u0027*fp32\u0027, \u0027in_ptr11\u0027: \u0027*fp32\u0027, \u0027in_ptr12\u0027: \u0027*fp32\u0027, \u0027in_ptr13\u0027: \u0027*fp32\u0027, \u0027in_ptr14\u0027: \u0027fp32\u0027, \u0027in_ptr15\u0027: \u0027*fp32\u0027, \u0027in_ptr16\u0027: \u0027*fp32\u0027, \u0027in_ptr17\u0027: \u0027*fp32\u0027, \u0027in_ptr18\u0027: \u0027*fp32\u0027, \u0027in_ptr19\u0027: \u0027fp32\u0027, \u0027in_ptr20\u0027: \u0027*fp32\u0027, \u0027in_ptr21\u0027: \u0027*fp32\u0027, \u0027in_ptr22\u0027: \u0027*fp32\u0027, \u0027in_ptr23\u0027: \u0027*fp32\u0027, \u0027in_ptr24\u0027: \u0027fp32\u0027, \u0027in_ptr25\u0027: \u0027*fp32\u0027, \u0027in_ptr26\u0027: \u0027*fp32\u0027, \u0027in_ptr27\u0027: \u0027*fp32\u0027, \u0027in_ptr28\u0027: \u0027*fp32\u0027, \u0027in_ptr29\u0027: \u0027fp32\u0027, \u0027in_ptr30\u0027: \u0027*fp32\u0027, \u0027in_ptr31\u0027: \u0027*fp32\u0027, \u0027in_ptr32\u0027: \u0027*fp32\u0027, \u0027in_ptr33\u0027: \u0027*fp32\u0027, \u0027in_ptr34\u0027: \u0027fp32\u0027, \u0027in_ptr35\u0027: \u0027*fp32\u0027, \u0027in_ptr36\u0027: \u0027*fp32\u0027, \u0027in_ptr37\u0027: \u0027*fp32\u0027, \u0027in_ptr38\u0027: \u0027*fp32\u0027, \u0027in_ptr39\u0027: \u0027fp32\u0027, \u0027in_ptr40\u0027: \u0027*fp32\u0027, \u0027in_ptr41\u0027: \u0027*fp32\u0027, \u0027in_ptr42\u0027: \u0027*fp32\u0027, \u0027in_ptr43\u0027: \u0027*fp32\u0027, \u0027in_ptr44\u0027: \u0027fp32\u0027, \u0027in_ptr45\u0027: \u0027*fp32\u0027, \u0027in_ptr46\u0027: \u0027*fp32\u0027, \u0027in_ptr47\u0027: \u0027*fp32\u0027, \u0027in_ptr48\u0027: \u0027*fp32\u0027, \u0027in_ptr49\u0027: \u0027fp32\u0027, \u0027out_ptr3\u0027: \u0027*fp32\u0027, \u0027out_ptr4\u0027: \u0027*fp32\u0027, \u0027out_ptr5\u0027: \u0027*fp32\u0027, \u0027out_ptr9\u0027: \u0027*fp32\u0027, \u0027out_ptr10\u0027: \u0027*fp32\u0027, \u0027out_ptr11\u0027: \u0027*fp32\u0027, \u0027out_ptr15\u0027: \u0027*fp32\u0027, \u0027out_ptr16\u0027: \u0027*fp32\u0027, \u0027out_ptr17\u0027: \u0027*fp32\u0027, \u0027out_ptr21\u0027: \u0027*fp32\u0027, \u0027out_ptr22\u0027: \u0027*fp32\u0027, \u0027out_ptr23\u0027: \u0027*fp32\u0027, \u0027out_ptr27\u0027: \u0027*fp32\u0027, \u0027out_ptr28\u0027: \u0027*fp32\u0027, \u0027out_ptr29\u0027: \u0027*fp32\u0027, \u0027out_ptr33\u0027: \u0027*fp32\u0027, \u0027out_ptr34\u0027: \u0027*fp32\u0027, \u0027out_ptr35\u0027: \u0027*fp32\u0027, \u0027out_ptr39\u0027: \u0027*fp32\u0027, \u0027out_ptr40\u0027: \u0027*fp32\u0027, \u0027out_ptr41\u0027: \u0027*fp32\u0027, \u0027out_ptr45\u0027: \u0027*fp32\u0027, \u0027out_ptr46\u0027: \u0027*fp32\u0027, \u0027out_ptr47\u0027: \u0027*fp32\u0027, \u0027out_ptr51\u0027: \u0027*fp32\u0027, \u0027out_ptr52\u0027: \u0027*fp32\u0027, \u0027out_ptr53\u0027: \u0027*fp32\u0027, \u0027out_ptr57\u0027: \u0027*fp32\u0027, \u0027out_ptr58\u0027: \u0027*fp32\u0027, \u0027out_ptr59\u0027: \u0027*fp32\u0027}, \u0027device\u0027: DeviceProperties(type=\u0027cuda\u0027, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), \u0027constants\u0027: {}, \u0027configs\u0027: [{(0,): [[\u0027tt.divisibility\u0027, 16]], (1,): [[\u0027tt.divisibility\u0027, 16]], (2,): [[\u0027tt.divisibility\u0027, 16]], (3,): [[\u0027tt.divisibility\u0027, 16]], (5,): [[\u0027tt.divisibility\u0027, 16]], (6,): [[\u0027tt.divisibility\u0027, 16]], (7,): [[\u0027tt.divisibility\u0027, 16]], (8,): [[\u0027tt.divisibility\u0027, 16]], (10,): [[\u0027tt.divisibility\u0027, 16]], (11,): [[\u0027tt.divisibility\u0027, 16]], (12,): [[\u0027tt.divisibility\u0027, 16]], (13,): [[\u0027tt.divisibility\u0027, 16]], (15,): [[\u0027tt.divisibility\u0027, 16]], (16,): [[\u0027tt.divisibility\u0027, 16]], (17,): [[\u0027tt.divisibility\u0027, 16]], (18,): [[\u0027tt.divisibility\u0027, 16]], (20,): [[\u0027tt.divisibility\u0027, 16]], (21,): [[\u0027tt.divisibility\u0027, 16]], (22,): [[\u0027tt.divisibility\u0027, 16]], (23,): [[\u0027tt.divisibility\u0027, 16]], (25,): [[\u0027tt.divisibility\u0027, 16]], (26,): [[\u0027tt.divisibility\u0027, 16]], (27,): [[\u0027tt.divisibility\u0027, 16]], (28,): [[\u0027tt.divisibility\u0027, 16]], (30,): [[\u0027tt.divisibility\u0027, 16]], (31,): [[\u0027tt.divisibility\u0027, 16]], (32,): [[\u0027tt.divisibility\u0027, 16]], (33,): [[\u0027tt.divisibility\u0027, 16]], (35,): [[\u0027tt.divisibility\u0027, 16]], (36,): [[\u0027tt.divisibility\u0027, 16]], (37,): [[\u0027tt.divisibility\u0027, 16]], (38,): [[\u0027tt.divisibility\u0027, 16]], (40,): [[\u0027tt.divisibility\u0027, 16]], (41,): [[\u0027tt.divisibility\u0027, 16]], (42,): [[\u0027tt.divisibility\u0027, 16]], (43,): [[\u0027tt.divisibility\u0027, 16]], (45,): [[\u0027tt.divisibility\u0027, 16]], (46,): [[\u0027tt.divisibility\u0027, 16]], (47,): [[\u0027tt.divisibility\u0027, 16]], (48,): [[\u0027tt.divisibility\u0027, 16]], (50,): [[\u0027tt.divisibility\u0027, 16]], (51,): [[\u0027tt.divisibility\u0027, 16]], (52,): [[\u0027tt.divisibility\u0027, 16]], (53,): [[\u0027tt.divisibility\u0027, 16]], (54,): [[\u0027tt.divisibility\u0027, 16]], (55,): [[\u0027tt.divisibility\u0027, 16]], (56,): [[\u0027tt.divisibility\u0027, 16]], (57,): [[\u0027tt.divisibility\u0027, 16]], (58,): [[\u0027tt.divisibility\u0027, 16]], (59,): [[\u0027tt.divisibility\u0027, 16]], (60,): [[\u0027tt.divisibility\u0027, 16]], (61,): [[\u0027tt.divisibility\u0027, 16]], (62,): [[\u0027tt.divisibility\u0027, 16]], (63,): [[\u0027tt.divisibility\u0027, 16]], (64,): [[\u0027tt.divisibility\u0027, 16]], (65,): [[\u0027tt.divisibility\u0027, 16]], (66,): [[\u0027tt.divisibility\u0027, 16]], (67,): [[\u0027tt.divisibility\u0027, 16]], (68,): [[\u0027tt.divisibility\u0027, 16]], (69,): [[\u0027tt.divisibility\u0027, 16]], (70,): [[\u0027tt.divisibility\u0027, 16]], (71,): [[\u0027tt.divisibility\u0027, 16]], (72,): [[\u0027tt.divisibility\u0027, 16]], (73,): [[\u0027tt.divisibility\u0027, 16]], (74,): [[\u0027tt.divisibility\u0027, 16]], (75,): [[\u0027tt.divisibility\u0027, 16]], (76,): [[\u0027tt.divisibility\u0027, 16]], (77,): [[\u0027tt.divisibility\u0027, 16]], (78,): [[\u0027tt.divisibility\u0027, 16]], (79,): [[\u0027tt.divisibility\u0027, 16]]}]}, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] inductor_meta={\u0027grid_type\u0027: \u0027SequentialComboKernelGrid\u0027, \u0027combo_grid_meta\u0027: {\u0027num_kernels\u0027: 10, \u0027min_blocks\u0027: 0, \u0027default_config\u0027: {\u0027XBLOCK\u0027: 1024}, \u0027no_x_dim_0\u0027: False, \u0027xnumel_0\u0027: 1048576, \u0027no_x_dim_1\u0027: False, \u0027xnumel_1\u0027: 1048576, \u0027no_x_dim_2\u0027: False, \u0027xnumel_2\u0027: 1048576, \u0027no_x_dim_3\u0027: False, \u0027xnumel_3\u0027: 1048576, \u0027no_x_dim_4\u0027: False, \u0027xnumel_4\u0027: 1048576, \u0027no_x_dim_5\u0027: False, \u0027xnumel_5\u0027: 1048576, \u0027no_x_dim_6\u0027: False, \u0027xnumel_6\u0027: 1048576, \u0027no_x_dim_7\u0027: False, \u0027xnumel_7\u0027: 1048576, \u0027no_x_dim_8\u0027: False, \u0027xnumel_8\u0027: 1048576, \u0027no_x_dim_9\u0027: False, \u0027xnumel_9\u0027: 1048576}, \u0027kernel_name\u0027: \u0027triton_for_fused_1\u0027, \u0027mutated_arg_names\u0027: [\u0027in_ptr1\u0027, \u0027in_ptr11\u0027, \u0027in_ptr12\u0027, \u0027in_ptr13\u0027, \u0027in_ptr16\u0027, \u0027in_ptr17\u0027, \u0027in_ptr18\u0027, \u0027in_ptr2\u0027, \u0027in_ptr21\u0027, \u0027in_ptr22\u0027, \u0027in_ptr23\u0027, \u0027in_ptr26\u0027, \u0027in_ptr27\u0027, \u0027in_ptr28\u0027, \u0027in_ptr3\u0027, \u0027in_ptr31\u0027, \u0027in_ptr32\u0027, \u0027in_ptr33\u0027, \u0027in_ptr36\u0027, \u0027in_ptr37\u0027, \u0027in_ptr38\u0027, \u0027in_ptr41\u0027, \u0027in_ptr42\u0027, \u0027in_ptr43\u0027, \u0027in_ptr46\u0027, \u0027in_ptr47\u0027, \u0027in_ptr48\u0027, \u0027in_ptr6\u0027, \u0027in_ptr7\u0027, \u0027in_ptr8\u0027, \u0027out_ptr10\u0027, \u0027out_ptr11\u0027, \u0027out_ptr15\u0027, \u0027out_ptr16\u0027, \u0027out_ptr17\u0027, \u0027out_ptr21\u0027, \u0027out_ptr22\u0027, \u0027out_ptr23\u0027, \u0027out_ptr27\u0027, \u0027out_ptr28\u0027, \u0027out_ptr29\u0027, \u0027out_ptr3\u0027, \u0027out_ptr33\u0027, \u0027out_ptr34\u0027, \u0027out_ptr35\u0027, \u0027out_ptr39\u0027, \u0027out_ptr4\u0027, \u0027out_ptr40\u0027, \u0027out_ptr41\u0027, \u0027out_ptr45\u0027, \u0027out_ptr46\u0027, \u0027out_ptr47\u0027, \u0027out_ptr5\u0027, \u0027out_ptr51\u0027, \u0027out_ptr52\u0027, \u0027out_ptr53\u0027, \u0027out_ptr57\u0027, \u0027out_ptr58\u0027, \u0027out_ptr59\u0027, \u0027out_ptr9\u0027], \u0027backend_hash\u0027: \u00275C4E406C711B3861DF9C100323E0EC398E2F633BD8802E2E564CD4776AA7ED44\u0027, \u0027are_deterministic_algorithms_enabled\u0027: False, \u0027assert_indirect_indexing\u0027: True, \u0027autotune_local_cache\u0027: True, \u0027autotune_pointwise\u0027: True, \u0027autotune_remote_cache\u0027: None, \u0027force_disable_caches\u0027: False, \u0027dynamic_scale_rblock\u0027: True, \u0027max_autotune\u0027: False, \u0027max_autotune_pointwise\u0027: False, \u0027min_split_scan_rblock\u0027: 256, \u0027spill_threshold\u0027: 16, \u0027store_cubin\u0027: False}, V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] ) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] @triton.jit V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid = tl.program_id(0) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] XBLOCK: tl.constexpr = 1024 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_0 = tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] if pid \u003c num_xblocks_0: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x0 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp0 = tl.load(in_ptr0 + (x0), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp1 = tl.load(in_ptr1 + (x0), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp8 = tl.load(in_ptr2 + (x0), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp15 = tl.load(in_ptr3 + (x0), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp17 = in_ptr4 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp2 = tmp0 - tmp1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp3 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp4 = tmp3 * tmp2 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp5 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp6 = tl.where(tmp5, tmp0, tmp1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp7 = tmp4 + tmp6 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp9 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp10 = tmp8 * tmp9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp11 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp12 = tmp0 * tmp11 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp13 = tmp12 * tmp0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp14 = tmp10 + tmp13 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp16 = libdevice.sqrt(tmp14) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp18 = libdevice.pow(tmp9, tmp17) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp19 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp20 = tmp19 - tmp18 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp21 = libdevice.sqrt(tmp20) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp22 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp23 = libdevice.pow(tmp22, tmp17) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp24 = tmp19 - tmp23 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp25 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp26 = (tmp25 / tmp24) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp27 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp28 = tmp26 * tmp27 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp29 = -tmp28 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp30 = tmp21 * tmp29 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp31 = (tmp16 / tmp30) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp32 = (tmp25 / tmp29) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp33 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp34 = tmp32 * tmp33 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp35 = tmp31 + tmp34 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp36 = (tmp7 / tmp35) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp37 = tmp15 + tmp36 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr3 + (x0), tmp7, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr4 + (x0), tmp14, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr5 + (x0), tmp37, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_1: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x1 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp38 = tl.load(in_ptr5 + (x1), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp39 = tl.load(in_ptr6 + (x1), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp46 = tl.load(in_ptr7 + (x1), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp53 = tl.load(in_ptr8 + (x1), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp55 = in_ptr9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp40 = tmp38 - tmp39 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp41 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp42 = tmp41 * tmp40 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp43 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp44 = tl.where(tmp43, tmp38, tmp39) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp45 = tmp42 + tmp44 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp47 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp48 = tmp46 * tmp47 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp49 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp50 = tmp38 * tmp49 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp51 = tmp50 * tmp38 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp52 = tmp48 + tmp51 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp54 = libdevice.sqrt(tmp52) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp56 = libdevice.pow(tmp47, tmp55) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp57 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp58 = tmp57 - tmp56 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp59 = libdevice.sqrt(tmp58) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp60 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp61 = libdevice.pow(tmp60, tmp55) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp62 = tmp57 - tmp61 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp63 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp64 = (tmp63 / tmp62) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp65 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp66 = tmp64 * tmp65 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp67 = -tmp66 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp68 = tmp59 * tmp67 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp69 = (tmp54 / tmp68) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp70 = (tmp63 / tmp67) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp71 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp72 = tmp70 * tmp71 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp73 = tmp69 + tmp72 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp74 = (tmp45 / tmp73) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp75 = tmp53 + tmp74 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr9 + (x1), tmp45, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr10 + (x1), tmp52, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr11 + (x1), tmp75, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_2: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x2 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp76 = tl.load(in_ptr10 + (x2), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp77 = tl.load(in_ptr11 + (x2), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp84 = tl.load(in_ptr12 + (x2), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp91 = tl.load(in_ptr13 + (x2), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp93 = in_ptr14 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp78 = tmp76 - tmp77 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp79 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp80 = tmp79 * tmp78 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp81 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp82 = tl.where(tmp81, tmp76, tmp77) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp83 = tmp80 + tmp82 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp85 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp86 = tmp84 * tmp85 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp87 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp88 = tmp76 * tmp87 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp89 = tmp88 * tmp76 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp90 = tmp86 + tmp89 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp92 = libdevice.sqrt(tmp90) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp94 = libdevice.pow(tmp85, tmp93) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp95 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp96 = tmp95 - tmp94 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp97 = libdevice.sqrt(tmp96) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp98 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp99 = libdevice.pow(tmp98, tmp93) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp100 = tmp95 - tmp99 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp101 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp102 = (tmp101 / tmp100) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp103 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp104 = tmp102 * tmp103 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp105 = -tmp104 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp106 = tmp97 * tmp105 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp107 = (tmp92 / tmp106) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp108 = (tmp101 / tmp105) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp109 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp110 = tmp108 * tmp109 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp111 = tmp107 + tmp110 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp112 = (tmp83 / tmp111) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp113 = tmp91 + tmp112 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr15 + (x2), tmp83, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr16 + (x2), tmp90, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr17 + (x2), tmp113, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_3: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_2 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x3 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp114 = tl.load(in_ptr15 + (x3), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp115 = tl.load(in_ptr16 + (x3), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp122 = tl.load(in_ptr17 + (x3), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp129 = tl.load(in_ptr18 + (x3), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp131 = in_ptr19 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp116 = tmp114 - tmp115 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp117 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp118 = tmp117 * tmp116 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp119 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp120 = tl.where(tmp119, tmp114, tmp115) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp121 = tmp118 + tmp120 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp123 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp124 = tmp122 * tmp123 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp125 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp126 = tmp114 * tmp125 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp127 = tmp126 * tmp114 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp128 = tmp124 + tmp127 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp130 = libdevice.sqrt(tmp128) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp132 = libdevice.pow(tmp123, tmp131) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp133 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp134 = tmp133 - tmp132 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp135 = libdevice.sqrt(tmp134) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp136 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp137 = libdevice.pow(tmp136, tmp131) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp138 = tmp133 - tmp137 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp139 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp140 = (tmp139 / tmp138) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp141 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp142 = tmp140 * tmp141 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp143 = -tmp142 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp144 = tmp135 * tmp143 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp145 = (tmp130 / tmp144) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp146 = (tmp139 / tmp143) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp147 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp148 = tmp146 * tmp147 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp149 = tmp145 + tmp148 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp150 = (tmp121 / tmp149) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp151 = tmp129 + tmp150 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr21 + (x3), tmp121, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr22 + (x3), tmp128, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr23 + (x3), tmp151, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_4: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_3 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x4 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp152 = tl.load(in_ptr20 + (x4), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp153 = tl.load(in_ptr21 + (x4), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp160 = tl.load(in_ptr22 + (x4), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp167 = tl.load(in_ptr23 + (x4), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp169 = in_ptr24 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp154 = tmp152 - tmp153 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp155 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp156 = tmp155 * tmp154 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp157 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp158 = tl.where(tmp157, tmp152, tmp153) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp159 = tmp156 + tmp158 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp161 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp162 = tmp160 * tmp161 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp163 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp164 = tmp152 * tmp163 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp165 = tmp164 * tmp152 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp166 = tmp162 + tmp165 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp168 = libdevice.sqrt(tmp166) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp170 = libdevice.pow(tmp161, tmp169) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp171 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp172 = tmp171 - tmp170 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp173 = libdevice.sqrt(tmp172) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp174 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp175 = libdevice.pow(tmp174, tmp169) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp176 = tmp171 - tmp175 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp177 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp178 = (tmp177 / tmp176) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp179 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp180 = tmp178 * tmp179 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp181 = -tmp180 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp182 = tmp173 * tmp181 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp183 = (tmp168 / tmp182) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp184 = (tmp177 / tmp181) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp185 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp186 = tmp184 * tmp185 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp187 = tmp183 + tmp186 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp188 = (tmp159 / tmp187) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp189 = tmp167 + tmp188 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr27 + (x4), tmp159, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr28 + (x4), tmp166, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr29 + (x4), tmp189, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_5: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_4 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x5 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp190 = tl.load(in_ptr25 + (x5), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp191 = tl.load(in_ptr26 + (x5), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp198 = tl.load(in_ptr27 + (x5), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp205 = tl.load(in_ptr28 + (x5), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp207 = in_ptr29 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp192 = tmp190 - tmp191 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp193 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp194 = tmp193 * tmp192 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp195 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp196 = tl.where(tmp195, tmp190, tmp191) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp197 = tmp194 + tmp196 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp199 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp200 = tmp198 * tmp199 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp201 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp202 = tmp190 * tmp201 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp203 = tmp202 * tmp190 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp204 = tmp200 + tmp203 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp206 = libdevice.sqrt(tmp204) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp208 = libdevice.pow(tmp199, tmp207) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp209 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp210 = tmp209 - tmp208 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp211 = libdevice.sqrt(tmp210) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp212 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp213 = libdevice.pow(tmp212, tmp207) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp214 = tmp209 - tmp213 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp215 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp216 = (tmp215 / tmp214) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp217 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp218 = tmp216 * tmp217 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp219 = -tmp218 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp220 = tmp211 * tmp219 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp221 = (tmp206 / tmp220) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp222 = (tmp215 / tmp219) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp223 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp224 = tmp222 * tmp223 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp225 = tmp221 + tmp224 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp226 = (tmp197 / tmp225) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp227 = tmp205 + tmp226 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr33 + (x5), tmp197, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr34 + (x5), tmp204, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr35 + (x5), tmp227, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_6: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_5 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x6 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp228 = tl.load(in_ptr30 + (x6), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp229 = tl.load(in_ptr31 + (x6), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp236 = tl.load(in_ptr32 + (x6), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp243 = tl.load(in_ptr33 + (x6), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp245 = in_ptr34 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp230 = tmp228 - tmp229 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp231 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp232 = tmp231 * tmp230 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp233 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp234 = tl.where(tmp233, tmp228, tmp229) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp235 = tmp232 + tmp234 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp237 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp238 = tmp236 * tmp237 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp239 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp240 = tmp228 * tmp239 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp241 = tmp240 * tmp228 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp242 = tmp238 + tmp241 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp244 = libdevice.sqrt(tmp242) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp246 = libdevice.pow(tmp237, tmp245) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp247 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp248 = tmp247 - tmp246 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp249 = libdevice.sqrt(tmp248) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp250 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp251 = libdevice.pow(tmp250, tmp245) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp252 = tmp247 - tmp251 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp253 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp254 = (tmp253 / tmp252) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp255 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp256 = tmp254 * tmp255 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp257 = -tmp256 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp258 = tmp249 * tmp257 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp259 = (tmp244 / tmp258) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp260 = (tmp253 / tmp257) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp261 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp262 = tmp260 * tmp261 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp263 = tmp259 + tmp262 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp264 = (tmp235 / tmp263) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp265 = tmp243 + tmp264 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr39 + (x6), tmp235, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr40 + (x6), tmp242, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr41 + (x6), tmp265, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_7: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_6 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x7 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp266 = tl.load(in_ptr35 + (x7), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp267 = tl.load(in_ptr36 + (x7), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp274 = tl.load(in_ptr37 + (x7), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp281 = tl.load(in_ptr38 + (x7), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp283 = in_ptr39 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp268 = tmp266 - tmp267 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp269 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp270 = tmp269 * tmp268 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp271 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp272 = tl.where(tmp271, tmp266, tmp267) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp273 = tmp270 + tmp272 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp275 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp276 = tmp274 * tmp275 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp277 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp278 = tmp266 * tmp277 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp279 = tmp278 * tmp266 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp280 = tmp276 + tmp279 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp282 = libdevice.sqrt(tmp280) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp284 = libdevice.pow(tmp275, tmp283) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp285 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp286 = tmp285 - tmp284 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp287 = libdevice.sqrt(tmp286) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp288 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp289 = libdevice.pow(tmp288, tmp283) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp290 = tmp285 - tmp289 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp291 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp292 = (tmp291 / tmp290) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp293 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp294 = tmp292 * tmp293 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp295 = -tmp294 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp296 = tmp287 * tmp295 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp297 = (tmp282 / tmp296) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp298 = (tmp291 / tmp295) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp299 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp300 = tmp298 * tmp299 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp301 = tmp297 + tmp300 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp302 = (tmp273 / tmp301) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp303 = tmp281 + tmp302 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr45 + (x7), tmp273, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr46 + (x7), tmp280, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr47 + (x7), tmp303, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_8: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_7 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x8 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp304 = tl.load(in_ptr40 + (x8), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp305 = tl.load(in_ptr41 + (x8), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp312 = tl.load(in_ptr42 + (x8), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp319 = tl.load(in_ptr43 + (x8), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp321 = in_ptr44 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp306 = tmp304 - tmp305 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp307 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp308 = tmp307 * tmp306 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp309 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp310 = tl.where(tmp309, tmp304, tmp305) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp311 = tmp308 + tmp310 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp313 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp314 = tmp312 * tmp313 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp315 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp316 = tmp304 * tmp315 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp317 = tmp316 * tmp304 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp318 = tmp314 + tmp317 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp320 = libdevice.sqrt(tmp318) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp322 = libdevice.pow(tmp313, tmp321) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp323 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp324 = tmp323 - tmp322 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp325 = libdevice.sqrt(tmp324) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp326 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp327 = libdevice.pow(tmp326, tmp321) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp328 = tmp323 - tmp327 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp329 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp330 = (tmp329 / tmp328) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp331 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp332 = tmp330 * tmp331 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp333 = -tmp332 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp334 = tmp325 * tmp333 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp335 = (tmp320 / tmp334) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp336 = (tmp329 / tmp333) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp337 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp338 = tmp336 * tmp337 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp339 = tmp335 + tmp338 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp340 = (tmp311 / tmp339) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp341 = tmp319 + tmp340 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr51 + (x8), tmp311, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr52 + (x8), tmp318, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr53 + (x8), tmp341, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] elif pid \u003c num_xblocks_9: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pid_offset = pid - num_xblocks_8 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xnumel = 1048576 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] r0_numel = 1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] x9 = xindex V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp342 = tl.load(in_ptr45 + (x9), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp343 = tl.load(in_ptr46 + (x9), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp350 = tl.load(in_ptr47 + (x9), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp357 = tl.load(in_ptr48 + (x9), None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp359 = in_ptr49 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp344 = tmp342 - tmp343 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp345 = 0.10000000149011612 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp346 = tmp345 * tmp344 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp347 = tl.full([1], False, tl.int1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp348 = tl.where(tmp347, tmp342, tmp343) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp349 = tmp346 + tmp348 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp351 = 0.999 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp352 = tmp350 * tmp351 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp353 = 0.0010000000000000009 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp354 = tmp342 * tmp353 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp355 = tmp354 * tmp342 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp356 = tmp352 + tmp355 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp358 = libdevice.sqrt(tmp356) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp360 = libdevice.pow(tmp351, tmp359) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp361 = 1.0 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp362 = tmp361 - tmp360 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp363 = libdevice.sqrt(tmp362) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp364 = 0.9 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp365 = libdevice.pow(tmp364, tmp359) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp366 = tmp361 - tmp365 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp367 = tl.full([1], 1, tl.int32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp368 = (tmp367 / tmp366) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp369 = 0.001 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp370 = tmp368 * tmp369 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp371 = -tmp370 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp372 = tmp363 * tmp371 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp373 = (tmp358 / tmp372) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp374 = (tmp367 / tmp371) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp375 = 1e-08 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp376 = tmp374 * tmp375 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp377 = tmp373 + tmp376 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp378 = (tmp349 / tmp377) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tmp379 = tmp357 + tmp378 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr57 + (x9), tmp349, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr58 + (x9), tmp356, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] tl.store(out_ptr59 + (x9), tmp379, None) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] else: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] pass V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] \u0027\u0027\u0027, device_str=\u0027cuda\u0027) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] async_compile.wait(globals()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del async_compile V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] class Runner: V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def __init__(self, partitions): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] self.partitions = partitions V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def recursively_apply_fns(self, fns): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] new_callables = [] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] for fn, c in zip(fns, self.partitions): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] new_callables.append(fn(c)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] self.partitions = new_callables V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def call(self, args): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] args.clear() V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg0_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg1_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg2_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg3_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg4_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg5_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg6_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg7_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg8_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg9_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg10_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg11_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg12_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg13_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg14_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg15_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg16_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg17_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg18_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg19_1, (), ()) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg20_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg21_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg22_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg23_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg24_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg25_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg26_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg27_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg28_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg29_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg30_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg31_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg32_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg33_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg34_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg35_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg36_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg37_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg38_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg39_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg40_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg41_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg42_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg43_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg44_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg45_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg46_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg47_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg48_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] assert_size_stride(arg49_1, (1024, 1024), (1024, 1)) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] with torch.cuda._DeviceGuard(0): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] torch.cuda.set_device(0) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] stream0 = get_raw_stream(0) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg0_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg10_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg11_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg12_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg13_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg14_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg15_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg16_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg17_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg18_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg19_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg1_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg20_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg21_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg22_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg23_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg24_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg25_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg26_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg27_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg28_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg29_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg2_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg30_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg31_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg32_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg33_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg34_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg35_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg36_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg37_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg38_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg39_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg3_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg40_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg41_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg42_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg43_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg44_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg45_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg46_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg47_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg48_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg49_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg4_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg5_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg6_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg7_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg8_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] del arg9_1 V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] return () V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] runner = Runner(partitions=[]) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] call = runner.call V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] recursively_apply_fns = runner.recursively_apply_fns V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10): V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._dynamo.testing import rand_strided V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.utils import print_performance V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg0_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg1_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg2_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg3_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg4_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg5_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg6_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg7_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg8_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg9_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg10_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg11_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg12_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg13_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg14_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg15_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg16_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg17_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg18_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg19_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg20_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg21_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg22_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg23_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg24_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg25_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg26_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg27_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg28_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg29_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg30_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg31_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg32_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg33_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg34_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg35_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg36_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg37_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg38_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg39_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg40_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg41_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg42_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg43_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg44_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg45_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg46_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg47_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg48_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] arg49_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1]) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] return print_performance(fn, times=times, repeat=repeat) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] if __name__ == \"__main__\": V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] from torch._inductor.wrapper_benchmark import compiled_module_main V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] compiled_module_main(\u0027None\u0027, benchmark_compiled_module) V1015 19:14:02.418000 22460 torch/_inductor/graph.py:2371] [0/1] [__output_code] V1015 19:14:02.472000 22460 torch/_inductor/graph.py:2382] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/rm/crmhpjxzwenotqwjwl3d7kmcop4uprfxdwzvnddzkch3uomol3gu.py I1015 19:14:02.600000 22460 torch/_inductor/graph.py:2343] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/rm/crmhpjxzwenotqwjwl3d7kmcop4uprfxdwzvnddzkch3uomol3gu.py eager runtime: 1203.8487999996053us compiled runtime: 785.2021686176158us Conclusion# In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map. By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a valuable resource for developers looking to improve the performance of their models with horizontal fusion. See also: Compiled optimizer tutorial - an intro into the compiled optimizer. Compiling the optimizer with PT2 - deeper technical details on the compiled optimizer. Total running time of the script: (0 minutes 16.082 seconds) Download Jupyter notebook: foreach_map.ipynb Download Python source code: foreach_map.py Download zipped: foreach_map.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/foreach_map.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>