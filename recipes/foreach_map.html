
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-07-20T23:02:43+00:00" />
    <title>Explicit horizontal fusion with foreach_map and torch.compile &#8212; PyTorch Tutorials 2.8.0+cu128 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=c9393ea6" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=bffbcef7"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/foreach_map';</script>
    <link rel="canonical" href="https://pytorch.org/tutorials/recipes/foreach_map.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compile Time Caching Configuration" href="torch_compile_caching_configuration_tutorial.html" />
    <link rel="prev" title="(beta) Utilizing Torch Function modes with torch.compile" href="torch_compile_torch_function_modes.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>
<link rel="canonical" href="/recipes/foreach_map.html" crossorigin="anonymous">
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects.
  document.addEventListener('DOMContentLoaded', function() {
    // Hide cookie banner on local environments
    if (window.location.hostname === 'localhost' ||
        window.location.hostname === '0.0.0.0' ||
        window.location.hostname === '127.0.0.1' ||
        window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="../_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy" content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
   height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
   <!-- End Google Tag Manager (noscript) -->
   <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
   new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
   j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
   'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
   j.onload = function() {
     window.dispatchEvent(new Event('gtm_loaded'));
     console.log('GTM loaded successfully');
   };
   })(window,document,'script','dataLayer','GTM-T8XT4PS');
</script>
 <!-- End Google Tag Manager -->
 <!-- Facebook Pixel Code -->
<script>
   !function(f,b,e,v,n,t,s)
   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
   n.callMethod.apply(n,arguments):n.queue.push(arguments)};
   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
   n.queue=[];t=b.createElement(e);t.async=!0;
   t.src=v;s=b.getElementsByTagName(e)[0];
   s.parentNode.insertBefore(t,s)}(window,document,'script',
   'https://connect.facebook.net/en_US/fbevents.js');
   fbq('init', '243028289693773');
   fbq('track', 'PageView');
</script>
<script>
   document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
 </script>
<noscript>
   <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1"/>
</noscript>
<script>
   function gtag() {
    window.dataLayer.push(arguments);
   }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function(e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>


  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>

  </head>
<body data-feedback-url="https://github.com/pytorch/tutorials" class="pytorch-body">
     <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started">Get Started</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/pytorch-domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
   
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>

  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.8.0+cu128</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_backend_ipex.html">Intel® Extension for PyTorch* Backend on Intel® CPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda_rpc.html">Direct Device-to-Device Communication with TensorPipe CUDA RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="inference_tuning_on_aws_graviton.html">(Beta) PyTorch Inference Performance Tuning on AWS Graviton Processors</a></li>
<li class="toctree-l1"><a class="reference internal" href="amx.html">Leverage Intel® Advanced Matrix Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../recipes_index.html" class="nav-link">Recipes</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Explicit...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article"id="pytorch-article">
   <!-- Hidden breadcrumb schema for SEO only -->
   <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
        <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <link itemprop="item" href="../recipes_index.html">
          <meta itemprop="name" content="Recipes">
          <meta itemprop="position" content="1">
        </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Explicit horizontal fusion with foreach_map and torch.compile">
        <meta itemprop="position" content="2">
      </div>
   </div>

    
    <script>
      if((window.location.href.indexOf("/unstable/")!= -1) && (window.location.href.indexOf("/unstable/unstable_index")< 1))
        {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function() {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/foreach_map</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
         <div id="google-colab-link">
         <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
         <div class="call-to-action-desktop-view">Run in Google Colab</div>
         <div class="call-to-action-mobile-view">Colab</div>
         </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
         <div id="download-notebook-link">
         <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
         <div class="call-to-action-desktop-view">Download Notebook</div>
         <div class="call-to-action-mobile-view">Notebook</div>
         </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
         <div id="github-view-link">
         <img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
         <div class="call-to-action-desktop-view">View on GitHub</div>
         <div class="call-to-action-mobile-view">GitHub</div>
         </div>
      </a>
    </div>
    
    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-foreach-map-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="explicit-horizontal-fusion-with-foreach-map-and-torch-compile">
<span id="sphx-glr-recipes-foreach-map-py"></span><h1>Explicit horizontal fusion with foreach_map and torch.compile<a class="headerlink" href="#explicit-horizontal-fusion-with-foreach-map-and-torch-compile" title="Link to this heading">#</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<dl class="simple">
<dt>Horizontal fusion is a key optimization in ML compilers. In eager,</dt><dd><p>this is typically expressed using the torch._foreach* ops which parallelizes
operations across a list of tensors. However, supporting all possible permutations
of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map
allows conversion of any pointwise op in <code class="docutils literal notranslate"><span class="pre">torch</span></code> to a horiztonally fused foreach
variant. In this tutorial, we will demonstrate how to implement the Adam optimizer
with <code class="docutils literal notranslate"><span class="pre">foreach_map</span></code> to generate a fully fused kernel.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This recipe describes a prototype feature. Prototype features are typically
at an early stage for feedback and testing and are subject to change.</p>
</div>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>PyTorch v2.7.0 or later</p></li>
</ul>
<section id="model-setup">
<h3>Model Setup<a class="headerlink" href="#model-setup" title="Link to this heading">#</a></h3>
<p>For this example, we’ll use a simple sequence of linear layers.
We instantiate an independent copy to compare the two optimizer implementations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># exit cleanly if we are on a device that doesn&#39;t support ``torch.compile``</span>
<span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because torch.compile is not supported on this device.&quot;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create simple model</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># run forward pass</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># run backward to populate the grads for our optimizer below</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="helper-functions-for-foreach-map-implementation">
<h3>Helper functions for foreach_map implementation<a class="headerlink" href="#helper-functions-for-foreach-map-implementation" title="Link to this heading">#</a></h3>
<p>In this section, we’ll begin our implementation of the Adam optimizer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._higher_order_ops.foreach_map</span><span class="w"> </span><span class="kn">import</span> <span class="n">foreach_map</span>

<span class="c1"># Helper function to extract optimizer states from a torch.optim.Adam instance</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_inputs</span><span class="p">(</span><span class="n">optim</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optim</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
            <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg&quot;</span><span class="p">])</span>
            <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg_sq&quot;</span><span class="p">])</span>
            <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">steps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avg_sqs</span>


<span class="c1"># Functions to update the different optimizer states</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_exp_avg_sq</span><span class="p">(</span><span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">beta2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">exp_avg</span><span class="p">,</span> <span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">bias_correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="n">bias_correction2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta2</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">lr</span> <span class="o">/</span> <span class="n">bias_correction1</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">bias_correction2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">))</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">eps</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">(</span><span class="n">param</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">div</span></a><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">))</span>

<span class="c1"># Our full Adam implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">foreach_map_adam</span><span class="p">(</span>
    <span class="n">steps</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">exp_avgs</span><span class="p">,</span>
    <span class="n">exp_avg_sqs</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">with</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
        <span class="c1"># update step</span>
        <span class="n">updated_steps</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">updated_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weight_decay</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">,</span> <span class="p">(</span><span class="n">grads</span><span class="p">,),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="c1"># Higher-order operators (HOPs) cannot have multiple outputs at the moment</span>
        <span class="c1"># need to call foreach_map once for each output</span>
        <span class="n">exp_avgs_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp" title="torch.lerp" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span></a><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
        <span class="n">exp_avgs_sq_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="n">update_exp_avg_sq</span><span class="p">,</span> <span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">beta2</span><span class="p">)</span>
        <span class="n">params_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span>
            <span class="n">update_param</span><span class="p">,</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">steps</span><span class="p">,</span>
            <span class="n">exp_avgs_updated</span><span class="p">,</span>
            <span class="n">exp_avgs_sq_updated</span><span class="p">,</span>
            <span class="n">beta1</span><span class="p">,</span>
            <span class="n">beta2</span><span class="p">,</span>
            <span class="n">lr</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Higher-order operators (HOPs) don&#39;t support input mutation today</span>
        <span class="c1"># so manually  update the states in-place</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avgs_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">exp_avgs_sq_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">params_updated</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</section>
<section id="setting-up-and-running-the-compiled-kernel">
<h3>Setting up and running the compiled kernel<a class="headerlink" href="#setting-up-and-running-the-compiled-kernel" title="Link to this heading">#</a></h3>
<p>In this section, we’ll run our Adam optimizer
and compare the results</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is only supported on CUDA devices that have a compute capability of 7.0 or higher.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model_copy</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># warm up the optimizer state dict</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager_copy</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="p">)</span>
<span class="n">compiled_adam</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foreach_map_adam</span><span class="p">)</span>

<span class="c1"># optionally view the output code</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs" class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">output_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Warmup runs to compile the function</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
    <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">for</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">],</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a><span class="p">)</span>

<span class="c1"># Benchmark performance</span>

 <span class="c1"># Let&#39;s define a helpful benchmarking function:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">benchmark</span>

<span class="k">def</span><span class="w"> </span><span class="nf">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">benchmark</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span>
        <span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;f(*args, **kwargs)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span> <span class="n">f</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">t0</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mf">1e6</span>

<span class="n">eager_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">)</span>
<span class="n">compiled_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">eager_runtime</span> <span class="o">&gt;</span> <span class="n">compiled_runtime</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;eager runtime: </span><span class="si">{</span><span class="n">eager_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;compiled runtime: </span><span class="si">{</span><span class="n">compiled_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] Output code:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] # AOT ID: [&#39;0_inference&#39;]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import torch
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import math
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import random
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import os
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import tempfile
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from math import inf, nan
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from cmath import nanj
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch import device, empty_strided
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import triton
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import triton.language as tl
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] aten = torch.ops.aten
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] _quantized = torch.ops._quantized
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] async_compile = AsyncCompile()
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/al/calrezlmzale753uatf4r4hyoxrgj2cygyga4s35ygdnlqxtbqrk.py
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] # Source node to ATen node mapping:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] triton_for_fused_0 = async_compile.triton(&#39;triton_for_fused_0&#39;, &#39;&#39;&#39;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import triton
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] import triton.language as tl
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] @triton_heuristics.foreach(
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_warps=8,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr6&#39;: &#39;*fp32&#39;, &#39;out_ptr7&#39;: &#39;*fp32&#39;, &#39;out_ptr8&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr24&#39;: &#39;*fp32&#39;, &#39;out_ptr25&#39;: &#39;*fp32&#39;, &#39;out_ptr26&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr42&#39;: &#39;*fp32&#39;, &#39;out_ptr43&#39;: &#39;*fp32&#39;, &#39;out_ptr44&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr60&#39;: &#39;*fp32&#39;, &#39;out_ptr61&#39;: &#39;*fp32&#39;, &#39;out_ptr62&#39;: &#39;*fp32&#39;, &#39;out_ptr69&#39;: &#39;*fp32&#39;, &#39;out_ptr70&#39;: &#39;*fp32&#39;, &#39;out_ptr71&#39;: &#39;*fp32&#39;, &#39;out_ptr78&#39;: &#39;*fp32&#39;, &#39;out_ptr79&#39;: &#39;*fp32&#39;, &#39;out_ptr80&#39;: &#39;*fp32&#39;, &#39;out_ptr87&#39;: &#39;*fp32&#39;, &#39;out_ptr88&#39;: &#39;*fp32&#39;, &#39;out_ptr89&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_0&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr24&#39;, &#39;out_ptr25&#39;, &#39;out_ptr26&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr42&#39;, &#39;out_ptr43&#39;, &#39;out_ptr44&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr6&#39;, &#39;out_ptr60&#39;, &#39;out_ptr61&#39;, &#39;out_ptr62&#39;, &#39;out_ptr69&#39;, &#39;out_ptr7&#39;, &#39;out_ptr70&#39;, &#39;out_ptr71&#39;, &#39;out_ptr78&#39;, &#39;out_ptr79&#39;, &#39;out_ptr8&#39;, &#39;out_ptr80&#39;, &#39;out_ptr87&#39;, &#39;out_ptr88&#39;, &#39;out_ptr89&#39;], &#39;backend_hash&#39;: &#39;5521EADCB2516098F638687B39B477AA524882055648F5AE9FFB68D065B487C6&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] )
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] @triton.jit
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] def triton_for_fused_0(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr6, out_ptr7, out_ptr8, out_ptr15, out_ptr16, out_ptr17, out_ptr24, out_ptr25, out_ptr26, out_ptr33, out_ptr34, out_ptr35, out_ptr42, out_ptr43, out_ptr44, out_ptr51, out_ptr52, out_ptr53, out_ptr60, out_ptr61, out_ptr62, out_ptr69, out_ptr70, out_ptr71, out_ptr78, out_ptr79, out_ptr80, out_ptr87, out_ptr88, out_ptr89):
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     pid = tl.program_id(0)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1024
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     if pid &lt; num_xblocks_0:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x0 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp17 = in_ptr4
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp2 = tmp0 - tmp1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp3 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp4 = tmp3 * tmp2
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp7 = tmp4 + tmp6
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp9 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp11 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp12 = tmp0 * tmp11
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp13 = tmp12 * tmp0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp14 = tmp10 + tmp13
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp16 = libdevice.sqrt(tmp14)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp18 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp19 = tmp17 + tmp18
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp20 = libdevice.pow(tmp9, tmp19)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp21 = tmp18 - tmp20
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp22 = libdevice.sqrt(tmp21)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp23 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp24 = libdevice.pow(tmp23, tmp19)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp25 = tmp18 - tmp24
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp26 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp27 = (tmp26 / tmp25)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp28 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp29 = tmp27 * tmp28
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp30 = -tmp29
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp31 = tmp22 * tmp30
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp32 = (tmp16 / tmp31)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp33 = (tmp26 / tmp30)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp34 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp35 = tmp33 * tmp34
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp36 = tmp32 + tmp35
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp37 = (tmp7 / tmp36)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp38 = tmp15 + tmp37
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr6 + (x0), tmp38, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr7 + (x0), tmp7, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr8 + (x0), tmp14, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_1:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x1 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp39 = tl.load(in_ptr5 + (x1), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp40 = tl.load(in_ptr6 + (x1), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp47 = tl.load(in_ptr7 + (x1), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp54 = tl.load(in_ptr8 + (x1), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp56 = in_ptr9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp41 = tmp39 - tmp40
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp42 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp43 = tmp42 * tmp41
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp44 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp45 = tl.where(tmp44, tmp39, tmp40)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp46 = tmp43 + tmp45
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp48 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp49 = tmp47 * tmp48
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp50 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp51 = tmp39 * tmp50
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp52 = tmp51 * tmp39
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp53 = tmp49 + tmp52
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp55 = libdevice.sqrt(tmp53)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp57 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp58 = tmp56 + tmp57
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp59 = libdevice.pow(tmp48, tmp58)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp60 = tmp57 - tmp59
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp61 = libdevice.sqrt(tmp60)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp62 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp63 = libdevice.pow(tmp62, tmp58)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp64 = tmp57 - tmp63
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp65 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp66 = (tmp65 / tmp64)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp67 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp68 = tmp66 * tmp67
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp69 = -tmp68
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp70 = tmp61 * tmp69
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp71 = (tmp55 / tmp70)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp72 = (tmp65 / tmp69)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp73 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp74 = tmp72 * tmp73
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp75 = tmp71 + tmp74
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp76 = (tmp46 / tmp75)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp77 = tmp54 + tmp76
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr15 + (x1), tmp77, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr16 + (x1), tmp46, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr17 + (x1), tmp53, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_2:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x2 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp78 = tl.load(in_ptr10 + (x2), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp79 = tl.load(in_ptr11 + (x2), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp86 = tl.load(in_ptr12 + (x2), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp93 = tl.load(in_ptr13 + (x2), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp95 = in_ptr14
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp80 = tmp78 - tmp79
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp81 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp82 = tmp81 * tmp80
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp83 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp84 = tl.where(tmp83, tmp78, tmp79)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp85 = tmp82 + tmp84
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp87 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp88 = tmp86 * tmp87
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp89 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp90 = tmp78 * tmp89
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp91 = tmp90 * tmp78
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp92 = tmp88 + tmp91
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp94 = libdevice.sqrt(tmp92)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp96 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp97 = tmp95 + tmp96
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp98 = libdevice.pow(tmp87, tmp97)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp99 = tmp96 - tmp98
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp100 = libdevice.sqrt(tmp99)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp101 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp102 = libdevice.pow(tmp101, tmp97)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp103 = tmp96 - tmp102
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp104 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp105 = (tmp104 / tmp103)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp106 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp107 = tmp105 * tmp106
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp108 = -tmp107
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp109 = tmp100 * tmp108
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp110 = (tmp94 / tmp109)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp111 = (tmp104 / tmp108)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp112 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp113 = tmp111 * tmp112
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp114 = tmp110 + tmp113
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp115 = (tmp85 / tmp114)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp116 = tmp93 + tmp115
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr24 + (x2), tmp116, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr25 + (x2), tmp85, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr26 + (x2), tmp92, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_3:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_2
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x3 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp117 = tl.load(in_ptr15 + (x3), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp118 = tl.load(in_ptr16 + (x3), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp125 = tl.load(in_ptr17 + (x3), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp132 = tl.load(in_ptr18 + (x3), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp134 = in_ptr19
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp119 = tmp117 - tmp118
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp120 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp121 = tmp120 * tmp119
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp122 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp123 = tl.where(tmp122, tmp117, tmp118)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp124 = tmp121 + tmp123
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp126 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp127 = tmp125 * tmp126
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp128 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp129 = tmp117 * tmp128
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp130 = tmp129 * tmp117
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp131 = tmp127 + tmp130
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp133 = libdevice.sqrt(tmp131)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp135 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp136 = tmp134 + tmp135
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp137 = libdevice.pow(tmp126, tmp136)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp138 = tmp135 - tmp137
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp139 = libdevice.sqrt(tmp138)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp140 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp141 = libdevice.pow(tmp140, tmp136)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp142 = tmp135 - tmp141
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp143 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp144 = (tmp143 / tmp142)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp145 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp146 = tmp144 * tmp145
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp147 = -tmp146
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp148 = tmp139 * tmp147
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp149 = (tmp133 / tmp148)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp150 = (tmp143 / tmp147)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp151 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp152 = tmp150 * tmp151
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp153 = tmp149 + tmp152
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp154 = (tmp124 / tmp153)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp155 = tmp132 + tmp154
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr33 + (x3), tmp155, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr34 + (x3), tmp124, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr35 + (x3), tmp131, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_4:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_3
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x4 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp156 = tl.load(in_ptr20 + (x4), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp157 = tl.load(in_ptr21 + (x4), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp164 = tl.load(in_ptr22 + (x4), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp171 = tl.load(in_ptr23 + (x4), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp173 = in_ptr24
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp158 = tmp156 - tmp157
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp159 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp160 = tmp159 * tmp158
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp161 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp162 = tl.where(tmp161, tmp156, tmp157)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp163 = tmp160 + tmp162
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp165 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp166 = tmp164 * tmp165
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp167 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp168 = tmp156 * tmp167
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp169 = tmp168 * tmp156
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp170 = tmp166 + tmp169
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp172 = libdevice.sqrt(tmp170)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp174 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp175 = tmp173 + tmp174
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp176 = libdevice.pow(tmp165, tmp175)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp177 = tmp174 - tmp176
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp178 = libdevice.sqrt(tmp177)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp179 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp180 = libdevice.pow(tmp179, tmp175)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp181 = tmp174 - tmp180
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp182 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp183 = (tmp182 / tmp181)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp184 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp185 = tmp183 * tmp184
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp186 = -tmp185
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp187 = tmp178 * tmp186
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp188 = (tmp172 / tmp187)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp189 = (tmp182 / tmp186)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp190 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp191 = tmp189 * tmp190
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp192 = tmp188 + tmp191
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp193 = (tmp163 / tmp192)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp194 = tmp171 + tmp193
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr42 + (x4), tmp194, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr43 + (x4), tmp163, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr44 + (x4), tmp170, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_5:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_4
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x5 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp195 = tl.load(in_ptr25 + (x5), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp196 = tl.load(in_ptr26 + (x5), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp203 = tl.load(in_ptr27 + (x5), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp210 = tl.load(in_ptr28 + (x5), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp212 = in_ptr29
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp197 = tmp195 - tmp196
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp198 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp199 = tmp198 * tmp197
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp200 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp201 = tl.where(tmp200, tmp195, tmp196)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp202 = tmp199 + tmp201
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp204 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp205 = tmp203 * tmp204
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp206 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp207 = tmp195 * tmp206
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp208 = tmp207 * tmp195
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp209 = tmp205 + tmp208
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp211 = libdevice.sqrt(tmp209)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp213 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp214 = tmp212 + tmp213
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp215 = libdevice.pow(tmp204, tmp214)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp216 = tmp213 - tmp215
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp217 = libdevice.sqrt(tmp216)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp218 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp219 = libdevice.pow(tmp218, tmp214)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp220 = tmp213 - tmp219
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp221 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp222 = (tmp221 / tmp220)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp223 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp224 = tmp222 * tmp223
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp225 = -tmp224
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp226 = tmp217 * tmp225
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp227 = (tmp211 / tmp226)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp228 = (tmp221 / tmp225)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp229 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp230 = tmp228 * tmp229
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp231 = tmp227 + tmp230
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp232 = (tmp202 / tmp231)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp233 = tmp210 + tmp232
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr51 + (x5), tmp233, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr52 + (x5), tmp202, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr53 + (x5), tmp209, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_6:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_5
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x6 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp234 = tl.load(in_ptr30 + (x6), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp235 = tl.load(in_ptr31 + (x6), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp242 = tl.load(in_ptr32 + (x6), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp249 = tl.load(in_ptr33 + (x6), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp251 = in_ptr34
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp236 = tmp234 - tmp235
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp237 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp238 = tmp237 * tmp236
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp239 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp240 = tl.where(tmp239, tmp234, tmp235)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp241 = tmp238 + tmp240
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp243 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp244 = tmp242 * tmp243
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp245 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp246 = tmp234 * tmp245
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp247 = tmp246 * tmp234
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp248 = tmp244 + tmp247
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp250 = libdevice.sqrt(tmp248)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp252 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp253 = tmp251 + tmp252
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp254 = libdevice.pow(tmp243, tmp253)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp255 = tmp252 - tmp254
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp256 = libdevice.sqrt(tmp255)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp257 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp258 = libdevice.pow(tmp257, tmp253)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp259 = tmp252 - tmp258
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp260 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp261 = (tmp260 / tmp259)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp262 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp263 = tmp261 * tmp262
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp264 = -tmp263
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp265 = tmp256 * tmp264
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp266 = (tmp250 / tmp265)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp267 = (tmp260 / tmp264)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp268 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp269 = tmp267 * tmp268
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp270 = tmp266 + tmp269
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp271 = (tmp241 / tmp270)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp272 = tmp249 + tmp271
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr60 + (x6), tmp272, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr61 + (x6), tmp241, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr62 + (x6), tmp248, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_7:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_6
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x7 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp273 = tl.load(in_ptr35 + (x7), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp274 = tl.load(in_ptr36 + (x7), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp281 = tl.load(in_ptr37 + (x7), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp288 = tl.load(in_ptr38 + (x7), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp290 = in_ptr39
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp275 = tmp273 - tmp274
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp276 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp277 = tmp276 * tmp275
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp278 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp279 = tl.where(tmp278, tmp273, tmp274)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp280 = tmp277 + tmp279
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp282 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp283 = tmp281 * tmp282
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp284 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp285 = tmp273 * tmp284
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp286 = tmp285 * tmp273
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp287 = tmp283 + tmp286
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp289 = libdevice.sqrt(tmp287)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp291 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp292 = tmp290 + tmp291
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp293 = libdevice.pow(tmp282, tmp292)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp294 = tmp291 - tmp293
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp295 = libdevice.sqrt(tmp294)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp296 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp297 = libdevice.pow(tmp296, tmp292)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp298 = tmp291 - tmp297
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp299 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp300 = (tmp299 / tmp298)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp301 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp302 = tmp300 * tmp301
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp303 = -tmp302
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp304 = tmp295 * tmp303
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp305 = (tmp289 / tmp304)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp306 = (tmp299 / tmp303)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp307 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp308 = tmp306 * tmp307
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp309 = tmp305 + tmp308
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp310 = (tmp280 / tmp309)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp311 = tmp288 + tmp310
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr69 + (x7), tmp311, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr70 + (x7), tmp280, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr71 + (x7), tmp287, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_8:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_7
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x8 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp312 = tl.load(in_ptr40 + (x8), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp313 = tl.load(in_ptr41 + (x8), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp320 = tl.load(in_ptr42 + (x8), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp327 = tl.load(in_ptr43 + (x8), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp329 = in_ptr44
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp314 = tmp312 - tmp313
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp315 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp316 = tmp315 * tmp314
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp317 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp318 = tl.where(tmp317, tmp312, tmp313)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp319 = tmp316 + tmp318
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp321 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp322 = tmp320 * tmp321
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp323 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp324 = tmp312 * tmp323
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp325 = tmp324 * tmp312
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp326 = tmp322 + tmp325
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp328 = libdevice.sqrt(tmp326)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp330 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp331 = tmp329 + tmp330
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp332 = libdevice.pow(tmp321, tmp331)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp333 = tmp330 - tmp332
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp334 = libdevice.sqrt(tmp333)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp335 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp336 = libdevice.pow(tmp335, tmp331)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp337 = tmp330 - tmp336
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp338 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp339 = (tmp338 / tmp337)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp340 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp341 = tmp339 * tmp340
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp342 = -tmp341
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp343 = tmp334 * tmp342
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp344 = (tmp328 / tmp343)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp345 = (tmp338 / tmp342)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp346 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp347 = tmp345 * tmp346
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp348 = tmp344 + tmp347
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp349 = (tmp319 / tmp348)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp350 = tmp327 + tmp349
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr78 + (x8), tmp350, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr79 + (x8), tmp319, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr80 + (x8), tmp326, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     elif pid &lt; num_xblocks_9:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pid_offset = pid - num_xblocks_8
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xnumel = 1048576
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         r0_numel = 1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         x9 = xindex
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp351 = tl.load(in_ptr45 + (x9), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp352 = tl.load(in_ptr46 + (x9), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp359 = tl.load(in_ptr47 + (x9), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp366 = tl.load(in_ptr48 + (x9), None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp368 = in_ptr49
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp353 = tmp351 - tmp352
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp354 = 0.10000000149011612
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp355 = tmp354 * tmp353
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp356 = tl.full([1], False, tl.int1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp357 = tl.where(tmp356, tmp351, tmp352)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp358 = tmp355 + tmp357
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp360 = 0.999
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp361 = tmp359 * tmp360
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp362 = 0.0010000000000000009
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp363 = tmp351 * tmp362
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp364 = tmp363 * tmp351
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp365 = tmp361 + tmp364
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp367 = libdevice.sqrt(tmp365)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp369 = 1.0
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp370 = tmp368 + tmp369
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp371 = libdevice.pow(tmp360, tmp370)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp372 = tmp369 - tmp371
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp373 = libdevice.sqrt(tmp372)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp374 = 0.9
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp375 = libdevice.pow(tmp374, tmp370)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp376 = tmp369 - tmp375
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp377 = tl.full([1], 1, tl.int32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp378 = (tmp377 / tmp376)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp379 = 0.001
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp380 = tmp378 * tmp379
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp381 = -tmp380
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp382 = tmp373 * tmp381
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp383 = (tmp367 / tmp382)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp384 = (tmp377 / tmp381)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp385 = 1e-08
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp386 = tmp384 * tmp385
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp387 = tmp383 + tmp386
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp388 = (tmp358 / tmp387)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tmp389 = tmp366 + tmp388
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr87 + (x9), tmp389, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr88 + (x9), tmp358, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         tl.store(out_ptr89 + (x9), tmp365, None)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     else:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         pass
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] cpp_fused__foreach_copy_1 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] extern &quot;C&quot;  void kernel(const float* in_ptr0,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr1,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr2,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr3,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr4,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr5,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr6,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr7,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr8,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        const float* in_ptr9,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr1,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr3,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr5,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr7,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr9,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr11,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr13,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr15,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr17,
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                        float* out_ptr19)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr11[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr13[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr15[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr17[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             {
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]                 out_ptr19[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]             }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] }
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] &#39;&#39;&#39;)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] async_compile.wait(globals())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] del async_compile
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] def call(args):
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     args.clear()
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg10_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg11_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg12_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg13_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg14_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg15_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg16_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg17_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg18_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg19_1, (), ())
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         torch.cuda.set_device(0)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         triton_for_fused_0.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1, arg31_1, arg21_1, arg41_1, arg1_1, arg11_1, arg32_1, arg22_1, arg42_1, arg2_1, arg12_1, arg33_1, arg23_1, arg43_1, arg3_1, arg13_1, arg34_1, arg24_1, arg44_1, arg4_1, arg14_1, arg35_1, arg25_1, arg45_1, arg5_1, arg15_1, arg36_1, arg26_1, arg46_1, arg6_1, arg16_1, arg37_1, arg27_1, arg47_1, arg7_1, arg17_1, arg38_1, arg28_1, arg48_1, arg8_1, arg18_1, arg39_1, arg29_1, arg49_1, arg9_1, arg19_1, arg0_1, arg20_1, arg40_1, arg1_1, arg21_1, arg41_1, arg2_1, arg22_1, arg42_1, arg3_1, arg23_1, arg43_1, arg4_1, arg24_1, arg44_1, arg5_1, arg25_1, arg45_1, arg6_1, arg26_1, arg46_1, arg7_1, arg27_1, arg47_1, arg8_1, arg28_1, arg48_1, arg9_1, arg29_1, arg49_1, stream=stream0)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg0_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg1_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg20_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg21_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg22_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg23_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg24_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg25_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg26_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg27_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg28_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg29_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg2_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg30_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg31_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg32_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg33_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg34_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg35_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg36_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg37_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg38_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg39_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg3_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg40_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg41_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg42_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg43_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg44_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg45_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg46_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg47_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg48_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg49_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg4_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg5_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg6_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg7_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg8_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]         del arg9_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     cpp_fused__foreach_copy_1(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg10_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg11_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg12_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg13_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg14_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg15_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg16_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg17_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg18_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     del arg19_1
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     return ()
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code] if __name__ == &quot;__main__&quot;:
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0902 15:22:00.337000 22327 torch/_inductor/graph.py:2345] [0/0] [__output_code]
V0902 15:22:00.383000 22327 torch/_inductor/graph.py:2356] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/ff/cffqwnpkieergngjngozdun467la5vp6eyiisxxpikirosuditrp.py
I0902 15:22:04.362000 22327 torch/_inductor/graph.py:2317] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/ff/cffqwnpkieergngjngozdun467la5vp6eyiisxxpikirosuditrp.py
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] Output code:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] # AOT ID: [&#39;1_inference&#39;]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import torch
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import math
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import random
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import os
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import tempfile
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from math import inf, nan
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from cmath import nanj
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.utils import maybe_profile
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch import device, empty_strided
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import triton
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import triton.language as tl
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] aten = torch.ops.aten
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] inductor_ops = torch.ops.inductor
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] _quantized = torch.ops._quantized
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] async_compile = AsyncCompile()
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/al/calrezlmzale753uatf4r4hyoxrgj2cygyga4s35ygdnlqxtbqrk.py
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] # Source node to ATen node mapping:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] triton_for_fused_0 = async_compile.triton(&#39;triton_for_fused_0&#39;, &#39;&#39;&#39;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import triton
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] import triton.language as tl
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] @triton_heuristics.foreach(
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_warps=8,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr6&#39;: &#39;*fp32&#39;, &#39;out_ptr7&#39;: &#39;*fp32&#39;, &#39;out_ptr8&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr24&#39;: &#39;*fp32&#39;, &#39;out_ptr25&#39;: &#39;*fp32&#39;, &#39;out_ptr26&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr42&#39;: &#39;*fp32&#39;, &#39;out_ptr43&#39;: &#39;*fp32&#39;, &#39;out_ptr44&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr60&#39;: &#39;*fp32&#39;, &#39;out_ptr61&#39;: &#39;*fp32&#39;, &#39;out_ptr62&#39;: &#39;*fp32&#39;, &#39;out_ptr69&#39;: &#39;*fp32&#39;, &#39;out_ptr70&#39;: &#39;*fp32&#39;, &#39;out_ptr71&#39;: &#39;*fp32&#39;, &#39;out_ptr78&#39;: &#39;*fp32&#39;, &#39;out_ptr79&#39;: &#39;*fp32&#39;, &#39;out_ptr80&#39;: &#39;*fp32&#39;, &#39;out_ptr87&#39;: &#39;*fp32&#39;, &#39;out_ptr88&#39;: &#39;*fp32&#39;, &#39;out_ptr89&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_0&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr24&#39;, &#39;out_ptr25&#39;, &#39;out_ptr26&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr42&#39;, &#39;out_ptr43&#39;, &#39;out_ptr44&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr6&#39;, &#39;out_ptr60&#39;, &#39;out_ptr61&#39;, &#39;out_ptr62&#39;, &#39;out_ptr69&#39;, &#39;out_ptr7&#39;, &#39;out_ptr70&#39;, &#39;out_ptr71&#39;, &#39;out_ptr78&#39;, &#39;out_ptr79&#39;, &#39;out_ptr8&#39;, &#39;out_ptr80&#39;, &#39;out_ptr87&#39;, &#39;out_ptr88&#39;, &#39;out_ptr89&#39;], &#39;backend_hash&#39;: &#39;5521EADCB2516098F638687B39B477AA524882055648F5AE9FFB68D065B487C6&#39;, &#39;are_deterministic_algorithms_enabled&#39;: False, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False},
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] )
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] @triton.jit
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] def triton_for_fused_0(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr6, out_ptr7, out_ptr8, out_ptr15, out_ptr16, out_ptr17, out_ptr24, out_ptr25, out_ptr26, out_ptr33, out_ptr34, out_ptr35, out_ptr42, out_ptr43, out_ptr44, out_ptr51, out_ptr52, out_ptr53, out_ptr60, out_ptr61, out_ptr62, out_ptr69, out_ptr70, out_ptr71, out_ptr78, out_ptr79, out_ptr80, out_ptr87, out_ptr88, out_ptr89):
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     pid = tl.program_id(0)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     XBLOCK: tl.constexpr = 1024
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     if pid &lt; num_xblocks_0:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x0 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp17 = in_ptr4
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp2 = tmp0 - tmp1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp3 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp4 = tmp3 * tmp2
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp7 = tmp4 + tmp6
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp9 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp10 = tmp8 * tmp9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp11 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp12 = tmp0 * tmp11
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp13 = tmp12 * tmp0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp14 = tmp10 + tmp13
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp16 = libdevice.sqrt(tmp14)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp18 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp19 = tmp17 + tmp18
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp20 = libdevice.pow(tmp9, tmp19)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp21 = tmp18 - tmp20
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp22 = libdevice.sqrt(tmp21)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp23 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp24 = libdevice.pow(tmp23, tmp19)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp25 = tmp18 - tmp24
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp26 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp27 = (tmp26 / tmp25)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp28 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp29 = tmp27 * tmp28
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp30 = -tmp29
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp31 = tmp22 * tmp30
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp32 = (tmp16 / tmp31)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp33 = (tmp26 / tmp30)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp34 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp35 = tmp33 * tmp34
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp36 = tmp32 + tmp35
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp37 = (tmp7 / tmp36)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp38 = tmp15 + tmp37
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr6 + (x0), tmp38, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr7 + (x0), tmp7, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr8 + (x0), tmp14, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_1:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x1 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp39 = tl.load(in_ptr5 + (x1), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp40 = tl.load(in_ptr6 + (x1), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp47 = tl.load(in_ptr7 + (x1), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp54 = tl.load(in_ptr8 + (x1), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp56 = in_ptr9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp41 = tmp39 - tmp40
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp42 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp43 = tmp42 * tmp41
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp44 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp45 = tl.where(tmp44, tmp39, tmp40)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp46 = tmp43 + tmp45
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp48 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp49 = tmp47 * tmp48
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp50 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp51 = tmp39 * tmp50
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp52 = tmp51 * tmp39
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp53 = tmp49 + tmp52
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp55 = libdevice.sqrt(tmp53)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp57 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp58 = tmp56 + tmp57
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp59 = libdevice.pow(tmp48, tmp58)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp60 = tmp57 - tmp59
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp61 = libdevice.sqrt(tmp60)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp62 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp63 = libdevice.pow(tmp62, tmp58)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp64 = tmp57 - tmp63
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp65 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp66 = (tmp65 / tmp64)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp67 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp68 = tmp66 * tmp67
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp69 = -tmp68
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp70 = tmp61 * tmp69
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp71 = (tmp55 / tmp70)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp72 = (tmp65 / tmp69)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp73 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp74 = tmp72 * tmp73
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp75 = tmp71 + tmp74
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp76 = (tmp46 / tmp75)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp77 = tmp54 + tmp76
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr15 + (x1), tmp77, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr16 + (x1), tmp46, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr17 + (x1), tmp53, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_2:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x2 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp78 = tl.load(in_ptr10 + (x2), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp79 = tl.load(in_ptr11 + (x2), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp86 = tl.load(in_ptr12 + (x2), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp93 = tl.load(in_ptr13 + (x2), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp95 = in_ptr14
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp80 = tmp78 - tmp79
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp81 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp82 = tmp81 * tmp80
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp83 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp84 = tl.where(tmp83, tmp78, tmp79)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp85 = tmp82 + tmp84
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp87 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp88 = tmp86 * tmp87
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp89 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp90 = tmp78 * tmp89
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp91 = tmp90 * tmp78
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp92 = tmp88 + tmp91
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp94 = libdevice.sqrt(tmp92)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp96 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp97 = tmp95 + tmp96
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp98 = libdevice.pow(tmp87, tmp97)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp99 = tmp96 - tmp98
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp100 = libdevice.sqrt(tmp99)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp101 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp102 = libdevice.pow(tmp101, tmp97)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp103 = tmp96 - tmp102
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp104 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp105 = (tmp104 / tmp103)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp106 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp107 = tmp105 * tmp106
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp108 = -tmp107
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp109 = tmp100 * tmp108
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp110 = (tmp94 / tmp109)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp111 = (tmp104 / tmp108)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp112 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp113 = tmp111 * tmp112
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp114 = tmp110 + tmp113
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp115 = (tmp85 / tmp114)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp116 = tmp93 + tmp115
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr24 + (x2), tmp116, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr25 + (x2), tmp85, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr26 + (x2), tmp92, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_3:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_2
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x3 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp117 = tl.load(in_ptr15 + (x3), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp118 = tl.load(in_ptr16 + (x3), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp125 = tl.load(in_ptr17 + (x3), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp132 = tl.load(in_ptr18 + (x3), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp134 = in_ptr19
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp119 = tmp117 - tmp118
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp120 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp121 = tmp120 * tmp119
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp122 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp123 = tl.where(tmp122, tmp117, tmp118)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp124 = tmp121 + tmp123
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp126 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp127 = tmp125 * tmp126
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp128 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp129 = tmp117 * tmp128
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp130 = tmp129 * tmp117
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp131 = tmp127 + tmp130
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp133 = libdevice.sqrt(tmp131)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp135 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp136 = tmp134 + tmp135
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp137 = libdevice.pow(tmp126, tmp136)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp138 = tmp135 - tmp137
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp139 = libdevice.sqrt(tmp138)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp140 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp141 = libdevice.pow(tmp140, tmp136)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp142 = tmp135 - tmp141
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp143 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp144 = (tmp143 / tmp142)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp145 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp146 = tmp144 * tmp145
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp147 = -tmp146
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp148 = tmp139 * tmp147
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp149 = (tmp133 / tmp148)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp150 = (tmp143 / tmp147)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp151 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp152 = tmp150 * tmp151
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp153 = tmp149 + tmp152
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp154 = (tmp124 / tmp153)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp155 = tmp132 + tmp154
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr33 + (x3), tmp155, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr34 + (x3), tmp124, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr35 + (x3), tmp131, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_4:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_3
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x4 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp156 = tl.load(in_ptr20 + (x4), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp157 = tl.load(in_ptr21 + (x4), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp164 = tl.load(in_ptr22 + (x4), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp171 = tl.load(in_ptr23 + (x4), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp173 = in_ptr24
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp158 = tmp156 - tmp157
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp159 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp160 = tmp159 * tmp158
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp161 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp162 = tl.where(tmp161, tmp156, tmp157)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp163 = tmp160 + tmp162
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp165 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp166 = tmp164 * tmp165
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp167 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp168 = tmp156 * tmp167
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp169 = tmp168 * tmp156
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp170 = tmp166 + tmp169
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp172 = libdevice.sqrt(tmp170)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp174 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp175 = tmp173 + tmp174
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp176 = libdevice.pow(tmp165, tmp175)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp177 = tmp174 - tmp176
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp178 = libdevice.sqrt(tmp177)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp179 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp180 = libdevice.pow(tmp179, tmp175)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp181 = tmp174 - tmp180
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp182 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp183 = (tmp182 / tmp181)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp184 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp185 = tmp183 * tmp184
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp186 = -tmp185
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp187 = tmp178 * tmp186
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp188 = (tmp172 / tmp187)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp189 = (tmp182 / tmp186)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp190 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp191 = tmp189 * tmp190
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp192 = tmp188 + tmp191
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp193 = (tmp163 / tmp192)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp194 = tmp171 + tmp193
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr42 + (x4), tmp194, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr43 + (x4), tmp163, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr44 + (x4), tmp170, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_5:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_4
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x5 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp195 = tl.load(in_ptr25 + (x5), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp196 = tl.load(in_ptr26 + (x5), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp203 = tl.load(in_ptr27 + (x5), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp210 = tl.load(in_ptr28 + (x5), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp212 = in_ptr29
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp197 = tmp195 - tmp196
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp198 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp199 = tmp198 * tmp197
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp200 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp201 = tl.where(tmp200, tmp195, tmp196)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp202 = tmp199 + tmp201
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp204 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp205 = tmp203 * tmp204
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp206 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp207 = tmp195 * tmp206
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp208 = tmp207 * tmp195
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp209 = tmp205 + tmp208
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp211 = libdevice.sqrt(tmp209)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp213 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp214 = tmp212 + tmp213
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp215 = libdevice.pow(tmp204, tmp214)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp216 = tmp213 - tmp215
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp217 = libdevice.sqrt(tmp216)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp218 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp219 = libdevice.pow(tmp218, tmp214)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp220 = tmp213 - tmp219
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp221 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp222 = (tmp221 / tmp220)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp223 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp224 = tmp222 * tmp223
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp225 = -tmp224
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp226 = tmp217 * tmp225
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp227 = (tmp211 / tmp226)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp228 = (tmp221 / tmp225)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp229 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp230 = tmp228 * tmp229
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp231 = tmp227 + tmp230
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp232 = (tmp202 / tmp231)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp233 = tmp210 + tmp232
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr51 + (x5), tmp233, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr52 + (x5), tmp202, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr53 + (x5), tmp209, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_6:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_5
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x6 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp234 = tl.load(in_ptr30 + (x6), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp235 = tl.load(in_ptr31 + (x6), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp242 = tl.load(in_ptr32 + (x6), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp249 = tl.load(in_ptr33 + (x6), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp251 = in_ptr34
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp236 = tmp234 - tmp235
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp237 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp238 = tmp237 * tmp236
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp239 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp240 = tl.where(tmp239, tmp234, tmp235)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp241 = tmp238 + tmp240
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp243 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp244 = tmp242 * tmp243
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp245 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp246 = tmp234 * tmp245
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp247 = tmp246 * tmp234
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp248 = tmp244 + tmp247
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp250 = libdevice.sqrt(tmp248)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp252 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp253 = tmp251 + tmp252
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp254 = libdevice.pow(tmp243, tmp253)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp255 = tmp252 - tmp254
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp256 = libdevice.sqrt(tmp255)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp257 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp258 = libdevice.pow(tmp257, tmp253)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp259 = tmp252 - tmp258
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp260 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp261 = (tmp260 / tmp259)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp262 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp263 = tmp261 * tmp262
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp264 = -tmp263
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp265 = tmp256 * tmp264
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp266 = (tmp250 / tmp265)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp267 = (tmp260 / tmp264)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp268 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp269 = tmp267 * tmp268
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp270 = tmp266 + tmp269
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp271 = (tmp241 / tmp270)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp272 = tmp249 + tmp271
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr60 + (x6), tmp272, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr61 + (x6), tmp241, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr62 + (x6), tmp248, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_7:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_6
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x7 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp273 = tl.load(in_ptr35 + (x7), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp274 = tl.load(in_ptr36 + (x7), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp281 = tl.load(in_ptr37 + (x7), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp288 = tl.load(in_ptr38 + (x7), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp290 = in_ptr39
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp275 = tmp273 - tmp274
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp276 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp277 = tmp276 * tmp275
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp278 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp279 = tl.where(tmp278, tmp273, tmp274)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp280 = tmp277 + tmp279
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp282 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp283 = tmp281 * tmp282
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp284 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp285 = tmp273 * tmp284
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp286 = tmp285 * tmp273
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp287 = tmp283 + tmp286
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp289 = libdevice.sqrt(tmp287)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp291 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp292 = tmp290 + tmp291
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp293 = libdevice.pow(tmp282, tmp292)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp294 = tmp291 - tmp293
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp295 = libdevice.sqrt(tmp294)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp296 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp297 = libdevice.pow(tmp296, tmp292)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp298 = tmp291 - tmp297
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp299 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp300 = (tmp299 / tmp298)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp301 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp302 = tmp300 * tmp301
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp303 = -tmp302
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp304 = tmp295 * tmp303
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp305 = (tmp289 / tmp304)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp306 = (tmp299 / tmp303)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp307 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp308 = tmp306 * tmp307
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp309 = tmp305 + tmp308
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp310 = (tmp280 / tmp309)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp311 = tmp288 + tmp310
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr69 + (x7), tmp311, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr70 + (x7), tmp280, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr71 + (x7), tmp287, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_8:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_7
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x8 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp312 = tl.load(in_ptr40 + (x8), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp313 = tl.load(in_ptr41 + (x8), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp320 = tl.load(in_ptr42 + (x8), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp327 = tl.load(in_ptr43 + (x8), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp329 = in_ptr44
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp314 = tmp312 - tmp313
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp315 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp316 = tmp315 * tmp314
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp317 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp318 = tl.where(tmp317, tmp312, tmp313)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp319 = tmp316 + tmp318
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp321 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp322 = tmp320 * tmp321
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp323 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp324 = tmp312 * tmp323
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp325 = tmp324 * tmp312
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp326 = tmp322 + tmp325
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp328 = libdevice.sqrt(tmp326)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp330 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp331 = tmp329 + tmp330
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp332 = libdevice.pow(tmp321, tmp331)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp333 = tmp330 - tmp332
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp334 = libdevice.sqrt(tmp333)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp335 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp336 = libdevice.pow(tmp335, tmp331)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp337 = tmp330 - tmp336
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp338 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp339 = (tmp338 / tmp337)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp340 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp341 = tmp339 * tmp340
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp342 = -tmp341
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp343 = tmp334 * tmp342
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp344 = (tmp328 / tmp343)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp345 = (tmp338 / tmp342)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp346 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp347 = tmp345 * tmp346
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp348 = tmp344 + tmp347
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp349 = (tmp319 / tmp348)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp350 = tmp327 + tmp349
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr78 + (x8), tmp350, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr79 + (x8), tmp319, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr80 + (x8), tmp326, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     elif pid &lt; num_xblocks_9:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pid_offset = pid - num_xblocks_8
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xnumel = 1048576
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         r0_numel = 1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         x9 = xindex
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp351 = tl.load(in_ptr45 + (x9), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp352 = tl.load(in_ptr46 + (x9), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp359 = tl.load(in_ptr47 + (x9), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp366 = tl.load(in_ptr48 + (x9), None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp368 = in_ptr49
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp353 = tmp351 - tmp352
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp354 = 0.10000000149011612
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp355 = tmp354 * tmp353
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp356 = tl.full([1], False, tl.int1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp357 = tl.where(tmp356, tmp351, tmp352)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp358 = tmp355 + tmp357
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp360 = 0.999
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp361 = tmp359 * tmp360
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp362 = 0.0010000000000000009
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp363 = tmp351 * tmp362
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp364 = tmp363 * tmp351
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp365 = tmp361 + tmp364
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp367 = libdevice.sqrt(tmp365)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp369 = 1.0
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp370 = tmp368 + tmp369
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp371 = libdevice.pow(tmp360, tmp370)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp372 = tmp369 - tmp371
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp373 = libdevice.sqrt(tmp372)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp374 = 0.9
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp375 = libdevice.pow(tmp374, tmp370)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp376 = tmp369 - tmp375
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp377 = tl.full([1], 1, tl.int32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp378 = (tmp377 / tmp376)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp379 = 0.001
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp380 = tmp378 * tmp379
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp381 = -tmp380
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp382 = tmp373 * tmp381
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp383 = (tmp367 / tmp382)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp384 = (tmp377 / tmp381)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp385 = 1e-08
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp386 = tmp384 * tmp385
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp387 = tmp383 + tmp386
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp388 = (tmp358 / tmp387)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tmp389 = tmp366 + tmp388
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr87 + (x9), tmp389, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr88 + (x9), tmp358, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         tl.store(out_ptr89 + (x9), tmp365, None)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     else:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         pass
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] cpp_fused__foreach_copy_1 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], &#39;&#39;&#39;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] extern &quot;C&quot;  void kernel(const float* in_ptr0,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr1,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr2,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr3,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr4,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr5,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr6,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr7,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr8,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        const float* in_ptr9,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr1,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr3,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr5,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr7,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr9,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr11,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr13,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr15,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr17,
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                        float* out_ptr19)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr11[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr13[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr15[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr17[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             {
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]                 out_ptr19[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]             }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] }
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] &#39;&#39;&#39;)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] async_compile.wait(globals())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] del async_compile
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] def call(args):
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     args.clear()
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg10_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg11_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg12_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg13_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg14_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg15_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg16_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg17_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg18_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg19_1, (), ())
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     with torch.cuda._DeviceGuard(0):
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         torch.cuda.set_device(0)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         # Unsorted Source Nodes: [], Original ATen: []
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         stream0 = get_raw_stream(0)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         triton_for_fused_0.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1, arg31_1, arg21_1, arg41_1, arg1_1, arg11_1, arg32_1, arg22_1, arg42_1, arg2_1, arg12_1, arg33_1, arg23_1, arg43_1, arg3_1, arg13_1, arg34_1, arg24_1, arg44_1, arg4_1, arg14_1, arg35_1, arg25_1, arg45_1, arg5_1, arg15_1, arg36_1, arg26_1, arg46_1, arg6_1, arg16_1, arg37_1, arg27_1, arg47_1, arg7_1, arg17_1, arg38_1, arg28_1, arg48_1, arg8_1, arg18_1, arg39_1, arg29_1, arg49_1, arg9_1, arg19_1, arg0_1, arg20_1, arg40_1, arg1_1, arg21_1, arg41_1, arg2_1, arg22_1, arg42_1, arg3_1, arg23_1, arg43_1, arg4_1, arg24_1, arg44_1, arg5_1, arg25_1, arg45_1, arg6_1, arg26_1, arg46_1, arg7_1, arg27_1, arg47_1, arg8_1, arg28_1, arg48_1, arg9_1, arg29_1, arg49_1, stream=stream0)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg0_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg1_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg20_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg21_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg22_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg23_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg24_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg25_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg26_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg27_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg28_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg29_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg2_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg30_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg31_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg32_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg33_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg34_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg35_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg36_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg37_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg38_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg39_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg3_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg40_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg41_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg42_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg43_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg44_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg45_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg46_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg47_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg48_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg49_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg4_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg5_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg6_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg7_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg8_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]         del arg9_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     cpp_fused__foreach_copy_1(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg10_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg11_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg12_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg13_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg14_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg15_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg16_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg17_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg18_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     del arg19_1
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     return ()
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     from torch._dynamo.testing import rand_strided
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     from torch._inductor.utils import print_performance
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code] if __name__ == &quot;__main__&quot;:
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0902 15:22:07.239000 22327 torch/_inductor/graph.py:2345] [0/1] [__output_code]
V0902 15:22:07.280000 22327 torch/_inductor/graph.py:2356] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/da/cdabi6efsaqwxkw2y4xsbsvooc4l752igga6mfi4rfeqb4ikja3b.py
I0902 15:22:07.320000 22327 torch/_inductor/graph.py:2317] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/da/cdabi6efsaqwxkw2y4xsbsvooc4l752igga6mfi4rfeqb4ikja3b.py
eager runtime: 1203.4719599995472us
compiled runtime: 767.546394634466us
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map.
By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam
optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide
on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a
valuable resource for developers looking to improve the performance of their models with horizontal fusion.</p>
<p>See also:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/compiling_optimizer.html">Compiled optimizer tutorial</a> - an intro into the compiled optimizer.</p></li>
<li><p><a class="reference external" href="https://dev-discuss.pytorch.org/t/compiling-the-optimizer-with-pt2/1669">Compiling the optimizer with PT2</a> - deeper technical details on the compiled optimizer.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 15.908 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-foreach-map-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/162cf335b789dd055d4192f77cb0251c/foreach_map.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">foreach_map.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bcb9aa4fd3968b85310b970dbd86bbc3/foreach_map.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">foreach_map.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/faee5eeb51c8f314872395cc1b776677/foreach_map.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">foreach_map.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
  </article>

              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-setup">Model Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions-for-foreach-map-implementation">Helper functions for foreach_map implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-and-running-the-compiled-kernel">Setting up and running the compiled kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

   <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <h2>Docs</h2>
            <p>Access comprehensive developer documentation for PyTorch</p>
            <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
          </div>

          <div class="col-md-4">
            <h2>Tutorials</h2>
            <p>Get in-depth tutorials for beginners and advanced developers</p>
            <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
          </div>

          <div class="col-md-4">
            <h2>Resources</h2>
            <p>Find development resources and get your questions answered</p>
            <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
          </div>
        </div>
      </div>
  </div>

  <footer class="site-footer">
      <div class="container footer-container">

          
      <div class="newsletter" id="newsletter">
  
        <p
          class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
      
      
          <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
          <script>
            hbspt.forms.create({
              region: "na1",
              portalId: "8112310",
              formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
            });
          </script>
          
      
        <p
          class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
          
      </div>
      
  
  
      <div class="lf-grid">  
        <ul class="social-links">
          <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
          </a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
          </a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
          </a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
          </a></li>
          <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack"><path fill="currentColor" d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z"></path></svg>
          </a></li>
          <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat"><path fill="currentColor" d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z"></path><path fill="currentColor" d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z"></path></svg>
          </a></li>
        </ul>
      </div>
  
      <div class="privacy-policy">
        <div class="copyright">
          <p>
            &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
          </p>
        </div>
      </div>


       </div>
 </footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>

   
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
   <script type="application/ld+json">
      {
         "@context": "https://schema.org",
         "@type": "Article",
         "headline": "Explicit horizontal fusion with foreach_map and torch.compile",
         "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
         "url": "/recipes/foreach_map.html",
         "author": {
           "@type": "Organization",
           "name": "PyTorch Contributors",
           "url": "https://pytorch.org"
         },
         "image": "../_static/img/pytorch_seo.png",
         "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "/recipes/foreach_map.html"
         },
        "datePublished": "",
         "dateModified": "",
         "articleBody": "Note Go to the end to download the full example code. Explicit horizontal fusion with foreach_map and torch.compile# Author: Michael Lazos Horizontal fusion is a key optimization in ML compilers. In eager,this is typically expressed using the torch._foreach* ops which parallelizes operations across a list of tensors. However, supporting all possible permutations of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map allows conversion of any pointwise op in torch to a horiztonally fused foreach variant. In this tutorial, we will demonstrate how to implement the Adam optimizer with foreach_map to generate a fully fused kernel. Note This recipe describes a prototype feature. Prototype features are typically at an early stage for feedback and testing and are subject to change. Prerequisites# PyTorch v2.7.0 or later Model Setup# For this example, we’ll use a simple sequence of linear layers. We instantiate an independent copy to compare the two optimizer implementations. import torch # exit cleanly if we are on a device that doesn&#39;t support ``torch.compile`` if torch.cuda.get_device_capability() &lt; (7, 0): print(\&#34;Exiting because torch.compile is not supported on this device.\&#34;) import sys sys.exit(0) # Create simple model model = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\&#34;cuda\&#34;) for _ in range(10)] ) model_copy = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\&#34;cuda\&#34;) for _ in range(10)] ) input = torch.rand(1024, device=\&#34;cuda\&#34;) # run forward pass output = model(input) output_copy = model_copy(input) # run backward to populate the grads for our optimizer below output.sum().backward() output_copy.sum().backward() Helper functions for foreach_map implementation# In this section, we’ll begin our implementation of the Adam optimizer. from torch._higher_order_ops.foreach_map import foreach_map # Helper function to extract optimizer states from a torch.optim.Adam instance def get_inputs(optim): steps = [] params = [] grads = [] exp_avgs = [] exp_avg_sqs = [] for group in optim.param_groups: for p in group[\&#34;params\&#34;]: params.append(p) grads.append(p.grad) state = optim.state[p] exp_avgs.append(state[\&#34;exp_avg\&#34;]) exp_avg_sqs.append(state[\&#34;exp_avg_sq\&#34;]) steps.append(state[\&#34;step\&#34;]) return steps, params, exp_avgs, exp_avg_sqs # Functions to update the different optimizer states def update_exp_avg_sq(exp_avg_sq, grad, beta2): return exp_avg_sq.mul(beta2).addcmul(grad, grad, value=1 - beta2) def update_param(param, step, exp_avg, exp_avg_sq, beta1, beta2, lr, eps): bias_correction1 = 1 - torch.pow(beta1, step) bias_correction2 = (1 - torch.pow(beta2, step)).sqrt() step_size = (lr / bias_correction1).neg() denom = (exp_avg_sq.sqrt() / (bias_correction2 * step_size)).add(eps / step_size) return torch.add(param, torch.div(exp_avg, denom)) # Our full Adam implementation def foreach_map_adam( steps, params, exp_avgs, exp_avg_sqs, weight_decay=0, beta1=0.9, beta2=0.999, lr=1e-3, eps=1e-8, ): with torch.no..."
       }
   </script>

  </body>
</html>