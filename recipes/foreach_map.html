
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta property="article:modified_time" content="2022-07-20T23:02:43+00:00" />
    <title>Explicit horizontal fusion with foreach_map and torch.compile &#8212; PyTorch Tutorials 2.10.0+cu130 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=536c50fe" />
    <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=36fba2ff" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=ef8a0acd"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/katex.min.js?v=be8ff15f"></script>
    <script src="../_static/auto-render.min.js?v=ad136472"></script>
    <script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'recipes/foreach_map';</script>
    <link rel="canonical" href="https://docs.pytorch.org/tutorials/recipes/foreach_map.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Compile Time Caching Configuration" href="torch_compile_caching_configuration_tutorial.html" />
    <link rel="prev" title="(beta) Utilizing Torch Function modes with torch.compile" href="torch_compile_torch_function_modes.html" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->


<link rel="stylesheet" type="text/css" href="../_static/css/theme.css" crossorigin="anonymous">
<script type="text/javascript" src="../_static/js/theme.js"></script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&display=swap" rel="stylesheet">
<meta property="og:image" content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" />
<link rel="stylesheet" href="../_static/webfonts/all.min.css" crossorigin="anonymous">
<meta http-equiv="Content-Security-Policy"
  content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;">
<meta name="pytorch_project" content="tutorials">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" height="0" width="0"
    style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.10.0+cu130');
</script>
<noscript>
  <img height="1" width="1" src="https://www.facebook.com/tr?id=243028289693773&ev=PageView&noscript=1" />
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->

<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>

<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>

<script async src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Jul 20, 2022"/>

  </head>

<body data-feedback-url="https://github.com/pytorch/tutorials" class="pytorch-body">
  
    <div class="container-fluid header-holder tutorials-header" id="header-holder">
   <div class="header-container-wrapper">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                <span>Learn</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
                  <span class=dropdown-title>Get Started</span>
                </a>
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
                  <span class="dropdown-title">Webinars</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Community</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Landscape</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
                  <span class="dropdown-title">Join the Ecosystem</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
                  <span class="dropdown-title">Community Hub</span>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
                  <span class="dropdown-title">Forums</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
                  <span class="dropdown-title">Contributor Awards</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
                  <span class="dropdown-title">Community Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
                  <span class="dropdown-title">PyTorch Ambassadors</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Projects</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
                  <span class="dropdown-title">vLLM</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
                  <span class="dropdown-title">DeepSpeed</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
                  <span class="dropdown-title">Host Your Project</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/projects/ray/">
                  <span class="dropdown-title">RAY</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span> Docs</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/domains">
                  <span class="dropdown-title">Domains</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>Blogs & News</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">Blog</span>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/announcements">
                  <span class="dropdown-title">Announcements</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
                  <span class="dropdown-title">Case Studies</span>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                </a>
            </div>
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
              <span>About</span>
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/members">
                  <span class="dropdown-title">Members</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact">
                  <span class="dropdown-title">Contact</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/wp-content/uploads/2025/09/pytorch_brand_guide_091925a.pdf">
                  <span class="dropdown-title">Brand Guidelines</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown main-menu-button">
              <a href="https://pytorch.org/join" data-cta="join">
                JOIN
              </a>
            </div>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu">
        <i class="fa-solid fa-ellipsis"></i>
      </a>
    </div>
  </div>
 </div>

 <!-- Begin Mobile Menu -->

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="header-container-wrapper">
      <div class="mobile-main-menu-header-container">
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu">
        </a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">
    <div class="main-menu">
      <ul>
         <li class="resources-mobile-menu-title">
           <a>Learn</a>
         </li>
         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/get-started/locally">Get Started</a>
           </li>
           <li>
             <a href="https://docs.pytorch.org/tutorials">Tutorials</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
           </li>
           <li>
             <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
           </li>
           <li>
            <a href="https://pytorch.org/webinars/">Webinars</a>
          </li>
        </ul>
         <li class="resources-mobile-menu-title">
           <a>Community</a>
         </li>
         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Landscape</a>
          </li>
          <li>
             <a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
           </li>
           <li>
             <a href="https://pytorch.org/community-hub/">Community Hub</a>
           </li>
           <li>
             <a href="https://discuss.pytorch.org/">Forums</a>
           </li>
           <li>
             <a href="https://pytorch.org/resources">Developer Resources</a>
           </li>
           <li>
             <a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
           </li>
           <li>
            <a href="https://pytorch.org/community-events/">Community Events</a>
          </li>
          <li>
            <a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
          </li>
       </ul>

         <li class="resources-mobile-menu-title">
           <a>Projects</a>
         </li>

         <ul class="resources-mobile-menu-items">
           <li>
             <a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
           </li>

           <li>
             <a href="https://pytorch.org/projects/vllm/">vLLM</a>
           </li>
           <li>
            <a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
          </li>
          <li>
             <a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
           </li>
         </ul>

         <li class="resources-mobile-menu-title">
           <a>Docs</a>
         </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
          </li>

          <li>
            <a href="https://pytorch.org/domains">Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>

         <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>
          <li>
            <a href="https://pytorch.org/announcements">Announcements</a>
          </li>

          <li>
            <a href="https://pytorch.org/case-studies/">Case Studies</a>
          </li>
          <li>
            <a href="https://pytorch.org/events">Events</a>
          </li>
          <li>
             <a href="https://pytorch.org/newsletter">Newsletter</a>
           </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="https://pytorch.org/members">Members</a>
          </li>
          <li>
            <a href="https://pytorch.org/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="https://pytorch.org/tac">Technical Advisory Council</a>
         </li>
         <li>
             <a href="https://pytorch.org/credits">Cloud Credit Program</a>
          </li>
          <li>
             <a href="https://pytorch.org/staff">Staff</a>
          </li>
          <li>
             <a href="https://pytorch.org/contact">Contact</a>
          </li>
        </ul>
      </ul>
    </div>
  </div>
</div>

<!-- End Mobile Menu -->
  
  
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">
  <a href="../index.html" class="version">v2.10.0+cu130</a>
</div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
      
        <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
  
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/PyTorch" title="X" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-x-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">X</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pytorch/tutorials" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://dev-discuss.pytorch.org/" title="Discourse" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discourse</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://pypi.org/project/torch/" title="PyPi" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-python fa-lg" aria-hidden="true"></i>
            <span class="sr-only">PyPi</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="recipes/defining_a_neural_network.html">Defining a Neural Network in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_logs.html">(beta) Using TORCH_LOGS python API with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/what_is_state_dict.html">What is a state_dict in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/warmstarting_model_using_parameters_from_a_different_model.html">Warmstarting model using parameters from a different model in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/zeroing_out_gradients.html">Zeroing out gradients in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/profiler_recipe.html">PyTorch Profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/Captum_Recipe.html">Model Interpretability using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/amp_recipe.html">Automatic Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tuning_guide.html">Performance Tuning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/timer_quick_start.html">Timer quick start</a></li>
<li class="toctree-l1"><a class="reference internal" href="zero_redundancy_optimizer.html">Shard Optimizer States with ZeroRedundancyOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_comm_debug_mode.html">Getting Started with <code class="docutils literal notranslate"><span class="pre">CommDebugMode</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/benchmark.html">SyntaxError</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/module_load_state_dict_tips.html">Tips for Loading an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> from a Checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/reasoning_about_shapes.html">Reasoning about Shapes in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/swap_tensors.html">Extension points in <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> for <code class="docutils literal notranslate"><span class="pre">load_state_dict</span></code> and tensor subclasses</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="recipes/tensorboard_with_pytorch.html">How to use TensorBoard with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_torch_function_modes.html">(beta) Utilizing Torch Function modes with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Explicit horizontal fusion with foreach_map and torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_caching_configuration_tutorial.html">Compile Time Caching Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="regional_aot.html">Reducing AoT cold start compilation time with regional compilation</a></li>
<li class="toctree-l1"><a class="reference internal" href="intel_neural_compressor_for_pytorch.html">Ease-of-use quantization for PyTorch with Intel® Neural Compressor</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_device_mesh.html">Getting Started with DeviceMesh</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_async_checkpoint_recipe.html">Asynchronous Saving with Distributed Checkpoint (DCP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug_mode_tutorial.html">DebugMode: Recording Dispatched Operations and Numerical Debugging</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../recipes_index.html" class="nav-link">Recipes</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Explicit...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>
</div>
      
    </div>
  
</div>
</div>
              
              
  
<div id="searchbox"></div>
  <article class="bd-article" id="pytorch-article">
    <!-- Hidden breadcrumb schema for SEO only -->
    <div style="display:none;" itemscope itemtype="https://schema.org/BreadcrumbList">
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <link itemprop="item" href="../recipes_index.html">
        <meta itemprop="name" content="Recipes">
        <meta itemprop="position" content="1">
      </div>
      
      <div itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
        <meta itemprop="name" content="Explicit horizontal fusion with foreach_map and torch.compile">
        <meta itemprop="position" content="2">
      </div>
    </div>

    
    <script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
    
    
    <div class="pytorch-call-to-action-links">
      <div id="tutorial-type">recipes/foreach_map</div>
      <a id="colab-link" data-behavior="call-to-action-event" data-response="Run in Google Colab" target="_blank">
        <div id="google-colab-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-colab.svg" />
          <div class="call-to-action-desktop-view">Run in Google Colab</div>
          <div class="call-to-action-mobile-view">Colab</div>
        </div>
      </a>
      <a id="notebook-link" data-behavior="call-to-action-event" data-response="Download Notebook">
        <div id="download-notebook-link">
          <img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg" />
          <div class="call-to-action-desktop-view">Download Notebook</div>
          <div class="call-to-action-mobile-view">Notebook</div>
        </div>
      </a>
      <a id="github-link" data-behavior="call-to-action-event" data-response="View on Github" target="_blank">
        <div id="github-view-link">
          <img class="call-to-action-img" src="../_static/img/pytorch-github.svg" />
          <div class="call-to-action-desktop-view">View on GitHub</div>
          <div class="call-to-action-mobile-view">GitHub</div>
        </div>
      </a>
    </div>
    

    
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-recipes-foreach-map-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="explicit-horizontal-fusion-with-foreach-map-and-torch-compile">
<span id="sphx-glr-recipes-foreach-map-py"></span><h1>Explicit horizontal fusion with foreach_map and torch.compile<a class="headerlink" href="#explicit-horizontal-fusion-with-foreach-map-and-torch-compile" title="Link to this heading">#</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/mlazos">Michael Lazos</a></p>
<dl class="simple">
<dt>Horizontal fusion is a key optimization in ML compilers. In eager,</dt><dd><p>this is typically expressed using the torch._foreach* ops which parallelizes
operations across a list of tensors. However, supporting all possible permutations
of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map
allows conversion of any pointwise op in <code class="docutils literal notranslate"><span class="pre">torch</span></code> to a horiztonally fused foreach
variant. In this tutorial, we will demonstrate how to implement the Adam optimizer
with <code class="docutils literal notranslate"><span class="pre">foreach_map</span></code> to generate a fully fused kernel.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This recipe describes a prototype feature. Prototype features are typically
at an early stage for feedback and testing and are subject to change.</p>
</div>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>PyTorch v2.7.0 or later</p></li>
</ul>
<section id="model-setup">
<h3>Model Setup<a class="headerlink" href="#model-setup" title="Link to this heading">#</a></h3>
<p>For this example, we’ll use a simple sequence of linear layers.
We instantiate an independent copy to compare the two optimizer implementations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># exit cleanly if we are on a device that doesn&#39;t support ``torch.compile``</span>
<span class="k">if</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability" title="torch.cuda.get_device_capability" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_capability</span></a><span class="p">()</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exiting because torch.compile is not supported on this device.&quot;</span><span class="p">)</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create simple model</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
    <span class="o">*</span><span class="p">[</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
<span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch.rand" title="torch.rand" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">rand</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># run forward pass</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model_copy</span></a><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># run backward to populate the grads for our optimizer below</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">output_copy</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="helper-functions-for-foreach-map-implementation">
<h3>Helper functions for foreach_map implementation<a class="headerlink" href="#helper-functions-for-foreach-map-implementation" title="Link to this heading">#</a></h3>
<p>In this section, we’ll begin our implementation of the Adam optimizer.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._higher_order_ops.foreach_map</span><span class="w"> </span><span class="kn">import</span> <span class="n">foreach_map</span>

<span class="c1"># Helper function to extract optimizer states from a torch.optim.Adam instance</span>
<span class="k">def</span><span class="w"> </span><span class="nf">get_inputs</span><span class="p">(</span><span class="n">optim</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avgs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">exp_avg_sqs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optim</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s2">&quot;params&quot;</span><span class="p">]:</span>
            <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
            <span class="n">exp_avgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg&quot;</span><span class="p">])</span>
            <span class="n">exp_avg_sqs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;exp_avg_sq&quot;</span><span class="p">])</span>
            <span class="n">steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">steps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avg_sqs</span>


<span class="c1"># Functions to update the different optimizer states</span>
<span class="k">def</span><span class="w"> </span><span class="nf">update_exp_avg_sq</span><span class="p">(</span><span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">beta2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">beta2</span><span class="p">)</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update_param</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">exp_avg</span><span class="p">,</span> <span class="n">exp_avg_sq</span><span class="p">,</span> <span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
    <span class="n">bias_correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
    <span class="n">bias_correction2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.pow.html#torch.pow" title="torch.pow" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">pow</span></a><span class="p">(</span><span class="n">beta2</span><span class="p">,</span> <span class="n">step</span><span class="p">))</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
    <span class="n">step_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">lr</span> <span class="o">/</span> <span class="n">bias_correction1</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>
    <span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="n">bias_correction2</span> <span class="o">*</span> <span class="n">step_size</span><span class="p">))</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">eps</span> <span class="o">/</span> <span class="n">step_size</span><span class="p">)</span>
    <span class="k">return</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">(</span><span class="n">param</span><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.div.html#torch.div" title="torch.div" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">div</span></a><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">))</span>

<span class="c1"># Our full Adam implementation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">foreach_map_adam</span><span class="p">(</span>
    <span class="n">steps</span><span class="p">,</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">exp_avgs</span><span class="p">,</span>
    <span class="n">exp_avg_sqs</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
<span class="p">):</span>
    <span class="k">with</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
        <span class="c1"># update step</span>
        <span class="n">updated_steps</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">steps</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">updated_steps</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weight_decay</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.add.html#torch.add" title="torch.add" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">add</span></a><span class="p">,</span> <span class="p">(</span><span class="n">grads</span><span class="p">,),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">)</span>

        <span class="c1"># Higher-order operators (HOPs) cannot have multiple outputs at the moment</span>
        <span class="c1"># need to call foreach_map once for each output</span>
        <span class="n">exp_avgs_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp" title="torch.lerp" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span></a><span class="p">,</span> <span class="n">exp_avgs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
        <span class="n">exp_avgs_sq_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span><span class="n">update_exp_avg_sq</span><span class="p">,</span> <span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">beta2</span><span class="p">)</span>
        <span class="n">params_updated</span> <span class="o">=</span> <span class="n">foreach_map</span><span class="p">(</span>
            <span class="n">update_param</span><span class="p">,</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">steps</span><span class="p">,</span>
            <span class="n">exp_avgs_updated</span><span class="p">,</span>
            <span class="n">exp_avgs_sq_updated</span><span class="p">,</span>
            <span class="n">beta1</span><span class="p">,</span>
            <span class="n">beta2</span><span class="p">,</span>
            <span class="n">lr</span><span class="p">,</span>
            <span class="n">eps</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Higher-order operators (HOPs) don&#39;t support input mutation today</span>
        <span class="c1"># so manually  update the states in-place</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avgs</span><span class="p">,</span> <span class="n">exp_avgs_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">exp_avg_sqs</span><span class="p">,</span> <span class="n">exp_avgs_sq_updated</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_foreach_copy_</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">params_updated</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</section>
<section id="setting-up-and-running-the-compiled-kernel">
<h3>Setting up and running the compiled kernel<a class="headerlink" href="#setting-up-and-running-the-compiled-kernel" title="Link to this heading">#</a></h3>
<p>In this section, we’ll run our Adam optimizer
and compare the results</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is only supported on CUDA devices that have a compute capability of 7.0 or higher.</p>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model_copy</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="c1"># warm up the optimizer state dict</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager_copy</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">get_inputs</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="p">)</span>
<span class="n">compiled_adam</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foreach_map_adam</span><span class="p">)</span>

<span class="c1"># optionally view the output code</span>
<a href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs" class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">output_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Warmup runs to compile the function</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">()</span>
    <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">for</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">],</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">opt_eager_copy</span></a><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;params&quot;</span><span class="p">]):</span>
    <a href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span></a><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">eager_p</span></a><span class="p">,</span> <a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter" class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">compile_p</span></a><span class="p">)</span>

<span class="c1"># Benchmark performance</span>

 <span class="c1"># Let&#39;s define a helpful benchmarking function:</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.benchmark</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">benchmark</span>

<span class="k">def</span><span class="w"> </span><span class="nf">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">benchmark</span><span class="o">.</span><span class="n">Timer</span></a><span class="p">(</span>
        <span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;f(*args, **kwargs)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span> <span class="n">f</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">t0</span><span class="o">.</span><span class="n">blocked_autorange</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span> <span class="o">*</span> <span class="mf">1e6</span>

<span class="n">eager_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><a href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam.step" title="torch.optim.Adam.step" class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-method"><span class="n">opt_eager</span><span class="o">.</span><span class="n">step</span></a><span class="p">)</span>
<span class="n">compiled_runtime</span> <span class="o">=</span> <span class="n">benchmark_torch_function_in_microseconds</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">compiled_adam</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">))</span>

<span class="k">assert</span> <span class="n">eager_runtime</span> <span class="o">&gt;</span> <span class="n">compiled_runtime</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;eager runtime: </span><span class="si">{</span><span class="n">eager_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;compiled runtime: </span><span class="si">{</span><span class="n">compiled_runtime</span><span class="si">}</span><span class="s2">us&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] Output code:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # AOT ID: [&#39;0_inference&#39;]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import torch
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import math
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import random
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import os
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import tempfile
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from math import inf, nan
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from cmath import nanj
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch import device, empty_strided
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton.language as tl
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] aten = torch.ops.aten
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] _quantized = torch.ops._quantized
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] async_compile = AsyncCompile()
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], r&#39;&#39;&#39;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] extern &quot;C&quot;  void  kernel(const float* in_ptr0,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr1,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr2,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr3,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr4,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr5,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr6,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr7,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr8,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        const float* in_ptr9,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr0,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr1,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr2,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr3,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr4,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr5,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr6,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr7,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr8,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                        float* out_ptr9)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr0[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr2[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr4[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr6[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr8[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             {
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] }
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] &#39;&#39;&#39;)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/e3/ce3euorr6vahk3fpfyslv4qsd5j5uxxkmrpreilu6uqnb3gbwb2v.py
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # Source node to ATen node mapping:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] triton_for_fused_1 = async_compile.triton(&#39;triton_for_fused_1&#39;, &#39;&#39;&#39;
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton.language as tl
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] @triton_heuristics.foreach(
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     filename=__file__,
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr3&#39;: &#39;*fp32&#39;, &#39;out_ptr4&#39;: &#39;*fp32&#39;, &#39;out_ptr5&#39;: &#39;*fp32&#39;, &#39;out_ptr9&#39;: &#39;*fp32&#39;, &#39;out_ptr10&#39;: &#39;*fp32&#39;, &#39;out_ptr11&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr21&#39;: &#39;*fp32&#39;, &#39;out_ptr22&#39;: &#39;*fp32&#39;, &#39;out_ptr23&#39;: &#39;*fp32&#39;, &#39;out_ptr27&#39;: &#39;*fp32&#39;, &#39;out_ptr28&#39;: &#39;*fp32&#39;, &#39;out_ptr29&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr39&#39;: &#39;*fp32&#39;, &#39;out_ptr40&#39;: &#39;*fp32&#39;, &#39;out_ptr41&#39;: &#39;*fp32&#39;, &#39;out_ptr45&#39;: &#39;*fp32&#39;, &#39;out_ptr46&#39;: &#39;*fp32&#39;, &#39;out_ptr47&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr57&#39;: &#39;*fp32&#39;, &#39;out_ptr58&#39;: &#39;*fp32&#39;, &#39;out_ptr59&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_1&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr10&#39;, &#39;out_ptr11&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr21&#39;, &#39;out_ptr22&#39;, &#39;out_ptr23&#39;, &#39;out_ptr27&#39;, &#39;out_ptr28&#39;, &#39;out_ptr29&#39;, &#39;out_ptr3&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr39&#39;, &#39;out_ptr4&#39;, &#39;out_ptr40&#39;, &#39;out_ptr41&#39;, &#39;out_ptr45&#39;, &#39;out_ptr46&#39;, &#39;out_ptr47&#39;, &#39;out_ptr5&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr57&#39;, &#39;out_ptr58&#39;, &#39;out_ptr59&#39;, &#39;out_ptr9&#39;], &#39;backend_hash&#39;: &#39;DC36EA6BB5AEA639F493BE6C610554D7008666A7D52F3C35F9DAC37F278CCC65&#39;, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False, &#39;deterministic&#39;: False, &#39;force_filter_reduction_configs&#39;: False, &#39;are_deterministic_algorithms_enabled&#39;: False},
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] )
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] @triton.jit
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     pid = tl.program_id(0)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     XBLOCK: tl.constexpr = 1024
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     if pid &lt; num_xblocks_0:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x0 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp17 = in_ptr4
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp2 = tmp0 - tmp1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp3 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp4 = tmp3 * tmp2
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp7 = tmp4 + tmp6
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp9 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp10 = tmp8 * tmp9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp11 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp12 = tmp0 * tmp11
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp13 = tmp12 * tmp0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp14 = tmp10 + tmp13
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp16 = tl.sqrt_rn(tmp14)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp18 = libdevice.pow(tmp9, tmp17)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp19 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp20 = tmp19 - tmp18
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp21 = tl.sqrt_rn(tmp20)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp22 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp23 = libdevice.pow(tmp22, tmp17)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp24 = tmp19 - tmp23
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp25 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp26 = (tmp25 / tmp24)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp27 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp28 = tmp26 * tmp27
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp29 = -tmp28
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp30 = tmp21 * tmp29
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp31 = (tmp16 / tmp30)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp32 = (tmp25 / tmp29)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp33 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp34 = tmp32 * tmp33
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp35 = tmp31 + tmp34
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp36 = (tmp7 / tmp35)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp37 = tmp15 + tmp36
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr3 + (x0), tmp7, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr4 + (x0), tmp14, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr5 + (x0), tmp37, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_1:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x1 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp38 = tl.load(in_ptr5 + (x1), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp39 = tl.load(in_ptr6 + (x1), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp46 = tl.load(in_ptr7 + (x1), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp53 = tl.load(in_ptr8 + (x1), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp55 = in_ptr9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp40 = tmp38 - tmp39
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp41 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp42 = tmp41 * tmp40
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp43 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp44 = tl.where(tmp43, tmp38, tmp39)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp45 = tmp42 + tmp44
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp47 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp48 = tmp46 * tmp47
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp49 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp50 = tmp38 * tmp49
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp51 = tmp50 * tmp38
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp52 = tmp48 + tmp51
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp54 = tl.sqrt_rn(tmp52)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp56 = libdevice.pow(tmp47, tmp55)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp57 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp58 = tmp57 - tmp56
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp59 = tl.sqrt_rn(tmp58)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp60 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp61 = libdevice.pow(tmp60, tmp55)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp62 = tmp57 - tmp61
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp63 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp64 = (tmp63 / tmp62)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp65 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp66 = tmp64 * tmp65
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp67 = -tmp66
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp68 = tmp59 * tmp67
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp69 = (tmp54 / tmp68)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp70 = (tmp63 / tmp67)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp71 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp72 = tmp70 * tmp71
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp73 = tmp69 + tmp72
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp74 = (tmp45 / tmp73)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp75 = tmp53 + tmp74
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr9 + (x1), tmp45, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr10 + (x1), tmp52, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr11 + (x1), tmp75, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_2:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x2 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp76 = tl.load(in_ptr10 + (x2), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp77 = tl.load(in_ptr11 + (x2), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp84 = tl.load(in_ptr12 + (x2), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp91 = tl.load(in_ptr13 + (x2), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp93 = in_ptr14
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp78 = tmp76 - tmp77
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp79 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp80 = tmp79 * tmp78
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp81 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp82 = tl.where(tmp81, tmp76, tmp77)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp83 = tmp80 + tmp82
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp85 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp86 = tmp84 * tmp85
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp87 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp88 = tmp76 * tmp87
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp89 = tmp88 * tmp76
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp90 = tmp86 + tmp89
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp92 = tl.sqrt_rn(tmp90)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp94 = libdevice.pow(tmp85, tmp93)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp95 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp96 = tmp95 - tmp94
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp97 = tl.sqrt_rn(tmp96)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp98 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp99 = libdevice.pow(tmp98, tmp93)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp100 = tmp95 - tmp99
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp101 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp102 = (tmp101 / tmp100)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp103 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp104 = tmp102 * tmp103
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp105 = -tmp104
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp106 = tmp97 * tmp105
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp107 = (tmp92 / tmp106)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp108 = (tmp101 / tmp105)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp109 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp110 = tmp108 * tmp109
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp111 = tmp107 + tmp110
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp112 = (tmp83 / tmp111)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp113 = tmp91 + tmp112
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr15 + (x2), tmp83, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr16 + (x2), tmp90, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr17 + (x2), tmp113, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_3:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_2
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x3 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp114 = tl.load(in_ptr15 + (x3), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp115 = tl.load(in_ptr16 + (x3), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp122 = tl.load(in_ptr17 + (x3), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp129 = tl.load(in_ptr18 + (x3), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp131 = in_ptr19
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp116 = tmp114 - tmp115
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp117 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp118 = tmp117 * tmp116
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp119 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp120 = tl.where(tmp119, tmp114, tmp115)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp121 = tmp118 + tmp120
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp123 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp124 = tmp122 * tmp123
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp125 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp126 = tmp114 * tmp125
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp127 = tmp126 * tmp114
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp128 = tmp124 + tmp127
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp130 = tl.sqrt_rn(tmp128)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp132 = libdevice.pow(tmp123, tmp131)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp133 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp134 = tmp133 - tmp132
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp135 = tl.sqrt_rn(tmp134)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp136 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp137 = libdevice.pow(tmp136, tmp131)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp138 = tmp133 - tmp137
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp139 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp140 = (tmp139 / tmp138)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp141 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp142 = tmp140 * tmp141
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp143 = -tmp142
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp144 = tmp135 * tmp143
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp145 = (tmp130 / tmp144)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp146 = (tmp139 / tmp143)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp147 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp148 = tmp146 * tmp147
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp149 = tmp145 + tmp148
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp150 = (tmp121 / tmp149)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp151 = tmp129 + tmp150
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr21 + (x3), tmp121, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr22 + (x3), tmp128, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr23 + (x3), tmp151, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_4:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_3
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x4 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp152 = tl.load(in_ptr20 + (x4), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp153 = tl.load(in_ptr21 + (x4), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp160 = tl.load(in_ptr22 + (x4), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp167 = tl.load(in_ptr23 + (x4), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp169 = in_ptr24
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp154 = tmp152 - tmp153
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp155 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp156 = tmp155 * tmp154
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp157 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp158 = tl.where(tmp157, tmp152, tmp153)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp159 = tmp156 + tmp158
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp161 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp162 = tmp160 * tmp161
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp163 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp164 = tmp152 * tmp163
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp165 = tmp164 * tmp152
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp166 = tmp162 + tmp165
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp168 = tl.sqrt_rn(tmp166)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp170 = libdevice.pow(tmp161, tmp169)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp171 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp172 = tmp171 - tmp170
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp173 = tl.sqrt_rn(tmp172)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp174 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp175 = libdevice.pow(tmp174, tmp169)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp176 = tmp171 - tmp175
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp177 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp178 = (tmp177 / tmp176)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp179 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp180 = tmp178 * tmp179
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp181 = -tmp180
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp182 = tmp173 * tmp181
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp183 = (tmp168 / tmp182)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp184 = (tmp177 / tmp181)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp185 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp186 = tmp184 * tmp185
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp187 = tmp183 + tmp186
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp188 = (tmp159 / tmp187)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp189 = tmp167 + tmp188
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr27 + (x4), tmp159, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr28 + (x4), tmp166, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr29 + (x4), tmp189, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_5:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_4
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x5 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp190 = tl.load(in_ptr25 + (x5), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp191 = tl.load(in_ptr26 + (x5), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp198 = tl.load(in_ptr27 + (x5), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp205 = tl.load(in_ptr28 + (x5), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp207 = in_ptr29
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp192 = tmp190 - tmp191
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp193 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp194 = tmp193 * tmp192
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp195 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp196 = tl.where(tmp195, tmp190, tmp191)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp197 = tmp194 + tmp196
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp199 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp200 = tmp198 * tmp199
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp201 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp202 = tmp190 * tmp201
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp203 = tmp202 * tmp190
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp204 = tmp200 + tmp203
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp206 = tl.sqrt_rn(tmp204)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp208 = libdevice.pow(tmp199, tmp207)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp209 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp210 = tmp209 - tmp208
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp211 = tl.sqrt_rn(tmp210)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp212 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp213 = libdevice.pow(tmp212, tmp207)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp214 = tmp209 - tmp213
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp215 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp216 = (tmp215 / tmp214)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp217 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp218 = tmp216 * tmp217
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp219 = -tmp218
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp220 = tmp211 * tmp219
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp221 = (tmp206 / tmp220)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp222 = (tmp215 / tmp219)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp223 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp224 = tmp222 * tmp223
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp225 = tmp221 + tmp224
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp226 = (tmp197 / tmp225)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp227 = tmp205 + tmp226
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr33 + (x5), tmp197, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr34 + (x5), tmp204, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr35 + (x5), tmp227, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_6:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_5
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x6 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp228 = tl.load(in_ptr30 + (x6), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp229 = tl.load(in_ptr31 + (x6), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp236 = tl.load(in_ptr32 + (x6), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp243 = tl.load(in_ptr33 + (x6), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp245 = in_ptr34
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp230 = tmp228 - tmp229
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp231 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp232 = tmp231 * tmp230
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp233 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp234 = tl.where(tmp233, tmp228, tmp229)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp235 = tmp232 + tmp234
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp237 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp238 = tmp236 * tmp237
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp239 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp240 = tmp228 * tmp239
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp241 = tmp240 * tmp228
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp242 = tmp238 + tmp241
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp244 = tl.sqrt_rn(tmp242)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp246 = libdevice.pow(tmp237, tmp245)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp247 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp248 = tmp247 - tmp246
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp249 = tl.sqrt_rn(tmp248)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp250 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp251 = libdevice.pow(tmp250, tmp245)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp252 = tmp247 - tmp251
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp253 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp254 = (tmp253 / tmp252)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp255 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp256 = tmp254 * tmp255
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp257 = -tmp256
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp258 = tmp249 * tmp257
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp259 = (tmp244 / tmp258)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp260 = (tmp253 / tmp257)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp261 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp262 = tmp260 * tmp261
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp263 = tmp259 + tmp262
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp264 = (tmp235 / tmp263)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp265 = tmp243 + tmp264
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr39 + (x6), tmp235, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr40 + (x6), tmp242, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr41 + (x6), tmp265, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_7:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_6
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x7 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp266 = tl.load(in_ptr35 + (x7), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp267 = tl.load(in_ptr36 + (x7), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp274 = tl.load(in_ptr37 + (x7), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp281 = tl.load(in_ptr38 + (x7), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp283 = in_ptr39
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp268 = tmp266 - tmp267
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp269 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp270 = tmp269 * tmp268
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp271 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp272 = tl.where(tmp271, tmp266, tmp267)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp273 = tmp270 + tmp272
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp275 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp276 = tmp274 * tmp275
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp277 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp278 = tmp266 * tmp277
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp279 = tmp278 * tmp266
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp280 = tmp276 + tmp279
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp282 = tl.sqrt_rn(tmp280)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp284 = libdevice.pow(tmp275, tmp283)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp285 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp286 = tmp285 - tmp284
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp287 = tl.sqrt_rn(tmp286)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp288 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp289 = libdevice.pow(tmp288, tmp283)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp290 = tmp285 - tmp289
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp291 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp292 = (tmp291 / tmp290)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp293 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp294 = tmp292 * tmp293
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp295 = -tmp294
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp296 = tmp287 * tmp295
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp297 = (tmp282 / tmp296)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp298 = (tmp291 / tmp295)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp299 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp300 = tmp298 * tmp299
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp301 = tmp297 + tmp300
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp302 = (tmp273 / tmp301)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp303 = tmp281 + tmp302
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr45 + (x7), tmp273, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr46 + (x7), tmp280, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr47 + (x7), tmp303, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_8:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_7
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x8 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp304 = tl.load(in_ptr40 + (x8), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp305 = tl.load(in_ptr41 + (x8), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp312 = tl.load(in_ptr42 + (x8), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp319 = tl.load(in_ptr43 + (x8), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp321 = in_ptr44
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp306 = tmp304 - tmp305
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp307 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp308 = tmp307 * tmp306
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp309 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp310 = tl.where(tmp309, tmp304, tmp305)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp311 = tmp308 + tmp310
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp313 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp314 = tmp312 * tmp313
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp315 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp316 = tmp304 * tmp315
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp317 = tmp316 * tmp304
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp318 = tmp314 + tmp317
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp320 = tl.sqrt_rn(tmp318)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp322 = libdevice.pow(tmp313, tmp321)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp323 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp324 = tmp323 - tmp322
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp325 = tl.sqrt_rn(tmp324)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp326 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp327 = libdevice.pow(tmp326, tmp321)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp328 = tmp323 - tmp327
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp329 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp330 = (tmp329 / tmp328)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp331 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp332 = tmp330 * tmp331
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp333 = -tmp332
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp334 = tmp325 * tmp333
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp335 = (tmp320 / tmp334)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp336 = (tmp329 / tmp333)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp337 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp338 = tmp336 * tmp337
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp339 = tmp335 + tmp338
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp340 = (tmp311 / tmp339)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp341 = tmp319 + tmp340
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr51 + (x8), tmp311, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr52 + (x8), tmp318, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr53 + (x8), tmp341, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     elif pid &lt; num_xblocks_9:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pid_offset = pid - num_xblocks_8
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xnumel = 1048576
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         r0_numel = 1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         x9 = xindex
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp342 = tl.load(in_ptr45 + (x9), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp343 = tl.load(in_ptr46 + (x9), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp350 = tl.load(in_ptr47 + (x9), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp357 = tl.load(in_ptr48 + (x9), None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp359 = in_ptr49
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp344 = tmp342 - tmp343
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp345 = 0.10000000149011612
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp346 = tmp345 * tmp344
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp347 = tl.full([1], False, tl.int1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp348 = tl.where(tmp347, tmp342, tmp343)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp349 = tmp346 + tmp348
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp351 = 0.999
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp352 = tmp350 * tmp351
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp353 = 0.0010000000000000009
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp354 = tmp342 * tmp353
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp355 = tmp354 * tmp342
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp356 = tmp352 + tmp355
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp358 = tl.sqrt_rn(tmp356)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp360 = libdevice.pow(tmp351, tmp359)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp361 = 1.0
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp362 = tmp361 - tmp360
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp363 = tl.sqrt_rn(tmp362)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp364 = 0.9
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp365 = libdevice.pow(tmp364, tmp359)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp366 = tmp361 - tmp365
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp367 = tl.full([1], 1, tl.int32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp368 = (tmp367 / tmp366)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp369 = 0.001
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp370 = tmp368 * tmp369
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp371 = -tmp370
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp372 = tmp363 * tmp371
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp373 = (tmp358 / tmp372)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp374 = (tmp367 / tmp371)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp375 = 1e-08
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp376 = tmp374 * tmp375
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp377 = tmp373 + tmp376
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp378 = (tmp349 / tmp377)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tmp379 = tmp357 + tmp378
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr57 + (x9), tmp349, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr58 + (x9), tmp356, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         tl.store(out_ptr59 + (x9), tmp379, None)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     else:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         pass
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] async_compile.wait(globals())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del async_compile
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] class Runner:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     def __init__(self, partitions):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         self.partitions = partitions
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     def recursively_apply_fns(self, fns):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         new_callables = []
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         for fn, c in zip(fns, self.partitions):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             new_callables.append(fn(c))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         self.partitions = new_callables
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     def call(self, args):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         args.clear()
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg10_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg11_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg12_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg13_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg14_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg15_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg16_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg17_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg18_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg19_1, (), ())
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         with torch.cuda._DeviceGuard(0):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             torch.cuda.set_device(0)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             # Unsorted Source Nodes: [], Original ATen: []
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             stream0 = get_raw_stream(0)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg0_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg10_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg11_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg12_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg13_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg14_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg15_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg16_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg17_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg18_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg19_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg1_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg20_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg21_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg22_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg23_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg24_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg25_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg26_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg27_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg28_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg29_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg2_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg30_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg31_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg32_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg33_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg34_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg35_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg36_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg37_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg38_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg39_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg3_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg40_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg41_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg42_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg43_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg44_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg45_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg46_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg47_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg48_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg49_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg4_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg5_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg6_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg7_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg8_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]             del arg9_1
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]         return ()
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] runner = Runner(partitions=[])
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] call = runner.call
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] if __name__ == &quot;__main__&quot;:
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code]
V0121 17:28:41.638000 23168 torch/_inductor/graph.py:2480] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/7g/c7gwzff5a3nb2e2g63fszyo4xdi4ktgf4qx5vgruvhskmvltmjln.py
I0121 17:28:42.917000 23168 torch/_inductor/graph.py:2440] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/7g/c7gwzff5a3nb2e2g63fszyo4xdi4ktgf4qx5vgruvhskmvltmjln.py
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] Output code:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # AOT ID: [&#39;1_inference&#39;]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import torch
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import math
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import random
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import os
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import tempfile
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from math import inf, nan
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from cmath import nanj
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.utils import maybe_profile
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch import device, empty_strided
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton.language as tl
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] aten = torch.ops.aten
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] inductor_ops = torch.ops.inductor
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] _quantized = torch.ops._quantized
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] async_compile = AsyncCompile()
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([&#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;const float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;, &#39;float*&#39;], r&#39;&#39;&#39;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] #include &lt;torch/csrc/inductor/cpp_prefix.h&gt;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] extern &quot;C&quot;  void  kernel(const float* in_ptr0,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr1,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr2,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr3,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr4,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr5,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr6,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr7,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr8,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        const float* in_ptr9,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr0,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr1,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr2,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr3,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr4,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr5,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr6,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr7,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr8,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                        float* out_ptr9)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr0[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr0[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr1[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr1[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr2[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr2[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr3[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr3[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr4[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr4[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr5[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr5[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr6[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr6[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr7[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr7[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr8[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr8[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             {
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp0 = in_ptr9[static_cast&lt;int64_t&gt;(0L)];
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp1 = static_cast&lt;float&gt;(1.0);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 auto tmp2 = float(tmp0 + tmp1);
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]                 out_ptr9[static_cast&lt;int64_t&gt;(0L)] = tmp2;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] }
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] &#39;&#39;&#39;)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/e3/ce3euorr6vahk3fpfyslv4qsd5j5uxxkmrpreilu6uqnb3gbwb2v.py
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: []
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # Source node to ATen node mapping:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] triton_for_fused_1 = async_compile.triton(&#39;triton_for_fused_1&#39;, &#39;&#39;&#39;
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton.language as tl
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] @triton_heuristics.foreach(
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     filename=__file__,
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     triton_meta={&#39;signature&#39;: {&#39;in_ptr0&#39;: &#39;*fp32&#39;, &#39;in_ptr1&#39;: &#39;*fp32&#39;, &#39;in_ptr2&#39;: &#39;*fp32&#39;, &#39;in_ptr3&#39;: &#39;*fp32&#39;, &#39;in_ptr4&#39;: &#39;fp32&#39;, &#39;in_ptr5&#39;: &#39;*fp32&#39;, &#39;in_ptr6&#39;: &#39;*fp32&#39;, &#39;in_ptr7&#39;: &#39;*fp32&#39;, &#39;in_ptr8&#39;: &#39;*fp32&#39;, &#39;in_ptr9&#39;: &#39;fp32&#39;, &#39;in_ptr10&#39;: &#39;*fp32&#39;, &#39;in_ptr11&#39;: &#39;*fp32&#39;, &#39;in_ptr12&#39;: &#39;*fp32&#39;, &#39;in_ptr13&#39;: &#39;*fp32&#39;, &#39;in_ptr14&#39;: &#39;fp32&#39;, &#39;in_ptr15&#39;: &#39;*fp32&#39;, &#39;in_ptr16&#39;: &#39;*fp32&#39;, &#39;in_ptr17&#39;: &#39;*fp32&#39;, &#39;in_ptr18&#39;: &#39;*fp32&#39;, &#39;in_ptr19&#39;: &#39;fp32&#39;, &#39;in_ptr20&#39;: &#39;*fp32&#39;, &#39;in_ptr21&#39;: &#39;*fp32&#39;, &#39;in_ptr22&#39;: &#39;*fp32&#39;, &#39;in_ptr23&#39;: &#39;*fp32&#39;, &#39;in_ptr24&#39;: &#39;fp32&#39;, &#39;in_ptr25&#39;: &#39;*fp32&#39;, &#39;in_ptr26&#39;: &#39;*fp32&#39;, &#39;in_ptr27&#39;: &#39;*fp32&#39;, &#39;in_ptr28&#39;: &#39;*fp32&#39;, &#39;in_ptr29&#39;: &#39;fp32&#39;, &#39;in_ptr30&#39;: &#39;*fp32&#39;, &#39;in_ptr31&#39;: &#39;*fp32&#39;, &#39;in_ptr32&#39;: &#39;*fp32&#39;, &#39;in_ptr33&#39;: &#39;*fp32&#39;, &#39;in_ptr34&#39;: &#39;fp32&#39;, &#39;in_ptr35&#39;: &#39;*fp32&#39;, &#39;in_ptr36&#39;: &#39;*fp32&#39;, &#39;in_ptr37&#39;: &#39;*fp32&#39;, &#39;in_ptr38&#39;: &#39;*fp32&#39;, &#39;in_ptr39&#39;: &#39;fp32&#39;, &#39;in_ptr40&#39;: &#39;*fp32&#39;, &#39;in_ptr41&#39;: &#39;*fp32&#39;, &#39;in_ptr42&#39;: &#39;*fp32&#39;, &#39;in_ptr43&#39;: &#39;*fp32&#39;, &#39;in_ptr44&#39;: &#39;fp32&#39;, &#39;in_ptr45&#39;: &#39;*fp32&#39;, &#39;in_ptr46&#39;: &#39;*fp32&#39;, &#39;in_ptr47&#39;: &#39;*fp32&#39;, &#39;in_ptr48&#39;: &#39;*fp32&#39;, &#39;in_ptr49&#39;: &#39;fp32&#39;, &#39;out_ptr3&#39;: &#39;*fp32&#39;, &#39;out_ptr4&#39;: &#39;*fp32&#39;, &#39;out_ptr5&#39;: &#39;*fp32&#39;, &#39;out_ptr9&#39;: &#39;*fp32&#39;, &#39;out_ptr10&#39;: &#39;*fp32&#39;, &#39;out_ptr11&#39;: &#39;*fp32&#39;, &#39;out_ptr15&#39;: &#39;*fp32&#39;, &#39;out_ptr16&#39;: &#39;*fp32&#39;, &#39;out_ptr17&#39;: &#39;*fp32&#39;, &#39;out_ptr21&#39;: &#39;*fp32&#39;, &#39;out_ptr22&#39;: &#39;*fp32&#39;, &#39;out_ptr23&#39;: &#39;*fp32&#39;, &#39;out_ptr27&#39;: &#39;*fp32&#39;, &#39;out_ptr28&#39;: &#39;*fp32&#39;, &#39;out_ptr29&#39;: &#39;*fp32&#39;, &#39;out_ptr33&#39;: &#39;*fp32&#39;, &#39;out_ptr34&#39;: &#39;*fp32&#39;, &#39;out_ptr35&#39;: &#39;*fp32&#39;, &#39;out_ptr39&#39;: &#39;*fp32&#39;, &#39;out_ptr40&#39;: &#39;*fp32&#39;, &#39;out_ptr41&#39;: &#39;*fp32&#39;, &#39;out_ptr45&#39;: &#39;*fp32&#39;, &#39;out_ptr46&#39;: &#39;*fp32&#39;, &#39;out_ptr47&#39;: &#39;*fp32&#39;, &#39;out_ptr51&#39;: &#39;*fp32&#39;, &#39;out_ptr52&#39;: &#39;*fp32&#39;, &#39;out_ptr53&#39;: &#39;*fp32&#39;, &#39;out_ptr57&#39;: &#39;*fp32&#39;, &#39;out_ptr58&#39;: &#39;*fp32&#39;, &#39;out_ptr59&#39;: &#39;*fp32&#39;}, &#39;device&#39;: DeviceProperties(type=&#39;cuda&#39;, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), &#39;constants&#39;: {}, &#39;configs&#39;: [{(0,): [[&#39;tt.divisibility&#39;, 16]], (1,): [[&#39;tt.divisibility&#39;, 16]], (2,): [[&#39;tt.divisibility&#39;, 16]], (3,): [[&#39;tt.divisibility&#39;, 16]], (5,): [[&#39;tt.divisibility&#39;, 16]], (6,): [[&#39;tt.divisibility&#39;, 16]], (7,): [[&#39;tt.divisibility&#39;, 16]], (8,): [[&#39;tt.divisibility&#39;, 16]], (10,): [[&#39;tt.divisibility&#39;, 16]], (11,): [[&#39;tt.divisibility&#39;, 16]], (12,): [[&#39;tt.divisibility&#39;, 16]], (13,): [[&#39;tt.divisibility&#39;, 16]], (15,): [[&#39;tt.divisibility&#39;, 16]], (16,): [[&#39;tt.divisibility&#39;, 16]], (17,): [[&#39;tt.divisibility&#39;, 16]], (18,): [[&#39;tt.divisibility&#39;, 16]], (20,): [[&#39;tt.divisibility&#39;, 16]], (21,): [[&#39;tt.divisibility&#39;, 16]], (22,): [[&#39;tt.divisibility&#39;, 16]], (23,): [[&#39;tt.divisibility&#39;, 16]], (25,): [[&#39;tt.divisibility&#39;, 16]], (26,): [[&#39;tt.divisibility&#39;, 16]], (27,): [[&#39;tt.divisibility&#39;, 16]], (28,): [[&#39;tt.divisibility&#39;, 16]], (30,): [[&#39;tt.divisibility&#39;, 16]], (31,): [[&#39;tt.divisibility&#39;, 16]], (32,): [[&#39;tt.divisibility&#39;, 16]], (33,): [[&#39;tt.divisibility&#39;, 16]], (35,): [[&#39;tt.divisibility&#39;, 16]], (36,): [[&#39;tt.divisibility&#39;, 16]], (37,): [[&#39;tt.divisibility&#39;, 16]], (38,): [[&#39;tt.divisibility&#39;, 16]], (40,): [[&#39;tt.divisibility&#39;, 16]], (41,): [[&#39;tt.divisibility&#39;, 16]], (42,): [[&#39;tt.divisibility&#39;, 16]], (43,): [[&#39;tt.divisibility&#39;, 16]], (45,): [[&#39;tt.divisibility&#39;, 16]], (46,): [[&#39;tt.divisibility&#39;, 16]], (47,): [[&#39;tt.divisibility&#39;, 16]], (48,): [[&#39;tt.divisibility&#39;, 16]], (50,): [[&#39;tt.divisibility&#39;, 16]], (51,): [[&#39;tt.divisibility&#39;, 16]], (52,): [[&#39;tt.divisibility&#39;, 16]], (53,): [[&#39;tt.divisibility&#39;, 16]], (54,): [[&#39;tt.divisibility&#39;, 16]], (55,): [[&#39;tt.divisibility&#39;, 16]], (56,): [[&#39;tt.divisibility&#39;, 16]], (57,): [[&#39;tt.divisibility&#39;, 16]], (58,): [[&#39;tt.divisibility&#39;, 16]], (59,): [[&#39;tt.divisibility&#39;, 16]], (60,): [[&#39;tt.divisibility&#39;, 16]], (61,): [[&#39;tt.divisibility&#39;, 16]], (62,): [[&#39;tt.divisibility&#39;, 16]], (63,): [[&#39;tt.divisibility&#39;, 16]], (64,): [[&#39;tt.divisibility&#39;, 16]], (65,): [[&#39;tt.divisibility&#39;, 16]], (66,): [[&#39;tt.divisibility&#39;, 16]], (67,): [[&#39;tt.divisibility&#39;, 16]], (68,): [[&#39;tt.divisibility&#39;, 16]], (69,): [[&#39;tt.divisibility&#39;, 16]], (70,): [[&#39;tt.divisibility&#39;, 16]], (71,): [[&#39;tt.divisibility&#39;, 16]], (72,): [[&#39;tt.divisibility&#39;, 16]], (73,): [[&#39;tt.divisibility&#39;, 16]], (74,): [[&#39;tt.divisibility&#39;, 16]], (75,): [[&#39;tt.divisibility&#39;, 16]], (76,): [[&#39;tt.divisibility&#39;, 16]], (77,): [[&#39;tt.divisibility&#39;, 16]], (78,): [[&#39;tt.divisibility&#39;, 16]], (79,): [[&#39;tt.divisibility&#39;, 16]]}]},
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     inductor_meta={&#39;grid_type&#39;: &#39;SequentialComboKernelGrid&#39;, &#39;combo_grid_meta&#39;: {&#39;num_kernels&#39;: 10, &#39;min_blocks&#39;: 0, &#39;default_config&#39;: {&#39;XBLOCK&#39;: 1024}, &#39;no_x_dim_0&#39;: False, &#39;xnumel_0&#39;: 1048576, &#39;no_x_dim_1&#39;: False, &#39;xnumel_1&#39;: 1048576, &#39;no_x_dim_2&#39;: False, &#39;xnumel_2&#39;: 1048576, &#39;no_x_dim_3&#39;: False, &#39;xnumel_3&#39;: 1048576, &#39;no_x_dim_4&#39;: False, &#39;xnumel_4&#39;: 1048576, &#39;no_x_dim_5&#39;: False, &#39;xnumel_5&#39;: 1048576, &#39;no_x_dim_6&#39;: False, &#39;xnumel_6&#39;: 1048576, &#39;no_x_dim_7&#39;: False, &#39;xnumel_7&#39;: 1048576, &#39;no_x_dim_8&#39;: False, &#39;xnumel_8&#39;: 1048576, &#39;no_x_dim_9&#39;: False, &#39;xnumel_9&#39;: 1048576}, &#39;kernel_name&#39;: &#39;triton_for_fused_1&#39;, &#39;mutated_arg_names&#39;: [&#39;in_ptr1&#39;, &#39;in_ptr11&#39;, &#39;in_ptr12&#39;, &#39;in_ptr13&#39;, &#39;in_ptr16&#39;, &#39;in_ptr17&#39;, &#39;in_ptr18&#39;, &#39;in_ptr2&#39;, &#39;in_ptr21&#39;, &#39;in_ptr22&#39;, &#39;in_ptr23&#39;, &#39;in_ptr26&#39;, &#39;in_ptr27&#39;, &#39;in_ptr28&#39;, &#39;in_ptr3&#39;, &#39;in_ptr31&#39;, &#39;in_ptr32&#39;, &#39;in_ptr33&#39;, &#39;in_ptr36&#39;, &#39;in_ptr37&#39;, &#39;in_ptr38&#39;, &#39;in_ptr41&#39;, &#39;in_ptr42&#39;, &#39;in_ptr43&#39;, &#39;in_ptr46&#39;, &#39;in_ptr47&#39;, &#39;in_ptr48&#39;, &#39;in_ptr6&#39;, &#39;in_ptr7&#39;, &#39;in_ptr8&#39;, &#39;out_ptr10&#39;, &#39;out_ptr11&#39;, &#39;out_ptr15&#39;, &#39;out_ptr16&#39;, &#39;out_ptr17&#39;, &#39;out_ptr21&#39;, &#39;out_ptr22&#39;, &#39;out_ptr23&#39;, &#39;out_ptr27&#39;, &#39;out_ptr28&#39;, &#39;out_ptr29&#39;, &#39;out_ptr3&#39;, &#39;out_ptr33&#39;, &#39;out_ptr34&#39;, &#39;out_ptr35&#39;, &#39;out_ptr39&#39;, &#39;out_ptr4&#39;, &#39;out_ptr40&#39;, &#39;out_ptr41&#39;, &#39;out_ptr45&#39;, &#39;out_ptr46&#39;, &#39;out_ptr47&#39;, &#39;out_ptr5&#39;, &#39;out_ptr51&#39;, &#39;out_ptr52&#39;, &#39;out_ptr53&#39;, &#39;out_ptr57&#39;, &#39;out_ptr58&#39;, &#39;out_ptr59&#39;, &#39;out_ptr9&#39;], &#39;backend_hash&#39;: &#39;DC36EA6BB5AEA639F493BE6C610554D7008666A7D52F3C35F9DAC37F278CCC65&#39;, &#39;assert_indirect_indexing&#39;: True, &#39;autotune_local_cache&#39;: True, &#39;autotune_pointwise&#39;: True, &#39;autotune_remote_cache&#39;: None, &#39;force_disable_caches&#39;: False, &#39;dynamic_scale_rblock&#39;: True, &#39;max_autotune&#39;: False, &#39;max_autotune_pointwise&#39;: False, &#39;min_split_scan_rblock&#39;: 256, &#39;spill_threshold&#39;: 16, &#39;store_cubin&#39;: False, &#39;deterministic&#39;: False, &#39;force_filter_reduction_configs&#39;: False, &#39;are_deterministic_algorithms_enabled&#39;: False},
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] )
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] @triton.jit
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     pid = tl.program_id(0)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     XBLOCK: tl.constexpr = 1024
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_0 = tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     if pid &lt; num_xblocks_0:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x0 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp0 = tl.load(in_ptr0 + (x0), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp1 = tl.load(in_ptr1 + (x0), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp8 = tl.load(in_ptr2 + (x0), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp15 = tl.load(in_ptr3 + (x0), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp17 = in_ptr4
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp2 = tmp0 - tmp1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp3 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp4 = tmp3 * tmp2
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp5 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp6 = tl.where(tmp5, tmp0, tmp1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp7 = tmp4 + tmp6
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp9 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp10 = tmp8 * tmp9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp11 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp12 = tmp0 * tmp11
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp13 = tmp12 * tmp0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp14 = tmp10 + tmp13
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp16 = tl.sqrt_rn(tmp14)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp18 = libdevice.pow(tmp9, tmp17)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp19 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp20 = tmp19 - tmp18
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp21 = tl.sqrt_rn(tmp20)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp22 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp23 = libdevice.pow(tmp22, tmp17)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp24 = tmp19 - tmp23
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp25 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp26 = (tmp25 / tmp24)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp27 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp28 = tmp26 * tmp27
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp29 = -tmp28
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp30 = tmp21 * tmp29
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp31 = (tmp16 / tmp30)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp32 = (tmp25 / tmp29)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp33 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp34 = tmp32 * tmp33
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp35 = tmp31 + tmp34
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp36 = (tmp7 / tmp35)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp37 = tmp15 + tmp36
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr3 + (x0), tmp7, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr4 + (x0), tmp14, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr5 + (x0), tmp37, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_1:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x1 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp38 = tl.load(in_ptr5 + (x1), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp39 = tl.load(in_ptr6 + (x1), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp46 = tl.load(in_ptr7 + (x1), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp53 = tl.load(in_ptr8 + (x1), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp55 = in_ptr9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp40 = tmp38 - tmp39
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp41 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp42 = tmp41 * tmp40
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp43 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp44 = tl.where(tmp43, tmp38, tmp39)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp45 = tmp42 + tmp44
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp47 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp48 = tmp46 * tmp47
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp49 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp50 = tmp38 * tmp49
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp51 = tmp50 * tmp38
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp52 = tmp48 + tmp51
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp54 = tl.sqrt_rn(tmp52)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp56 = libdevice.pow(tmp47, tmp55)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp57 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp58 = tmp57 - tmp56
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp59 = tl.sqrt_rn(tmp58)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp60 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp61 = libdevice.pow(tmp60, tmp55)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp62 = tmp57 - tmp61
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp63 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp64 = (tmp63 / tmp62)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp65 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp66 = tmp64 * tmp65
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp67 = -tmp66
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp68 = tmp59 * tmp67
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp69 = (tmp54 / tmp68)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp70 = (tmp63 / tmp67)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp71 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp72 = tmp70 * tmp71
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp73 = tmp69 + tmp72
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp74 = (tmp45 / tmp73)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp75 = tmp53 + tmp74
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr9 + (x1), tmp45, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr10 + (x1), tmp52, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr11 + (x1), tmp75, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_2:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x2 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp76 = tl.load(in_ptr10 + (x2), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp77 = tl.load(in_ptr11 + (x2), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp84 = tl.load(in_ptr12 + (x2), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp91 = tl.load(in_ptr13 + (x2), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp93 = in_ptr14
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp78 = tmp76 - tmp77
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp79 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp80 = tmp79 * tmp78
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp81 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp82 = tl.where(tmp81, tmp76, tmp77)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp83 = tmp80 + tmp82
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp85 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp86 = tmp84 * tmp85
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp87 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp88 = tmp76 * tmp87
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp89 = tmp88 * tmp76
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp90 = tmp86 + tmp89
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp92 = tl.sqrt_rn(tmp90)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp94 = libdevice.pow(tmp85, tmp93)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp95 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp96 = tmp95 - tmp94
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp97 = tl.sqrt_rn(tmp96)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp98 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp99 = libdevice.pow(tmp98, tmp93)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp100 = tmp95 - tmp99
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp101 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp102 = (tmp101 / tmp100)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp103 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp104 = tmp102 * tmp103
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp105 = -tmp104
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp106 = tmp97 * tmp105
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp107 = (tmp92 / tmp106)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp108 = (tmp101 / tmp105)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp109 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp110 = tmp108 * tmp109
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp111 = tmp107 + tmp110
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp112 = (tmp83 / tmp111)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp113 = tmp91 + tmp112
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr15 + (x2), tmp83, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr16 + (x2), tmp90, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr17 + (x2), tmp113, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_3:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_2
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x3 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp114 = tl.load(in_ptr15 + (x3), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp115 = tl.load(in_ptr16 + (x3), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp122 = tl.load(in_ptr17 + (x3), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp129 = tl.load(in_ptr18 + (x3), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp131 = in_ptr19
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp116 = tmp114 - tmp115
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp117 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp118 = tmp117 * tmp116
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp119 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp120 = tl.where(tmp119, tmp114, tmp115)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp121 = tmp118 + tmp120
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp123 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp124 = tmp122 * tmp123
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp125 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp126 = tmp114 * tmp125
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp127 = tmp126 * tmp114
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp128 = tmp124 + tmp127
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp130 = tl.sqrt_rn(tmp128)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp132 = libdevice.pow(tmp123, tmp131)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp133 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp134 = tmp133 - tmp132
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp135 = tl.sqrt_rn(tmp134)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp136 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp137 = libdevice.pow(tmp136, tmp131)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp138 = tmp133 - tmp137
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp139 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp140 = (tmp139 / tmp138)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp141 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp142 = tmp140 * tmp141
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp143 = -tmp142
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp144 = tmp135 * tmp143
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp145 = (tmp130 / tmp144)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp146 = (tmp139 / tmp143)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp147 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp148 = tmp146 * tmp147
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp149 = tmp145 + tmp148
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp150 = (tmp121 / tmp149)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp151 = tmp129 + tmp150
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr21 + (x3), tmp121, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr22 + (x3), tmp128, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr23 + (x3), tmp151, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_4:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_3
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x4 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp152 = tl.load(in_ptr20 + (x4), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp153 = tl.load(in_ptr21 + (x4), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp160 = tl.load(in_ptr22 + (x4), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp167 = tl.load(in_ptr23 + (x4), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp169 = in_ptr24
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp154 = tmp152 - tmp153
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp155 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp156 = tmp155 * tmp154
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp157 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp158 = tl.where(tmp157, tmp152, tmp153)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp159 = tmp156 + tmp158
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp161 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp162 = tmp160 * tmp161
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp163 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp164 = tmp152 * tmp163
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp165 = tmp164 * tmp152
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp166 = tmp162 + tmp165
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp168 = tl.sqrt_rn(tmp166)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp170 = libdevice.pow(tmp161, tmp169)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp171 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp172 = tmp171 - tmp170
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp173 = tl.sqrt_rn(tmp172)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp174 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp175 = libdevice.pow(tmp174, tmp169)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp176 = tmp171 - tmp175
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp177 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp178 = (tmp177 / tmp176)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp179 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp180 = tmp178 * tmp179
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp181 = -tmp180
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp182 = tmp173 * tmp181
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp183 = (tmp168 / tmp182)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp184 = (tmp177 / tmp181)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp185 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp186 = tmp184 * tmp185
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp187 = tmp183 + tmp186
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp188 = (tmp159 / tmp187)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp189 = tmp167 + tmp188
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr27 + (x4), tmp159, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr28 + (x4), tmp166, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr29 + (x4), tmp189, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_5:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_4
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x5 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp190 = tl.load(in_ptr25 + (x5), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp191 = tl.load(in_ptr26 + (x5), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp198 = tl.load(in_ptr27 + (x5), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp205 = tl.load(in_ptr28 + (x5), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp207 = in_ptr29
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp192 = tmp190 - tmp191
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp193 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp194 = tmp193 * tmp192
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp195 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp196 = tl.where(tmp195, tmp190, tmp191)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp197 = tmp194 + tmp196
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp199 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp200 = tmp198 * tmp199
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp201 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp202 = tmp190 * tmp201
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp203 = tmp202 * tmp190
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp204 = tmp200 + tmp203
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp206 = tl.sqrt_rn(tmp204)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp208 = libdevice.pow(tmp199, tmp207)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp209 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp210 = tmp209 - tmp208
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp211 = tl.sqrt_rn(tmp210)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp212 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp213 = libdevice.pow(tmp212, tmp207)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp214 = tmp209 - tmp213
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp215 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp216 = (tmp215 / tmp214)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp217 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp218 = tmp216 * tmp217
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp219 = -tmp218
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp220 = tmp211 * tmp219
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp221 = (tmp206 / tmp220)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp222 = (tmp215 / tmp219)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp223 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp224 = tmp222 * tmp223
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp225 = tmp221 + tmp224
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp226 = (tmp197 / tmp225)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp227 = tmp205 + tmp226
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr33 + (x5), tmp197, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr34 + (x5), tmp204, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr35 + (x5), tmp227, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_6:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_5
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x6 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp228 = tl.load(in_ptr30 + (x6), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp229 = tl.load(in_ptr31 + (x6), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp236 = tl.load(in_ptr32 + (x6), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp243 = tl.load(in_ptr33 + (x6), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp245 = in_ptr34
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp230 = tmp228 - tmp229
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp231 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp232 = tmp231 * tmp230
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp233 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp234 = tl.where(tmp233, tmp228, tmp229)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp235 = tmp232 + tmp234
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp237 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp238 = tmp236 * tmp237
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp239 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp240 = tmp228 * tmp239
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp241 = tmp240 * tmp228
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp242 = tmp238 + tmp241
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp244 = tl.sqrt_rn(tmp242)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp246 = libdevice.pow(tmp237, tmp245)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp247 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp248 = tmp247 - tmp246
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp249 = tl.sqrt_rn(tmp248)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp250 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp251 = libdevice.pow(tmp250, tmp245)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp252 = tmp247 - tmp251
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp253 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp254 = (tmp253 / tmp252)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp255 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp256 = tmp254 * tmp255
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp257 = -tmp256
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp258 = tmp249 * tmp257
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp259 = (tmp244 / tmp258)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp260 = (tmp253 / tmp257)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp261 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp262 = tmp260 * tmp261
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp263 = tmp259 + tmp262
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp264 = (tmp235 / tmp263)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp265 = tmp243 + tmp264
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr39 + (x6), tmp235, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr40 + (x6), tmp242, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr41 + (x6), tmp265, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_7:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_6
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x7 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp266 = tl.load(in_ptr35 + (x7), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp267 = tl.load(in_ptr36 + (x7), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp274 = tl.load(in_ptr37 + (x7), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp281 = tl.load(in_ptr38 + (x7), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp283 = in_ptr39
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp268 = tmp266 - tmp267
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp269 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp270 = tmp269 * tmp268
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp271 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp272 = tl.where(tmp271, tmp266, tmp267)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp273 = tmp270 + tmp272
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp275 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp276 = tmp274 * tmp275
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp277 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp278 = tmp266 * tmp277
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp279 = tmp278 * tmp266
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp280 = tmp276 + tmp279
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp282 = tl.sqrt_rn(tmp280)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp284 = libdevice.pow(tmp275, tmp283)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp285 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp286 = tmp285 - tmp284
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp287 = tl.sqrt_rn(tmp286)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp288 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp289 = libdevice.pow(tmp288, tmp283)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp290 = tmp285 - tmp289
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp291 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp292 = (tmp291 / tmp290)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp293 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp294 = tmp292 * tmp293
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp295 = -tmp294
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp296 = tmp287 * tmp295
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp297 = (tmp282 / tmp296)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp298 = (tmp291 / tmp295)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp299 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp300 = tmp298 * tmp299
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp301 = tmp297 + tmp300
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp302 = (tmp273 / tmp301)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp303 = tmp281 + tmp302
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr45 + (x7), tmp273, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr46 + (x7), tmp280, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr47 + (x7), tmp303, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_8:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_7
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x8 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp304 = tl.load(in_ptr40 + (x8), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp305 = tl.load(in_ptr41 + (x8), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp312 = tl.load(in_ptr42 + (x8), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp319 = tl.load(in_ptr43 + (x8), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp321 = in_ptr44
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp306 = tmp304 - tmp305
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp307 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp308 = tmp307 * tmp306
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp309 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp310 = tl.where(tmp309, tmp304, tmp305)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp311 = tmp308 + tmp310
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp313 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp314 = tmp312 * tmp313
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp315 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp316 = tmp304 * tmp315
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp317 = tmp316 * tmp304
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp318 = tmp314 + tmp317
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp320 = tl.sqrt_rn(tmp318)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp322 = libdevice.pow(tmp313, tmp321)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp323 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp324 = tmp323 - tmp322
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp325 = tl.sqrt_rn(tmp324)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp326 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp327 = libdevice.pow(tmp326, tmp321)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp328 = tmp323 - tmp327
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp329 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp330 = (tmp329 / tmp328)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp331 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp332 = tmp330 * tmp331
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp333 = -tmp332
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp334 = tmp325 * tmp333
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp335 = (tmp320 / tmp334)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp336 = (tmp329 / tmp333)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp337 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp338 = tmp336 * tmp337
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp339 = tmp335 + tmp338
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp340 = (tmp311 / tmp339)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp341 = tmp319 + tmp340
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr51 + (x8), tmp311, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr52 + (x8), tmp318, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr53 + (x8), tmp341, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     elif pid &lt; num_xblocks_9:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pid_offset = pid - num_xblocks_8
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xnumel = 1048576
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         r0_numel = 1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xoffset = pid_offset * XBLOCK
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         xmask = tl.full([XBLOCK], True, tl.int1)[:]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         x9 = xindex
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp342 = tl.load(in_ptr45 + (x9), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp343 = tl.load(in_ptr46 + (x9), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp350 = tl.load(in_ptr47 + (x9), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp357 = tl.load(in_ptr48 + (x9), None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp359 = in_ptr49
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp344 = tmp342 - tmp343
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp345 = 0.10000000149011612
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp346 = tmp345 * tmp344
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp347 = tl.full([1], False, tl.int1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp348 = tl.where(tmp347, tmp342, tmp343)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp349 = tmp346 + tmp348
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp351 = 0.999
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp352 = tmp350 * tmp351
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp353 = 0.0010000000000000009
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp354 = tmp342 * tmp353
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp355 = tmp354 * tmp342
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp356 = tmp352 + tmp355
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp358 = tl.sqrt_rn(tmp356)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp360 = libdevice.pow(tmp351, tmp359)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp361 = 1.0
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp362 = tmp361 - tmp360
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp363 = tl.sqrt_rn(tmp362)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp364 = 0.9
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp365 = libdevice.pow(tmp364, tmp359)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp366 = tmp361 - tmp365
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp367 = tl.full([1], 1, tl.int32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp368 = (tmp367 / tmp366)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp369 = 0.001
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp370 = tmp368 * tmp369
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp371 = -tmp370
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp372 = tmp363 * tmp371
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp373 = (tmp358 / tmp372)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp374 = (tmp367 / tmp371)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp375 = 1e-08
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp376 = tmp374 * tmp375
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp377 = tmp373 + tmp376
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp378 = (tmp349 / tmp377)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tmp379 = tmp357 + tmp378
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr57 + (x9), tmp349, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr58 + (x9), tmp356, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         tl.store(out_ptr59 + (x9), tmp379, None)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     else:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         pass
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] &#39;&#39;&#39;, device_str=&#39;cuda&#39;)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] async_compile.wait(globals())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del async_compile
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] class Runner:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     def __init__(self, partitions):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         self.partitions = partitions
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     def recursively_apply_fns(self, fns):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         new_callables = []
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         for fn, c in zip(fns, self.partitions):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             new_callables.append(fn(c))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         self.partitions = new_callables
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     def call(self, args):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         args.clear()
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg0_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg1_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg2_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg3_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg4_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg5_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg6_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg7_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg8_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg9_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg10_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg11_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg12_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg13_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg14_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg15_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg16_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg17_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg18_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg19_1, (), ())
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg20_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg21_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg22_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg23_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg24_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg25_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg26_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg27_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg28_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg29_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg30_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg31_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg32_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg33_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg34_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg35_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg36_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg37_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg38_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg39_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg40_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg41_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg42_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg43_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg44_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg45_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg46_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg47_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg48_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         assert_size_stride(arg49_1, (1024, 1024), (1024, 1))
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         with torch.cuda._DeviceGuard(0):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             torch.cuda.set_device(0)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             # Unsorted Source Nodes: [], Original ATen: []
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             stream0 = get_raw_stream(0)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg0_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg10_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg11_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg12_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg13_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg14_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg15_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg16_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg17_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg18_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg19_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg1_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg20_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg21_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg22_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg23_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg24_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg25_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg26_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg27_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg28_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg29_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg2_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg30_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg31_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg32_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg33_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg34_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg35_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg36_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg37_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg38_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg39_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg3_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg40_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg41_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg42_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg43_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg44_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg45_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg46_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg47_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg48_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg49_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg4_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg5_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg6_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg7_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg8_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]             del arg9_1
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]         return ()
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] runner = Runner(partitions=[])
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] call = runner.call
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] recursively_apply_fns = runner.recursively_apply_fns
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     from torch._dynamo.testing import rand_strided
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     from torch._inductor.utils import print_performance
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg0_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg1_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg2_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg3_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg4_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg5_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg6_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg7_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg8_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg9_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg10_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg11_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg12_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg13_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg14_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg15_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg16_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg17_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg18_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg19_1 = rand_strided((), (), device=&#39;cpu&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg20_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg21_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg22_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg23_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg24_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg25_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg26_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg27_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg28_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg29_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg30_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg31_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg32_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg33_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg34_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg35_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg36_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg37_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg38_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg39_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg40_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg41_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg42_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg43_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg44_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg45_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg46_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg47_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg48_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     arg49_1 = rand_strided((1024, 1024), (1024, 1), device=&#39;cuda:0&#39;, dtype=torch.float32)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1])
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] if __name__ == &quot;__main__&quot;:
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]     compiled_module_main(&#39;None&#39;, benchmark_compiled_module)
V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code]
V0121 17:28:45.530000 23168 torch/_inductor/graph.py:2480] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/dl/cdlhgjqcuqbu3ayx7yodirku4j26rypg2y46ph7i7r4oygg47wbs.py
I0121 17:28:45.655000 23168 torch/_inductor/graph.py:2440] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/dl/cdlhgjqcuqbu3ayx7yodirku4j26rypg2y46ph7i7r4oygg47wbs.py
eager runtime: 1202.695570000287us
compiled runtime: 765.1694045758799us
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map.
By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam
optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide
on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a
valuable resource for developers looking to improve the performance of their models with horizontal fusion.</p>
<p>See also:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/tutorials/recipes/compiling_optimizer.html">Compiled optimizer tutorial</a> - an intro into the compiled optimizer.</p></li>
<li><p><a class="reference external" href="https://dev-discuss.pytorch.org/t/compiling-the-optimizer-with-pt2/1669">Compiling the optimizer with PT2</a> - deeper technical details on the compiled optimizer.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 10.633 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-recipes-foreach-map-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/162cf335b789dd055d4192f77cb0251c/foreach_map.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">foreach_map.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/bcb9aa4fd3968b85310b970dbd86bbc3/foreach_map.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">foreach_map.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/faee5eeb51c8f314872395cc1b776677/foreach_map.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">foreach_map.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>


                </article>
              
  </article>
  
              
              
                <footer class="bd-footer-article">
                  <div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item">
<div class="feedback">
  
<div class="rating">
    Rate this Page
    <div class="stars">
        
        <span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
        
        <span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
        
    </div>
</div>

  <div class="feedback-send">
    <button class="feedback-btn"
            onclick="openGitHubIssue()"
            data-bs-title="Create a GitHub Issue"
            data-bs-placement="bottom"
            data-bs-toggle="tooltip"
            data-gtm="feedback-btn-click">Send Feedback
    </button>
  </div>
</div>

<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>

<div class="footer-info">
  <p class="copyright">
    
  </p>

  <p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
  
</div>
                </footer>
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="torch_compile_torch_function_modes.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">(beta) Utilizing Torch Function modes with torch.compile</p>
      </div>
    </a>
    <a class="right-next"
       href="torch_compile_caching_configuration_tutorial.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Compile Time Caching Configuration</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
    
       <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-setup">Model Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions-for-foreach-map-implementation">Helper functions for foreach_map implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-and-running-the-compiled-kernel">Setting up and running the compiled kernel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
  </nav></div>
    




<div class="sidebar-secondary-item">
  <div class="sidebar-heading">PyTorch Libraries</div>
  <ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
  
   <li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
  
  </ul>
</div>

</div>
</div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  

<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
      </div>

      <div class="col-md-4">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>




<footer class="site-footer">

  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>


      <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
      <script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>


      <p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a
          href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>

    </div>

    <div class="lf-grid">
      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook">
              <path fill="currentColor"
                d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" />
            </svg>
          </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X">
              <path fill="currentColor"
                d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" />
            </svg>
          </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube">
              <path fill="currentColor"
                d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" />
            </svg>
          </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn">
              <rect width="512" height="512" rx="0" fill="currentColor" />
              <circle fill="#000" cx="142" cy="138" r="37" />
              <path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198" />
              <path fill="#000"
                d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" />
            </svg>
          </a></li>
        <li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack">
              <path fill="currentColor"
                d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z">
              </path>
            </svg>
          </a></li>
        <li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat">
              <path fill="currentColor"
                d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z">
              </path>
              <path fill="currentColor"
                d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z">
              </path>
            </svg>
          </a></li>
      </ul>
    </div>
    
    <div class="privacy-policy">
      <div class="copyright">
      
        <p>
          &copy; PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a
            href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a
            href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
        
      </div>
    </div>


  </div>
</footer>

<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/img/pytorch-x.svg">
  </div>
</div>
  
  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  <script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Explicit horizontal fusion with foreach_map and torch.compile",
       "headline": "Explicit horizontal fusion with foreach_map and torch.compile",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/recipes/foreach_map.html",
       "articleBody": "Note Go to the end to download the full example code. Explicit horizontal fusion with foreach_map and torch.compile# Author: Michael Lazos Horizontal fusion is a key optimization in ML compilers. In eager,this is typically expressed using the torch._foreach* ops which parallelizes operations across a list of tensors. However, supporting all possible permutations of arguments is quite difficult (e.g. mixtures of scalars and lists). Foreach_map allows conversion of any pointwise op in torch to a horiztonally fused foreach variant. In this tutorial, we will demonstrate how to implement the Adam optimizer with foreach_map to generate a fully fused kernel. Note This recipe describes a prototype feature. Prototype features are typically at an early stage for feedback and testing and are subject to change. Prerequisites# PyTorch v2.7.0 or later Model Setup# For this example, we\u2019ll use a simple sequence of linear layers. We instantiate an independent copy to compare the two optimizer implementations. import torch # exit cleanly if we are on a device that doesn\u0027t support ``torch.compile`` if torch.cuda.get_device_capability() \u003c (7, 0): print(\"Exiting because torch.compile is not supported on this device.\") import sys sys.exit(0) # Create simple model model = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\"cuda\") for _ in range(10)] ) model_copy = torch.nn.Sequential( *[torch.nn.Linear(1024, 1024, False, device=\"cuda\") for _ in range(10)] ) input = torch.rand(1024, device=\"cuda\") # run forward pass output = model(input) output_copy = model_copy(input) # run backward to populate the grads for our optimizer below output.sum().backward() output_copy.sum().backward() Helper functions for foreach_map implementation# In this section, we\u2019ll begin our implementation of the Adam optimizer. from torch._higher_order_ops.foreach_map import foreach_map # Helper function to extract optimizer states from a torch.optim.Adam instance def get_inputs(optim): steps = [] params = [] grads = [] exp_avgs = [] exp_avg_sqs = [] for group in optim.param_groups: for p in group[\"params\"]: params.append(p) grads.append(p.grad) state = optim.state[p] exp_avgs.append(state[\"exp_avg\"]) exp_avg_sqs.append(state[\"exp_avg_sq\"]) steps.append(state[\"step\"]) return steps, params, exp_avgs, exp_avg_sqs # Functions to update the different optimizer states def update_exp_avg_sq(exp_avg_sq, grad, beta2): return exp_avg_sq.mul(beta2).addcmul(grad, grad, value=1 - beta2) def update_param(param, step, exp_avg, exp_avg_sq, beta1, beta2, lr, eps): bias_correction1 = 1 - torch.pow(beta1, step) bias_correction2 = (1 - torch.pow(beta2, step)).sqrt() step_size = (lr / bias_correction1).neg() denom = (exp_avg_sq.sqrt() / (bias_correction2 * step_size)).add(eps / step_size) return torch.add(param, torch.div(exp_avg, denom)) # Our full Adam implementation def foreach_map_adam( steps, params, exp_avgs, exp_avg_sqs, weight_decay=0, beta1=0.9, beta2=0.999, lr=1e-3, eps=1e-8, ): with torch.no_grad(): grads = [param.grad for param in params] # update step updated_steps = foreach_map(lambda x: x + 1, steps) torch._foreach_copy_(steps, updated_steps) if weight_decay != 0: foreach_map(torch.add, (grads,), alpha=weight_decay) # Higher-order operators (HOPs) cannot have multiple outputs at the moment # need to call foreach_map once for each output exp_avgs_updated = foreach_map(torch.lerp, exp_avgs, grads, 1 - beta1) exp_avgs_sq_updated = foreach_map(update_exp_avg_sq, exp_avg_sqs, grads, beta2) params_updated = foreach_map( update_param, params, steps, exp_avgs_updated, exp_avgs_sq_updated, beta1, beta2, lr, eps, ) # Higher-order operators (HOPs) don\u0027t support input mutation today # so manually update the states in-place torch._foreach_copy_(exp_avgs, exp_avgs_updated) torch._foreach_copy_(exp_avg_sqs, exp_avgs_sq_updated) torch._foreach_copy_(params, params_updated) return Setting up and running the compiled kernel# In this section, we\u2019ll run our Adam optimizer and compare the results Note torch.compile is only supported on CUDA devices that have a compute capability of 7.0 or higher. opt_eager = torch.optim.Adam(model.parameters(), lr=torch.tensor(0.01)) opt_eager_copy = torch.optim.Adam(model_copy.parameters(), lr=torch.tensor(0.01)) # warm up the optimizer state dict opt_eager.step() opt_eager_copy.step() inputs = get_inputs(opt_eager_copy) compiled_adam = torch.compile(foreach_map_adam) # optionally view the output code torch._logging.set_logs(output_code=True) # Warmup runs to compile the function for _ in range(5): opt_eager.step() compiled_adam(*inputs) for eager_p, compile_p in zip(opt_eager.param_groups[0][\"params\"], opt_eager_copy.param_groups[0][\"params\"]): torch.allclose(eager_p, compile_p) # Benchmark performance # Let\u0027s define a helpful benchmarking function: import torch.utils.benchmark as benchmark def benchmark_torch_function_in_microseconds(f, *args, **kwargs): t0 = benchmark.Timer( stmt=\"f(*args, **kwargs)\", globals={\"args\": args, \"kwargs\": kwargs, \"f\": f} ) return t0.blocked_autorange().mean * 1e6 eager_runtime = benchmark_torch_function_in_microseconds(opt_eager.step) compiled_runtime = benchmark_torch_function_in_microseconds(lambda: compiled_adam(*inputs)) assert eager_runtime \u003e compiled_runtime print(f\"eager runtime: {eager_runtime}us\") print(f\"compiled runtime: {compiled_runtime}us\") V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] Output code: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # AOT ID: [\u00270_inference\u0027] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from ctypes import c_void_p, c_long, c_int V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import torch V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import math V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import random V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import os V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import tempfile V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from math import inf, nan V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from cmath import nanj V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.utils import maybe_profile V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch import device, empty_strided V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.async_compile import AsyncCompile V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton.language as tl V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] aten = torch.ops.aten V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] inductor_ops = torch.ops.inductor V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] _quantized = torch.ops._quantized V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] async_compile = AsyncCompile() V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([\u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027], r\u0027\u0027\u0027 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] #include \u003ctorch/csrc/inductor/cpp_prefix.h\u003e V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] extern \"C\" void kernel(const float* in_ptr0, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr1, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr2, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr3, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr4, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr5, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr6, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr7, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr8, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] const float* in_ptr9, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr0, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr1, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr2, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr3, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr4, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr5, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr6, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr7, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr8, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] float* out_ptr9) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr0[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr0[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr1[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr1[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr2[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr2[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr3[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr3[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr4[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr4[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr5[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr5[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr6[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr6[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr7[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr7[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr8[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr8[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] { V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp0 = in_ptr9[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] out_ptr9[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] } V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] \u0027\u0027\u0027) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # kernel path: /tmp/torchinductor_ci-user/e3/ce3euorr6vahk3fpfyslv4qsd5j5uxxkmrpreilu6uqnb3gbwb2v.py V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # Source node to ATen node mapping: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] triton_for_fused_1 = async_compile.triton(\u0027triton_for_fused_1\u0027, \u0027\u0027\u0027 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] import triton.language as tl V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] @triton_heuristics.foreach( V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] filename=__file__, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] triton_meta={\u0027signature\u0027: {\u0027in_ptr0\u0027: \u0027*fp32\u0027, \u0027in_ptr1\u0027: \u0027*fp32\u0027, \u0027in_ptr2\u0027: \u0027*fp32\u0027, \u0027in_ptr3\u0027: \u0027*fp32\u0027, \u0027in_ptr4\u0027: \u0027fp32\u0027, \u0027in_ptr5\u0027: \u0027*fp32\u0027, \u0027in_ptr6\u0027: \u0027*fp32\u0027, \u0027in_ptr7\u0027: \u0027*fp32\u0027, \u0027in_ptr8\u0027: \u0027*fp32\u0027, \u0027in_ptr9\u0027: \u0027fp32\u0027, \u0027in_ptr10\u0027: \u0027*fp32\u0027, \u0027in_ptr11\u0027: \u0027*fp32\u0027, \u0027in_ptr12\u0027: \u0027*fp32\u0027, \u0027in_ptr13\u0027: \u0027*fp32\u0027, \u0027in_ptr14\u0027: \u0027fp32\u0027, \u0027in_ptr15\u0027: \u0027*fp32\u0027, \u0027in_ptr16\u0027: \u0027*fp32\u0027, \u0027in_ptr17\u0027: \u0027*fp32\u0027, \u0027in_ptr18\u0027: \u0027*fp32\u0027, \u0027in_ptr19\u0027: \u0027fp32\u0027, \u0027in_ptr20\u0027: \u0027*fp32\u0027, \u0027in_ptr21\u0027: \u0027*fp32\u0027, \u0027in_ptr22\u0027: \u0027*fp32\u0027, \u0027in_ptr23\u0027: \u0027*fp32\u0027, \u0027in_ptr24\u0027: \u0027fp32\u0027, \u0027in_ptr25\u0027: \u0027*fp32\u0027, \u0027in_ptr26\u0027: \u0027*fp32\u0027, \u0027in_ptr27\u0027: \u0027*fp32\u0027, \u0027in_ptr28\u0027: \u0027*fp32\u0027, \u0027in_ptr29\u0027: \u0027fp32\u0027, \u0027in_ptr30\u0027: \u0027*fp32\u0027, \u0027in_ptr31\u0027: \u0027*fp32\u0027, \u0027in_ptr32\u0027: \u0027*fp32\u0027, \u0027in_ptr33\u0027: \u0027*fp32\u0027, \u0027in_ptr34\u0027: \u0027fp32\u0027, \u0027in_ptr35\u0027: \u0027*fp32\u0027, \u0027in_ptr36\u0027: \u0027*fp32\u0027, \u0027in_ptr37\u0027: \u0027*fp32\u0027, \u0027in_ptr38\u0027: \u0027*fp32\u0027, \u0027in_ptr39\u0027: \u0027fp32\u0027, \u0027in_ptr40\u0027: \u0027*fp32\u0027, \u0027in_ptr41\u0027: \u0027*fp32\u0027, \u0027in_ptr42\u0027: \u0027*fp32\u0027, \u0027in_ptr43\u0027: \u0027*fp32\u0027, \u0027in_ptr44\u0027: \u0027fp32\u0027, \u0027in_ptr45\u0027: \u0027*fp32\u0027, \u0027in_ptr46\u0027: \u0027*fp32\u0027, \u0027in_ptr47\u0027: \u0027*fp32\u0027, \u0027in_ptr48\u0027: \u0027*fp32\u0027, \u0027in_ptr49\u0027: \u0027fp32\u0027, \u0027out_ptr3\u0027: \u0027*fp32\u0027, \u0027out_ptr4\u0027: \u0027*fp32\u0027, \u0027out_ptr5\u0027: \u0027*fp32\u0027, \u0027out_ptr9\u0027: \u0027*fp32\u0027, \u0027out_ptr10\u0027: \u0027*fp32\u0027, \u0027out_ptr11\u0027: \u0027*fp32\u0027, \u0027out_ptr15\u0027: \u0027*fp32\u0027, \u0027out_ptr16\u0027: \u0027*fp32\u0027, \u0027out_ptr17\u0027: \u0027*fp32\u0027, \u0027out_ptr21\u0027: \u0027*fp32\u0027, \u0027out_ptr22\u0027: \u0027*fp32\u0027, \u0027out_ptr23\u0027: \u0027*fp32\u0027, \u0027out_ptr27\u0027: \u0027*fp32\u0027, \u0027out_ptr28\u0027: \u0027*fp32\u0027, \u0027out_ptr29\u0027: \u0027*fp32\u0027, \u0027out_ptr33\u0027: \u0027*fp32\u0027, \u0027out_ptr34\u0027: \u0027*fp32\u0027, \u0027out_ptr35\u0027: \u0027*fp32\u0027, \u0027out_ptr39\u0027: \u0027*fp32\u0027, \u0027out_ptr40\u0027: \u0027*fp32\u0027, \u0027out_ptr41\u0027: \u0027*fp32\u0027, \u0027out_ptr45\u0027: \u0027*fp32\u0027, \u0027out_ptr46\u0027: \u0027*fp32\u0027, \u0027out_ptr47\u0027: \u0027*fp32\u0027, \u0027out_ptr51\u0027: \u0027*fp32\u0027, \u0027out_ptr52\u0027: \u0027*fp32\u0027, \u0027out_ptr53\u0027: \u0027*fp32\u0027, \u0027out_ptr57\u0027: \u0027*fp32\u0027, \u0027out_ptr58\u0027: \u0027*fp32\u0027, \u0027out_ptr59\u0027: \u0027*fp32\u0027}, \u0027device\u0027: DeviceProperties(type=\u0027cuda\u0027, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), \u0027constants\u0027: {}, \u0027configs\u0027: [{(0,): [[\u0027tt.divisibility\u0027, 16]], (1,): [[\u0027tt.divisibility\u0027, 16]], (2,): [[\u0027tt.divisibility\u0027, 16]], (3,): [[\u0027tt.divisibility\u0027, 16]], (5,): [[\u0027tt.divisibility\u0027, 16]], (6,): [[\u0027tt.divisibility\u0027, 16]], (7,): [[\u0027tt.divisibility\u0027, 16]], (8,): [[\u0027tt.divisibility\u0027, 16]], (10,): [[\u0027tt.divisibility\u0027, 16]], (11,): [[\u0027tt.divisibility\u0027, 16]], (12,): [[\u0027tt.divisibility\u0027, 16]], (13,): [[\u0027tt.divisibility\u0027, 16]], (15,): [[\u0027tt.divisibility\u0027, 16]], (16,): [[\u0027tt.divisibility\u0027, 16]], (17,): [[\u0027tt.divisibility\u0027, 16]], (18,): [[\u0027tt.divisibility\u0027, 16]], (20,): [[\u0027tt.divisibility\u0027, 16]], (21,): [[\u0027tt.divisibility\u0027, 16]], (22,): [[\u0027tt.divisibility\u0027, 16]], (23,): [[\u0027tt.divisibility\u0027, 16]], (25,): [[\u0027tt.divisibility\u0027, 16]], (26,): [[\u0027tt.divisibility\u0027, 16]], (27,): [[\u0027tt.divisibility\u0027, 16]], (28,): [[\u0027tt.divisibility\u0027, 16]], (30,): [[\u0027tt.divisibility\u0027, 16]], (31,): [[\u0027tt.divisibility\u0027, 16]], (32,): [[\u0027tt.divisibility\u0027, 16]], (33,): [[\u0027tt.divisibility\u0027, 16]], (35,): [[\u0027tt.divisibility\u0027, 16]], (36,): [[\u0027tt.divisibility\u0027, 16]], (37,): [[\u0027tt.divisibility\u0027, 16]], (38,): [[\u0027tt.divisibility\u0027, 16]], (40,): [[\u0027tt.divisibility\u0027, 16]], (41,): [[\u0027tt.divisibility\u0027, 16]], (42,): [[\u0027tt.divisibility\u0027, 16]], (43,): [[\u0027tt.divisibility\u0027, 16]], (45,): [[\u0027tt.divisibility\u0027, 16]], (46,): [[\u0027tt.divisibility\u0027, 16]], (47,): [[\u0027tt.divisibility\u0027, 16]], (48,): [[\u0027tt.divisibility\u0027, 16]], (50,): [[\u0027tt.divisibility\u0027, 16]], (51,): [[\u0027tt.divisibility\u0027, 16]], (52,): [[\u0027tt.divisibility\u0027, 16]], (53,): [[\u0027tt.divisibility\u0027, 16]], (54,): [[\u0027tt.divisibility\u0027, 16]], (55,): [[\u0027tt.divisibility\u0027, 16]], (56,): [[\u0027tt.divisibility\u0027, 16]], (57,): [[\u0027tt.divisibility\u0027, 16]], (58,): [[\u0027tt.divisibility\u0027, 16]], (59,): [[\u0027tt.divisibility\u0027, 16]], (60,): [[\u0027tt.divisibility\u0027, 16]], (61,): [[\u0027tt.divisibility\u0027, 16]], (62,): [[\u0027tt.divisibility\u0027, 16]], (63,): [[\u0027tt.divisibility\u0027, 16]], (64,): [[\u0027tt.divisibility\u0027, 16]], (65,): [[\u0027tt.divisibility\u0027, 16]], (66,): [[\u0027tt.divisibility\u0027, 16]], (67,): [[\u0027tt.divisibility\u0027, 16]], (68,): [[\u0027tt.divisibility\u0027, 16]], (69,): [[\u0027tt.divisibility\u0027, 16]], (70,): [[\u0027tt.divisibility\u0027, 16]], (71,): [[\u0027tt.divisibility\u0027, 16]], (72,): [[\u0027tt.divisibility\u0027, 16]], (73,): [[\u0027tt.divisibility\u0027, 16]], (74,): [[\u0027tt.divisibility\u0027, 16]], (75,): [[\u0027tt.divisibility\u0027, 16]], (76,): [[\u0027tt.divisibility\u0027, 16]], (77,): [[\u0027tt.divisibility\u0027, 16]], (78,): [[\u0027tt.divisibility\u0027, 16]], (79,): [[\u0027tt.divisibility\u0027, 16]]}]}, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] inductor_meta={\u0027grid_type\u0027: \u0027SequentialComboKernelGrid\u0027, \u0027combo_grid_meta\u0027: {\u0027num_kernels\u0027: 10, \u0027min_blocks\u0027: 0, \u0027default_config\u0027: {\u0027XBLOCK\u0027: 1024}, \u0027no_x_dim_0\u0027: False, \u0027xnumel_0\u0027: 1048576, \u0027no_x_dim_1\u0027: False, \u0027xnumel_1\u0027: 1048576, \u0027no_x_dim_2\u0027: False, \u0027xnumel_2\u0027: 1048576, \u0027no_x_dim_3\u0027: False, \u0027xnumel_3\u0027: 1048576, \u0027no_x_dim_4\u0027: False, \u0027xnumel_4\u0027: 1048576, \u0027no_x_dim_5\u0027: False, \u0027xnumel_5\u0027: 1048576, \u0027no_x_dim_6\u0027: False, \u0027xnumel_6\u0027: 1048576, \u0027no_x_dim_7\u0027: False, \u0027xnumel_7\u0027: 1048576, \u0027no_x_dim_8\u0027: False, \u0027xnumel_8\u0027: 1048576, \u0027no_x_dim_9\u0027: False, \u0027xnumel_9\u0027: 1048576}, \u0027kernel_name\u0027: \u0027triton_for_fused_1\u0027, \u0027mutated_arg_names\u0027: [\u0027in_ptr1\u0027, \u0027in_ptr11\u0027, \u0027in_ptr12\u0027, \u0027in_ptr13\u0027, \u0027in_ptr16\u0027, \u0027in_ptr17\u0027, \u0027in_ptr18\u0027, \u0027in_ptr2\u0027, \u0027in_ptr21\u0027, \u0027in_ptr22\u0027, \u0027in_ptr23\u0027, \u0027in_ptr26\u0027, \u0027in_ptr27\u0027, \u0027in_ptr28\u0027, \u0027in_ptr3\u0027, \u0027in_ptr31\u0027, \u0027in_ptr32\u0027, \u0027in_ptr33\u0027, \u0027in_ptr36\u0027, \u0027in_ptr37\u0027, \u0027in_ptr38\u0027, \u0027in_ptr41\u0027, \u0027in_ptr42\u0027, \u0027in_ptr43\u0027, \u0027in_ptr46\u0027, \u0027in_ptr47\u0027, \u0027in_ptr48\u0027, \u0027in_ptr6\u0027, \u0027in_ptr7\u0027, \u0027in_ptr8\u0027, \u0027out_ptr10\u0027, \u0027out_ptr11\u0027, \u0027out_ptr15\u0027, \u0027out_ptr16\u0027, \u0027out_ptr17\u0027, \u0027out_ptr21\u0027, \u0027out_ptr22\u0027, \u0027out_ptr23\u0027, \u0027out_ptr27\u0027, \u0027out_ptr28\u0027, \u0027out_ptr29\u0027, \u0027out_ptr3\u0027, \u0027out_ptr33\u0027, \u0027out_ptr34\u0027, \u0027out_ptr35\u0027, \u0027out_ptr39\u0027, \u0027out_ptr4\u0027, \u0027out_ptr40\u0027, \u0027out_ptr41\u0027, \u0027out_ptr45\u0027, \u0027out_ptr46\u0027, \u0027out_ptr47\u0027, \u0027out_ptr5\u0027, \u0027out_ptr51\u0027, \u0027out_ptr52\u0027, \u0027out_ptr53\u0027, \u0027out_ptr57\u0027, \u0027out_ptr58\u0027, \u0027out_ptr59\u0027, \u0027out_ptr9\u0027], \u0027backend_hash\u0027: \u0027DC36EA6BB5AEA639F493BE6C610554D7008666A7D52F3C35F9DAC37F278CCC65\u0027, \u0027assert_indirect_indexing\u0027: True, \u0027autotune_local_cache\u0027: True, \u0027autotune_pointwise\u0027: True, \u0027autotune_remote_cache\u0027: None, \u0027force_disable_caches\u0027: False, \u0027dynamic_scale_rblock\u0027: True, \u0027max_autotune\u0027: False, \u0027max_autotune_pointwise\u0027: False, \u0027min_split_scan_rblock\u0027: 256, \u0027spill_threshold\u0027: 16, \u0027store_cubin\u0027: False, \u0027deterministic\u0027: False, \u0027force_filter_reduction_configs\u0027: False, \u0027are_deterministic_algorithms_enabled\u0027: False}, V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] ) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] @triton.jit V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid = tl.program_id(0) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] XBLOCK: tl.constexpr = 1024 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_0 = tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] if pid \u003c num_xblocks_0: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x0 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp0 = tl.load(in_ptr0 + (x0), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp1 = tl.load(in_ptr1 + (x0), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp8 = tl.load(in_ptr2 + (x0), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp15 = tl.load(in_ptr3 + (x0), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp17 = in_ptr4 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp2 = tmp0 - tmp1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp3 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp4 = tmp3 * tmp2 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp5 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp6 = tl.where(tmp5, tmp0, tmp1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp7 = tmp4 + tmp6 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp9 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp10 = tmp8 * tmp9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp11 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp12 = tmp0 * tmp11 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp13 = tmp12 * tmp0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp14 = tmp10 + tmp13 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp16 = tl.sqrt_rn(tmp14) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp18 = libdevice.pow(tmp9, tmp17) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp19 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp20 = tmp19 - tmp18 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp21 = tl.sqrt_rn(tmp20) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp22 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp23 = libdevice.pow(tmp22, tmp17) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp24 = tmp19 - tmp23 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp25 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp26 = (tmp25 / tmp24) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp27 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp28 = tmp26 * tmp27 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp29 = -tmp28 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp30 = tmp21 * tmp29 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp31 = (tmp16 / tmp30) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp32 = (tmp25 / tmp29) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp33 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp34 = tmp32 * tmp33 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp35 = tmp31 + tmp34 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp36 = (tmp7 / tmp35) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp37 = tmp15 + tmp36 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr3 + (x0), tmp7, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr4 + (x0), tmp14, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr5 + (x0), tmp37, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_1: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x1 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp38 = tl.load(in_ptr5 + (x1), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp39 = tl.load(in_ptr6 + (x1), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp46 = tl.load(in_ptr7 + (x1), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp53 = tl.load(in_ptr8 + (x1), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp55 = in_ptr9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp40 = tmp38 - tmp39 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp41 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp42 = tmp41 * tmp40 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp43 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp44 = tl.where(tmp43, tmp38, tmp39) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp45 = tmp42 + tmp44 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp47 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp48 = tmp46 * tmp47 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp49 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp50 = tmp38 * tmp49 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp51 = tmp50 * tmp38 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp52 = tmp48 + tmp51 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp54 = tl.sqrt_rn(tmp52) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp56 = libdevice.pow(tmp47, tmp55) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp57 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp58 = tmp57 - tmp56 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp59 = tl.sqrt_rn(tmp58) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp60 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp61 = libdevice.pow(tmp60, tmp55) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp62 = tmp57 - tmp61 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp63 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp64 = (tmp63 / tmp62) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp65 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp66 = tmp64 * tmp65 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp67 = -tmp66 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp68 = tmp59 * tmp67 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp69 = (tmp54 / tmp68) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp70 = (tmp63 / tmp67) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp71 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp72 = tmp70 * tmp71 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp73 = tmp69 + tmp72 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp74 = (tmp45 / tmp73) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp75 = tmp53 + tmp74 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr9 + (x1), tmp45, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr10 + (x1), tmp52, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr11 + (x1), tmp75, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_2: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x2 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp76 = tl.load(in_ptr10 + (x2), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp77 = tl.load(in_ptr11 + (x2), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp84 = tl.load(in_ptr12 + (x2), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp91 = tl.load(in_ptr13 + (x2), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp93 = in_ptr14 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp78 = tmp76 - tmp77 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp79 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp80 = tmp79 * tmp78 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp81 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp82 = tl.where(tmp81, tmp76, tmp77) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp83 = tmp80 + tmp82 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp85 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp86 = tmp84 * tmp85 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp87 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp88 = tmp76 * tmp87 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp89 = tmp88 * tmp76 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp90 = tmp86 + tmp89 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp92 = tl.sqrt_rn(tmp90) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp94 = libdevice.pow(tmp85, tmp93) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp95 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp96 = tmp95 - tmp94 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp97 = tl.sqrt_rn(tmp96) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp98 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp99 = libdevice.pow(tmp98, tmp93) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp100 = tmp95 - tmp99 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp101 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp102 = (tmp101 / tmp100) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp103 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp104 = tmp102 * tmp103 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp105 = -tmp104 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp106 = tmp97 * tmp105 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp107 = (tmp92 / tmp106) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp108 = (tmp101 / tmp105) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp109 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp110 = tmp108 * tmp109 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp111 = tmp107 + tmp110 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp112 = (tmp83 / tmp111) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp113 = tmp91 + tmp112 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr15 + (x2), tmp83, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr16 + (x2), tmp90, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr17 + (x2), tmp113, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_3: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_2 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x3 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp114 = tl.load(in_ptr15 + (x3), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp115 = tl.load(in_ptr16 + (x3), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp122 = tl.load(in_ptr17 + (x3), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp129 = tl.load(in_ptr18 + (x3), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp131 = in_ptr19 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp116 = tmp114 - tmp115 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp117 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp118 = tmp117 * tmp116 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp119 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp120 = tl.where(tmp119, tmp114, tmp115) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp121 = tmp118 + tmp120 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp123 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp124 = tmp122 * tmp123 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp125 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp126 = tmp114 * tmp125 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp127 = tmp126 * tmp114 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp128 = tmp124 + tmp127 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp130 = tl.sqrt_rn(tmp128) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp132 = libdevice.pow(tmp123, tmp131) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp133 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp134 = tmp133 - tmp132 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp135 = tl.sqrt_rn(tmp134) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp136 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp137 = libdevice.pow(tmp136, tmp131) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp138 = tmp133 - tmp137 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp139 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp140 = (tmp139 / tmp138) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp141 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp142 = tmp140 * tmp141 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp143 = -tmp142 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp144 = tmp135 * tmp143 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp145 = (tmp130 / tmp144) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp146 = (tmp139 / tmp143) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp147 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp148 = tmp146 * tmp147 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp149 = tmp145 + tmp148 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp150 = (tmp121 / tmp149) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp151 = tmp129 + tmp150 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr21 + (x3), tmp121, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr22 + (x3), tmp128, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr23 + (x3), tmp151, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_4: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_3 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x4 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp152 = tl.load(in_ptr20 + (x4), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp153 = tl.load(in_ptr21 + (x4), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp160 = tl.load(in_ptr22 + (x4), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp167 = tl.load(in_ptr23 + (x4), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp169 = in_ptr24 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp154 = tmp152 - tmp153 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp155 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp156 = tmp155 * tmp154 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp157 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp158 = tl.where(tmp157, tmp152, tmp153) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp159 = tmp156 + tmp158 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp161 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp162 = tmp160 * tmp161 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp163 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp164 = tmp152 * tmp163 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp165 = tmp164 * tmp152 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp166 = tmp162 + tmp165 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp168 = tl.sqrt_rn(tmp166) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp170 = libdevice.pow(tmp161, tmp169) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp171 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp172 = tmp171 - tmp170 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp173 = tl.sqrt_rn(tmp172) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp174 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp175 = libdevice.pow(tmp174, tmp169) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp176 = tmp171 - tmp175 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp177 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp178 = (tmp177 / tmp176) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp179 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp180 = tmp178 * tmp179 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp181 = -tmp180 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp182 = tmp173 * tmp181 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp183 = (tmp168 / tmp182) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp184 = (tmp177 / tmp181) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp185 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp186 = tmp184 * tmp185 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp187 = tmp183 + tmp186 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp188 = (tmp159 / tmp187) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp189 = tmp167 + tmp188 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr27 + (x4), tmp159, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr28 + (x4), tmp166, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr29 + (x4), tmp189, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_5: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_4 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x5 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp190 = tl.load(in_ptr25 + (x5), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp191 = tl.load(in_ptr26 + (x5), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp198 = tl.load(in_ptr27 + (x5), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp205 = tl.load(in_ptr28 + (x5), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp207 = in_ptr29 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp192 = tmp190 - tmp191 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp193 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp194 = tmp193 * tmp192 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp195 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp196 = tl.where(tmp195, tmp190, tmp191) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp197 = tmp194 + tmp196 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp199 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp200 = tmp198 * tmp199 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp201 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp202 = tmp190 * tmp201 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp203 = tmp202 * tmp190 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp204 = tmp200 + tmp203 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp206 = tl.sqrt_rn(tmp204) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp208 = libdevice.pow(tmp199, tmp207) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp209 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp210 = tmp209 - tmp208 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp211 = tl.sqrt_rn(tmp210) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp212 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp213 = libdevice.pow(tmp212, tmp207) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp214 = tmp209 - tmp213 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp215 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp216 = (tmp215 / tmp214) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp217 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp218 = tmp216 * tmp217 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp219 = -tmp218 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp220 = tmp211 * tmp219 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp221 = (tmp206 / tmp220) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp222 = (tmp215 / tmp219) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp223 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp224 = tmp222 * tmp223 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp225 = tmp221 + tmp224 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp226 = (tmp197 / tmp225) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp227 = tmp205 + tmp226 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr33 + (x5), tmp197, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr34 + (x5), tmp204, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr35 + (x5), tmp227, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_6: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_5 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x6 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp228 = tl.load(in_ptr30 + (x6), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp229 = tl.load(in_ptr31 + (x6), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp236 = tl.load(in_ptr32 + (x6), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp243 = tl.load(in_ptr33 + (x6), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp245 = in_ptr34 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp230 = tmp228 - tmp229 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp231 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp232 = tmp231 * tmp230 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp233 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp234 = tl.where(tmp233, tmp228, tmp229) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp235 = tmp232 + tmp234 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp237 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp238 = tmp236 * tmp237 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp239 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp240 = tmp228 * tmp239 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp241 = tmp240 * tmp228 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp242 = tmp238 + tmp241 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp244 = tl.sqrt_rn(tmp242) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp246 = libdevice.pow(tmp237, tmp245) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp247 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp248 = tmp247 - tmp246 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp249 = tl.sqrt_rn(tmp248) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp250 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp251 = libdevice.pow(tmp250, tmp245) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp252 = tmp247 - tmp251 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp253 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp254 = (tmp253 / tmp252) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp255 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp256 = tmp254 * tmp255 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp257 = -tmp256 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp258 = tmp249 * tmp257 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp259 = (tmp244 / tmp258) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp260 = (tmp253 / tmp257) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp261 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp262 = tmp260 * tmp261 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp263 = tmp259 + tmp262 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp264 = (tmp235 / tmp263) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp265 = tmp243 + tmp264 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr39 + (x6), tmp235, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr40 + (x6), tmp242, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr41 + (x6), tmp265, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_7: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_6 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x7 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp266 = tl.load(in_ptr35 + (x7), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp267 = tl.load(in_ptr36 + (x7), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp274 = tl.load(in_ptr37 + (x7), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp281 = tl.load(in_ptr38 + (x7), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp283 = in_ptr39 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp268 = tmp266 - tmp267 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp269 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp270 = tmp269 * tmp268 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp271 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp272 = tl.where(tmp271, tmp266, tmp267) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp273 = tmp270 + tmp272 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp275 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp276 = tmp274 * tmp275 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp277 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp278 = tmp266 * tmp277 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp279 = tmp278 * tmp266 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp280 = tmp276 + tmp279 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp282 = tl.sqrt_rn(tmp280) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp284 = libdevice.pow(tmp275, tmp283) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp285 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp286 = tmp285 - tmp284 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp287 = tl.sqrt_rn(tmp286) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp288 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp289 = libdevice.pow(tmp288, tmp283) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp290 = tmp285 - tmp289 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp291 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp292 = (tmp291 / tmp290) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp293 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp294 = tmp292 * tmp293 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp295 = -tmp294 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp296 = tmp287 * tmp295 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp297 = (tmp282 / tmp296) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp298 = (tmp291 / tmp295) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp299 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp300 = tmp298 * tmp299 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp301 = tmp297 + tmp300 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp302 = (tmp273 / tmp301) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp303 = tmp281 + tmp302 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr45 + (x7), tmp273, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr46 + (x7), tmp280, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr47 + (x7), tmp303, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_8: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_7 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x8 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp304 = tl.load(in_ptr40 + (x8), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp305 = tl.load(in_ptr41 + (x8), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp312 = tl.load(in_ptr42 + (x8), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp319 = tl.load(in_ptr43 + (x8), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp321 = in_ptr44 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp306 = tmp304 - tmp305 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp307 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp308 = tmp307 * tmp306 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp309 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp310 = tl.where(tmp309, tmp304, tmp305) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp311 = tmp308 + tmp310 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp313 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp314 = tmp312 * tmp313 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp315 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp316 = tmp304 * tmp315 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp317 = tmp316 * tmp304 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp318 = tmp314 + tmp317 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp320 = tl.sqrt_rn(tmp318) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp322 = libdevice.pow(tmp313, tmp321) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp323 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp324 = tmp323 - tmp322 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp325 = tl.sqrt_rn(tmp324) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp326 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp327 = libdevice.pow(tmp326, tmp321) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp328 = tmp323 - tmp327 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp329 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp330 = (tmp329 / tmp328) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp331 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp332 = tmp330 * tmp331 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp333 = -tmp332 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp334 = tmp325 * tmp333 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp335 = (tmp320 / tmp334) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp336 = (tmp329 / tmp333) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp337 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp338 = tmp336 * tmp337 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp339 = tmp335 + tmp338 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp340 = (tmp311 / tmp339) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp341 = tmp319 + tmp340 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr51 + (x8), tmp311, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr52 + (x8), tmp318, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr53 + (x8), tmp341, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] elif pid \u003c num_xblocks_9: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pid_offset = pid - num_xblocks_8 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xnumel = 1048576 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] r0_numel = 1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] x9 = xindex V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp342 = tl.load(in_ptr45 + (x9), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp343 = tl.load(in_ptr46 + (x9), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp350 = tl.load(in_ptr47 + (x9), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp357 = tl.load(in_ptr48 + (x9), None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp359 = in_ptr49 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp344 = tmp342 - tmp343 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp345 = 0.10000000149011612 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp346 = tmp345 * tmp344 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp347 = tl.full([1], False, tl.int1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp348 = tl.where(tmp347, tmp342, tmp343) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp349 = tmp346 + tmp348 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp351 = 0.999 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp352 = tmp350 * tmp351 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp353 = 0.0010000000000000009 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp354 = tmp342 * tmp353 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp355 = tmp354 * tmp342 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp356 = tmp352 + tmp355 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp358 = tl.sqrt_rn(tmp356) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp360 = libdevice.pow(tmp351, tmp359) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp361 = 1.0 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp362 = tmp361 - tmp360 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp363 = tl.sqrt_rn(tmp362) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp364 = 0.9 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp365 = libdevice.pow(tmp364, tmp359) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp366 = tmp361 - tmp365 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp367 = tl.full([1], 1, tl.int32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp368 = (tmp367 / tmp366) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp369 = 0.001 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp370 = tmp368 * tmp369 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp371 = -tmp370 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp372 = tmp363 * tmp371 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp373 = (tmp358 / tmp372) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp374 = (tmp367 / tmp371) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp375 = 1e-08 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp376 = tmp374 * tmp375 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp377 = tmp373 + tmp376 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp378 = (tmp349 / tmp377) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tmp379 = tmp357 + tmp378 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr57 + (x9), tmp349, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr58 + (x9), tmp356, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] tl.store(out_ptr59 + (x9), tmp379, None) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] else: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] pass V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] \u0027\u0027\u0027, device_str=\u0027cuda\u0027) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] async_compile.wait(globals()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del async_compile V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] class Runner: V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def __init__(self, partitions): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] self.partitions = partitions V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def recursively_apply_fns(self, fns): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] new_callables = [] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] for fn, c in zip(fns, self.partitions): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] new_callables.append(fn(c)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] self.partitions = new_callables V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def call(self, args): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] args.clear() V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg0_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg1_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg2_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg3_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg4_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg5_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg6_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg7_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg8_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg9_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg10_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg11_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg12_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg13_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg14_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg15_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg16_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg17_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg18_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg19_1, (), ()) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg20_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg21_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg22_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg23_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg24_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg25_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg26_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg27_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg28_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg29_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg30_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg31_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg32_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg33_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg34_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg35_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg36_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg37_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg38_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg39_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg40_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg41_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg42_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg43_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg44_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg45_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg46_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg47_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg48_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] assert_size_stride(arg49_1, (1024, 1024), (1024, 1)) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] with torch.cuda._DeviceGuard(0): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] torch.cuda.set_device(0) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] stream0 = get_raw_stream(0) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg0_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg10_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg11_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg12_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg13_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg14_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg15_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg16_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg17_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg18_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg19_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg1_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg20_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg21_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg22_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg23_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg24_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg25_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg26_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg27_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg28_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg29_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg2_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg30_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg31_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg32_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg33_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg34_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg35_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg36_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg37_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg38_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg39_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg3_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg40_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg41_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg42_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg43_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg44_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg45_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg46_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg47_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg48_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg49_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg4_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg5_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg6_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg7_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg8_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] del arg9_1 V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] return () V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] runner = Runner(partitions=[]) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] call = runner.call V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] recursively_apply_fns = runner.recursively_apply_fns V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10): V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._dynamo.testing import rand_strided V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.utils import print_performance V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg0_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg1_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg2_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg3_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg4_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg5_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg6_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg7_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg8_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg9_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg10_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg11_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg12_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg13_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg14_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg15_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg16_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg17_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg18_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg19_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg20_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg21_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg22_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg23_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg24_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg25_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg26_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg27_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg28_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg29_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg30_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg31_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg32_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg33_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg34_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg35_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg36_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg37_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg38_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg39_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg40_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg41_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg42_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg43_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg44_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg45_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg46_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg47_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg48_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] arg49_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1]) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] return print_performance(fn, times=times, repeat=repeat) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] if __name__ == \"__main__\": V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] from torch._inductor.wrapper_benchmark import compiled_module_main V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] compiled_module_main(\u0027None\u0027, benchmark_compiled_module) V0121 17:28:41.590000 23168 torch/_inductor/graph.py:2469] [0/0] [__output_code] V0121 17:28:41.638000 23168 torch/_inductor/graph.py:2480] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/7g/c7gwzff5a3nb2e2g63fszyo4xdi4ktgf4qx5vgruvhskmvltmjln.py I0121 17:28:42.917000 23168 torch/_inductor/graph.py:2440] [0/0] [__output_code] Output code written to: /tmp/torchinductor_ci-user/7g/c7gwzff5a3nb2e2g63fszyo4xdi4ktgf4qx5vgruvhskmvltmjln.py V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] Output code: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # AOT ID: [\u00271_inference\u0027] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from ctypes import c_void_p, c_long, c_int V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import torch V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import math V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import random V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import os V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import tempfile V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from math import inf, nan V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from cmath import nanj V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.hooks import run_intermediate_hooks V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.utils import maybe_profile V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.codegen.memory_planning import _align as align V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch import device, empty_strided V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.async_compile import AsyncCompile V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.select_algorithm import extern_kernels V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton.language as tl V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.triton_heuristics import start_graph, end_graph V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] aten = torch.ops.aten V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] inductor_ops = torch.ops.inductor V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] _quantized = torch.ops._quantized V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_alignment = torch._C._dynamo.guards.assert_alignment V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cpu_pinned = torch._C._dynamo.guards._empty_strided_cpu_pinned V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_xpu = torch._C._dynamo.guards._empty_strided_xpu V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_mtia = torch._C._dynamo.guards._empty_strided_mtia V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] reinterpret_tensor = torch._C._dynamo.guards._reinterpret_tensor V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] async_compile = AsyncCompile() V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] empty_strided_p2p = torch._C._distributed_c10d._SymmetricMemory.empty_strided_p2p V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] cpp_fused__foreach_copy_0 = async_compile.cpp_pybinding([\u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027const float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027, \u0027float*\u0027], r\u0027\u0027\u0027 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] #include \u003ctorch/csrc/inductor/cpp_prefix.h\u003e V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] extern \"C\" void kernel(const float* in_ptr0, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr1, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr2, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr3, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr4, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr5, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr6, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr7, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr8, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] const float* in_ptr9, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr0, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr1, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr2, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr3, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr4, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr5, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr6, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr7, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr8, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] float* out_ptr9) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr0[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr0[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr1[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr1[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr2[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr2[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr3[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr3[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr4[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr4[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr5[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr5[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr6[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr6[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr7[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr7[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr8[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr8[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] { V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp0 = in_ptr9[static_cast\u003cint64_t\u003e(0L)]; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp1 = static_cast\u003cfloat\u003e(1.0); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] auto tmp2 = float(tmp0 + tmp1); V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] out_ptr9[static_cast\u003cint64_t\u003e(0L)] = tmp2; V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] } V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] \u0027\u0027\u0027) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # kernel path: /tmp/torchinductor_ci-user/e3/ce3euorr6vahk3fpfyslv4qsd5j5uxxkmrpreilu6uqnb3gbwb2v.py V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # Source node to ATen node mapping: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] triton_for_fused_1 = async_compile.triton(\u0027triton_for_fused_1\u0027, \u0027\u0027\u0027 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] import triton.language as tl V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime import triton_helpers, triton_heuristics V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.triton_helpers import libdevice, math as tl_math V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.runtime.hints import AutotuneHint, ReductionHint, TileHint, DeviceProperties V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] @triton_heuristics.foreach( V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] filename=__file__, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] triton_meta={\u0027signature\u0027: {\u0027in_ptr0\u0027: \u0027*fp32\u0027, \u0027in_ptr1\u0027: \u0027*fp32\u0027, \u0027in_ptr2\u0027: \u0027*fp32\u0027, \u0027in_ptr3\u0027: \u0027*fp32\u0027, \u0027in_ptr4\u0027: \u0027fp32\u0027, \u0027in_ptr5\u0027: \u0027*fp32\u0027, \u0027in_ptr6\u0027: \u0027*fp32\u0027, \u0027in_ptr7\u0027: \u0027*fp32\u0027, \u0027in_ptr8\u0027: \u0027*fp32\u0027, \u0027in_ptr9\u0027: \u0027fp32\u0027, \u0027in_ptr10\u0027: \u0027*fp32\u0027, \u0027in_ptr11\u0027: \u0027*fp32\u0027, \u0027in_ptr12\u0027: \u0027*fp32\u0027, \u0027in_ptr13\u0027: \u0027*fp32\u0027, \u0027in_ptr14\u0027: \u0027fp32\u0027, \u0027in_ptr15\u0027: \u0027*fp32\u0027, \u0027in_ptr16\u0027: \u0027*fp32\u0027, \u0027in_ptr17\u0027: \u0027*fp32\u0027, \u0027in_ptr18\u0027: \u0027*fp32\u0027, \u0027in_ptr19\u0027: \u0027fp32\u0027, \u0027in_ptr20\u0027: \u0027*fp32\u0027, \u0027in_ptr21\u0027: \u0027*fp32\u0027, \u0027in_ptr22\u0027: \u0027*fp32\u0027, \u0027in_ptr23\u0027: \u0027*fp32\u0027, \u0027in_ptr24\u0027: \u0027fp32\u0027, \u0027in_ptr25\u0027: \u0027*fp32\u0027, \u0027in_ptr26\u0027: \u0027*fp32\u0027, \u0027in_ptr27\u0027: \u0027*fp32\u0027, \u0027in_ptr28\u0027: \u0027*fp32\u0027, \u0027in_ptr29\u0027: \u0027fp32\u0027, \u0027in_ptr30\u0027: \u0027*fp32\u0027, \u0027in_ptr31\u0027: \u0027*fp32\u0027, \u0027in_ptr32\u0027: \u0027*fp32\u0027, \u0027in_ptr33\u0027: \u0027*fp32\u0027, \u0027in_ptr34\u0027: \u0027fp32\u0027, \u0027in_ptr35\u0027: \u0027*fp32\u0027, \u0027in_ptr36\u0027: \u0027*fp32\u0027, \u0027in_ptr37\u0027: \u0027*fp32\u0027, \u0027in_ptr38\u0027: \u0027*fp32\u0027, \u0027in_ptr39\u0027: \u0027fp32\u0027, \u0027in_ptr40\u0027: \u0027*fp32\u0027, \u0027in_ptr41\u0027: \u0027*fp32\u0027, \u0027in_ptr42\u0027: \u0027*fp32\u0027, \u0027in_ptr43\u0027: \u0027*fp32\u0027, \u0027in_ptr44\u0027: \u0027fp32\u0027, \u0027in_ptr45\u0027: \u0027*fp32\u0027, \u0027in_ptr46\u0027: \u0027*fp32\u0027, \u0027in_ptr47\u0027: \u0027*fp32\u0027, \u0027in_ptr48\u0027: \u0027*fp32\u0027, \u0027in_ptr49\u0027: \u0027fp32\u0027, \u0027out_ptr3\u0027: \u0027*fp32\u0027, \u0027out_ptr4\u0027: \u0027*fp32\u0027, \u0027out_ptr5\u0027: \u0027*fp32\u0027, \u0027out_ptr9\u0027: \u0027*fp32\u0027, \u0027out_ptr10\u0027: \u0027*fp32\u0027, \u0027out_ptr11\u0027: \u0027*fp32\u0027, \u0027out_ptr15\u0027: \u0027*fp32\u0027, \u0027out_ptr16\u0027: \u0027*fp32\u0027, \u0027out_ptr17\u0027: \u0027*fp32\u0027, \u0027out_ptr21\u0027: \u0027*fp32\u0027, \u0027out_ptr22\u0027: \u0027*fp32\u0027, \u0027out_ptr23\u0027: \u0027*fp32\u0027, \u0027out_ptr27\u0027: \u0027*fp32\u0027, \u0027out_ptr28\u0027: \u0027*fp32\u0027, \u0027out_ptr29\u0027: \u0027*fp32\u0027, \u0027out_ptr33\u0027: \u0027*fp32\u0027, \u0027out_ptr34\u0027: \u0027*fp32\u0027, \u0027out_ptr35\u0027: \u0027*fp32\u0027, \u0027out_ptr39\u0027: \u0027*fp32\u0027, \u0027out_ptr40\u0027: \u0027*fp32\u0027, \u0027out_ptr41\u0027: \u0027*fp32\u0027, \u0027out_ptr45\u0027: \u0027*fp32\u0027, \u0027out_ptr46\u0027: \u0027*fp32\u0027, \u0027out_ptr47\u0027: \u0027*fp32\u0027, \u0027out_ptr51\u0027: \u0027*fp32\u0027, \u0027out_ptr52\u0027: \u0027*fp32\u0027, \u0027out_ptr53\u0027: \u0027*fp32\u0027, \u0027out_ptr57\u0027: \u0027*fp32\u0027, \u0027out_ptr58\u0027: \u0027*fp32\u0027, \u0027out_ptr59\u0027: \u0027*fp32\u0027}, \u0027device\u0027: DeviceProperties(type=\u0027cuda\u0027, index=0, multi_processor_count=80, cc=86, major=8, regs_per_multiprocessor=65536, max_threads_per_multi_processor=1536, max_threads_per_block=1024, warp_size=32), \u0027constants\u0027: {}, \u0027configs\u0027: [{(0,): [[\u0027tt.divisibility\u0027, 16]], (1,): [[\u0027tt.divisibility\u0027, 16]], (2,): [[\u0027tt.divisibility\u0027, 16]], (3,): [[\u0027tt.divisibility\u0027, 16]], (5,): [[\u0027tt.divisibility\u0027, 16]], (6,): [[\u0027tt.divisibility\u0027, 16]], (7,): [[\u0027tt.divisibility\u0027, 16]], (8,): [[\u0027tt.divisibility\u0027, 16]], (10,): [[\u0027tt.divisibility\u0027, 16]], (11,): [[\u0027tt.divisibility\u0027, 16]], (12,): [[\u0027tt.divisibility\u0027, 16]], (13,): [[\u0027tt.divisibility\u0027, 16]], (15,): [[\u0027tt.divisibility\u0027, 16]], (16,): [[\u0027tt.divisibility\u0027, 16]], (17,): [[\u0027tt.divisibility\u0027, 16]], (18,): [[\u0027tt.divisibility\u0027, 16]], (20,): [[\u0027tt.divisibility\u0027, 16]], (21,): [[\u0027tt.divisibility\u0027, 16]], (22,): [[\u0027tt.divisibility\u0027, 16]], (23,): [[\u0027tt.divisibility\u0027, 16]], (25,): [[\u0027tt.divisibility\u0027, 16]], (26,): [[\u0027tt.divisibility\u0027, 16]], (27,): [[\u0027tt.divisibility\u0027, 16]], (28,): [[\u0027tt.divisibility\u0027, 16]], (30,): [[\u0027tt.divisibility\u0027, 16]], (31,): [[\u0027tt.divisibility\u0027, 16]], (32,): [[\u0027tt.divisibility\u0027, 16]], (33,): [[\u0027tt.divisibility\u0027, 16]], (35,): [[\u0027tt.divisibility\u0027, 16]], (36,): [[\u0027tt.divisibility\u0027, 16]], (37,): [[\u0027tt.divisibility\u0027, 16]], (38,): [[\u0027tt.divisibility\u0027, 16]], (40,): [[\u0027tt.divisibility\u0027, 16]], (41,): [[\u0027tt.divisibility\u0027, 16]], (42,): [[\u0027tt.divisibility\u0027, 16]], (43,): [[\u0027tt.divisibility\u0027, 16]], (45,): [[\u0027tt.divisibility\u0027, 16]], (46,): [[\u0027tt.divisibility\u0027, 16]], (47,): [[\u0027tt.divisibility\u0027, 16]], (48,): [[\u0027tt.divisibility\u0027, 16]], (50,): [[\u0027tt.divisibility\u0027, 16]], (51,): [[\u0027tt.divisibility\u0027, 16]], (52,): [[\u0027tt.divisibility\u0027, 16]], (53,): [[\u0027tt.divisibility\u0027, 16]], (54,): [[\u0027tt.divisibility\u0027, 16]], (55,): [[\u0027tt.divisibility\u0027, 16]], (56,): [[\u0027tt.divisibility\u0027, 16]], (57,): [[\u0027tt.divisibility\u0027, 16]], (58,): [[\u0027tt.divisibility\u0027, 16]], (59,): [[\u0027tt.divisibility\u0027, 16]], (60,): [[\u0027tt.divisibility\u0027, 16]], (61,): [[\u0027tt.divisibility\u0027, 16]], (62,): [[\u0027tt.divisibility\u0027, 16]], (63,): [[\u0027tt.divisibility\u0027, 16]], (64,): [[\u0027tt.divisibility\u0027, 16]], (65,): [[\u0027tt.divisibility\u0027, 16]], (66,): [[\u0027tt.divisibility\u0027, 16]], (67,): [[\u0027tt.divisibility\u0027, 16]], (68,): [[\u0027tt.divisibility\u0027, 16]], (69,): [[\u0027tt.divisibility\u0027, 16]], (70,): [[\u0027tt.divisibility\u0027, 16]], (71,): [[\u0027tt.divisibility\u0027, 16]], (72,): [[\u0027tt.divisibility\u0027, 16]], (73,): [[\u0027tt.divisibility\u0027, 16]], (74,): [[\u0027tt.divisibility\u0027, 16]], (75,): [[\u0027tt.divisibility\u0027, 16]], (76,): [[\u0027tt.divisibility\u0027, 16]], (77,): [[\u0027tt.divisibility\u0027, 16]], (78,): [[\u0027tt.divisibility\u0027, 16]], (79,): [[\u0027tt.divisibility\u0027, 16]]}]}, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] inductor_meta={\u0027grid_type\u0027: \u0027SequentialComboKernelGrid\u0027, \u0027combo_grid_meta\u0027: {\u0027num_kernels\u0027: 10, \u0027min_blocks\u0027: 0, \u0027default_config\u0027: {\u0027XBLOCK\u0027: 1024}, \u0027no_x_dim_0\u0027: False, \u0027xnumel_0\u0027: 1048576, \u0027no_x_dim_1\u0027: False, \u0027xnumel_1\u0027: 1048576, \u0027no_x_dim_2\u0027: False, \u0027xnumel_2\u0027: 1048576, \u0027no_x_dim_3\u0027: False, \u0027xnumel_3\u0027: 1048576, \u0027no_x_dim_4\u0027: False, \u0027xnumel_4\u0027: 1048576, \u0027no_x_dim_5\u0027: False, \u0027xnumel_5\u0027: 1048576, \u0027no_x_dim_6\u0027: False, \u0027xnumel_6\u0027: 1048576, \u0027no_x_dim_7\u0027: False, \u0027xnumel_7\u0027: 1048576, \u0027no_x_dim_8\u0027: False, \u0027xnumel_8\u0027: 1048576, \u0027no_x_dim_9\u0027: False, \u0027xnumel_9\u0027: 1048576}, \u0027kernel_name\u0027: \u0027triton_for_fused_1\u0027, \u0027mutated_arg_names\u0027: [\u0027in_ptr1\u0027, \u0027in_ptr11\u0027, \u0027in_ptr12\u0027, \u0027in_ptr13\u0027, \u0027in_ptr16\u0027, \u0027in_ptr17\u0027, \u0027in_ptr18\u0027, \u0027in_ptr2\u0027, \u0027in_ptr21\u0027, \u0027in_ptr22\u0027, \u0027in_ptr23\u0027, \u0027in_ptr26\u0027, \u0027in_ptr27\u0027, \u0027in_ptr28\u0027, \u0027in_ptr3\u0027, \u0027in_ptr31\u0027, \u0027in_ptr32\u0027, \u0027in_ptr33\u0027, \u0027in_ptr36\u0027, \u0027in_ptr37\u0027, \u0027in_ptr38\u0027, \u0027in_ptr41\u0027, \u0027in_ptr42\u0027, \u0027in_ptr43\u0027, \u0027in_ptr46\u0027, \u0027in_ptr47\u0027, \u0027in_ptr48\u0027, \u0027in_ptr6\u0027, \u0027in_ptr7\u0027, \u0027in_ptr8\u0027, \u0027out_ptr10\u0027, \u0027out_ptr11\u0027, \u0027out_ptr15\u0027, \u0027out_ptr16\u0027, \u0027out_ptr17\u0027, \u0027out_ptr21\u0027, \u0027out_ptr22\u0027, \u0027out_ptr23\u0027, \u0027out_ptr27\u0027, \u0027out_ptr28\u0027, \u0027out_ptr29\u0027, \u0027out_ptr3\u0027, \u0027out_ptr33\u0027, \u0027out_ptr34\u0027, \u0027out_ptr35\u0027, \u0027out_ptr39\u0027, \u0027out_ptr4\u0027, \u0027out_ptr40\u0027, \u0027out_ptr41\u0027, \u0027out_ptr45\u0027, \u0027out_ptr46\u0027, \u0027out_ptr47\u0027, \u0027out_ptr5\u0027, \u0027out_ptr51\u0027, \u0027out_ptr52\u0027, \u0027out_ptr53\u0027, \u0027out_ptr57\u0027, \u0027out_ptr58\u0027, \u0027out_ptr59\u0027, \u0027out_ptr9\u0027], \u0027backend_hash\u0027: \u0027DC36EA6BB5AEA639F493BE6C610554D7008666A7D52F3C35F9DAC37F278CCC65\u0027, \u0027assert_indirect_indexing\u0027: True, \u0027autotune_local_cache\u0027: True, \u0027autotune_pointwise\u0027: True, \u0027autotune_remote_cache\u0027: None, \u0027force_disable_caches\u0027: False, \u0027dynamic_scale_rblock\u0027: True, \u0027max_autotune\u0027: False, \u0027max_autotune_pointwise\u0027: False, \u0027min_split_scan_rblock\u0027: 256, \u0027spill_threshold\u0027: 16, \u0027store_cubin\u0027: False, \u0027deterministic\u0027: False, \u0027force_filter_reduction_configs\u0027: False, \u0027are_deterministic_algorithms_enabled\u0027: False}, V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] ) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] @triton.jit V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def triton_for_fused_1(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, in_ptr10, in_ptr11, in_ptr12, in_ptr13, in_ptr14, in_ptr15, in_ptr16, in_ptr17, in_ptr18, in_ptr19, in_ptr20, in_ptr21, in_ptr22, in_ptr23, in_ptr24, in_ptr25, in_ptr26, in_ptr27, in_ptr28, in_ptr29, in_ptr30, in_ptr31, in_ptr32, in_ptr33, in_ptr34, in_ptr35, in_ptr36, in_ptr37, in_ptr38, in_ptr39, in_ptr40, in_ptr41, in_ptr42, in_ptr43, in_ptr44, in_ptr45, in_ptr46, in_ptr47, in_ptr48, in_ptr49, out_ptr3, out_ptr4, out_ptr5, out_ptr9, out_ptr10, out_ptr11, out_ptr15, out_ptr16, out_ptr17, out_ptr21, out_ptr22, out_ptr23, out_ptr27, out_ptr28, out_ptr29, out_ptr33, out_ptr34, out_ptr35, out_ptr39, out_ptr40, out_ptr41, out_ptr45, out_ptr46, out_ptr47, out_ptr51, out_ptr52, out_ptr53, out_ptr57, out_ptr58, out_ptr59): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid = tl.program_id(0) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] XBLOCK: tl.constexpr = 1024 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_0 = tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_1 = num_xblocks_0 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_2 = num_xblocks_1 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_3 = num_xblocks_2 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_4 = num_xblocks_3 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_5 = num_xblocks_4 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_6 = num_xblocks_5 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_7 = num_xblocks_6 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_8 = num_xblocks_7 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] num_xblocks_9 = num_xblocks_8 + tl.cdiv(1048576, XBLOCK) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] if pid \u003c num_xblocks_0: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x0 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp0 = tl.load(in_ptr0 + (x0), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp1 = tl.load(in_ptr1 + (x0), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp8 = tl.load(in_ptr2 + (x0), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp15 = tl.load(in_ptr3 + (x0), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp17 = in_ptr4 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp2 = tmp0 - tmp1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp3 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp4 = tmp3 * tmp2 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp5 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp6 = tl.where(tmp5, tmp0, tmp1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp7 = tmp4 + tmp6 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp9 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp10 = tmp8 * tmp9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp11 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp12 = tmp0 * tmp11 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp13 = tmp12 * tmp0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp14 = tmp10 + tmp13 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp16 = tl.sqrt_rn(tmp14) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp18 = libdevice.pow(tmp9, tmp17) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp19 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp20 = tmp19 - tmp18 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp21 = tl.sqrt_rn(tmp20) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp22 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp23 = libdevice.pow(tmp22, tmp17) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp24 = tmp19 - tmp23 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp25 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp26 = (tmp25 / tmp24) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp27 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp28 = tmp26 * tmp27 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp29 = -tmp28 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp30 = tmp21 * tmp29 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp31 = (tmp16 / tmp30) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp32 = (tmp25 / tmp29) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp33 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp34 = tmp32 * tmp33 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp35 = tmp31 + tmp34 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp36 = (tmp7 / tmp35) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp37 = tmp15 + tmp36 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr3 + (x0), tmp7, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr4 + (x0), tmp14, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr5 + (x0), tmp37, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_1: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x1 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp38 = tl.load(in_ptr5 + (x1), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp39 = tl.load(in_ptr6 + (x1), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp46 = tl.load(in_ptr7 + (x1), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp53 = tl.load(in_ptr8 + (x1), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp55 = in_ptr9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp40 = tmp38 - tmp39 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp41 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp42 = tmp41 * tmp40 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp43 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp44 = tl.where(tmp43, tmp38, tmp39) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp45 = tmp42 + tmp44 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp47 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp48 = tmp46 * tmp47 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp49 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp50 = tmp38 * tmp49 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp51 = tmp50 * tmp38 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp52 = tmp48 + tmp51 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp54 = tl.sqrt_rn(tmp52) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp56 = libdevice.pow(tmp47, tmp55) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp57 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp58 = tmp57 - tmp56 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp59 = tl.sqrt_rn(tmp58) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp60 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp61 = libdevice.pow(tmp60, tmp55) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp62 = tmp57 - tmp61 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp63 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp64 = (tmp63 / tmp62) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp65 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp66 = tmp64 * tmp65 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp67 = -tmp66 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp68 = tmp59 * tmp67 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp69 = (tmp54 / tmp68) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp70 = (tmp63 / tmp67) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp71 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp72 = tmp70 * tmp71 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp73 = tmp69 + tmp72 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp74 = (tmp45 / tmp73) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp75 = tmp53 + tmp74 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr9 + (x1), tmp45, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr10 + (x1), tmp52, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr11 + (x1), tmp75, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_2: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x2 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp76 = tl.load(in_ptr10 + (x2), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp77 = tl.load(in_ptr11 + (x2), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp84 = tl.load(in_ptr12 + (x2), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp91 = tl.load(in_ptr13 + (x2), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp93 = in_ptr14 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp78 = tmp76 - tmp77 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp79 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp80 = tmp79 * tmp78 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp81 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp82 = tl.where(tmp81, tmp76, tmp77) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp83 = tmp80 + tmp82 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp85 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp86 = tmp84 * tmp85 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp87 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp88 = tmp76 * tmp87 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp89 = tmp88 * tmp76 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp90 = tmp86 + tmp89 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp92 = tl.sqrt_rn(tmp90) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp94 = libdevice.pow(tmp85, tmp93) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp95 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp96 = tmp95 - tmp94 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp97 = tl.sqrt_rn(tmp96) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp98 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp99 = libdevice.pow(tmp98, tmp93) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp100 = tmp95 - tmp99 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp101 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp102 = (tmp101 / tmp100) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp103 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp104 = tmp102 * tmp103 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp105 = -tmp104 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp106 = tmp97 * tmp105 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp107 = (tmp92 / tmp106) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp108 = (tmp101 / tmp105) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp109 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp110 = tmp108 * tmp109 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp111 = tmp107 + tmp110 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp112 = (tmp83 / tmp111) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp113 = tmp91 + tmp112 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr15 + (x2), tmp83, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr16 + (x2), tmp90, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr17 + (x2), tmp113, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_3: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_2 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x3 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp114 = tl.load(in_ptr15 + (x3), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp115 = tl.load(in_ptr16 + (x3), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp122 = tl.load(in_ptr17 + (x3), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp129 = tl.load(in_ptr18 + (x3), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp131 = in_ptr19 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp116 = tmp114 - tmp115 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp117 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp118 = tmp117 * tmp116 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp119 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp120 = tl.where(tmp119, tmp114, tmp115) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp121 = tmp118 + tmp120 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp123 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp124 = tmp122 * tmp123 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp125 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp126 = tmp114 * tmp125 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp127 = tmp126 * tmp114 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp128 = tmp124 + tmp127 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp130 = tl.sqrt_rn(tmp128) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp132 = libdevice.pow(tmp123, tmp131) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp133 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp134 = tmp133 - tmp132 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp135 = tl.sqrt_rn(tmp134) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp136 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp137 = libdevice.pow(tmp136, tmp131) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp138 = tmp133 - tmp137 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp139 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp140 = (tmp139 / tmp138) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp141 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp142 = tmp140 * tmp141 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp143 = -tmp142 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp144 = tmp135 * tmp143 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp145 = (tmp130 / tmp144) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp146 = (tmp139 / tmp143) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp147 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp148 = tmp146 * tmp147 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp149 = tmp145 + tmp148 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp150 = (tmp121 / tmp149) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp151 = tmp129 + tmp150 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr21 + (x3), tmp121, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr22 + (x3), tmp128, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr23 + (x3), tmp151, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_4: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_3 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x4 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp152 = tl.load(in_ptr20 + (x4), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp153 = tl.load(in_ptr21 + (x4), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp160 = tl.load(in_ptr22 + (x4), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp167 = tl.load(in_ptr23 + (x4), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp169 = in_ptr24 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp154 = tmp152 - tmp153 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp155 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp156 = tmp155 * tmp154 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp157 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp158 = tl.where(tmp157, tmp152, tmp153) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp159 = tmp156 + tmp158 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp161 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp162 = tmp160 * tmp161 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp163 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp164 = tmp152 * tmp163 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp165 = tmp164 * tmp152 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp166 = tmp162 + tmp165 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp168 = tl.sqrt_rn(tmp166) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp170 = libdevice.pow(tmp161, tmp169) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp171 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp172 = tmp171 - tmp170 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp173 = tl.sqrt_rn(tmp172) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp174 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp175 = libdevice.pow(tmp174, tmp169) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp176 = tmp171 - tmp175 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp177 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp178 = (tmp177 / tmp176) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp179 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp180 = tmp178 * tmp179 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp181 = -tmp180 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp182 = tmp173 * tmp181 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp183 = (tmp168 / tmp182) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp184 = (tmp177 / tmp181) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp185 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp186 = tmp184 * tmp185 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp187 = tmp183 + tmp186 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp188 = (tmp159 / tmp187) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp189 = tmp167 + tmp188 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr27 + (x4), tmp159, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr28 + (x4), tmp166, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr29 + (x4), tmp189, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_5: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_4 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x5 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp190 = tl.load(in_ptr25 + (x5), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp191 = tl.load(in_ptr26 + (x5), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp198 = tl.load(in_ptr27 + (x5), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp205 = tl.load(in_ptr28 + (x5), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp207 = in_ptr29 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp192 = tmp190 - tmp191 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp193 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp194 = tmp193 * tmp192 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp195 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp196 = tl.where(tmp195, tmp190, tmp191) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp197 = tmp194 + tmp196 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp199 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp200 = tmp198 * tmp199 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp201 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp202 = tmp190 * tmp201 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp203 = tmp202 * tmp190 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp204 = tmp200 + tmp203 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp206 = tl.sqrt_rn(tmp204) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp208 = libdevice.pow(tmp199, tmp207) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp209 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp210 = tmp209 - tmp208 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp211 = tl.sqrt_rn(tmp210) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp212 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp213 = libdevice.pow(tmp212, tmp207) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp214 = tmp209 - tmp213 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp215 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp216 = (tmp215 / tmp214) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp217 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp218 = tmp216 * tmp217 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp219 = -tmp218 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp220 = tmp211 * tmp219 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp221 = (tmp206 / tmp220) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp222 = (tmp215 / tmp219) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp223 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp224 = tmp222 * tmp223 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp225 = tmp221 + tmp224 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp226 = (tmp197 / tmp225) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp227 = tmp205 + tmp226 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr33 + (x5), tmp197, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr34 + (x5), tmp204, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr35 + (x5), tmp227, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_6: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_5 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x6 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp228 = tl.load(in_ptr30 + (x6), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp229 = tl.load(in_ptr31 + (x6), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp236 = tl.load(in_ptr32 + (x6), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp243 = tl.load(in_ptr33 + (x6), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp245 = in_ptr34 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp230 = tmp228 - tmp229 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp231 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp232 = tmp231 * tmp230 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp233 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp234 = tl.where(tmp233, tmp228, tmp229) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp235 = tmp232 + tmp234 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp237 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp238 = tmp236 * tmp237 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp239 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp240 = tmp228 * tmp239 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp241 = tmp240 * tmp228 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp242 = tmp238 + tmp241 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp244 = tl.sqrt_rn(tmp242) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp246 = libdevice.pow(tmp237, tmp245) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp247 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp248 = tmp247 - tmp246 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp249 = tl.sqrt_rn(tmp248) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp250 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp251 = libdevice.pow(tmp250, tmp245) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp252 = tmp247 - tmp251 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp253 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp254 = (tmp253 / tmp252) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp255 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp256 = tmp254 * tmp255 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp257 = -tmp256 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp258 = tmp249 * tmp257 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp259 = (tmp244 / tmp258) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp260 = (tmp253 / tmp257) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp261 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp262 = tmp260 * tmp261 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp263 = tmp259 + tmp262 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp264 = (tmp235 / tmp263) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp265 = tmp243 + tmp264 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr39 + (x6), tmp235, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr40 + (x6), tmp242, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr41 + (x6), tmp265, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_7: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_6 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x7 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp266 = tl.load(in_ptr35 + (x7), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp267 = tl.load(in_ptr36 + (x7), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp274 = tl.load(in_ptr37 + (x7), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp281 = tl.load(in_ptr38 + (x7), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp283 = in_ptr39 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp268 = tmp266 - tmp267 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp269 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp270 = tmp269 * tmp268 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp271 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp272 = tl.where(tmp271, tmp266, tmp267) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp273 = tmp270 + tmp272 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp275 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp276 = tmp274 * tmp275 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp277 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp278 = tmp266 * tmp277 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp279 = tmp278 * tmp266 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp280 = tmp276 + tmp279 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp282 = tl.sqrt_rn(tmp280) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp284 = libdevice.pow(tmp275, tmp283) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp285 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp286 = tmp285 - tmp284 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp287 = tl.sqrt_rn(tmp286) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp288 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp289 = libdevice.pow(tmp288, tmp283) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp290 = tmp285 - tmp289 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp291 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp292 = (tmp291 / tmp290) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp293 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp294 = tmp292 * tmp293 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp295 = -tmp294 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp296 = tmp287 * tmp295 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp297 = (tmp282 / tmp296) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp298 = (tmp291 / tmp295) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp299 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp300 = tmp298 * tmp299 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp301 = tmp297 + tmp300 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp302 = (tmp273 / tmp301) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp303 = tmp281 + tmp302 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr45 + (x7), tmp273, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr46 + (x7), tmp280, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr47 + (x7), tmp303, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_8: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_7 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x8 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp304 = tl.load(in_ptr40 + (x8), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp305 = tl.load(in_ptr41 + (x8), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp312 = tl.load(in_ptr42 + (x8), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp319 = tl.load(in_ptr43 + (x8), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp321 = in_ptr44 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp306 = tmp304 - tmp305 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp307 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp308 = tmp307 * tmp306 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp309 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp310 = tl.where(tmp309, tmp304, tmp305) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp311 = tmp308 + tmp310 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp313 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp314 = tmp312 * tmp313 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp315 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp316 = tmp304 * tmp315 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp317 = tmp316 * tmp304 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp318 = tmp314 + tmp317 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp320 = tl.sqrt_rn(tmp318) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp322 = libdevice.pow(tmp313, tmp321) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp323 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp324 = tmp323 - tmp322 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp325 = tl.sqrt_rn(tmp324) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp326 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp327 = libdevice.pow(tmp326, tmp321) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp328 = tmp323 - tmp327 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp329 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp330 = (tmp329 / tmp328) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp331 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp332 = tmp330 * tmp331 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp333 = -tmp332 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp334 = tmp325 * tmp333 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp335 = (tmp320 / tmp334) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp336 = (tmp329 / tmp333) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp337 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp338 = tmp336 * tmp337 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp339 = tmp335 + tmp338 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp340 = (tmp311 / tmp339) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp341 = tmp319 + tmp340 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr51 + (x8), tmp311, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr52 + (x8), tmp318, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr53 + (x8), tmp341, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] elif pid \u003c num_xblocks_9: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pid_offset = pid - num_xblocks_8 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xnumel = 1048576 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] r0_numel = 1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xoffset = pid_offset * XBLOCK V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xindex = xoffset + tl.arange(0, XBLOCK)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] xmask = tl.full([XBLOCK], True, tl.int1)[:] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] x9 = xindex V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp342 = tl.load(in_ptr45 + (x9), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp343 = tl.load(in_ptr46 + (x9), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp350 = tl.load(in_ptr47 + (x9), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp357 = tl.load(in_ptr48 + (x9), None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp359 = in_ptr49 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp344 = tmp342 - tmp343 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp345 = 0.10000000149011612 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp346 = tmp345 * tmp344 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp347 = tl.full([1], False, tl.int1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp348 = tl.where(tmp347, tmp342, tmp343) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp349 = tmp346 + tmp348 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp351 = 0.999 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp352 = tmp350 * tmp351 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp353 = 0.0010000000000000009 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp354 = tmp342 * tmp353 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp355 = tmp354 * tmp342 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp356 = tmp352 + tmp355 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp358 = tl.sqrt_rn(tmp356) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp360 = libdevice.pow(tmp351, tmp359) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp361 = 1.0 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp362 = tmp361 - tmp360 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp363 = tl.sqrt_rn(tmp362) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp364 = 0.9 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp365 = libdevice.pow(tmp364, tmp359) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp366 = tmp361 - tmp365 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp367 = tl.full([1], 1, tl.int32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp368 = (tmp367 / tmp366) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp369 = 0.001 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp370 = tmp368 * tmp369 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp371 = -tmp370 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp372 = tmp363 * tmp371 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp373 = (tmp358 / tmp372) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp374 = (tmp367 / tmp371) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp375 = 1e-08 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp376 = tmp374 * tmp375 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp377 = tmp373 + tmp376 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp378 = (tmp349 / tmp377) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tmp379 = tmp357 + tmp378 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr57 + (x9), tmp349, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr58 + (x9), tmp356, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] tl.store(out_ptr59 + (x9), tmp379, None) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] else: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] pass V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] \u0027\u0027\u0027, device_str=\u0027cuda\u0027) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] async_compile.wait(globals()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del async_compile V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] class Runner: V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def __init__(self, partitions): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] self.partitions = partitions V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def recursively_apply_fns(self, fns): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] new_callables = [] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] for fn, c in zip(fns, self.partitions): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] new_callables.append(fn(c)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] self.partitions = new_callables V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def call(self, args): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1 = args V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] args.clear() V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg0_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg1_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg2_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg3_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg4_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg5_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg6_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg7_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg8_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg9_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg10_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg11_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg12_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg13_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg14_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg15_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg16_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg17_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg18_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg19_1, (), ()) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg20_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg21_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg22_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg23_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg24_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg25_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg26_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg27_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg28_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg29_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg30_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg31_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg32_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg33_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg34_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg35_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg36_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg37_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg38_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg39_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg40_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg41_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg42_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg43_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg44_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg45_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg46_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg47_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg48_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] assert_size_stride(arg49_1, (1024, 1024), (1024, 1)) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] cpp_fused__foreach_copy_0(arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] with torch.cuda._DeviceGuard(0): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] torch.cuda.set_device(0) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] # Unsorted Source Nodes: [], Original ATen: [] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] stream0 = get_raw_stream(0) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] triton_for_fused_1.run(arg30_1, arg20_1, arg40_1, arg0_1, arg10_1.item(), arg31_1, arg21_1, arg41_1, arg1_1, arg11_1.item(), arg32_1, arg22_1, arg42_1, arg2_1, arg12_1.item(), arg33_1, arg23_1, arg43_1, arg3_1, arg13_1.item(), arg34_1, arg24_1, arg44_1, arg4_1, arg14_1.item(), arg35_1, arg25_1, arg45_1, arg5_1, arg15_1.item(), arg36_1, arg26_1, arg46_1, arg6_1, arg16_1.item(), arg37_1, arg27_1, arg47_1, arg7_1, arg17_1.item(), arg38_1, arg28_1, arg48_1, arg8_1, arg18_1.item(), arg39_1, arg29_1, arg49_1, arg9_1, arg19_1.item(), arg20_1, arg40_1, arg0_1, arg21_1, arg41_1, arg1_1, arg22_1, arg42_1, arg2_1, arg23_1, arg43_1, arg3_1, arg24_1, arg44_1, arg4_1, arg25_1, arg45_1, arg5_1, arg26_1, arg46_1, arg6_1, arg27_1, arg47_1, arg7_1, arg28_1, arg48_1, arg8_1, arg29_1, arg49_1, arg9_1, stream=stream0) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg0_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg10_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg11_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg12_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg13_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg14_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg15_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg16_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg17_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg18_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg19_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg1_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg20_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg21_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg22_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg23_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg24_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg25_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg26_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg27_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg28_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg29_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg2_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg30_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg31_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg32_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg33_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg34_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg35_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg36_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg37_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg38_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg39_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg3_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg40_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg41_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg42_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg43_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg44_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg45_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg46_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg47_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg48_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg49_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg4_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg5_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg6_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg7_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg8_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] del arg9_1 V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] return () V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] runner = Runner(partitions=[]) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] call = runner.call V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] recursively_apply_fns = runner.recursively_apply_fns V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] def benchmark_compiled_module(times=10, repeat=10): V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._dynamo.testing import rand_strided V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.utils import print_performance V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg0_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg1_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg2_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg3_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg4_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg5_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg6_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg7_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg8_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg9_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg10_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg11_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg12_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg13_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg14_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg15_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg16_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg17_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg18_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg19_1 = rand_strided((), (), device=\u0027cpu\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg20_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg21_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg22_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg23_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg24_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg25_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg26_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg27_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg28_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg29_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg30_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg31_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg32_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg33_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg34_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg35_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg36_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg37_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg38_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg39_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg40_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg41_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg42_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg43_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg44_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg45_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg46_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg47_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg48_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] arg49_1 = rand_strided((1024, 1024), (1024, 1), device=\u0027cuda:0\u0027, dtype=torch.float32) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1, arg19_1, arg20_1, arg21_1, arg22_1, arg23_1, arg24_1, arg25_1, arg26_1, arg27_1, arg28_1, arg29_1, arg30_1, arg31_1, arg32_1, arg33_1, arg34_1, arg35_1, arg36_1, arg37_1, arg38_1, arg39_1, arg40_1, arg41_1, arg42_1, arg43_1, arg44_1, arg45_1, arg46_1, arg47_1, arg48_1, arg49_1]) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] return print_performance(fn, times=times, repeat=repeat) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] if __name__ == \"__main__\": V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] from torch._inductor.wrapper_benchmark import compiled_module_main V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] compiled_module_main(\u0027None\u0027, benchmark_compiled_module) V0121 17:28:45.481000 23168 torch/_inductor/graph.py:2469] [0/1] [__output_code] V0121 17:28:45.530000 23168 torch/_inductor/graph.py:2480] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/dl/cdlhgjqcuqbu3ayx7yodirku4j26rypg2y46ph7i7r4oygg47wbs.py I0121 17:28:45.655000 23168 torch/_inductor/graph.py:2440] [0/1] [__output_code] Output code written to: /tmp/torchinductor_ci-user/dl/cdlhgjqcuqbu3ayx7yodirku4j26rypg2y46ph7i7r4oygg47wbs.py eager runtime: 1202.695570000287us compiled runtime: 765.1694045758799us Conclusion# In this tutorial, we successfully implemented a custom fully-fused Adam optimizer using foreach_map. By leveraging the power of foreach_map and torch.compile, we were able to create an optimized version of the Adam optimizer that can be used in various machine learning applications. This tutorial provides a comprehensive guide on how to use foreach_map and torch.compile to optimize machine learning models, and serves as a valuable resource for developers looking to improve the performance of their models with horizontal fusion. See also: Compiled optimizer tutorial - an intro into the compiled optimizer. Compiling the optimizer with PT2 - deeper technical details on the compiled optimizer. Total running time of the script: (0 minutes 10.633 seconds) Download Jupyter notebook: foreach_map.ipynb Download Python source code: foreach_map.py Download zipped: foreach_map.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/recipes/foreach_map.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
  <script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
  
  </body>
</html>