
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "beginner/examples_tensor/polynomial_numpy.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_beginner_examples_tensor_polynomial_numpy.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_examples_tensor_polynomial_numpy.py:


Warm-up: numpy
--------------

A third order polynomial, trained to predict :math:`y=\sin(x)` from :math:`-\pi`
to :math:`pi` by minimizing squared Euclidean distance.

This implementation uses numpy to manually compute the forward pass, loss, and
backward pass.

A numpy array is a generic n-dimensional array; it does not know anything about
deep learning or gradients or computational graphs, and is just a way to perform
generic numeric computations.

.. GENERATED FROM PYTHON SOURCE LINES 16-54




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    99 5806.753293617883
    199 3862.302919721171
    299 2570.8050391056754
    399 1712.7470230086592
    499 1142.4866207761052
    599 763.3713073438332
    699 511.2443402684038
    799 343.5085163881904
    899 231.8736180785256
    999 157.54582790736504
    1099 108.0362317769303
    1199 75.04301328061385
    1299 53.04579809569779
    1399 38.3724443885356
    1499 28.579325652677014
    1599 22.039679986329183
    1699 17.67008788366291
    1799 14.74867287604653
    1899 12.794226613464879
    1999 11.48581321126099
    Result: y = 0.025752059224916905 + 0.8124416095481773 x + -0.004442658732413325 x^2 + -0.08702920883270075 x^3






|

.. code-block:: default

    import numpy as np
    import math

    # Create random input and output data
    x = np.linspace(-math.pi, math.pi, 2000)
    y = np.sin(x)

    # Randomly initialize weights
    a = np.random.randn()
    b = np.random.randn()
    c = np.random.randn()
    d = np.random.randn()

    learning_rate = 1e-6
    for t in range(2000):
        # Forward pass: compute predicted y
        # y = a + b x + c x^2 + d x^3
        y_pred = a + b * x + c * x ** 2 + d * x ** 3

        # Compute and print loss
        loss = np.square(y_pred - y).sum()
        if t % 100 == 99:
            print(t, loss)

        # Backprop to compute gradients of a, b, c, d with respect to loss
        grad_y_pred = 2.0 * (y_pred - y)
        grad_a = grad_y_pred.sum()
        grad_b = (grad_y_pred * x).sum()
        grad_c = (grad_y_pred * x ** 2).sum()
        grad_d = (grad_y_pred * x ** 3).sum()

        # Update weights
        a -= learning_rate * grad_a
        b -= learning_rate * grad_b
        c -= learning_rate * grad_c
        d -= learning_rate * grad_d

    print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.237 seconds)


.. _sphx_glr_download_beginner_examples_tensor_polynomial_numpy.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: polynomial_numpy.py <polynomial_numpy.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: polynomial_numpy.ipynb <polynomial_numpy.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
