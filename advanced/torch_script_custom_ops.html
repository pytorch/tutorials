
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Extending TorchScript with Custom C++ Operators — PyTorch Tutorials 2.2.2+cu121 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css" rel="stylesheet" type="text/css"/>
<link href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom2.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="torch_script_custom_classes.html" rel="next" title="Extending TorchScript with Custom C++ Classes"/>
<link href="cpp_extension.html" rel="prev" title="Custom C++ and CUDA Extensions"/>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
<!-- End Google Tag Manager -->
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Edge
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/edge">
<span class="dropdown-title">About PyTorch Edge</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/executorch">
<span class="dropdown-title">ExecuTorch</span>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-orange-arrow">
                Docs
              </a>
<div class="resources-dropdown-menu">
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
<span class="dropdown-title">torchaudio</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
<span class="dropdown-title">torchtext</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
<span class="dropdown-title">torchvision</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
<span class="dropdown-title">torcharrow</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
<span class="dropdown-title">TorchData</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
<span class="dropdown-title">TorchRec</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
<span class="dropdown-title">TorchServe</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
<span class="dropdown-title">TorchX</span>
<p></p>
</a>
<a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
<span class="dropdown-title">PyTorch on XLA Devices</span>
<p></p>
</a>
</div>
</div></li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="resource-option with-down-arrow">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
<p>Learn about the PyTorch foundation</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
<span class="dropdown-title">Community</span>
<p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
<span class="dropdown-title">Community Stories</span>
<p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
<p>Find events, webinars, and podcasts</p>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
<span class="dropdown-title">Forums</span>
<p>A place to discuss PyTorch code, issues, install, research</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">GitHub</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  2.2.2+cu121
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tiatoolbox_tutorial.html">Whole Slide Image Classification Using PyTorch and TIAToolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/text_to_speech_with_torchaudio.html">Text-to-speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/translation_transformer.html">Language Translation with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/torchtext_custom_dataset_tutorial.html">Preprocess custom text dataset using Torchtext</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Profiling PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_intro_tutorial.html">Introduction to Holistic Trace Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-torch-compile">Using SDPA with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_pipeline.html">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_android.html">Image Segmentation DeepLabV3 on Android</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Extending TorchScript with Custom C++ Operators</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/advanced/torch_script_custom_ops.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">advanced/torch_script_custom_ops</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg">
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</img></div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="section" id="extending-torchscript-with-custom-c-operators">
<h1>Extending TorchScript with Custom C++ Operators<a class="headerlink" href="#extending-torchscript-with-custom-c-operators" title="Permalink to this heading">¶</a></h1>
<p>The PyTorch 1.0 release introduced a new programming model to PyTorch called
<a class="reference external" href="https://pytorch.org/docs/master/jit.html">TorchScript</a>. TorchScript is a
subset of the Python programming language which can be parsed, compiled and
optimized by the TorchScript compiler. Further, compiled TorchScript models have
the option of being serialized into an on-disk file format, which you can
subsequently load and run from pure C++ (as well as Python) for inference.</p>
<p>TorchScript supports a large subset of operations provided by the <code class="docutils literal notranslate"><span class="pre">torch</span></code>
package, allowing you to express many kinds of complex models purely as a series
of tensor operations from PyTorch’s “standard library”. Nevertheless, there may
be times where you find yourself in need of extending TorchScript with a custom
C++ or CUDA function. While we recommend that you only resort to this option if
your idea cannot be expressed (efficiently enough) as a simple Python function,
we do provide a very friendly and simple interface for defining custom C++ and
CUDA kernels using <a class="reference external" href="https://pytorch.org/cppdocs/#aten">ATen</a>, PyTorch’s high
performance C++ tensor library. Once bound into TorchScript, you can embed these
custom kernels (or “ops”) into your TorchScript model and execute them both in
Python and in their serialized form directly in C++.</p>
<p>The following paragraphs give an example of writing a TorchScript custom op to
call into <a class="reference external" href="https://www.opencv.org">OpenCV</a>, a computer vision library written
in C++. We will discuss how to work with tensors in C++, how to efficiently
convert them to third party tensor formats (in this case, OpenCV <code class="docutils literal notranslate"><span class="pre">Mat</span></code>), how
to register your operator with the TorchScript runtime and finally how to
compile the operator and use it in Python and C++.</p>
<div class="section" id="implementing-the-custom-operator-in-c">
<h2>Implementing the Custom Operator in C++<a class="headerlink" href="#implementing-the-custom-operator-in-c" title="Permalink to this heading">¶</a></h2>
<p>For this tutorial, we’ll be exposing the <a class="reference external" href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#warpperspective">warpPerspective</a>
function, which applies a perspective transformation to an image, from OpenCV to
TorchScript as a custom operator. The first step is to write the implementation
of our custom operator in C++. Let’s call the file for this implementation
<code class="docutils literal notranslate"><span class="pre">op.cpp</span></code> and make it look like this:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="nf">warp_perspective</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">image</span><span class="p">,</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">warp</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="c1">// BEGIN image_mat</span>
<span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">image_mat</span><span class="p">(</span><span class="cm">/*rows=*/</span><span class="n">image</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="w">                    </span><span class="cm">/*cols=*/</span><span class="n">image</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="w">                    </span><span class="cm">/*type=*/</span><span class="n">CV_32FC1</span><span class="p">,</span>
<span class="w">                    </span><span class="cm">/*data=*/</span><span class="n">image</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">());</span>
<span class="w">  </span><span class="c1">// END image_mat</span>

<span class="w">  </span><span class="c1">// BEGIN warp_mat</span>
<span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">warp_mat</span><span class="p">(</span><span class="cm">/*rows=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="w">                   </span><span class="cm">/*cols=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="w">                   </span><span class="cm">/*type=*/</span><span class="n">CV_32FC1</span><span class="p">,</span>
<span class="w">                   </span><span class="cm">/*data=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">());</span>
<span class="w">  </span><span class="c1">// END warp_mat</span>

<span class="w">  </span><span class="c1">// BEGIN output_mat</span>
<span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">output_mat</span><span class="p">;</span>
<span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">image_mat</span><span class="p">,</span><span class="w"> </span><span class="n">output_mat</span><span class="p">,</span><span class="w"> </span><span class="n">warp_mat</span><span class="p">,</span><span class="w"> </span><span class="cm">/*dsize=*/</span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">});</span>
<span class="w">  </span><span class="c1">// END output_mat</span>

<span class="w">  </span><span class="c1">// BEGIN output_tensor</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">output_mat</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(),</span><span class="w"> </span><span class="cm">/*sizes=*/</span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">});</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// END output_tensor</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The code for this operator is quite short. At the top of the file, we include
the OpenCV header file, <code class="docutils literal notranslate"><span class="pre">opencv2/opencv.hpp</span></code>, alongside the <code class="docutils literal notranslate"><span class="pre">torch/script.h</span></code>
header which exposes all the necessary goodies from PyTorch’s C++ API that we
need to write custom TorchScript operators. Our function <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code>
takes two arguments: an input <code class="docutils literal notranslate"><span class="pre">image</span></code> and the <code class="docutils literal notranslate"><span class="pre">warp</span></code> transformation matrix
we wish to apply to the image. The type of these inputs is <code class="docutils literal notranslate"><span class="pre">torch::Tensor</span></code>,
PyTorch’s tensor type in C++ (which is also the underlying type of all tensors
in Python). The return type of our <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> function will also be a
<code class="docutils literal notranslate"><span class="pre">torch::Tensor</span></code>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See <a class="reference external" href="https://pytorch.org/cppdocs/notes/tensor_basics.html">this note</a> for
more information about ATen, the library that provides the <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> class to
PyTorch. Further, <a class="reference external" href="https://pytorch.org/cppdocs/notes/tensor_creation.html">this tutorial</a> describes how to
allocate and initialize new tensor objects in C++ (not required for this
operator).</p>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The TorchScript compiler understands a fixed number of types. Only these types
can be used as arguments to your custom operator. Currently these types are:
<code class="docutils literal notranslate"><span class="pre">torch::Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">torch::Scalar</span></code>, <code class="docutils literal notranslate"><span class="pre">double</span></code>, <code class="docutils literal notranslate"><span class="pre">int64_t</span></code> and
<code class="docutils literal notranslate"><span class="pre">std::vector</span></code> s of these types. Note that <em>only</em> <code class="docutils literal notranslate"><span class="pre">double</span></code> and <em>not</em>
<code class="docutils literal notranslate"><span class="pre">float</span></code>, and <em>only</em> <code class="docutils literal notranslate"><span class="pre">int64_t</span></code> and <em>not</em> other integral types such as
<code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">short</span></code> or <code class="docutils literal notranslate"><span class="pre">long</span></code> are supported.</p>
</div>
<p>Inside of our function, the first thing we need to do is convert our PyTorch
tensors to OpenCV matrices, as OpenCV’s <code class="docutils literal notranslate"><span class="pre">warpPerspective</span></code> expects <code class="docutils literal notranslate"><span class="pre">cv::Mat</span></code>
objects as inputs. Fortunately, there is a way to do this <strong>without copying
any</strong> data. In the first few lines,</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">image_mat</span><span class="p">(</span><span class="cm">/*rows=*/</span><span class="n">image</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="w">                    </span><span class="cm">/*cols=*/</span><span class="n">image</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="w">                    </span><span class="cm">/*type=*/</span><span class="n">CV_32FC1</span><span class="p">,</span>
<span class="w">                    </span><span class="cm">/*data=*/</span><span class="n">image</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">());</span>
</pre></div>
</div>
<p>we are calling <a class="reference external" href="https://docs.opencv.org/trunk/d3/d63/classcv_1_1Mat.html#a922de793eabcec705b3579c5f95a643e">this constructor</a>
of the OpenCV <code class="docutils literal notranslate"><span class="pre">Mat</span></code> class to convert our tensor to a <code class="docutils literal notranslate"><span class="pre">Mat</span></code> object. We pass
it the number of rows and columns of the original <code class="docutils literal notranslate"><span class="pre">image</span></code> tensor, the datatype
(which we’ll fix as <code class="docutils literal notranslate"><span class="pre">float32</span></code> for this example), and finally a raw pointer to
the underlying data – a <code class="docutils literal notranslate"><span class="pre">float*</span></code>. What is special about this constructor of
the <code class="docutils literal notranslate"><span class="pre">Mat</span></code> class is that it does not copy the input data. Instead, it will
simply reference this memory for all operations performed on the <code class="docutils literal notranslate"><span class="pre">Mat</span></code>. If an
in-place operation is performed on the <code class="docutils literal notranslate"><span class="pre">image_mat</span></code>, this will be reflected in
the original <code class="docutils literal notranslate"><span class="pre">image</span></code> tensor (and vice-versa). This allows us to call
subsequent OpenCV routines with the library’s native matrix type, even though
we’re actually storing the data in a PyTorch tensor. We repeat this procedure to
convert the <code class="docutils literal notranslate"><span class="pre">warp</span></code> PyTorch tensor to the <code class="docutils literal notranslate"><span class="pre">warp_mat</span></code> OpenCV matrix:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">warp_mat</span><span class="p">(</span><span class="cm">/*rows=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
<span class="w">                   </span><span class="cm">/*cols=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
<span class="w">                   </span><span class="cm">/*type=*/</span><span class="n">CV_32FC1</span><span class="p">,</span>
<span class="w">                   </span><span class="cm">/*data=*/</span><span class="n">warp</span><span class="p">.</span><span class="n">data_ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">());</span>
</pre></div>
</div>
<p>Next, we are ready to call the OpenCV function we were so eager to use in
TorchScript: <code class="docutils literal notranslate"><span class="pre">warpPerspective</span></code>. For this, we pass the OpenCV function the
<code class="docutils literal notranslate"><span class="pre">image_mat</span></code> and <code class="docutils literal notranslate"><span class="pre">warp_mat</span></code> matrices, as well as an empty output matrix
called <code class="docutils literal notranslate"><span class="pre">output_mat</span></code>. We also specify the size <code class="docutils literal notranslate"><span class="pre">dsize</span></code> we want the output
matrix (image) to be. It is hardcoded to <code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">x</span> <span class="pre">8</span></code> for this example:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">Mat</span><span class="w"> </span><span class="n">output_mat</span><span class="p">;</span>
<span class="w">  </span><span class="n">cv</span><span class="o">::</span><span class="n">warpPerspective</span><span class="p">(</span><span class="n">image_mat</span><span class="p">,</span><span class="w"> </span><span class="n">output_mat</span><span class="p">,</span><span class="w"> </span><span class="n">warp_mat</span><span class="p">,</span><span class="w"> </span><span class="cm">/*dsize=*/</span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">});</span>
</pre></div>
</div>
<p>The final step in our custom operator implementation is to convert the
<code class="docutils literal notranslate"><span class="pre">output_mat</span></code> back into a PyTorch tensor, so that we can further use it in
PyTorch. This is strikingly similar to what we did earlier to convert in the
other direction. In this case, PyTorch provides a <code class="docutils literal notranslate"><span class="pre">torch::from_blob</span></code> method. A
<em>blob</em> in this case is intended to mean some opaque, flat pointer to memory that
we want to interpret as a PyTorch tensor. The call to <code class="docutils literal notranslate"><span class="pre">torch::from_blob</span></code> looks
like this:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">from_blob</span><span class="p">(</span><span class="n">output_mat</span><span class="p">.</span><span class="n">ptr</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(),</span><span class="w"> </span><span class="cm">/*sizes=*/</span><span class="p">{</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">});</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">clone</span><span class="p">();</span>
</pre></div>
</div>
<p>We use the <code class="docutils literal notranslate"><span class="pre">.ptr&lt;float&gt;()</span></code> method on the OpenCV <code class="docutils literal notranslate"><span class="pre">Mat</span></code> class to get a raw
pointer to the underlying data (just like <code class="docutils literal notranslate"><span class="pre">.data_ptr&lt;float&gt;()</span></code> for the PyTorch
tensor earlier). We also specify the output shape of the tensor, which we
hardcoded as <code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">x</span> <span class="pre">8</span></code>. The output of <code class="docutils literal notranslate"><span class="pre">torch::from_blob</span></code> is then a
<code class="docutils literal notranslate"><span class="pre">torch::Tensor</span></code>, pointing to the memory owned by the OpenCV matrix.</p>
<p>Before returning this tensor from our operator implementation, we must call
<code class="docutils literal notranslate"><span class="pre">.clone()</span></code> on the tensor to perform a memory copy of the underlying data. The
reason for this is that <code class="docutils literal notranslate"><span class="pre">torch::from_blob</span></code> returns a tensor that does not own
its data. At that point, the data is still owned by the OpenCV matrix. However,
this OpenCV matrix will go out of scope and be deallocated at the end of the
function. If we returned the <code class="docutils literal notranslate"><span class="pre">output</span></code> tensor as-is, it would point to invalid
memory by the time we use it outside the function. Calling <code class="docutils literal notranslate"><span class="pre">.clone()</span></code> returns
a new tensor with a copy of the original data that the new tensor owns itself.
It is thus safe to return to the outside world.</p>
</div>
<div class="section" id="registering-the-custom-operator-with-torchscript">
<h2>Registering the Custom Operator with TorchScript<a class="headerlink" href="#registering-the-custom-operator-with-torchscript" title="Permalink to this heading">¶</a></h2>
<p>Now that have implemented our custom operator in C++, we need to <em>register</em> it
with the TorchScript runtime and compiler. This will allow the TorchScript
compiler to resolve references to our custom operator in TorchScript code.
If you have ever used the pybind11 library, our syntax for registration
resembles the pybind11 syntax very closely.  To register a single function,
we write:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">TORCH_LIBRARY</span><span class="p">(</span><span class="n">my_ops</span><span class="p">,</span><span class="w"> </span><span class="n">m</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">m</span><span class="p">.</span><span class="n">def</span><span class="p">(</span><span class="s">"warp_perspective"</span><span class="p">,</span><span class="w"> </span><span class="n">warp_perspective</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>somewhere at the top level of our <code class="docutils literal notranslate"><span class="pre">op.cpp</span></code> file.  The <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code> macro
creates a function that will be called when your program starts.  The name
of your library (<code class="docutils literal notranslate"><span class="pre">my_ops</span></code>) is given as the first argument (it should not
be in quotes).  The second argument (<code class="docutils literal notranslate"><span class="pre">m</span></code>) defines a variable of type
<code class="docutils literal notranslate"><span class="pre">torch::Library</span></code> which is the main interface to register your operators.
The method <code class="docutils literal notranslate"><span class="pre">Library::def</span></code> actually creates an operator named <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code>,
exposing it to both Python and TorchScript.  You can define as many operators
as you like by making multiple calls to <code class="docutils literal notranslate"><span class="pre">def</span></code>.</p>
<p>Behinds the scenes, the <code class="docutils literal notranslate"><span class="pre">def</span></code> function is actually doing quite a bit of work:
it is using template metaprogramming to inspect the type signature of your
function and translate it into an operator schema which specifies the operators
type within TorchScript’s type system.</p>
</div>
<div class="section" id="building-the-custom-operator">
<h2>Building the Custom Operator<a class="headerlink" href="#building-the-custom-operator" title="Permalink to this heading">¶</a></h2>
<p>Now that we have implemented our custom operator in C++ and written its
registration code, it is time to build the operator into a (shared) library that
we can load into Python for research and experimentation, or into C++ for
inference in a no-Python environment. There exist multiple ways to build our
operator, using either pure CMake, or Python alternatives like <code class="docutils literal notranslate"><span class="pre">setuptools</span></code>.
For brevity, the paragraphs below only discuss the CMake approach. The appendix
of this tutorial dives into other alternatives.</p>
<div class="section" id="environment-setup">
<h3>Environment setup<a class="headerlink" href="#environment-setup" title="Permalink to this heading">¶</a></h3>
<p>We need an installation of PyTorch and OpenCV.  The easiest and most platform
independent way to get both is to via Conda:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">pytorch</span> <span class="n">pytorch</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">opencv</span>
</pre></div>
</div>
</div>
<div class="section" id="building-with-cmake">
<h3>Building with CMake<a class="headerlink" href="#building-with-cmake" title="Permalink to this heading">¶</a></h3>
<p>To build our custom operator into a shared library using the <a class="reference external" href="https://cmake.org">CMake</a> build system, we need to write a short <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code>
file and place it with our previous <code class="docutils literal notranslate"><span class="pre">op.cpp</span></code> file. For this, let’s agree on a
a directory structure that looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">warp</span><span class="o">-</span><span class="n">perspective</span><span class="o">/</span>
  <span class="n">op</span><span class="o">.</span><span class="n">cpp</span>
  <span class="n">CMakeLists</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<p>The contents of our <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> file should then be the following:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">cmake_minimum_required</span><span class="p">(</span><span class="n">VERSION</span><span class="w"> </span><span class="mf">3.1</span><span class="w"> </span><span class="n">FATAL_ERROR</span><span class="p">)</span>
<span class="n">project</span><span class="p">(</span><span class="n">warp_perspective</span><span class="p">)</span>

<span class="n">find_package</span><span class="p">(</span><span class="n">Torch</span><span class="w"> </span><span class="n">REQUIRED</span><span class="p">)</span>
<span class="n">find_package</span><span class="p">(</span><span class="n">OpenCV</span><span class="w"> </span><span class="n">REQUIRED</span><span class="p">)</span>

<span class="cp"># Define our library target</span>
<span class="n">add_library</span><span class="p">(</span><span class="n">warp_perspective</span><span class="w"> </span><span class="n">SHARED</span><span class="w"> </span><span class="n">op</span><span class="p">.</span><span class="n">cpp</span><span class="p">)</span>
<span class="cp"># Enable C++14</span>
<span class="n">target_compile_features</span><span class="p">(</span><span class="n">warp_perspective</span><span class="w"> </span><span class="n">PRIVATE</span><span class="w"> </span><span class="n">cxx_std_14</span><span class="p">)</span>
<span class="cp"># Link against LibTorch</span>
<span class="n">target_link_libraries</span><span class="p">(</span><span class="n">warp_perspective</span><span class="w"> </span><span class="s">"${TORCH_LIBRARIES}"</span><span class="p">)</span>
<span class="cp"># Link against OpenCV</span>
<span class="n">target_link_libraries</span><span class="p">(</span><span class="n">warp_perspective</span><span class="w"> </span><span class="n">opencv_core</span><span class="w"> </span><span class="n">opencv_imgproc</span><span class="p">)</span>
</pre></div>
</div>
<p>To now build our operator, we can run the following commands from our
<code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> folder:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>mkdir<span class="w"> </span>build
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
$<span class="w"> </span>cmake<span class="w"> </span>-DCMAKE_PREFIX_PATH<span class="o">=</span><span class="s2">"</span><span class="k">$(</span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">'import torch.utils; print(torch.utils.cmake_prefix_path)'</span><span class="k">)</span><span class="s2">"</span><span class="w"> </span>..
--<span class="w"> </span>The<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>The<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Found<span class="w"> </span>Threads:<span class="w"> </span>TRUE
--<span class="w"> </span>Found<span class="w"> </span>torch:<span class="w"> </span>/libtorch/lib/libtorch.so
--<span class="w"> </span>Configuring<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Generating<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Build<span class="w"> </span>files<span class="w"> </span>have<span class="w"> </span>been<span class="w"> </span>written<span class="w"> </span>to:<span class="w"> </span>/warp_perspective/build
$<span class="w"> </span>make<span class="w"> </span>-j
Scanning<span class="w"> </span>dependencies<span class="w"> </span>of<span class="w"> </span>target<span class="w"> </span>warp_perspective
<span class="o">[</span><span class="w"> </span><span class="m">50</span>%<span class="o">]</span><span class="w"> </span>Building<span class="w"> </span>CXX<span class="w"> </span>object<span class="w"> </span>CMakeFiles/warp_perspective.dir/op.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Linking<span class="w"> </span>CXX<span class="w"> </span>shared<span class="w"> </span>library<span class="w"> </span>libwarp_perspective.so
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Built<span class="w"> </span>target<span class="w"> </span>warp_perspective
</pre></div>
</div>
<p>which will place a <code class="docutils literal notranslate"><span class="pre">libwarp_perspective.so</span></code> shared library file in the
<code class="docutils literal notranslate"><span class="pre">build</span></code> folder. In the <code class="docutils literal notranslate"><span class="pre">cmake</span></code> command above, we use the helper
variable <code class="docutils literal notranslate"><span class="pre">torch.utils.cmake_prefix_path</span></code> to conveniently tell us where
the cmake files for our PyTorch install are.</p>
<p>We will explore how to use and call our operator in detail further below, but to
get an early sensation of success, we can try running the following code in
Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s2">"build/libwarp_perspective.so"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">)</span>
</pre></div>
</div>
<p>If all goes well, this should print something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">built</span><span class="o">-</span><span class="ow">in</span> <span class="n">method</span> <span class="n">my_ops</span><span class="p">::</span><span class="n">warp_perspective</span> <span class="n">of</span> <span class="n">PyCapsule</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f618fc6fa50</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>which is the Python function we will later use to invoke our custom operator.</p>
</div>
</div>
<div class="section" id="using-the-torchscript-custom-operator-in-python">
<h2>Using the TorchScript Custom Operator in Python<a class="headerlink" href="#using-the-torchscript-custom-operator-in-python" title="Permalink to this heading">¶</a></h2>
<p>Once our custom operator is built into a shared library  we are ready to use
this operator in our TorchScript models in Python. There are two parts to this:
first loading the operator into Python, and second using the operator in
TorchScript code.</p>
<p>You already saw how to import your operator into Python:
<code class="docutils literal notranslate"><span class="pre">torch.ops.load_library()</span></code>. This function takes the path to a shared library
containing custom operators, and loads it into the current process. Loading the
shared library will also execute the <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code> block. This will register
our custom operator with the TorchScript compiler and allow us to use that
operator in TorchScript code.</p>
<p>You can refer to your loaded operator as <code class="docutils literal notranslate"><span class="pre">torch.ops.&lt;namespace&gt;.&lt;function&gt;</span></code>,
where <code class="docutils literal notranslate"><span class="pre">&lt;namespace&gt;</span></code> is the namespace part of your operator name, and
<code class="docutils literal notranslate"><span class="pre">&lt;function&gt;</span></code> the function name of your operator. For the operator we wrote
above, the namespace was <code class="docutils literal notranslate"><span class="pre">my_ops</span></code> and the function name <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code>,
which means our operator is available as <code class="docutils literal notranslate"><span class="pre">torch.ops.my_ops.warp_perspective</span></code>.
While this function can be used in scripted or traced TorchScript modules, we
can also just use it in vanilla eager PyTorch and pass it regular PyTorch
tensors:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s2">"build/libwarp_perspective.so"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<p>producing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.3218</span><span class="p">,</span> <span class="mf">0.4611</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.3746</span><span class="p">,</span> <span class="mf">0.0978</span><span class="p">,</span> <span class="mf">0.5005</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">,</span> <span class="mf">0.4636</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.3245</span><span class="p">,</span> <span class="mf">0.0169</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.4458</span><span class="p">,</span> <span class="mf">0.4458</span><span class="p">,</span> <span class="mf">0.4458</span><span class="p">],</span>
      <span class="o">...</span><span class="p">,</span>
      <span class="p">[</span><span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1692</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1692</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">],</span>
      <span class="p">[</span><span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1862</span><span class="p">,</span> <span class="mf">0.1692</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">,</span> <span class="mf">0.0000</span><span class="p">]])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>What happens behind the scenes is that the first time you access
<code class="docutils literal notranslate"><span class="pre">torch.ops.namespace.function</span></code> in Python, the TorchScript compiler (in C++
land) will see if a function <code class="docutils literal notranslate"><span class="pre">namespace::function</span></code> has been registered, and
if so, return a Python handle to this function that we can subsequently use to
call into our C++ operator implementation from Python. This is one noteworthy
difference between TorchScript custom operators and C++ extensions: C++
extensions are bound manually using pybind11, while TorchScript custom ops are
bound on the fly by PyTorch itself. Pybind11 gives you more flexibility with
regards to what types and classes you can bind into Python and is thus
recommended for purely eager code, but it is not supported for TorchScript
ops.</p>
</div>
<p>From here on, you can use your custom operator in scripted or traced code just
as you would other functions from the <code class="docutils literal notranslate"><span class="pre">torch</span></code> package. In fact, “standard
library” functions like <code class="docutils literal notranslate"><span class="pre">torch.matmul</span></code> go through largely the same
registration path as custom operators, which makes custom operators really
first-class citizens when it comes to how and where they can be used in
TorchScript.  (One difference, however, is that standard library functions
have custom written Python argument parsing logic that differs from
<code class="docutils literal notranslate"><span class="pre">torch.ops</span></code> argument parsing.)</p>
<div class="section" id="using-the-custom-operator-with-tracing">
<h3>Using the Custom Operator with Tracing<a class="headerlink" href="#using-the-custom-operator-with-tracing" title="Permalink to this heading">¶</a></h3>
<p>Let’s start by embedding our operator in a traced function. Recall that for
tracing, we start with some vanilla Pytorch code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<p>and then call <code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code> on it. We further pass <code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code>
some example inputs, which it will forward to our implementation to record the
sequence of operations that occur as the inputs flow through it. The result of
this is effectively a “frozen” version of the eager PyTorch program, which the
TorchScript compiler can further analyze, optimize and serialize:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">compute</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>Producing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span><span class="p">(</span><span class="o">%</span><span class="n">x</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span><span class="p">),</span>
      <span class="o">%</span><span class="n">y</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">),</span>
      <span class="o">%</span><span class="n">z</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)):</span>
  <span class="o">%</span><span class="mi">3</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">matmul</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">,</span> <span class="o">%</span><span class="n">y</span><span class="p">)</span> <span class="c1"># test.py:10:0</span>
  <span class="o">%</span><span class="mi">4</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="n">z</span><span class="p">)</span> <span class="c1"># test.py:10:0</span>
  <span class="o">%</span><span class="mi">5</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">]()</span> <span class="c1"># test.py:10:0</span>
  <span class="o">%</span><span class="mi">6</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">add</span><span class="p">(</span><span class="o">%</span><span class="mi">3</span><span class="p">,</span> <span class="o">%</span><span class="mi">4</span><span class="p">,</span> <span class="o">%</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># test.py:10:0</span>
  <span class="k">return</span> <span class="p">(</span><span class="o">%</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, the exciting revelation is that we can simply drop our custom operator into
our PyTorch trace as if it were <code class="docutils literal notranslate"><span class="pre">torch.relu</span></code> or any other <code class="docutils literal notranslate"><span class="pre">torch</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<p>and then trace it as before:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)]</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">compute</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<p>Producing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">graph</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="mf">.1</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">4</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span><span class="p">),</span>
      <span class="o">%</span><span class="n">y</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">),</span>
      <span class="o">%</span><span class="n">z</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)):</span>
  <span class="o">%</span><span class="mi">3</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">3</span><span class="p">]()</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">4</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">6</span><span class="p">]()</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">5</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">]()</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">6</span> <span class="p">:</span> <span class="n">Device</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">]()</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">7</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">]()</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">8</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">3</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">eye</span><span class="p">(</span><span class="o">%</span><span class="mi">3</span><span class="p">,</span> <span class="o">%</span><span class="mi">4</span><span class="p">,</span> <span class="o">%</span><span class="mi">5</span><span class="p">,</span> <span class="o">%</span><span class="mi">6</span><span class="p">,</span> <span class="o">%</span><span class="mi">7</span><span class="p">)</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="n">x</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_ops</span><span class="p">::</span><span class="n">warp_perspective</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="mf">.1</span><span class="p">,</span> <span class="o">%</span><span class="mi">8</span><span class="p">)</span> <span class="c1"># test.py:25:0</span>
  <span class="o">%</span><span class="mi">10</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">matmul</span><span class="p">(</span><span class="o">%</span><span class="n">x</span><span class="p">,</span> <span class="o">%</span><span class="n">y</span><span class="p">)</span> <span class="c1"># test.py:26:0</span>
  <span class="o">%</span><span class="mi">11</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">relu</span><span class="p">(</span><span class="o">%</span><span class="n">z</span><span class="p">)</span> <span class="c1"># test.py:26:0</span>
  <span class="o">%</span><span class="mi">12</span> <span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">prim</span><span class="p">::</span><span class="n">Constant</span><span class="p">[</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">]()</span> <span class="c1"># test.py:26:0</span>
  <span class="o">%</span><span class="mi">13</span> <span class="p">:</span> <span class="n">Float</span><span class="p">(</span><span class="mi">8</span><span class="p">:</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">aten</span><span class="p">::</span><span class="n">add</span><span class="p">(</span><span class="o">%</span><span class="mi">10</span><span class="p">,</span> <span class="o">%</span><span class="mi">11</span><span class="p">,</span> <span class="o">%</span><span class="mi">12</span><span class="p">)</span> <span class="c1"># test.py:26:0</span>
  <span class="k">return</span> <span class="p">(</span><span class="o">%</span><span class="mi">13</span><span class="p">)</span>
</pre></div>
</div>
<p>Integrating TorchScript custom ops into traced PyTorch code is as easy as this!</p>
</div>
<div class="section" id="using-the-custom-operator-with-script">
<h3>Using the Custom Operator with Script<a class="headerlink" href="#using-the-custom-operator-with-script" title="Permalink to this heading">¶</a></h3>
<p>Besides tracing, another way to arrive at a TorchScript representation of a
PyTorch program is to directly write your code <em>in</em> TorchScript. TorchScript is
largely a subset of the Python language, with some restrictions that make it
easier for the TorchScript compiler to reason about programs. You turn your
regular PyTorch code into TorchScript by annotating it with
<code class="docutils literal notranslate"><span class="pre">@torch.jit.script</span></code> for free functions and <code class="docutils literal notranslate"><span class="pre">@torch.jit.script_method</span></code> for
methods in a class (which must also derive from <code class="docutils literal notranslate"><span class="pre">torch.jit.ScriptModule</span></code>). See
<a class="reference external" href="https://pytorch.org/docs/master/jit.html">here</a> for more details on
TorchScript annotations.</p>
<p>One particular reason to use TorchScript instead of tracing is that tracing is
unable to capture control flow in PyTorch code. As such, let us consider this
function which does use control flow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">42</span><span class="p">):</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">5</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">z</span>
</pre></div>
</div>
<p>To convert this function from vanilla PyTorch to TorchScript, we annotate it
with <code class="docutils literal notranslate"><span class="pre">@torch.jit.script</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">42</span><span class="p">):</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">5</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">z</span>
</pre></div>
</div>
<p>This will just-in-time compile the <code class="docutils literal notranslate"><span class="pre">compute</span></code> function into a graph
representation, which we can inspect in the <code class="docutils literal notranslate"><span class="pre">compute.graph</span></code> property:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">compute</span><span class="o">.</span><span class="n">graph</span>
<span class="go">graph(%x : Dynamic</span>
<span class="go">    %y : Dynamic) {</span>
<span class="go">  %14 : int = prim::Constant[value=1]()</span>
<span class="go">  %2 : int = prim::Constant[value=0]()</span>
<span class="go">  %7 : int = prim::Constant[value=42]()</span>
<span class="go">  %z.1 : int = prim::Constant[value=5]()</span>
<span class="go">  %z.2 : int = prim::Constant[value=10]()</span>
<span class="go">  %4 : Dynamic = aten::select(%x, %2, %2)</span>
<span class="go">  %6 : Dynamic = aten::select(%4, %2, %2)</span>
<span class="go">  %8 : Dynamic = aten::eq(%6, %7)</span>
<span class="go">  %9 : bool = prim::TensorToBool(%8)</span>
<span class="go">  %z : int = prim::If(%9)</span>
<span class="go">    block0() {</span>
<span class="go">      -&gt; (%z.1)</span>
<span class="go">    }</span>
<span class="go">    block1() {</span>
<span class="go">      -&gt; (%z.2)</span>
<span class="go">    }</span>
<span class="go">  %13 : Dynamic = aten::matmul(%x, %y)</span>
<span class="go">  %15 : Dynamic = aten::add(%13, %z, %14)</span>
<span class="go">  return (%15);</span>
<span class="go">}</span>
</pre></div>
</div>
<p>And now, just like before, we can use our custom operator like any other
function inside of our script code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s2">"libwarp_perspective.so"</span><span class="p">)</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">42</span><span class="p">):</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">5</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">z</span>
</pre></div>
</div>
<p>When the TorchScript compiler sees the reference to
<code class="docutils literal notranslate"><span class="pre">torch.ops.my_ops.warp_perspective</span></code>, it will find the implementation we
registered via the <code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code> function in C++, and compile it into its
graph representation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">compute</span><span class="o">.</span><span class="n">graph</span>
<span class="go">graph(%x.1 : Dynamic</span>
<span class="go">    %y : Dynamic) {</span>
<span class="go">    %20 : int = prim::Constant[value=1]()</span>
<span class="go">    %16 : int[] = prim::Constant[value=[0, -1]]()</span>
<span class="go">    %14 : int = prim::Constant[value=6]()</span>
<span class="go">    %2 : int = prim::Constant[value=0]()</span>
<span class="go">    %7 : int = prim::Constant[value=42]()</span>
<span class="go">    %z.1 : int = prim::Constant[value=5]()</span>
<span class="go">    %z.2 : int = prim::Constant[value=10]()</span>
<span class="go">    %13 : int = prim::Constant[value=3]()</span>
<span class="go">    %4 : Dynamic = aten::select(%x.1, %2, %2)</span>
<span class="go">    %6 : Dynamic = aten::select(%4, %2, %2)</span>
<span class="go">    %8 : Dynamic = aten::eq(%6, %7)</span>
<span class="go">    %9 : bool = prim::TensorToBool(%8)</span>
<span class="go">    %z : int = prim::If(%9)</span>
<span class="go">      block0() {</span>
<span class="go">        -&gt; (%z.1)</span>
<span class="go">      }</span>
<span class="go">      block1() {</span>
<span class="go">        -&gt; (%z.2)</span>
<span class="go">      }</span>
<span class="go">    %17 : Dynamic = aten::eye(%13, %14, %2, %16)</span>
<span class="go">    %x : Dynamic = my_ops::warp_perspective(%x.1, %17)</span>
<span class="go">    %19 : Dynamic = aten::matmul(%x, %y)</span>
<span class="go">    %21 : Dynamic = aten::add(%19, %z, %20)</span>
<span class="go">    return (%21);</span>
<span class="go">  }</span>
</pre></div>
</div>
<p>Notice in particular the reference to <code class="docutils literal notranslate"><span class="pre">my_ops::warp_perspective</span></code> at the end of
the graph.</p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The TorchScript graph representation is still subject to change. Do not rely
on it looking like this.</p>
</div>
<p>And that’s really it when it comes to using our custom operator in Python. In
short, you import the library containing your operator(s) using
<code class="docutils literal notranslate"><span class="pre">torch.ops.load_library</span></code>, and call your custom op like any other <code class="docutils literal notranslate"><span class="pre">torch</span></code>
operator from your traced or scripted TorchScript code.</p>
</div>
</div>
<div class="section" id="using-the-torchscript-custom-operator-in-c">
<h2>Using the TorchScript Custom Operator in C++<a class="headerlink" href="#using-the-torchscript-custom-operator-in-c" title="Permalink to this heading">¶</a></h2>
<p>One useful feature of TorchScript is the ability to serialize a model into an
on-disk file. This file can be sent over the wire, stored in a file system or,
more importantly, be dynamically deserialized and executed without needing to
keep the original source code around. This is possible in Python, but also in
C++. For this, PyTorch provides <a class="reference external" href="https://pytorch.org/cppdocs/">a pure C++ API</a>
for deserializing as well as executing TorchScript models. If you haven’t yet,
please read <a class="reference external" href="https://pytorch.org/tutorials/advanced/cpp_export.html">the tutorial on loading and running serialized TorchScript models
in C++</a>, on which the
next few paragraphs will build.</p>
<p>In short, custom operators can be executed just like regular <code class="docutils literal notranslate"><span class="pre">torch</span></code> operators
even when deserialized from a file and run in C++. The only requirement for this
is to link the custom operator shared library we built earlier with the C++
application in which we execute the model. In Python, this worked simply calling
<code class="docutils literal notranslate"><span class="pre">torch.ops.load_library</span></code>. In C++, you need to link the shared library with
your main application in whatever build system you are using. The following
example will showcase this using CMake.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Technically, you can also dynamically load the shared library into your C++
application at runtime in much the same way we did it in Python. On Linux,
<a class="reference external" href="https://tldp.org/HOWTO/Program-Library-HOWTO/dl-libraries.html">you can do this with dlopen</a>. There exist
equivalents on other platforms.</p>
</div>
<p>Building on the C++ execution tutorial linked above, let’s start with a minimal
C++ application in one file, <code class="docutils literal notranslate"><span class="pre">main.cpp</span></code> in a different folder from our
custom operator, that loads and executes a serialized TorchScript model:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;torch/script.h&gt;</span><span class="c1"> // One-stop header.</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;iostream&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;memory&gt;</span>


<span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">argv</span><span class="p">[])</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">argc</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">std</span><span class="o">::</span><span class="n">cerr</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">"usage: example-app &lt;path-to-exported-script-module&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">-1</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="c1">// Deserialize the ScriptModule from a file using torch::jit::load().</span>
<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">script</span><span class="o">::</span><span class="n">Module</span><span class="w"> </span><span class="k">module</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">load</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">::</span><span class="n">jit</span><span class="o">::</span><span class="n">IValue</span><span class="o">&gt;</span><span class="w"> </span><span class="n">inputs</span><span class="p">;</span>
<span class="w">  </span><span class="n">inputs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">}));</span>
<span class="w">  </span><span class="n">inputs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">torch</span><span class="o">::</span><span class="n">randn</span><span class="p">({</span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">}));</span>

<span class="w">  </span><span class="n">torch</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">module</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">move</span><span class="p">(</span><span class="n">inputs</span><span class="p">)).</span><span class="n">toTensor</span><span class="p">();</span>

<span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Along with a small <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> file:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.1</span><span class="w"> </span><span class="s">FATAL_ERROR</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">example_app</span><span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span><span class="s">Torch</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s2">"${TORCH_LIBRARIES}"</span><span class="p">)</span>
<span class="nb">target_compile_features</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">cxx_range_for</span><span class="p">)</span>
</pre></div>
</div>
<p>At this point, we should be able to build the application:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>mkdir<span class="w"> </span>build
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
$<span class="w"> </span>cmake<span class="w"> </span>-DCMAKE_PREFIX_PATH<span class="o">=</span><span class="s2">"</span><span class="k">$(</span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">'import torch.utils; print(torch.utils.cmake_prefix_path)'</span><span class="k">)</span><span class="s2">"</span><span class="w"> </span>..
--<span class="w"> </span>The<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>The<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Found<span class="w"> </span>Threads:<span class="w"> </span>TRUE
--<span class="w"> </span>Found<span class="w"> </span>torch:<span class="w"> </span>/libtorch/lib/libtorch.so
--<span class="w"> </span>Configuring<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Generating<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Build<span class="w"> </span>files<span class="w"> </span>have<span class="w"> </span>been<span class="w"> </span>written<span class="w"> </span>to:<span class="w"> </span>/example_app/build
$<span class="w"> </span>make<span class="w"> </span>-j
Scanning<span class="w"> </span>dependencies<span class="w"> </span>of<span class="w"> </span>target<span class="w"> </span>example_app
<span class="o">[</span><span class="w"> </span><span class="m">50</span>%<span class="o">]</span><span class="w"> </span>Building<span class="w"> </span>CXX<span class="w"> </span>object<span class="w"> </span>CMakeFiles/example_app.dir/main.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Linking<span class="w"> </span>CXX<span class="w"> </span>executable<span class="w"> </span>example_app
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Built<span class="w"> </span>target<span class="w"> </span>example_app
</pre></div>
</div>
<p>And run it without passing a model just yet:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./example_app
usage:<span class="w"> </span>example_app<span class="w"> </span>&lt;path-to-exported-script-module&gt;
</pre></div>
</div>
<p>Next, let’s serialize the script function we wrote earlier that uses our custom
operator:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s2">"libwarp_perspective.so"</span><span class="p">)</span>

<span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span>
<span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">bool</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">42</span><span class="p">):</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">5</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">z</span> <span class="o">=</span> <span class="mi">10</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">z</span>

<span class="n">compute</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"example.pt"</span><span class="p">)</span>
</pre></div>
</div>
<p>The last line will serialize the script function into a file called
“example.pt”. If we then pass this serialized model to our C++ application, we
can run it straight away:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./example_app<span class="w"> </span>example.pt
terminate<span class="w"> </span>called<span class="w"> </span>after<span class="w"> </span>throwing<span class="w"> </span>an<span class="w"> </span>instance<span class="w"> </span>of<span class="w"> </span><span class="s1">'torch::jit::script::ErrorReport'</span>
what<span class="o">()</span>:
Schema<span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">for</span><span class="w"> </span>node.<span class="w"> </span>File<span class="w"> </span>a<span class="w"> </span>bug<span class="w"> </span>report.
Node:<span class="w"> </span>%16<span class="w"> </span>:<span class="w"> </span><span class="nv">Dynamic</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>my_ops::warp_perspective<span class="o">(</span>%0,<span class="w"> </span>%19<span class="o">)</span>
</pre></div>
</div>
<p>Or maybe not. Maybe not just yet. Of course! We haven’t linked the custom
operator library with our application yet. Let’s do this right now, and to do it
properly let’s update our file organization slightly, to look like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">example_app</span><span class="o">/</span>
  <span class="n">CMakeLists</span><span class="o">.</span><span class="n">txt</span>
  <span class="n">main</span><span class="o">.</span><span class="n">cpp</span>
  <span class="n">warp_perspective</span><span class="o">/</span>
    <span class="n">CMakeLists</span><span class="o">.</span><span class="n">txt</span>
    <span class="n">op</span><span class="o">.</span><span class="n">cpp</span>
</pre></div>
</div>
<p>This will allow us to add the <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> library CMake target as a
subdirectory of our application target. The top level <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> in the
<code class="docutils literal notranslate"><span class="pre">example_app</span></code> folder should look like this:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">cmake_minimum_required</span><span class="p">(</span><span class="s">VERSION</span><span class="w"> </span><span class="s">3.1</span><span class="w"> </span><span class="s">FATAL_ERROR</span><span class="p">)</span>
<span class="nb">project</span><span class="p">(</span><span class="s">example_app</span><span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span><span class="s">Torch</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>

<span class="nb">add_subdirectory</span><span class="p">(</span><span class="s">warp_perspective</span><span class="p">)</span>

<span class="nb">add_executable</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s">main.cpp</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s2">"${TORCH_LIBRARIES}"</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s">-Wl,--no-as-needed</span><span class="w"> </span><span class="s">warp_perspective</span><span class="p">)</span>
<span class="nb">target_compile_features</span><span class="p">(</span><span class="s">example_app</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">cxx_range_for</span><span class="p">)</span>
</pre></div>
</div>
<p>This basic CMake configuration looks much like before, except that we add the
<code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> CMake build as a subdirectory. Once its CMake code runs, we
link our <code class="docutils literal notranslate"><span class="pre">example_app</span></code> application with the <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> shared
library.</p>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>There is one crucial detail embedded in the above example: The
<code class="docutils literal notranslate"><span class="pre">-Wl,--no-as-needed</span></code> prefix to the <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> link line. This is
required because we will not actually be calling any function from the
<code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> shared library in our application code. We only need the
<code class="docutils literal notranslate"><span class="pre">TORCH_LIBRARY</span></code> function to run. Inconveniently, this
confuses the linker and makes it think it can just skip linking against the
library altogether. On Linux, the <code class="docutils literal notranslate"><span class="pre">-Wl,--no-as-needed</span></code> flag forces the link
to happen (NB: this flag is specific to Linux!). There are other workarounds
for this. The simplest is to define <em>some function</em> in the operator library
that you need to call from the main application. This could be as simple as a
function <code class="docutils literal notranslate"><span class="pre">void</span> <span class="pre">init();</span></code> declared in some header, which is then defined as
<code class="docutils literal notranslate"><span class="pre">void</span> <span class="pre">init()</span> <span class="pre">{</span> <span class="pre">}</span></code> in the operator library. Calling this <code class="docutils literal notranslate"><span class="pre">init()</span></code> function
in the main application will give the linker the impression that this is a
library worth linking against. Unfortunately, this is outside of our control,
and we would rather let you know the reason and the simple workaround for this
than handing you some opaque macro to plop in your code.</p>
</div>
<p>Now, since we find the <code class="docutils literal notranslate"><span class="pre">Torch</span></code> package at the top level now, the
<code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> file in the  <code class="docutils literal notranslate"><span class="pre">warp_perspective</span></code> subdirectory can be
shortened a bit. It should look like this:</p>
<div class="highlight-cmake notranslate"><div class="highlight"><pre><span></span><span class="nb">find_package</span><span class="p">(</span><span class="s">OpenCV</span><span class="w"> </span><span class="s">REQUIRED</span><span class="p">)</span>
<span class="nb">add_library</span><span class="p">(</span><span class="s">warp_perspective</span><span class="w"> </span><span class="s">SHARED</span><span class="w"> </span><span class="s">op.cpp</span><span class="p">)</span>
<span class="nb">target_compile_features</span><span class="p">(</span><span class="s">warp_perspective</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">cxx_range_for</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">warp_perspective</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s2">"${TORCH_LIBRARIES}"</span><span class="p">)</span>
<span class="nb">target_link_libraries</span><span class="p">(</span><span class="s">warp_perspective</span><span class="w"> </span><span class="s">PRIVATE</span><span class="w"> </span><span class="s">opencv_core</span><span class="w"> </span><span class="s">opencv_photo</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s re-build our example app, which will also link with the custom operator
library. In the top level <code class="docutils literal notranslate"><span class="pre">example_app</span></code> directory:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>mkdir<span class="w"> </span>build
$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
$<span class="w"> </span>cmake<span class="w"> </span>-DCMAKE_PREFIX_PATH<span class="o">=</span><span class="s2">"</span><span class="k">$(</span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">'import torch.utils; print(torch.utils.cmake_prefix_path)'</span><span class="k">)</span><span class="s2">"</span><span class="w"> </span>..
--<span class="w"> </span>The<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>The<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>identification<span class="w"> </span>is<span class="w"> </span>GNU<span class="w"> </span><span class="m">5</span>.4.0
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>C<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/cc<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>C<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++
--<span class="w"> </span>Check<span class="w"> </span><span class="k">for</span><span class="w"> </span>working<span class="w"> </span>CXX<span class="w"> </span>compiler:<span class="w"> </span>/usr/bin/c++<span class="w"> </span>--<span class="w"> </span>works
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compiler<span class="w"> </span>ABI<span class="w"> </span>info<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features
--<span class="w"> </span>Detecting<span class="w"> </span>CXX<span class="w"> </span>compile<span class="w"> </span>features<span class="w"> </span>-<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread.h<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthreads<span class="w"> </span>-<span class="w"> </span>not<span class="w"> </span>found
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread
--<span class="w"> </span>Looking<span class="w"> </span><span class="k">for</span><span class="w"> </span>pthread_create<span class="w"> </span><span class="k">in</span><span class="w"> </span>pthread<span class="w"> </span>-<span class="w"> </span>found
--<span class="w"> </span>Found<span class="w"> </span>Threads:<span class="w"> </span>TRUE
--<span class="w"> </span>Found<span class="w"> </span>torch:<span class="w"> </span>/libtorch/lib/libtorch.so
--<span class="w"> </span>Configuring<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Generating<span class="w"> </span><span class="k">done</span>
--<span class="w"> </span>Build<span class="w"> </span>files<span class="w"> </span>have<span class="w"> </span>been<span class="w"> </span>written<span class="w"> </span>to:<span class="w"> </span>/warp_perspective/example_app/build
$<span class="w"> </span>make<span class="w"> </span>-j
Scanning<span class="w"> </span>dependencies<span class="w"> </span>of<span class="w"> </span>target<span class="w"> </span>warp_perspective
<span class="o">[</span><span class="w"> </span><span class="m">25</span>%<span class="o">]</span><span class="w"> </span>Building<span class="w"> </span>CXX<span class="w"> </span>object<span class="w"> </span>warp_perspective/CMakeFiles/warp_perspective.dir/op.cpp.o
<span class="o">[</span><span class="w"> </span><span class="m">50</span>%<span class="o">]</span><span class="w"> </span>Linking<span class="w"> </span>CXX<span class="w"> </span>shared<span class="w"> </span>library<span class="w"> </span>libwarp_perspective.so
<span class="o">[</span><span class="w"> </span><span class="m">50</span>%<span class="o">]</span><span class="w"> </span>Built<span class="w"> </span>target<span class="w"> </span>warp_perspective
Scanning<span class="w"> </span>dependencies<span class="w"> </span>of<span class="w"> </span>target<span class="w"> </span>example_app
<span class="o">[</span><span class="w"> </span><span class="m">75</span>%<span class="o">]</span><span class="w"> </span>Building<span class="w"> </span>CXX<span class="w"> </span>object<span class="w"> </span>CMakeFiles/example_app.dir/main.cpp.o
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Linking<span class="w"> </span>CXX<span class="w"> </span>executable<span class="w"> </span>example_app
<span class="o">[</span><span class="m">100</span>%<span class="o">]</span><span class="w"> </span>Built<span class="w"> </span>target<span class="w"> </span>example_app
</pre></div>
</div>
<p>If we now run the <code class="docutils literal notranslate"><span class="pre">example_app</span></code> binary and hand it our serialized model, we
should arrive at a happy ending:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>./example_app<span class="w"> </span>example.pt
<span class="m">11</span>.4125<span class="w">   </span><span class="m">5</span>.8262<span class="w">   </span><span class="m">9</span>.5345<span class="w">   </span><span class="m">8</span>.6111<span class="w">  </span><span class="m">12</span>.3997
<span class="w"> </span><span class="m">7</span>.4683<span class="w">  </span><span class="m">13</span>.5969<span class="w">   </span><span class="m">9</span>.0850<span class="w">  </span><span class="m">11</span>.0698<span class="w">   </span><span class="m">9</span>.4008
<span class="w"> </span><span class="m">7</span>.4597<span class="w">  </span><span class="m">15</span>.0926<span class="w">  </span><span class="m">12</span>.5727<span class="w">   </span><span class="m">8</span>.9319<span class="w">   </span><span class="m">9</span>.0666
<span class="w"> </span><span class="m">9</span>.4834<span class="w">  </span><span class="m">11</span>.1747<span class="w">   </span><span class="m">9</span>.0162<span class="w">  </span><span class="m">10</span>.9521<span class="w">   </span><span class="m">8</span>.6269
<span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000
<span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000
<span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000
<span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000<span class="w">  </span><span class="m">10</span>.0000
<span class="o">[</span><span class="w"> </span>Variable<span class="o">[</span>CPUFloatType<span class="o">]{</span><span class="m">8</span>,5<span class="o">}</span><span class="w"> </span><span class="o">]</span>
</pre></div>
</div>
<p>Success! You are now ready to inference away.</p>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">¶</a></h2>
<p>This tutorial walked you throw how to implement a custom TorchScript operator in
C++, how to build it into a shared library, how to use it in Python to define
TorchScript models and lastly how to load it into a C++ application for
inference workloads. You are now ready to extend your TorchScript models with
C++ operators that interface with third party C++ libraries, write custom high
performance CUDA kernels, or implement any other use case that requires the
lines between Python, TorchScript and C++ to blend smoothly.</p>
<p>As always, if you run into any problems or have questions, you can use our
<a class="reference external" href="https://discuss.pytorch.org/">forum</a> or <a class="reference external" href="https://github.com/pytorch/pytorch/issues">GitHub issues</a> to get in touch. Also, our
<a class="reference external" href="https://pytorch.org/cppdocs/notes/faq.html">frequently asked questions (FAQ) page</a> may have helpful information.</p>
</div>
<div class="section" id="appendix-a-more-ways-of-building-custom-operators">
<h2>Appendix A: More Ways of Building Custom Operators<a class="headerlink" href="#appendix-a-more-ways-of-building-custom-operators" title="Permalink to this heading">¶</a></h2>
<p>The section “Building the Custom Operator” explained how to build a custom
operator into a shared library using CMake. This appendix outlines two further
approaches for compilation. Both of them use Python as the “driver” or
“interface” to the compilation process. Also, both re-use the <a class="reference external" href="https://pytorch.org/docs/stable/cpp_extension.html">existing
infrastructure</a> PyTorch
provides for <a class="reference external" href="https://pytorch.org/tutorials/advanced/cpp_extension.html">*C++ extensions*</a>, which are the
vanilla (eager) PyTorch equivalent of TorchScript custom operators that rely on
<a class="reference external" href="https://github.com/pybind/pybind11">pybind11</a> for “explicit” binding of
functions from C++ into Python.</p>
<p>The first approach uses C++ extensions’ <a class="reference external" href="https://pytorch.org/docs/stable/cpp_extension.html#torch.utils.cpp_extension.load">convenient just-in-time (JIT)
compilation interface</a>
to compile your code in the background of your PyTorch script the first time you
run it. The second approach relies on the venerable <code class="docutils literal notranslate"><span class="pre">setuptools</span></code> package and
involves writing a separate <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> file. This allows more advanced
configuration as well as integration with other <code class="docutils literal notranslate"><span class="pre">setuptools</span></code>-based projects.
We will explore both approaches in detail below.</p>
<div class="section" id="building-with-jit-compilation">
<h3>Building with JIT compilation<a class="headerlink" href="#building-with-jit-compilation" title="Permalink to this heading">¶</a></h3>
<p>The JIT compilation feature provided by the PyTorch C++ extension toolkit allows
embedding the compilation of your custom operator directly into your Python
code, e.g. at the top of your training script.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>“JIT compilation” here has nothing to do with the JIT compilation taking place
in the TorchScript compiler to optimize your program. It simply means that
your custom operator C++ code will be compiled in a folder under your system’s
<cite>/tmp</cite> directory the first time you import it, as if you had compiled it
yourself beforehand.</p>
</div>
<p>This JIT compilation feature comes in two flavors. In the first, you still keep
your operator implementation in a separate file (<code class="docutils literal notranslate"><span class="pre">op.cpp</span></code>), and then use
<code class="docutils literal notranslate"><span class="pre">torch.utils.cpp_extension.load()</span></code> to compile your extension. Usually, this
function will return the Python module exposing your C++ extension. However,
since we are not compiling our custom operator into its own Python module, we
only want to compile a plain shared library . Fortunately,
<code class="docutils literal notranslate"><span class="pre">torch.utils.cpp_extension.load()</span></code> has an argument <code class="docutils literal notranslate"><span class="pre">is_python_module</span></code> which
we can set to <code class="docutils literal notranslate"><span class="pre">False</span></code> to indicate that we are only interested in building a
shared library and not a Python module. <code class="docutils literal notranslate"><span class="pre">torch.utils.cpp_extension.load()</span></code>
will then compile and also load the shared library into the current process,
just like <code class="docutils literal notranslate"><span class="pre">torch.ops.load_library</span></code> did before:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.utils.cpp_extension</span>

<span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">cpp_extension</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"warp_perspective"</span><span class="p">,</span>
    <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="s2">"op.cpp"</span><span class="p">],</span>
    <span class="n">extra_ldflags</span><span class="o">=</span><span class="p">[</span><span class="s2">"-lopencv_core"</span><span class="p">,</span> <span class="s2">"-lopencv_imgproc"</span><span class="p">],</span>
    <span class="n">is_python_module</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">)</span>
</pre></div>
</div>
<p>This should approximately print:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">built</span><span class="o">-</span><span class="ow">in</span> <span class="n">method</span> <span class="n">my_ops</span><span class="p">::</span><span class="n">warp_perspective</span> <span class="n">of</span> <span class="n">PyCapsule</span> <span class="nb">object</span> <span class="n">at</span> <span class="mh">0x7f3e0f840b10</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The second flavor of JIT compilation allows you to pass the source code for your
custom TorchScript operator as a string. For this, use
<code class="docutils literal notranslate"><span class="pre">torch.utils.cpp_extension.load_inline</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.cpp_extension</span>

<span class="n">op_source</span> <span class="o">=</span> <span class="s2">"""</span>
<span class="s2">#include &lt;opencv2/opencv.hpp&gt;</span>
<span class="s2">#include &lt;torch/script.h&gt;</span>

<span class="s2">torch::Tensor warp_perspective(torch::Tensor image, torch::Tensor warp) {</span>
<span class="s2">  cv::Mat image_mat(/*rows=*/image.size(0),</span>
<span class="s2">                    /*cols=*/image.size(1),</span>
<span class="s2">                    /*type=*/CV_32FC1,</span>
<span class="s2">                    /*data=*/image.data&lt;float&gt;());</span>
<span class="s2">  cv::Mat warp_mat(/*rows=*/warp.size(0),</span>
<span class="s2">                   /*cols=*/warp.size(1),</span>
<span class="s2">                   /*type=*/CV_32FC1,</span>
<span class="s2">                   /*data=*/warp.data&lt;float&gt;());</span>

<span class="s2">  cv::Mat output_mat;</span>
<span class="s2">  cv::warpPerspective(image_mat, output_mat, warp_mat, /*dsize=*/{64, 64});</span>

<span class="s2">  torch::Tensor output =</span>
<span class="s2">    torch::from_blob(output_mat.ptr&lt;float&gt;(), /*sizes=*/{64, 64});</span>
<span class="s2">  return output.clone();</span>
<span class="s2">}</span>

<span class="s2">TORCH_LIBRARY(my_ops, m) {</span>
<span class="s2">  m.def("warp_perspective", &amp;warp_perspective);</span>
<span class="s2">}</span>
<span class="s2">"""</span>

<span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">cpp_extension</span><span class="o">.</span><span class="n">load_inline</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"warp_perspective"</span><span class="p">,</span>
    <span class="n">cpp_sources</span><span class="o">=</span><span class="n">op_source</span><span class="p">,</span>
    <span class="n">extra_ldflags</span><span class="o">=</span><span class="p">[</span><span class="s2">"-lopencv_core"</span><span class="p">,</span> <span class="s2">"-lopencv_imgproc"</span><span class="p">],</span>
    <span class="n">is_python_module</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">)</span>
</pre></div>
</div>
<p>Naturally, it is best practice to only use
<code class="docutils literal notranslate"><span class="pre">torch.utils.cpp_extension.load_inline</span></code> if your source code is reasonably
short.</p>
<p>Note that if you’re using this in a Jupyter Notebook, you should not execute
the cell with the registration multiple times because each execution registers
a new library and re-registers the custom operator. If you need to re-execute it,
please restart the Python kernel of your notebook beforehand.</p>
</div>
<div class="section" id="building-with-setuptools">
<h3>Building with Setuptools<a class="headerlink" href="#building-with-setuptools" title="Permalink to this heading">¶</a></h3>
<p>The second approach to building our custom operator exclusively from Python is
to use <code class="docutils literal notranslate"><span class="pre">setuptools</span></code>. This has the advantage that <code class="docutils literal notranslate"><span class="pre">setuptools</span></code> has a quite
powerful and extensive interface for building Python modules written in C++.
However, since <code class="docutils literal notranslate"><span class="pre">setuptools</span></code> is really intended for building Python modules and
not plain shared libraries (which do not have the necessary entry points Python
expects from a module), this route can be slightly quirky. That said, all you
need is a <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> file in place of the <code class="docutils literal notranslate"><span class="pre">CMakeLists.txt</span></code> which looks like
this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">setuptools</span> <span class="kn">import</span> <span class="n">setup</span>
<span class="kn">from</span> <span class="nn">torch.utils.cpp_extension</span> <span class="kn">import</span> <span class="n">BuildExtension</span><span class="p">,</span> <span class="n">CppExtension</span>

<span class="n">setup</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"warp_perspective"</span><span class="p">,</span>
    <span class="n">ext_modules</span><span class="o">=</span><span class="p">[</span>
        <span class="n">CppExtension</span><span class="p">(</span>
            <span class="s2">"warp_perspective"</span><span class="p">,</span>
            <span class="p">[</span><span class="s2">"example_app/warp_perspective/op.cpp"</span><span class="p">],</span>
            <span class="n">libraries</span><span class="o">=</span><span class="p">[</span><span class="s2">"opencv_core"</span><span class="p">,</span> <span class="s2">"opencv_imgproc"</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">],</span>
    <span class="n">cmdclass</span><span class="o">=</span><span class="p">{</span><span class="s2">"build_ext"</span><span class="p">:</span> <span class="n">BuildExtension</span><span class="o">.</span><span class="n">with_options</span><span class="p">(</span><span class="n">no_python_abi_suffix</span><span class="o">=</span><span class="kc">True</span><span class="p">)},</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Notice that we enabled the <code class="docutils literal notranslate"><span class="pre">no_python_abi_suffix</span></code> option in the
<code class="docutils literal notranslate"><span class="pre">BuildExtension</span></code> at the bottom. This instructs <code class="docutils literal notranslate"><span class="pre">setuptools</span></code> to omit any
Python-3 specific ABI suffixes in the name of the produced shared library.
Otherwise, on Python 3.7 for example, the library may be called
<code class="docutils literal notranslate"><span class="pre">warp_perspective.cpython-37m-x86_64-linux-gnu.so</span></code> where
<code class="docutils literal notranslate"><span class="pre">cpython-37m-x86_64-linux-gnu</span></code> is the ABI tag, but we really just want it to
be called <code class="docutils literal notranslate"><span class="pre">warp_perspective.so</span></code></p>
<p>If we now run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">build</span> <span class="pre">develop</span></code> in a terminal from within the
folder in which <code class="docutils literal notranslate"><span class="pre">setup.py</span></code> is situated, we should see something like:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>python<span class="w"> </span>setup.py<span class="w"> </span>build<span class="w"> </span>develop
running<span class="w"> </span>build
running<span class="w"> </span>build_ext
building<span class="w"> </span><span class="s1">'warp_perspective'</span><span class="w"> </span>extension
creating<span class="w"> </span>build
creating<span class="w"> </span>build/temp.linux-x86_64-3.7
gcc<span class="w"> </span>-pthread<span class="w"> </span>-B<span class="w"> </span>/root/local/miniconda/compiler_compat<span class="w"> </span>-Wl,--sysroot<span class="o">=</span>/<span class="w"> </span>-Wsign-compare<span class="w"> </span>-DNDEBUG<span class="w"> </span>-g<span class="w"> </span>-fwrapv<span class="w"> </span>-O3<span class="w"> </span>-Wall<span class="w"> </span>-Wstrict-prototypes<span class="w"> </span>-fPIC<span class="w"> </span>-I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include<span class="w"> </span>-I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/torch/csrc/api/include<span class="w"> </span>-I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/TH<span class="w"> </span>-I/root/local/miniconda/lib/python3.7/site-packages/torch/lib/include/THC<span class="w"> </span>-I/root/local/miniconda/include/python3.7m<span class="w"> </span>-c<span class="w"> </span>op.cpp<span class="w"> </span>-o<span class="w"> </span>build/temp.linux-x86_64-3.7/op.o<span class="w"> </span>-DTORCH_API_INCLUDE_EXTENSION_H<span class="w"> </span>-DTORCH_EXTENSION_NAME<span class="o">=</span>warp_perspective<span class="w"> </span>-D_GLIBCXX_USE_CXX11_ABI<span class="o">=</span><span class="m">0</span><span class="w"> </span>-std<span class="o">=</span>c++11
cc1plus:<span class="w"> </span>warning:<span class="w"> </span><span class="nb">command</span><span class="w"> </span>line<span class="w"> </span>option<span class="w"> </span>‘-Wstrict-prototypes’<span class="w"> </span>is<span class="w"> </span>valid<span class="w"> </span><span class="k">for</span><span class="w"> </span>C/ObjC<span class="w"> </span>but<span class="w"> </span>not<span class="w"> </span><span class="k">for</span><span class="w"> </span>C++
creating<span class="w"> </span>build/lib.linux-x86_64-3.7
g++<span class="w"> </span>-pthread<span class="w"> </span>-shared<span class="w"> </span>-B<span class="w"> </span>/root/local/miniconda/compiler_compat<span class="w"> </span>-L/root/local/miniconda/lib<span class="w"> </span>-Wl,-rpath<span class="o">=</span>/root/local/miniconda/lib<span class="w"> </span>-Wl,--no-as-needed<span class="w"> </span>-Wl,--sysroot<span class="o">=</span>/<span class="w"> </span>build/temp.linux-x86_64-3.7/op.o<span class="w"> </span>-lopencv_core<span class="w"> </span>-lopencv_imgproc<span class="w"> </span>-o<span class="w"> </span>build/lib.linux-x86_64-3.7/warp_perspective.so
running<span class="w"> </span>develop
running<span class="w"> </span>egg_info
creating<span class="w"> </span>warp_perspective.egg-info
writing<span class="w"> </span>warp_perspective.egg-info/PKG-INFO
writing<span class="w"> </span>dependency_links<span class="w"> </span>to<span class="w"> </span>warp_perspective.egg-info/dependency_links.txt
writing<span class="w"> </span>top-level<span class="w"> </span>names<span class="w"> </span>to<span class="w"> </span>warp_perspective.egg-info/top_level.txt
writing<span class="w"> </span>manifest<span class="w"> </span>file<span class="w"> </span><span class="s1">'warp_perspective.egg-info/SOURCES.txt'</span>
reading<span class="w"> </span>manifest<span class="w"> </span>file<span class="w"> </span><span class="s1">'warp_perspective.egg-info/SOURCES.txt'</span>
writing<span class="w"> </span>manifest<span class="w"> </span>file<span class="w"> </span><span class="s1">'warp_perspective.egg-info/SOURCES.txt'</span>
running<span class="w"> </span>build_ext
copying<span class="w"> </span>build/lib.linux-x86_64-3.7/warp_perspective.so<span class="w"> </span>-&gt;
Creating<span class="w"> </span>/root/local/miniconda/lib/python3.7/site-packages/warp-perspective.egg-link<span class="w"> </span><span class="o">(</span>link<span class="w"> </span>to<span class="w"> </span>.<span class="o">)</span>
Adding<span class="w"> </span>warp-perspective<span class="w"> </span><span class="m">0</span>.0.0<span class="w"> </span>to<span class="w"> </span>easy-install.pth<span class="w"> </span>file

Installed<span class="w"> </span>/warp_perspective
Processing<span class="w"> </span>dependencies<span class="w"> </span><span class="k">for</span><span class="w"> </span>warp-perspective<span class="o">==</span><span class="m">0</span>.0.0
Finished<span class="w"> </span>processing<span class="w"> </span>dependencies<span class="w"> </span><span class="k">for</span><span class="w"> </span>warp-perspective<span class="o">==</span><span class="m">0</span>.0.0
</pre></div>
</div>
<p>This will produce a shared library called <code class="docutils literal notranslate"><span class="pre">warp_perspective.so</span></code>, which we can
pass to <code class="docutils literal notranslate"><span class="pre">torch.ops.load_library</span></code> as we did earlier to make our operator
visible to TorchScript:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">load_library</span><span class="p">(</span><span class="s2">"warp_perspective.so"</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_ops</span><span class="o">.</span><span class="n">warp_perspective</span><span class="p">)</span>
<span class="go">&lt;built-in method custom::warp_perspective of PyCapsule object at 0x7ff51c5b7bd0&gt;</span>
</pre></div>
</div>
</div>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="torch_script_custom_classes.html" rel="next" title="Extending TorchScript with Custom C++ Classes">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="cpp_extension.html" rel="prev" title="Custom C++ and CUDA Extensions"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="rating-hr hr-top"/>
<div class="rating-container">
<div class="rating-prompt">Rate this Tutorial</div>
<div class="stars-outer">
<i class="far fa-star" data-behavior="tutorial-rating" data-count="1" title="1 Star"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="2" title="2 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="3" title="3 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="4" title="4 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="5" title="5 Stars"></i>
</div>
</div>
<hr class="rating-hr hr-bottom">
<div role="contentinfo">
<p>
        © Copyright 2024, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</hr></footer>
</div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Extending TorchScript with Custom C++ Operators</a><ul>
<li><a class="reference internal" href="#implementing-the-custom-operator-in-c">Implementing the Custom Operator in C++</a></li>
<li><a class="reference internal" href="#registering-the-custom-operator-with-torchscript">Registering the Custom Operator with TorchScript</a></li>
<li><a class="reference internal" href="#building-the-custom-operator">Building the Custom Operator</a><ul>
<li><a class="reference internal" href="#environment-setup">Environment setup</a></li>
<li><a class="reference internal" href="#building-with-cmake">Building with CMake</a></li>
</ul>
</li>
<li><a class="reference internal" href="#using-the-torchscript-custom-operator-in-python">Using the TorchScript Custom Operator in Python</a><ul>
<li><a class="reference internal" href="#using-the-custom-operator-with-tracing">Using the Custom Operator with Tracing</a></li>
<li><a class="reference internal" href="#using-the-custom-operator-with-script">Using the Custom Operator with Script</a></li>
</ul>
</li>
<li><a class="reference internal" href="#using-the-torchscript-custom-operator-in-c">Using the TorchScript Custom Operator in C++</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
<li><a class="reference internal" href="#appendix-a-more-ways-of-building-custom-operators">Appendix A: More Ways of Building Custom Operators</a><ul>
<li><a class="reference internal" href="#building-with-jit-compilation">Building with JIT compilation</a></li>
<li><a class="reference internal" href="#building-with-setuptools">Building with Setuptools</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/katex.min.js"></script>
<script src="../_static/auto-render.min.js"></script>
<script src="../_static/katex_autorenderer.js"></script>
<script src="../_static/design-tabs.js"></script>
<script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });
    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count"),
      'customEvent:Rating': $(this).attr("data-count") // send to GA custom dimension customEvent:Rating.
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1">
</img></noscript>
<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Mobile'];
</script>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1">
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">Stay up to date</li>
<li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">PyTorch Podcasts</li>
<li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
<li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
<li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
</ul>
</div>
</div>
<div class="privacy-policy">
<ul>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
<li class="privacy-policy-links">|</li>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
</ul>
</div>
<div class="copyright">
<p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg"/>
</div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li class="resources-mobile-menu-title">
            Docs
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
</li>
<li>
<a href="https://pytorch.org/text/stable/index.html">torchtext</a>
</li>
<li>
<a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
</li>
<li>
<a href="https://pytorch.org/torcharrow">torcharrow</a>
</li>
<li>
<a href="https://pytorch.org/data">TorchData</a>
</li>
<li>
<a href="https://pytorch.org/torchrec">TorchRec</a>
</li>
<li>
<a href="https://pytorch.org/serve/">TorchServe</a>
</li>
<li>
<a href="https://pytorch.org/torchx/">TorchX</a>
</li>
<li>
<a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
            Resources
          </li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/features">About</a>
</li>
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/#community-module">Community</a>
</li>
<li>
<a href="https://pytorch.org/community-stories">Community Stories</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/hub">Models (Beta)</a>
</li>
</ul>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</img></body>
</html>