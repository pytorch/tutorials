

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Neural Transfer with PyTorch &mdash; PyTorch Tutorials 0.2.0_4 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/css/pytorch_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PyTorch Tutorials 0.2.0_4 documentation" href="../index.html"/>
        <link rel="next" title="Creating extensions using numpy and scipy" href="numpy_extensions_tutorial.html"/>
        <link rel="prev" title="Spatial Transformer Networks Tutorial" href="../intermediate/spatial_transformer_tutorial.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyTorch Tutorials
          

          
            
            <img src="../_static/pytorch-logo-dark.svg" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.2.0_4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Beginner Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html">What is PyTorch?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#tensors">Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#operations">Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html">Autograd: automatic differentiation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html">Neural Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#define-the-network">Define the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#loss-function">Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#backprop">Backprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/neural_networks_tutorial.html#update-the-weights">Update the weights</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html">Training a classifier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#what-about-data">What about data?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#training-an-image-classifier">Training an image classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#loading-and-normalizing-cifar10">1. Loading and normalizing CIFAR10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#define-a-convolution-neural-network">2. Define a Convolution Neural Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer">3. Define a Loss function and optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#train-the-network">4. Train the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#test-the-network-on-the-test-data">5. Test the network on the test data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#training-on-gpu">Training on GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/blitz/cifar10_tutorial.html#where-do-i-go-next">Where do I go next?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/former_torchies_tutorial.html">PyTorch for former Torch users</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#inplace-out-of-place">Inplace / Out-of-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#zero-indexing">Zero Indexing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#no-camel-casing">No camel casing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html">nn package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#example-1-convnet">Example 1: ConvNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#forward-and-backward-function-hooks">Forward and Backward Function Hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/nn_tutorial.html#example-2-recurrent-net">Example 2: Recurrent Net</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html">Multi-GPU examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html#dataparallel">DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/former_torchies/parallelism_tutorial.html#part-of-the-model-on-cpu-and-part-on-the-gpu">Part of the model on CPU and part on the GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#warm-up-numpy">Warm-up: numpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-tensors">PyTorch: Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#autograd">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-variables-and-autograd">PyTorch: Variables and autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-defining-new-autograd-functions">PyTorch: Defining new autograd functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#tensorflow-static-graphs">TensorFlow: Static Graphs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#nn-module"><cite>nn</cite> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-nn">PyTorch: nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-optim">PyTorch: optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-custom-nn-modules">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#pytorch-control-flow-weight-sharing">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/pytorch_with_examples.html#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id1">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_tensor/two_layer_net_numpy.html">Warm-up: numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_tensor/two_layer_net_tensor.html">PyTorch: Tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id2">Autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/two_layer_net_autograd.html">PyTorch: Variables and autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch: Defining new autograd functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_autograd/tf_two_layer_net.html">TensorFlow: Static Graphs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/pytorch_with_examples.html#id3"><cite>nn</cite> module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_nn.html">PyTorch: nn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_optim.html">PyTorch: optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/two_layer_net_module.html">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/examples_nn/dynamic_net.html">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#load-data">Load Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#visualize-a-few-images">Visualize a few images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#training-the-model">Training the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#visualizing-the-model-predictions">Visualizing the model predictions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#finetuning-the-convnet">Finetuning the convnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#train-and-evaluate">Train and evaluate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor">ConvNet as fixed feature extractor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html#id1">Train and evaluate</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/data_loading_tutorial.html">Data Loading and Processing Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#dataset-class">Dataset class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/data_loading_tutorial.html#compose-transforms">Compose transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#iterating-through-the-dataset">Iterating through the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/data_loading_tutorial.html#afterword-torchvision">Afterword: torchvision</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html">Introduction to PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#introduction-to-torch-s-tensor-library">Introduction to Torch’s tensor library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#creating-tensors">Creating Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#operations-with-tensors">Operations with Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#reshaping-tensors">Reshaping Tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/pytorch_tutorial.html#computation-graphs-and-automatic-differentiation">Computation Graphs and Automatic Differentiation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html">Deep Learning with PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#deep-learning-building-blocks-affine-maps-non-linearities-and-objectives">Deep Learning Building Blocks: Affine maps, non-linearities and objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#affine-maps">Affine Maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#non-linearities">Non-Linearities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#softmax-and-probabilities">Softmax and Probabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#objective-functions">Objective Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#optimization-and-training">Optimization and Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#creating-network-components-in-pytorch">Creating Network Components in Pytorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../beginner/nlp/deep_learning_tutorial.html#example-logistic-regression-bag-of-words-classifier">Example: Logistic Regression Bag-of-Words classifier</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html">Word Embeddings: Encoding Lexical Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#getting-dense-word-embeddings">Getting Dense Word Embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#word-embeddings-in-pytorch">Word Embeddings in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling">An Example: N-Gram Language Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words">Exercise: Computing Word Embeddings: Continuous Bag-of-Words</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html">Sequence Models and Long-Short Term Memory Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#lstm-s-in-pytorch">LSTM’s in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging">Example: An LSTM for Part-of-Speech Tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/sequence_models_tutorial.html#exercise-augmenting-the-lstm-part-of-speech-tagger-with-character-level-features">Exercise: Augmenting the LSTM part-of-speech tagger with character-level features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html">Advanced: Making Dynamic Decisions and the Bi-LSTM CRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#dynamic-versus-static-deep-learning-toolkits">Dynamic versus Static Deep Learning Toolkits</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#bi-lstm-conditional-random-field-discussion">Bi-LSTM Conditional Random Field Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../beginner/nlp/advanced_tutorial.html#exercise-a-new-loss-function-for-discriminative-tagging">Exercise: A new loss function for discriminative tagging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Intermediate Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-the-data">Preparing the Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#turning-names-into-tensors">Turning Names into Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#plotting-the-results">Plotting the Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#evaluating-the-results">Evaluating the Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#running-on-user-input">Running on User Input</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-the-data">Preparing the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#plotting-the-losses">Plotting the Losses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#sampling-the-network">Sampling the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#loading-data-files">Loading data files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model">The Seq2Seq Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-encoder">The Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-decoder">The Decoder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#simple-decoder">Simple Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#attention-decoder">Attention Decoder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#preparing-training-data">Preparing Training Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-the-model">Training the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#plotting-results">Plotting results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#evaluation">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-and-evaluating">Training and Evaluating</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#visualizing-attention">Visualizing Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#replay-memory">Replay Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#dqn-algorithm">DQN algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#q-network">Q-network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#input-extraction">Input extraction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#hyperparameters-and-utilities">Hyperparameters and utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training-loop">Training loop</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#point-to-point-communication">Point-to-Point Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#collective-communication">Collective Communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#distributed-training">Distributed Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#our-own-ring-allreduce">Our Own Ring-Allreduce</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/dist_tuto.html#advanced-topics">Advanced Topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#communication-backends">Communication Backends</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/dist_tuto.html#initialization-methods">Initialization Methods</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#loading-the-data">Loading the data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#depicting-spatial-transformer-networks">Depicting spatial transformer networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#training-the-model">Training the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html#visualizing-the-stn-results">Visualizing the STN results</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Advanced Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Neural Transfer with PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#neural-what">Neural what?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-does-it-work">How does it work?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#ok-how-does-it-work">OK. How does it work?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pytorch-implementation">PyTorch implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#packages">Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cuda">Cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-images">Load images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#display-images">Display images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#content-loss">Content loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#style-loss">Style loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-the-neural-network">Load the neural network</a></li>
<li class="toctree-l3"><a class="reference internal" href="#input-image">Input image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gradient-descent">Gradient descent</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parameter-less-example">Parameter-less example</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parametrized-example">Parametrized example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_caffe2.html">Transfering a model from PyTorch to Caffe2 and Mobile using ONNX</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_resolution_with_caffe2.html#transfering-srresnet-using-onnx">Transfering SRResNet using ONNX</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_resolution_with_caffe2.html#running-the-model-on-mobile-devices">Running the model on mobile devices</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="c_extension.html">Custom C extensions for pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="c_extension.html#step-1-prepare-your-c-code">Step 1. prepare your C code</a></li>
<li class="toctree-l2"><a class="reference internal" href="c_extension.html#step-2-include-it-in-your-python-code">Step 2: Include it in your Python code</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyTorch Tutorials</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Neural Transfer with PyTorch</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced/neural_style_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="neural-transfer-with-pytorch">
<span id="sphx-glr-advanced-neural-style-tutorial-py"></span><h1>Neural Transfer with PyTorch<a class="headerlink" href="#neural-transfer-with-pytorch" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://alexis-jacq.github.io">Alexis Jacq</a></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Welcome! This tutorial explains how to impletment the
<a class="reference external" href="https://arxiv.org/abs/1508.06576">Neural-Style</a> algorithm developed
by Leon A. Gatys, Alexander S. Ecker and Matthias Bethge.</p>
<div class="section" id="neural-what">
<h3>Neural what?<a class="headerlink" href="#neural-what" title="Permalink to this headline">¶</a></h3>
<p>The Neural-Style, or Neural-Transfer, is an algorithm that takes as
input a content-image (e.g. a tortle), a style-image (e.g. artistic
waves) and return the content of the content-image as if it was
‘painted’ using the artistic style of the style-image:</p>
<div class="figure">
<img alt="content1" src="../_images/neuralstyle.png" />
</div>
</div>
<div class="section" id="how-does-it-work">
<h3>How does it work?<a class="headerlink" href="#how-does-it-work" title="Permalink to this headline">¶</a></h3>
<p>The principle is simple: we define two distances, one for the content
(<span class="math">\(D_C\)</span>) and one for the style (<span class="math">\(D_S\)</span>). <span class="math">\(D_C\)</span> measures
how different the content is between two images, while <span class="math">\(D_S\)</span>
measures how different the style is between two images. Then, we take a
third image, the input, (e.g. a with noise), and we transform it in
order to both minimize its content-distance with the content-image and
its style-distance with the style-image.</p>
<div class="section" id="ok-how-does-it-work">
<h4>OK. How does it work?<a class="headerlink" href="#ok-how-does-it-work" title="Permalink to this headline">¶</a></h4>
<p>Well, going further requires some mathematics. Let <span class="math">\(C_{nn}\)</span> be a
pre-trained deep convolutional neural network and <span class="math">\(X\)</span> be any
image. <span class="math">\(C_{nn}(X)\)</span> is the network fed by <span class="math">\(X\)</span> (containing
feature maps at all layers). Let <span class="math">\(F_{XL} \in C_{nn}(X)\)</span> be the
feature maps at depth layer <span class="math">\(L\)</span>, all vectorized and concatenated
in one single vector. We simply define the content of <span class="math">\(X\)</span> at layer
<span class="math">\(L\)</span> by <span class="math">\(F_{XL}\)</span>. Then, if <span class="math">\(Y\)</span> is another image of same
the size than <span class="math">\(X\)</span>, we define the distance of content at layer
<span class="math">\(L\)</span> as follow:</p>
<div class="math">
\[D_C^L(X,Y) = \|F_{XL} - F_{YL}\|^2 = \sum_i (F_{XL}(i) - F_{YL}(i))^2\]</div>
<p>Where <span class="math">\(F_{XL}(i)\)</span> is the <span class="math">\(i^{th}\)</span> element of <span class="math">\(F_{XL}\)</span>.
The style is a bit less trivial to define. Let <span class="math">\(F_{XL}^k\)</span> with
<span class="math">\(k \leq K\)</span> be the vectorized <span class="math">\(k^{th}\)</span> of the <span class="math">\(K\)</span>
feature maps at layer <span class="math">\(L\)</span>. The style <span class="math">\(G_{XL}\)</span> of <span class="math">\(X\)</span>
at layer <span class="math">\(L\)</span> is defined by the Gram produce of all vectorized
feature maps <span class="math">\(F_{XL}^k\)</span> with <span class="math">\(k \leq K\)</span>. In other words,
<span class="math">\(G_{XL}\)</span> is a <span class="math">\(K\)</span>x<span class="math">\(K\)</span> matrix and the element
<span class="math">\(G_{XL}(k,l)\)</span> at the <span class="math">\(k^{th}\)</span> line and <span class="math">\(l^{th}\)</span> column
of <span class="math">\(G_{XL}\)</span> is the vectorial produce between <span class="math">\(F_{XL}^k\)</span> and
<span class="math">\(F_{XL}^l\)</span> :</p>
<div class="math">
\[G_{XL}(k,l) = \langle F_{XL}^k, F_{XL}^l\rangle = \sum_i F_{XL}^k(i) . F_{XL}^l(i)\]</div>
<p>Where <span class="math">\(F_{XL}^k(i)\)</span> is the <span class="math">\(i^{th}\)</span> element of
<span class="math">\(F_{XL}^k\)</span>. We can see <span class="math">\(G_{XL}(k,l)\)</span> as a measure of the
correlation between feature maps <span class="math">\(k\)</span> and <span class="math">\(l\)</span>. In that way,
<span class="math">\(G_{XL}\)</span> represents the correlation matrix of feature maps of
<span class="math">\(X\)</span> at layer <span class="math">\(L\)</span>. Note that the size of <span class="math">\(G_{XL}\)</span> only
depends on the number of feature maps, not on the size of <span class="math">\(X\)</span>.
Then, if <span class="math">\(Y\)</span> is another image <em>of any size</em>, we define the
distance of style at layer <span class="math">\(L\)</span> as follow:</p>
<div class="math">
\[D_S^L(X,Y) = \|G_{XL} - G_{YL}\|^2 = \sum_{k,l} (G_{XL}(k,l) - G_{YL}(k,l))^2\]</div>
<p>In order to minimize in one shot <span class="math">\(D_C(X,C)\)</span> between a variable
image <span class="math">\(X\)</span> and target content-image <span class="math">\(C\)</span> and <span class="math">\(D_S(X,S)\)</span>
between <span class="math">\(X\)</span> and target style-image <span class="math">\(S\)</span>, both computed at
several layers , we compute and sum the gradients (derivative with
respect to <span class="math">\(X\)</span>) of each distance at each wanted layer:</p>
<div class="math">
\[\nabla_{    extit{total}}(X,S,C) = \sum_{L_C} w_{CL_C}.\nabla_{     extit{content}}^{L_C}(X,C) + \sum_{L_S} w_{SL_S}.\nabla_{       extit{style}}^{L_S}(X,S)\]</div>
<p>Where <span class="math">\(L_C\)</span> and <span class="math">\(L_S\)</span> are respectivement the wanted layers
(arbitrary stated) of content and style and <span class="math">\(w_{CL_C}\)</span> and
<span class="math">\(w_{SL_S}\)</span> the weights (arbitrary stated) associated with the
style or the content at each wanted layer. Then, we run a gradient
descent over <span class="math">\(X\)</span>:</p>
<div class="math">
\[X \leftarrow X - \alpha \nabla_{      extit{total}}(X,S,C)\]</div>
<p>Ok. That’s enough with maths. If you want to go deeper (how to compute
the gradients) <strong>we encourage you to read the original paper</strong> by Leon
A. Gatys and AL, where everything is much better and much clearer
explained.</p>
<p>For our implementation in PyTorch, we already have everything
we need: indeed, with PyTorch, all the gradients are automatically and
dynamically computed for you (while you use functions from the library).
This is why the implementation of this algorithm becomes very
confortable with PyTorch.</p>
</div>
</div>
</div>
<div class="section" id="pytorch-implementation">
<h2>PyTorch implementation<a class="headerlink" href="#pytorch-implementation" title="Permalink to this headline">¶</a></h2>
<p>If you are not sure to understand all the mathematics above, you will
probably get it by implementing it. If you are discovering PyTorch, we
recommend you to first read this <a class="reference internal" href="../beginner/deep_learning_60min_blitz.html"><span class="doc">Introduction to
PyTorch</span></a>.</p>
<div class="section" id="packages">
<h3>Packages<a class="headerlink" href="#packages" title="Permalink to this headline">¶</a></h3>
<p>We will have recourse to the following packages:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">torch</span></code>, <code class="docutils literal"><span class="pre">torch.nn</span></code>, <code class="docutils literal"><span class="pre">numpy</span></code> (indispensables packages for
neural networks with PyTorch)</li>
<li><code class="docutils literal"><span class="pre">torch.autograd.Variable</span></code> (dynamic computation of the gradient wrt
a variable)</li>
<li><code class="docutils literal"><span class="pre">torch.optim</span></code> (efficient gradient descents)</li>
<li><code class="docutils literal"><span class="pre">PIL</span></code>, <code class="docutils literal"><span class="pre">PIL.Image</span></code>, <code class="docutils literal"><span class="pre">matplotlib.pyplot</span></code> (load and display
images)</li>
<li><code class="docutils literal"><span class="pre">torchvision.transforms</span></code> (treat PIL images and transform into torch
tensors)</li>
<li><code class="docutils literal"><span class="pre">torchvision.models</span></code> (train or load pre-trained models)</li>
<li><code class="docutils literal"><span class="pre">copy</span></code> (to deep copy the models; system package)</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="kn">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torchvision.models</span> <span class="kn">as</span> <span class="nn">models</span>

<span class="kn">import</span> <span class="nn">copy</span>
</pre></div>
</div>
</div>
<div class="section" id="cuda">
<h3>Cuda<a class="headerlink" href="#cuda" title="Permalink to this headline">¶</a></h3>
<p>If you have a GPU on your computer, it is preferable to run the
algorithm on it, especially if you want to try larger networks (like
VGG). For this, we have <code class="docutils literal"><span class="pre">torch.cuda.is_available()</span></code> that returns
<code class="docutils literal"><span class="pre">True</span></code> if you computer has an available GPU. Then, we can use method
<code class="docutils literal"><span class="pre">.cuda()</span></code> that moves allocated proccesses associated with a module
from the CPU to the GPU. When we want to move back this module to the
CPU (e.g. to use numpy), we use the <code class="docutils literal"><span class="pre">.cpu()</span></code> method. Finally,
<code class="docutils literal"><span class="pre">.type(dtype)</span></code> will be use to convert a <code class="docutils literal"><span class="pre">torch.FloatTensor</span></code> into
<code class="docutils literal"><span class="pre">torch.cuda.FloatTensor</span></code> to feed GPU processes.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">use_cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span>
</pre></div>
</div>
</div>
<div class="section" id="load-images">
<h3>Load images<a class="headerlink" href="#load-images" title="Permalink to this headline">¶</a></h3>
<p>In order to simplify the implementation, let’s start by importing a
style and a content image of the same dimentions. We then scale them to
the desired output image size (128 or 512 in the example, depending on gpu
availablity) and transform them into torch tensors, ready to feed
a neural network:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Here are links to download the images required to run the tutorial:
<a class="reference external" href="http://pytorch.org/tutorials/_static/img/neural-style/picasso.jpg">picasso.jpg</a> and
<a class="reference external" href="http://pytorch.org/tutorials/_static/img/neural-style/dancing.jpg">dancing.jpg</a>.
Download these two images and add them to a directory
with name <code class="docutils literal"><span class="pre">images</span></code></p>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># desired size of the output image</span>
<span class="n">imsize</span> <span class="o">=</span> <span class="mi">512</span> <span class="k">if</span> <span class="n">use_cuda</span> <span class="k">else</span> <span class="mi">128</span>  <span class="c1"># use small size if no gpu</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="n">imsize</span><span class="p">),</span>  <span class="c1"># scale imported image</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>  <span class="c1"># transform it into a torch tensor</span>


<span class="k">def</span> <span class="nf">image_loader</span><span class="p">(</span><span class="n">image_name</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">loader</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
    <span class="c1"># fake batch dimension required to fit network&#39;s input dimensions</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>


<span class="n">style_img</span> <span class="o">=</span> <span class="n">image_loader</span><span class="p">(</span><span class="s2">&quot;images/picasso.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">content_img</span> <span class="o">=</span> <span class="n">image_loader</span><span class="p">(</span><span class="s2">&quot;images/dancing.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

<span class="k">assert</span> <span class="n">style_img</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">content_img</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> \
    <span class="s2">&quot;we need to import style and content images of the same size&quot;</span>
</pre></div>
</div>
<p>Imported PIL images has values between 0 and 255. Transformed into torch
tensors, their values are between 0 and 1. This is an important detail:
neural networks from torch library are trained with 0-1 tensor image. If
you try to feed the networks with 0-255 tensor images the activated
feature maps will have no sense. This is not the case with pre-trained
networks from the Caffe library: they are trained with 0-255 tensor
images.</p>
</div>
<div class="section" id="display-images">
<h3>Display images<a class="headerlink" href="#display-images" title="Permalink to this headline">¶</a></h3>
<p>We will use <code class="docutils literal"><span class="pre">plt.imshow</span></code> to display images. So we need to first
reconvert them into PIL images:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">unloader</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">()</span>  <span class="c1"># reconvert into PIL image</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>  <span class="c1"># we clone the tensor to not do changes on it</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">imsize</span><span class="p">,</span> <span class="n">imsize</span><span class="p">)</span>  <span class="c1"># remove the fake batch dimension</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">unloader</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> <span class="c1"># pause a bit so that plots are updated</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">style_img</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Style Image&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">content_img</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Content Image&#39;</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_neural_style_tutorial_001.png"><img alt="../_images/sphx_glr_neural_style_tutorial_001.png" src="../_images/sphx_glr_neural_style_tutorial_001.png" style="width: 300.79999999999995px; height: 225.6px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_neural_style_tutorial_002.png"><img alt="../_images/sphx_glr_neural_style_tutorial_002.png" src="../_images/sphx_glr_neural_style_tutorial_002.png" style="width: 300.79999999999995px; height: 225.6px;" /></a>
</li>
</ul>
</div>
<div class="section" id="content-loss">
<h3>Content loss<a class="headerlink" href="#content-loss" title="Permalink to this headline">¶</a></h3>
<p>The content loss is a function that takes as input the feature maps
<span class="math">\(F_{XL}\)</span> at a layer <span class="math">\(L\)</span> in a network fed by <span class="math">\(X\)</span> and
return the weigthed content distance <span class="math">\(w_{CL}.D_C^L(X,C)\)</span> between
this image and the content image. Hence, the weight <span class="math">\(w_{CL}\)</span> and
the target content <span class="math">\(F_{CL}\)</span> are parameters of the function. We
implement this function as a torch module with a constructor that takes
these parameters as input. The distance <span class="math">\(\|F_{XL} - F_{YL}\|^2\)</span> is
the Mean Square Error between the two sets of feature maps, that can be
computed using a criterion <code class="docutils literal"><span class="pre">nn.MSELoss</span></code> stated as a third parameter.</p>
<p>We will add our content losses at each desired layer as additive modules
of the neural network. That way, each time we will feed the network with
an input image <span class="math">\(X\)</span>, all the content losses will be computed at the
desired layers and, thanks to autograd, all the gradients will be
computed. For that, we just need to make the <code class="docutils literal"><span class="pre">forward</span></code> method of our
module returning the input: the module becomes a ‘’transparent layer’’
of the neural network. The computed loss is saved as a parameter of the
module.</p>
<p>Finally, we define a fake <code class="docutils literal"><span class="pre">backward</span></code> method, that just call the
backward method of <code class="docutils literal"><span class="pre">nn.MSELoss</span></code> in order to reconstruct the gradient.
This method returns the computed loss: this will be useful when running
the gradient descent in order to display the evolution of style and
content losses.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ContentLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ContentLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># we &#39;detach&#39; the target content from the tree used</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="c1"># to dynamically compute the gradient: this is a stated value,</span>
        <span class="c1"># not a variable. Otherwise the forward method of the criterion</span>
        <span class="c1"># will throw an error.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="nb">input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="nb">input</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="n">retain_graph</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><strong>Important detail</strong>: this module, although it is named <code class="docutils literal"><span class="pre">ContentLoss</span></code>,
is not a true PyTorch Loss function. If you want to define your content
loss as a PyTorch Loss, you have to create a PyTorch autograd Function
and to recompute/implement the gradient by the hand in the <code class="docutils literal"><span class="pre">backward</span></code>
method.</p>
</div>
</div>
<div class="section" id="style-loss">
<h3>Style loss<a class="headerlink" href="#style-loss" title="Permalink to this headline">¶</a></h3>
<p>For the style loss, we need first to define a module that compute the
gram produce <span class="math">\(G_{XL}\)</span> given the feature maps <span class="math">\(F_{XL}\)</span> of the
neural network fed by <span class="math">\(X\)</span>, at layer <span class="math">\(L\)</span>. Let
<span class="math">\(\hat{F}_{XL}\)</span> be the re-shaped version of <span class="math">\(F_{XL}\)</span> into a
<span class="math">\(K\)</span>x<span class="math">\(N\)</span> matrix, where <span class="math">\(K\)</span> is the number of feature
maps at layer <span class="math">\(L\)</span> and <span class="math">\(N\)</span> the lenght of any vectorized
feature map <span class="math">\(F_{XL}^k\)</span>. The <span class="math">\(k^{th}\)</span> line of
<span class="math">\(\hat{F}_{XL}\)</span> is <span class="math">\(F_{XL}^k\)</span>. We let you check that
<span class="math">\(\hat{F}_{XL} \cdot \hat{F}_{XL}^T = G_{XL}\)</span>. Given that, it
becomes easy to implement our module:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GramMatrix</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>  <span class="c1"># a=batch size(=1)</span>
        <span class="c1"># b=number of feature maps</span>
        <span class="c1"># (c,d)=dimensions of a f. map (N=c*d)</span>

        <span class="n">features</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>  <span class="c1"># resise F_XL into \hat F_XL</span>

        <span class="n">G</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">features</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>  <span class="c1"># compute the gram product</span>

        <span class="c1"># we &#39;normalize&#39; the values of the gram matrix</span>
        <span class="c1"># by dividing by the number of element in each feature maps.</span>
        <span class="k">return</span> <span class="n">G</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">b</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
<p>The longer is the feature maps dimension <span class="math">\(N\)</span>, the bigger are the
values of the gram matrix. Therefore, if we don’t normalize by <span class="math">\(N\)</span>,
the loss computed at the first layers (before pooling layers) will have
much more importance during the gradient descent. We dont want that,
since the most interesting style features are in the deepest layers!</p>
<p>Then, the style loss module is implemented exactly the same way than the
content loss module, but we have to add the <code class="docutils literal"><span class="pre">gramMatrix</span></code> as a
parameter:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StyleLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">StyleLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gram</span> <span class="o">=</span> <span class="n">GramMatrix</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gram</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">G</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="n">retain_graph</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
</pre></div>
</div>
</div>
<div class="section" id="load-the-neural-network">
<h3>Load the neural network<a class="headerlink" href="#load-the-neural-network" title="Permalink to this headline">¶</a></h3>
<p>Now, we have to import a pre-trained neural network. As in the paper, we
are going to use a pretrained VGG network with 19 layers (VGG19).</p>
<p>PyTorch’s implementation of VGG is a module divided in two child
<code class="docutils literal"><span class="pre">Sequential</span></code> modules: <code class="docutils literal"><span class="pre">features</span></code> (containing convolution and pooling
layers) and <code class="docutils literal"><span class="pre">classifier</span></code> (containing fully connected layers). We are
just interested by <code class="docutils literal"><span class="pre">features</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">cnn</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">.</span><span class="n">features</span>

<span class="c1"># move it to the GPU if possible:</span>
<span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">cnn</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>
</div>
<p>A <code class="docutils literal"><span class="pre">Sequential</span></code> module contains an ordered list of child modules. For
instance, <code class="docutils literal"><span class="pre">vgg19.features</span></code> contains a sequence (Conv2d, ReLU,
Maxpool2d, Conv2d, ReLU…) aligned in the right order of depth. As we
said in <em>Content loss</em> section, we wand to add our style and content
loss modules as additive ‘transparent’ layers in our network, at desired
depths. For that, we construct a new <code class="docutils literal"><span class="pre">Sequential</span></code> module, in wich we
are going to add modules from <code class="docutils literal"><span class="pre">vgg19</span></code> and our loss modules in the
right order:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># desired depth layers to compute style/content losses :</span>
<span class="n">content_layers_default</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv_4&#39;</span><span class="p">]</span>
<span class="n">style_layers_default</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;conv_1&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_2&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_3&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_5&#39;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_style_model_and_losses</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">content_img</span><span class="p">,</span>
                               <span class="n">style_weight</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">content_layers</span><span class="o">=</span><span class="n">content_layers_default</span><span class="p">,</span>
                               <span class="n">style_layers</span><span class="o">=</span><span class="n">style_layers_default</span><span class="p">):</span>
    <span class="n">cnn</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cnn</span><span class="p">)</span>

    <span class="c1"># just in order to have an iterable access to or list of content/syle</span>
    <span class="c1"># losses</span>
    <span class="n">content_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">style_losses</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>  <span class="c1"># the new Sequential module network</span>
    <span class="n">gram</span> <span class="o">=</span> <span class="n">GramMatrix</span><span class="p">()</span>  <span class="c1"># we need a gram module in order to compute style targets</span>

    <span class="c1"># move these modules to the GPU if possible:</span>
    <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">gram</span> <span class="o">=</span> <span class="n">gram</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">cnn</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;conv_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">content_layers</span><span class="p">:</span>
                <span class="c1"># add content loss:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">content_img</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">content_loss</span> <span class="o">=</span> <span class="n">ContentLoss</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">content_weight</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;content_loss_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">content_loss</span><span class="p">)</span>
                <span class="n">content_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content_loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">style_layers</span><span class="p">:</span>
                <span class="c1"># add style loss:</span>
                <span class="n">target_feature</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">style_img</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">target_feature_gram</span> <span class="o">=</span> <span class="n">gram</span><span class="p">(</span><span class="n">target_feature</span><span class="p">)</span>
                <span class="n">style_loss</span> <span class="o">=</span> <span class="n">StyleLoss</span><span class="p">(</span><span class="n">target_feature_gram</span><span class="p">,</span> <span class="n">style_weight</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;style_loss_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">style_loss</span><span class="p">)</span>
                <span class="n">style_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">style_loss</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;relu_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">content_layers</span><span class="p">:</span>
                <span class="c1"># add content loss:</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">content_img</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">content_loss</span> <span class="o">=</span> <span class="n">ContentLoss</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">content_weight</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;content_loss_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">content_loss</span><span class="p">)</span>
                <span class="n">content_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content_loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">style_layers</span><span class="p">:</span>
                <span class="c1"># add style loss:</span>
                <span class="n">target_feature</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">style_img</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                <span class="n">target_feature_gram</span> <span class="o">=</span> <span class="n">gram</span><span class="p">(</span><span class="n">target_feature</span><span class="p">)</span>
                <span class="n">style_loss</span> <span class="o">=</span> <span class="n">StyleLoss</span><span class="p">(</span><span class="n">target_feature_gram</span><span class="p">,</span> <span class="n">style_weight</span><span class="p">)</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&quot;style_loss_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">style_loss</span><span class="p">)</span>
                <span class="n">style_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">style_loss</span><span class="p">)</span>

            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;pool_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">layer</span><span class="p">)</span>  <span class="c1"># ***</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">style_losses</span><span class="p">,</span> <span class="n">content_losses</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>In the paper they recommend to change max pooling layers into
average pooling. With AlexNet, that is a small network compared to VGG19
used in the paper, we are not going to see any difference of quality in
the result. However, you can use these lines instead if you want to do
this substitution:</p>
<div class="last highlight-default"><div class="highlight"><pre><span></span><span class="c1"># avgpool = nn.AvgPool2d(kernel_size=layer.kernel_size,</span>
<span class="c1">#                         stride=layer.stride, padding = layer.padding)</span>
<span class="c1"># model.add_module(name,avgpool)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="input-image">
<h3>Input image<a class="headerlink" href="#input-image" title="Permalink to this headline">¶</a></h3>
<p>Again, in order to simplify the code, we take an image of the same
dimensions than content and style images. This image can be a white
noise, or it can also be a copy of the content-image.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">input_img</span> <span class="o">=</span> <span class="n">content_img</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
<span class="c1"># if you want to use a white noise instead uncomment the below line:</span>
<span class="c1"># input_img = Variable(torch.randn(content_img.data.size())).type(dtype)</span>

<span class="c1"># add the original input image to the figure:</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">input_img</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Input Image&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_neural_style_tutorial_003.png" class="align-center" src="../_images/sphx_glr_neural_style_tutorial_003.png" />
</div>
<div class="section" id="gradient-descent">
<h3>Gradient descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h3>
<p>As Leon Gatys, the author of the algorithm, suggested
<a class="reference external" href="https://discuss.pytorch.org/t/pytorch-tutorial-for-neural-transfert-of-artistic-style/336/20?u=alexis-jacq">here</a>,
we will use L-BFGS algorithm to run our gradient descent. Unlike
training a network, we want to train the input image in order to
minimise the content/style losses. We would like to simply create a
PyTorch  L-BFGS optimizer, passing our image as the variable to optimize.
But <code class="docutils literal"><span class="pre">optim.LBFGS</span></code> takes as first argument a list of PyTorch
<code class="docutils literal"><span class="pre">Variable</span></code> that require gradient. Our input image is a <code class="docutils literal"><span class="pre">Variable</span></code>
but is not a leaf of the tree that requires computation of gradients. In
order to show that this variable requires a gradient, a possibility is
to construct a <code class="docutils literal"><span class="pre">Parameter</span></code> object from the input image. Then, we just
give a list containing this <code class="docutils literal"><span class="pre">Parameter</span></code> to the optimizer’s
constructor:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_input_param_optimizer</span><span class="p">(</span><span class="n">input_img</span><span class="p">):</span>
    <span class="c1"># this line to show that input is a parameter that requires a gradient</span>
    <span class="n">input_param</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">input_img</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">([</span><span class="n">input_param</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">input_param</span><span class="p">,</span> <span class="n">optimizer</span>
</pre></div>
</div>
<p><strong>Last step</strong>: the loop of gradient descent. At each step, we must feed
the network with the updated input in order to compute the new losses,
we must run the <code class="docutils literal"><span class="pre">backward</span></code> methods of each loss to dynamically compute
their gradients and perform the step of gradient descent. The optimizer
requires as argument a “closure”: a function that reevaluates the model
and returns the loss.</p>
<p>However, there’s a small catch. The optimized image may take its values
between <span class="math">\(-\infty\)</span> and <span class="math">\(+\infty\)</span> instead of staying between 0
and 1. In other words, the image might be well optimized and have absurd
values. In fact, we must perform an optimization under constraints in
order to keep having right vaues into our input image. There is a simple
solution: at each step, to correct the image to maintain its values into
the 0-1 interval.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_style_transfer</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">content_img</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">input_img</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
                       <span class="n">style_weight</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">content_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Run the style transfer.&quot;&quot;&quot;</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Building the style transfer model..&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">style_losses</span><span class="p">,</span> <span class="n">content_losses</span> <span class="o">=</span> <span class="n">get_style_model_and_losses</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span>
        <span class="n">style_img</span><span class="p">,</span> <span class="n">content_img</span><span class="p">,</span> <span class="n">style_weight</span><span class="p">,</span> <span class="n">content_weight</span><span class="p">)</span>
    <span class="n">input_param</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">get_input_param_optimizer</span><span class="p">(</span><span class="n">input_img</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Optimizing..&#39;</span><span class="p">)</span>
    <span class="n">run</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">while</span> <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">num_steps</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">closure</span><span class="p">():</span>
            <span class="c1"># correct the values of updated input image</span>
            <span class="n">input_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">model</span><span class="p">(</span><span class="n">input_param</span><span class="p">)</span>
            <span class="n">style_score</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">content_score</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">sl</span> <span class="ow">in</span> <span class="n">style_losses</span><span class="p">:</span>
                <span class="n">style_score</span> <span class="o">+=</span> <span class="n">sl</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">content_losses</span><span class="p">:</span>
                <span class="n">content_score</span> <span class="o">+=</span> <span class="n">cl</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">run</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">print</span><span class="p">(</span><span class="s2">&quot;run {}:&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run</span><span class="p">))</span>
                <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Style Loss : {:4f} Content Loss: {:4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">style_score</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">content_score</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                <span class="k">print</span><span class="p">()</span>

            <span class="k">return</span> <span class="n">style_score</span> <span class="o">+</span> <span class="n">content_score</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

    <span class="c1"># a last correction...</span>
    <span class="n">input_param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">input_param</span><span class="o">.</span><span class="n">data</span>
</pre></div>
</div>
<p>Finally, run the algorithm</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">run_style_transfer</span><span class="p">(</span><span class="n">cnn</span><span class="p">,</span> <span class="n">content_img</span><span class="p">,</span> <span class="n">style_img</span><span class="p">,</span> <span class="n">input_img</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Output Image&#39;</span><span class="p">)</span>

<span class="c1"># sphinx_gallery_thumbnail_number = 4</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_neural_style_tutorial_004.png" class="align-center" src="../_images/sphx_glr_neural_style_tutorial_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Building</span> <span class="n">the</span> <span class="n">style</span> <span class="n">transfer</span> <span class="n">model</span><span class="o">..</span>
<span class="n">Optimizing</span><span class="o">..</span>
<span class="n">run</span> <span class="p">[</span><span class="mi">50</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.147848</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.470452</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">100</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.043477</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.343297</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">150</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.035841</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.315429</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">200</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.031865</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.306764</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">250</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.030837</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.302101</span>

<span class="n">run</span> <span class="p">[</span><span class="mi">300</span><span class="p">]:</span>
<span class="n">Style</span> <span class="n">Loss</span> <span class="p">:</span> <span class="mf">0.030777</span> <span class="n">Content</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.299595</span>
</pre></div>
</div>
<p><strong>Total running time of the script:</strong> ( 1 minutes  36.006 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/neural_style_tutorial.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">neural_style_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/neural_style_tutorial.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">neural_style_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="numpy_extensions_tutorial.html" class="btn btn-neutral float-right" title="Creating extensions using numpy and scipy" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../intermediate/spatial_transformer_tutorial.html" class="btn btn-neutral" title="Spatial Transformer Networks Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2.0_4',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>