
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Saving and Loading Models — PyTorch Tutorials 1.0.0.dev20181206 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="finetuning_torchvision_models_tutorial.html" rel="next" title="Finetuning Torchvision Models"/>
<link href="transfer_learning_tutorial.html" rel="prev" title="Transfer Learning Tutorial"/>
<script src="../_static/js/modernizr.min.js"></script>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.0.0.dev20181206
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning Tutorial</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Saving and Loading Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Image</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="finetuning_torchvision_models_tutorial.html">Finetuning Torchvision Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer Using PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a Model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="chatbot_tutorial.html">Chatbot Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a></li>
</ul>
<p class="caption"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating Extensions Using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
</ul>
<p class="caption"><span class="caption-text">Production Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/ONNXLive.html">ONNX Live Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a PyTorch Model in C++</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Saving and Loading Models</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/saving_loading_models.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-saving-loading-models-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="saving-and-loading-models">
<span id="sphx-glr-beginner-saving-loading-models-py"></span><h1>Saving and Loading Models<a class="headerlink" href="#saving-and-loading-models" title="Permalink to this headline">¶</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/MatthewInkawhich">Matthew Inkawhich</a></p>
<p>This document provides solutions to a variety of use cases regarding the
saving and loading of PyTorch models. Feel free to read the whole
document, or just skip to the code you need for a desired use case.</p>
<p>When it comes to saving and loading models, there are three core
functions to be familiar with:</p>
<ol class="arabic simple">
<li><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save">torch.save</a>:
Saves a serialized object to disk. This function uses Python’s
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> utility
for serialization. Models, tensors, and dictionaries of all kinds of
objects can be saved using this function.</li>
<li><a class="reference external" href="https://pytorch.org/docs/stable/torch.html?highlight=torch%20load#torch.load">torch.load</a>:
Uses <a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a>’s
unpickling facilities to deserialize pickled object files to memory.
This function also facilitates the device to load the data into (see
<a class="reference external" href="#saving-loading-model-across-devices">Saving &amp; Loading Model Across
Devices</a>).</li>
<li><a class="reference external" href="https://pytorch.org/docs/stable/nn.html?highlight=load_state_dict#torch.nn.Module.load_state_dict">torch.nn.Module.load_state_dict</a>:
Loads a model’s parameter dictionary using a deserialized
<em>state_dict</em>. For more information on <em>state_dict</em>, see <a class="reference external" href="#what-is-a-state-dict">What is a
state_dict?</a>.</li>
</ol>
<p><strong>Contents:</strong></p>
<ul class="simple">
<li><a class="reference external" href="#what-is-a-state-dict">What is a state_dict?</a></li>
<li><a class="reference external" href="#saving-loading-model-for-inference">Saving &amp; Loading Model for
Inference</a></li>
<li><a class="reference external" href="#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training">Saving &amp; Loading a General
Checkpoint</a></li>
<li><a class="reference external" href="#saving-multiple-models-in-one-file">Saving Multiple Models in One
File</a></li>
<li><a class="reference external" href="#warmstarting-model-using-parameters-from-a-different-model">Warmstarting Model Using Parameters from a Different
Model</a></li>
<li><a class="reference external" href="#saving-loading-model-across-devices">Saving &amp; Loading Model Across
Devices</a></li>
</ul>
<div class="section" id="what-is-a-state-dict">
<h2>What is a <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>?<a class="headerlink" href="#what-is-a-state-dict" title="Permalink to this headline">¶</a></h2>
<p>In PyTorch, the learnable parameters (i.e. weights and biases) of an
<code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> model is contained in the model’s <em>parameters</em>
(accessed with <code class="docutils literal notranslate"><span class="pre">model.parameters()</span></code>). A <em>state_dict</em> is simply a
Python dictionary object that maps each layer to its parameter tensor.
Note that only layers with learnable parameters (convolutional layers,
linear layers, etc.) have entries in the model’s <em>state_dict</em>. Optimizer
objects (<code class="docutils literal notranslate"><span class="pre">torch.optim</span></code>) also have a <em>state_dict</em>, which contains
information about the optimizer’s state, as well as the hyperparameters
used.</p>
<p>Because <em>state_dict</em> objects are Python dictionaries, they can be easily
saved, updated, altered, and restored, adding a great deal of modularity
to PyTorch models and optimizers.</p>
<div class="section" id="example">
<h3>Example:<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>Let’s take a look at the <em>state_dict</em> from the simple model used in the
<a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py">Training a
classifier</a>
tutorial.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define model</span>
<span class="k">class</span> <span class="nc">TheModelClass</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TheModelClass</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Initialize model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">()</span>

<span class="c1"># Initialize optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Print model's state_dict</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Model's state_dict:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param_tensor</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">param_tensor</span><span class="p">,</span> <span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_tensor</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

<span class="c1"># Print optimizer's state_dict</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Optimizer's state_dict:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">var_name</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">var_name</span><span class="p">,</span> <span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">var_name</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Model</span><span class="s1">'s state_dict:</span>
<span class="n">conv1</span><span class="o">.</span><span class="n">weight</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">conv1</span><span class="o">.</span><span class="n">bias</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">6</span><span class="p">])</span>
<span class="n">conv2</span><span class="o">.</span><span class="n">weight</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">conv2</span><span class="o">.</span><span class="n">bias</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">16</span><span class="p">])</span>
<span class="n">fc1</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">120</span><span class="p">,</span> <span class="mi">400</span><span class="p">])</span>
<span class="n">fc1</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">120</span><span class="p">])</span>
<span class="n">fc2</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">84</span><span class="p">,</span> <span class="mi">120</span><span class="p">])</span>
<span class="n">fc2</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">84</span><span class="p">])</span>
<span class="n">fc3</span><span class="o">.</span><span class="n">weight</span>   <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">84</span><span class="p">])</span>
<span class="n">fc3</span><span class="o">.</span><span class="n">bias</span>     <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>

<span class="n">Optimizer</span><span class="s1">'s state_dict:</span>
<span class="n">state</span>    <span class="p">{}</span>
<span class="n">param_groups</span>     <span class="p">[{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">'momentum'</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span> <span class="s1">'dampening'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'weight_decay'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'nesterov'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s1">'params'</span><span class="p">:</span> <span class="p">[</span><span class="mi">4675713712</span><span class="p">,</span> <span class="mi">4675713784</span><span class="p">,</span> <span class="mi">4675714000</span><span class="p">,</span> <span class="mi">4675714072</span><span class="p">,</span> <span class="mi">4675714216</span><span class="p">,</span> <span class="mi">4675714288</span><span class="p">,</span> <span class="mi">4675714432</span><span class="p">,</span> <span class="mi">4675714504</span><span class="p">,</span> <span class="mi">4675714648</span><span class="p">,</span> <span class="mi">4675714720</span><span class="p">]}]</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="saving-loading-model-for-inference">
<h2>Saving &amp; Loading Model for Inference<a class="headerlink" href="#saving-loading-model-for-inference" title="Permalink to this headline">¶</a></h2>
<div class="section" id="save-load-state-dict-recommended">
<h3>Save/Load <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> (Recommended)<a class="headerlink" href="#save-load-state-dict-recommended" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>When saving a model for inference, it is only necessary to save the
trained model’s learned parameters. Saving the model’s <em>state_dict</em> with
the <code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> function will give you the most flexibility for
restoring the model later, which is why it is the recommended method for
saving models.</p>
<p>A common PyTorch convention is to save models using either a <code class="docutils literal notranslate"><span class="pre">.pt</span></code> or
<code class="docutils literal notranslate"><span class="pre">.pth</span></code> file extension.</p>
<p>Remember that you must call <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> to set dropout and batch
normalization layers to evaluation mode before running inference.
Failing to do this will yield inconsistent inference results.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Notice that the <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> function takes a dictionary
object, NOT a path to a saved object. This means that you must
deserialize the saved <em>state_dict</em> before you pass it to the
<code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> function. For example, you CANNOT load using
<code class="docutils literal notranslate"><span class="pre">model.load_state_dict(PATH)</span></code>.</p>
</div>
</div>
<div class="section" id="save-load-entire-model">
<h3>Save/Load Entire Model<a class="headerlink" href="#save-load-entire-model" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model class must be defined somewhere</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p>This save/load process uses the most intuitive syntax and involves the
least amount of code. Saving a model in this way will save the entire
module using Python’s
<a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickle</a> module. The
disadvantage of this approach is that the serialized data is bound to
the specific classes and the exact directory structure used when the
model is saved. The reason for this is because pickle does not save the
model class itself. Rather, it saves a path to the file containing the
class, which is used during load time. Because of this, your code can
break in various ways when used in other projects or after refactors.</p>
<p>A common PyTorch convention is to save models using either a <code class="docutils literal notranslate"><span class="pre">.pt</span></code> or
<code class="docutils literal notranslate"><span class="pre">.pth</span></code> file extension.</p>
<p>Remember that you must call <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> to set dropout and batch
normalization layers to evaluation mode before running inference.
Failing to do this will yield inconsistent inference results.</p>
</div>
</div>
<div class="section" id="saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training">
<h2>Saving &amp; Loading a General Checkpoint for Inference and/or Resuming Training<a class="headerlink" href="#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training" title="Permalink to this headline">¶</a></h2>
<div class="section" id="save">
<h3>Save:<a class="headerlink" href="#save" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'epoch'</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">'model_state_dict'</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'optimizer_state_dict'</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'loss'</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="load">
<h3>Load:<a class="headerlink" href="#load" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">TheOptimizerClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model_state_dict'</span><span class="p">])</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizer_state_dict'</span><span class="p">])</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'epoch'</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>When saving a general checkpoint, to be used for either inference or
resuming training, you must save more than just the model’s
<em>state_dict</em>. It is important to also save the optimizer’s <em>state_dict</em>,
as this contains buffers and parameters that are updated as the model
trains. Other items that you may want to save are the epoch you left off
on, the latest recorded training loss, external <code class="docutils literal notranslate"><span class="pre">torch.nn.Embedding</span></code>
layers, etc.</p>
<p>To save multiple components, organize them in a dictionary and use
<code class="docutils literal notranslate"><span class="pre">torch.save()</span></code> to serialize the dictionary. A common PyTorch
convention is to save these checkpoints using the <code class="docutils literal notranslate"><span class="pre">.tar</span></code> file
extension.</p>
<p>To load the items, first initialize the model and optimizer, then load
the dictionary locally using <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>. From here, you can easily
access the saved items by simply querying the dictionary as you would
expect.</p>
<p>Remember that you must call <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> to set dropout and batch
normalization layers to evaluation mode before running inference.
Failing to do this will yield inconsistent inference results. If you
wish to resuming training, call <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> to ensure these layers
are in training mode.</p>
</div>
</div>
<div class="section" id="saving-multiple-models-in-one-file">
<h2>Saving Multiple Models in One File<a class="headerlink" href="#saving-multiple-models-in-one-file" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id1">
<h3>Save:<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">({</span>
            <span class="s1">'modelA_state_dict'</span><span class="p">:</span> <span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'modelB_state_dict'</span><span class="p">:</span> <span class="n">modelB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'optimizerA_state_dict'</span><span class="p">:</span> <span class="n">optimizerA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s1">'optimizerB_state_dict'</span><span class="p">:</span> <span class="n">optimizerB</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="o">...</span>
            <span class="p">},</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h3>Load:<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modelA</span> <span class="o">=</span> <span class="n">TheModelAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerA</span> <span class="o">=</span> <span class="n">TheOptimizerAClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">optimizerB</span> <span class="o">=</span> <span class="n">TheOptimizerBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'modelA_state_dict'</span><span class="p">])</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'modelB_state_dict'</span><span class="p">])</span>
<span class="n">optimizerA</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizerA_state_dict'</span><span class="p">])</span>
<span class="n">optimizerB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">'optimizerB_state_dict'</span><span class="p">])</span>

<span class="n">modelA</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># - or -</span>
<span class="n">modelA</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>When saving a model comprised of multiple <code class="docutils literal notranslate"><span class="pre">torch.nn.Modules</span></code>, such as
a GAN, a sequence-to-sequence model, or an ensemble of models, you
follow the same approach as when you are saving a general checkpoint. In
other words, save a dictionary of each model’s <em>state_dict</em> and
corresponding optimizer. As mentioned before, you can save any other
items that may aid you in resuming training by simply appending them to
the dictionary.</p>
<p>A common PyTorch convention is to save these checkpoints using the
<code class="docutils literal notranslate"><span class="pre">.tar</span></code> file extension.</p>
<p>To load the models, first initialize the models and optimizers, then
load the dictionary locally using <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code>. From here, you can
easily access the saved items by simply querying the dictionary as you
would expect.</p>
<p>Remember that you must call <code class="docutils literal notranslate"><span class="pre">model.eval()</span></code> to set dropout and batch
normalization layers to evaluation mode before running inference.
Failing to do this will yield inconsistent inference results. If you
wish to resuming training, call <code class="docutils literal notranslate"><span class="pre">model.train()</span></code> to set these layers to
training mode.</p>
</div>
</div>
<div class="section" id="warmstarting-model-using-parameters-from-a-different-model">
<h2>Warmstarting Model Using Parameters from a Different Model<a class="headerlink" href="#warmstarting-model-using-parameters-from-a-different-model" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id3">
<h3>Save:<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">modelA</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h3>Load:<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">modelB</span> <span class="o">=</span> <span class="n">TheModelBClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">modelB</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Partially loading a model or loading a partial model are common
scenarios when transfer learning or training a new complex model.
Leveraging trained parameters, even if only a few are usable, will help
to warmstart the training process and hopefully help your model converge
much faster than training from scratch.</p>
<p>Whether you are loading from a partial <em>state_dict</em>, which is missing
some keys, or loading a <em>state_dict</em> with more keys than the model that
you are loading into, you can set the <code class="docutils literal notranslate"><span class="pre">strict</span></code> argument to <strong>False</strong>
in the <code class="docutils literal notranslate"><span class="pre">load_state_dict()</span></code> function to ignore non-matching keys.</p>
<p>If you want to load parameters from one layer to another, but some keys
do not match, simply change the name of the parameter keys in the
<em>state_dict</em> that you are loading to match the keys in the model that
you are loading into.</p>
</div>
</div>
<div class="section" id="saving-loading-model-across-devices">
<h2>Saving &amp; Loading Model Across Devices<a class="headerlink" href="#saving-loading-model-across-devices" title="Permalink to this headline">¶</a></h2>
<div class="section" id="save-on-gpu-load-on-cpu">
<h3>Save on GPU, Load on CPU<a class="headerlink" href="#save-on-gpu-load-on-cpu" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
<p>When loading a model on a CPU that was trained with a GPU, pass
<code class="docutils literal notranslate"><span class="pre">torch.device('cpu')</span></code> to the <code class="docutils literal notranslate"><span class="pre">map_location</span></code> argument in the
<code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> function. In this case, the storages underlying the
tensors are dynamically remapped to the CPU device using the
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> argument.</p>
</div>
<div class="section" id="save-on-gpu-load-on-gpu">
<h3>Save on GPU, Load on GPU<a class="headerlink" href="#save-on-gpu-load-on-gpu" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># Make sure to call input = input.to(device) on any input tensors that you feed to the model</span>
</pre></div>
</div>
<p>When loading a model on a GPU that was trained and saved on GPU, simply
convert the initialized <code class="docutils literal notranslate"><span class="pre">model</span></code> to a CUDA optimized model using
<code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code>. Also, be sure to use the
<code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code> function on all model inputs to prepare
the data for the model. Note that calling <code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code>
returns a new copy of <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code> on GPU. It does NOT overwrite
<code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>. Therefore, remember to manually overwrite tensors:
<code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code>.</p>
</div>
<div class="section" id="save-on-cpu-load-on-gpu">
<h3>Save on CPU, Load on GPU<a class="headerlink" href="#save-on-cpu-load-on-gpu" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TheModelClass</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">"cuda:0"</span><span class="p">))</span>  <span class="c1"># Choose whatever GPU device number you want</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># Make sure to call input = input.to(device) on any input tensors that you feed to the model</span>
</pre></div>
</div>
<p>When loading a model on a GPU that was trained and saved on CPU, set the
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> argument in the <code class="docutils literal notranslate"><span class="pre">torch.load()</span></code> function to
<em>cuda:device_id</em>. This loads the model to a given GPU device. Next, be
sure to call <code class="docutils literal notranslate"><span class="pre">model.to(torch.device('cuda'))</span></code> to convert the model’s
parameter tensors to CUDA tensors. Finally, be sure to use the
<code class="docutils literal notranslate"><span class="pre">.to(torch.device('cuda'))</span></code> function on all model inputs to prepare
the data for the CUDA optimized model. Note that calling
<code class="docutils literal notranslate"><span class="pre">my_tensor.to(device)</span></code> returns a new copy of <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code> on GPU. It
does NOT overwrite <code class="docutils literal notranslate"><span class="pre">my_tensor</span></code>. Therefore, remember to manually
overwrite tensors: <code class="docutils literal notranslate"><span class="pre">my_tensor</span> <span class="pre">=</span> <span class="pre">my_tensor.to(torch.device('cuda'))</span></code>.</p>
</div>
<div class="section" id="saving-torch-nn-dataparallel-models">
<h3>Saving <code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> Models<a class="headerlink" href="#saving-torch-nn-dataparallel-models" title="Permalink to this headline">¶</a></h3>
<p><strong>Save:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Load:</strong></p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load to whatever device you want</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> is a model wrapper that enables parallel GPU
utilization. To save a <code class="docutils literal notranslate"><span class="pre">DataParallel</span></code> model generically, save the
<code class="docutils literal notranslate"><span class="pre">model.module.state_dict()</span></code>. This way, you have the flexibility to
load the model any way you want to any device you want.</p>
<p><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-saving-loading-models-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/4d2be551311e56235080ce6a019a2cc1/saving_loading_models.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">saving_loading_models.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/b50843b19ff6d24140129232a11bcbff/saving_loading_models.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">saving_loading_models.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="finetuning_torchvision_models_tutorial.html" rel="next" title="Finetuning Torchvision Models">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="transfer_learning_tutorial.html" rel="prev" title="Transfer Learning Tutorial"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Saving and Loading Models</a><ul>
<li><a class="reference internal" href="#what-is-a-state-dict">What is a <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>?</a><ul>
<li><a class="reference internal" href="#example">Example:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#saving-loading-model-for-inference">Saving &amp; Loading Model for Inference</a><ul>
<li><a class="reference internal" href="#save-load-state-dict-recommended">Save/Load <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> (Recommended)</a></li>
<li><a class="reference internal" href="#save-load-entire-model">Save/Load Entire Model</a></li>
</ul>
</li>
<li><a class="reference internal" href="#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training">Saving &amp; Loading a General Checkpoint for Inference and/or Resuming Training</a><ul>
<li><a class="reference internal" href="#save">Save:</a></li>
<li><a class="reference internal" href="#load">Load:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#saving-multiple-models-in-one-file">Saving Multiple Models in One File</a><ul>
<li><a class="reference internal" href="#id1">Save:</a></li>
<li><a class="reference internal" href="#id2">Load:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#warmstarting-model-using-parameters-from-a-different-model">Warmstarting Model Using Parameters from a Different Model</a><ul>
<li><a class="reference internal" href="#id3">Save:</a></li>
<li><a class="reference internal" href="#id4">Load:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#saving-loading-model-across-devices">Saving &amp; Loading Model Across Devices</a><ul>
<li><a class="reference internal" href="#save-on-gpu-load-on-cpu">Save on GPU, Load on CPU</a></li>
<li><a class="reference internal" href="#save-on-gpu-load-on-gpu">Save on GPU, Load on GPU</a></li>
<li><a class="reference internal" href="#save-on-cpu-load-on-gpu">Save on CPU, Load on GPU</a></li>
<li><a class="reference internal" href="#saving-torch-nn-dataparallel-models">Saving <code class="docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code> Models</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<img alt="" height="1" src="http://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://pytorch.org/resources">Resources</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Follow Us</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="#">Get Started</a>
</li>
<li>
<a href="#">Features</a>
</li>
<li>
<a href="#">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>