
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Deploying a Seq2Seq Model with TorchScript — PyTorch Tutorials 2.4.0+cu121 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom.css" rel="stylesheet" type="text/css"/>
<link href="../_static/css/custom2.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
<!-- End Google Tag Manager -->
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
<link crossorigin="anonymous" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" rel="stylesheet"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                Learn
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started">
<span class="dropdown-title">Get Started</span>
<p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
<p>Whats new in PyTorch tutorials</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
<p>Familiarize yourself with PyTorch concepts and modules</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
<p>Bite-size, ready-to-deploy PyTorch code examples</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
<p>Master PyTorch basics with our engaging YouTube tutorial series</p>
</a>
</div>
</div>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                Ecosystem
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
<span class="dropdown-title">Tools</span>
<p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
<span class="dropdown-title">Community</span>
<p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
<span class="dropdown-title">Forums</span>
<p>A place to discuss PyTorch code, issues, install, research</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
<span class="dropdown-title">Contributor Awards - 2023</span>
<p>Award winners announced at this year's PyTorch Conference</p>
</a>
</div>
</div>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                Edge
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/edge">
<span class="dropdown-title">About PyTorch Edge</span>
<p>Build innovative and privacy-aware AI experiences for edge devices</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
<span class="dropdown-title">ExecuTorch</span>
<p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                Docs
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
<p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
<span class="dropdown-title">PyTorch Domains</span>
<p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
</a>
</div>
</div>
</li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                Blogs &amp; News 
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">PyTorch Blog</span>
<p>Catch up on the latest technical news and happenings</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
<span class="dropdown-title">Community Blog</span>
<p>Stories from the PyTorch ecosystem</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/videos">
<span class="dropdown-title">Videos</span>
<p>Learn about the latest PyTorch tutorials, new, and more </p>
<a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
<span class="dropdown-title">Community Stories</span>
<p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
<p>Find events, webinars, and podcasts</p>
</a>
</a></div>
</div></li>
<li>
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
                About
              </a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
<p>Learn more about the PyTorch Foundation</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
<p></p>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown">
<a data-cta="join" href="https://pytorch.org/join">
                Become a Member
              </a>
</div>
</li>
<li>
<div class="main-menu-item">
<a class="github-icon" href="https://github.com/pytorch/pytorch">
</a>
</div>
</li>
<!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
            2.4.0+cu121
        </div>
<div class="searchbox">
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<div class="gcse-search"></div>
</div>
</div>
<p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/custom_ops_landing_page.html">PyTorch Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pinmem_nonblock.html">A guide on good usage of <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> and <code class="docutils literal notranslate"><span class="pre">pin_memory()</span></code> in PyTorch</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tiatoolbox_tutorial.html">Whole Slide Image Classification Using PyTorch and TIAToolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/text_to_speech_with_torchaudio.html">Text-to-speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="translation_transformer.html">Language Translation with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_custom_dataset_tutorial.html">Preprocess custom text dataset using Torchtext</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="onnx/intro_onnx.html">Introduction to ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="onnx/intro_onnx.html">Introduction to ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Profiling PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="hta_intro_tutorial.html">Introduction to Holistic Trace Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/custom_ops_landing_page.html">PyTorch Custom Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/python_custom_ops.html">Python Custom Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_custom_ops.html">Custom C++ and CUDA Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/compiled_autograd_tutorial.html">Compiled Autograd: Capturing a larger backward graph for <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/TCPStore_libuv_backend.html">Introduction to Libuv TCPStore Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pipelining_tutorial.html">Introduction to Distributed Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Edge with ExecuTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html">Exporting to ExecuTorch Tutorial</a></li>
<li class="toctree-l1"><a class="reference external" href=" https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html">Running an ExecuTorch Model in C++ Tutorial</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html">Using the ExecuTorch SDK to Profile a Model</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-ios.html">Building an ExecuTorch iOS Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-android.html">Building an ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html">Lowering a Model as a Delegate</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchrec_intro_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Deploying a Seq2Seq Model with TorchScript</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/deploy_seq2seq_hybrid_frontend_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/deploy_seq2seq_hybrid_frontend_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-beginner-deploy-seq2seq-hybrid-frontend-tutorial-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="deploying-a-seq2seq-model-with-torchscript">
<span id="sphx-glr-beginner-deploy-seq2seq-hybrid-frontend-tutorial-py"></span><h1>Deploying a Seq2Seq Model with TorchScript<a class="headerlink" href="#deploying-a-seq2seq-model-with-torchscript" title="Permalink to this heading">¶</a></h1>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/MatthewInkawhich">Matthew Inkawhich</a></p>
<p>This tutorial will walk through the process of transitioning a
sequence-to-sequence model to TorchScript using the TorchScript
API. The model that we will convert is the chatbot model from the
<a class="reference external" href="https://pytorch.org/tutorials/beginner/chatbot_tutorial.html">Chatbot tutorial</a>.
You can either treat this tutorial as a “Part 2” to the Chatbot tutorial
and deploy your own pretrained model, or you can start with this
document and use a pretrained model that we host. In the latter case,
you can reference the original Chatbot tutorial for details
regarding data preprocessing, model theory and definition, and model
training.</p>
<div class="section" id="what-is-torchscript">
<h2>What is TorchScript?<a class="headerlink" href="#what-is-torchscript" title="Permalink to this heading">¶</a></h2>
<p>During the research and development phase of a deep learning-based
project, it is advantageous to interact with an <strong>eager</strong>, imperative
interface like PyTorch’s. This gives users the ability to write
familiar, idiomatic Python, allowing for the use of Python data
structures, control flow operations, print statements, and debugging
utilities. Although the eager interface is a beneficial tool for
research and experimentation applications, when it comes time to deploy
the model in a production environment, having a <strong>graph</strong>-based model
representation is very beneficial. A deferred graph representation
allows for optimizations such as out-of-order execution, and the ability
to target highly optimized hardware architectures. Also, a graph-based
representation enables framework-agnostic model exportation. PyTorch
provides mechanisms for incrementally converting eager-mode code into
TorchScript, a statically analyzable and optimizable subset of Python
that Torch uses to represent deep learning programs independently from
the Python runtime.</p>
<p>The API for converting eager-mode PyTorch programs into TorchScript is
found in the <code class="docutils literal notranslate"><span class="pre">torch.jit</span></code> module. This module has two core modalities for
converting an eager-mode model to a TorchScript graph representation:
<strong>tracing</strong> and <strong>scripting</strong>. The <code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code> function takes a
module or function and a set of example inputs. It then runs the example
input through the function or module while tracing the computational
steps that are encountered, and outputs a graph-based function that
performs the traced operations. <strong>Tracing</strong> is great for straightforward
modules and functions that do not involve data-dependent control flow,
such as standard convolutional neural networks. However, if a function
with data-dependent if statements and loops is traced, only the
operations called along the execution route taken by the example input
will be recorded. In other words, the control flow itself is not
captured. To convert modules and functions containing data-dependent
control flow, a <strong>scripting</strong> mechanism is provided. The
<code class="docutils literal notranslate"><span class="pre">torch.jit.script</span></code> function/decorator takes a module or function and
does not requires example inputs. Scripting then explicitly converts
the module or function code to TorchScript, including all control flows.
One caveat with using scripting is that it only supports a subset of
Python, so you might need to rewrite the code to make it compatible
with the TorchScript syntax.</p>
<p>For all details relating to the supported features, see the <a class="reference external" href="https://pytorch.org/docs/master/jit.html">TorchScript
language reference</a>.
To provide the maximum flexibility, you can also mix tracing and scripting
modes together to represent your whole program, and these techniques can
be applied incrementally.</p>
<div class="figure align-center">
<img alt="workflow" src="../_images/pytorch_workflow.png"/>
</div>
</div>
<div class="section" id="acknowledgments">
<h2>Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permalink to this heading">¶</a></h2>
<p>This tutorial was inspired by the following sources:</p>
<ol class="arabic simple">
<li><p>Yuan-Kuei Wu’s pytorch-chatbot implementation:
<a class="reference external" href="https://github.com/ywk991112/pytorch-chatbot">https://github.com/ywk991112/pytorch-chatbot</a></p></li>
<li><p>Sean Robertson’s practical-pytorch seq2seq-translation example:
<a class="reference external" href="https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation">https://github.com/spro/practical-pytorch/tree/master/seq2seq-translation</a></p></li>
<li><p>FloydHub’s Cornell Movie Corpus preprocessing code:
<a class="reference external" href="https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus">https://github.com/floydhub/textutil-preprocess-cornell-movie-corpus</a></p></li>
</ol>
</div>
<div class="section" id="prepare-environment">
<h2>Prepare Environment<a class="headerlink" href="#prepare-environment" title="Permalink to this heading">¶</a></h2>
<p>First, we will import the required modules and set some constants. If
you are planning on using your own model, be sure that the
<code class="docutils literal notranslate"><span class="pre">MAX_LENGTH</span></code> constant is set correctly. As a reminder, this constant
defines the maximum allowed sentence length during training and the
maximum length output that the model is capable of producing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">unicodedata</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>


<span class="n">MAX_LENGTH</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Maximum sentence length</span>

<span class="c1"># Default word tokens</span>
<span class="n">PAD_token</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Used for padding short sentences</span>
<span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Start-of-sentence token</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># End-of-sentence token</span>
</pre></div>
</div>
</div>
<div class="section" id="model-overview">
<h2>Model Overview<a class="headerlink" href="#model-overview" title="Permalink to this heading">¶</a></h2>
<p>As mentioned, the model that we are using is a
<a class="reference external" href="https://arxiv.org/abs/1409.3215">sequence-to-sequence</a> (seq2seq)
model. This type of model is used in cases when our input is a
variable-length sequence, and our output is also a variable length
sequence that is not necessarily a one-to-one mapping of the input. A
seq2seq model is comprised of two recurrent neural networks (RNNs) that
work cooperatively: an <strong>encoder</strong> and a <strong>decoder</strong>.</p>
<div class="figure align-center">
<img alt="model" src="../_images/seq2seq_ts.png"/>
</div>
<p>Image source:
<a class="reference external" href="https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/">https://jeddy92.github.io/JEddy92.github.io/ts_seq2seq_intro/</a></p>
<div class="section" id="encoder">
<h3>Encoder<a class="headerlink" href="#encoder" title="Permalink to this heading">¶</a></h3>
<p>The encoder RNN iterates through the input sentence one token
(e.g. word) at a time, at each time step outputting an “output” vector
and a “hidden state” vector. The hidden state vector is then passed to
the next time step, while the output vector is recorded. The encoder
transforms the context it saw at each point in the sequence into a set
of points in a high-dimensional space, which the decoder will use to
generate a meaningful output for the given task.</p>
</div>
<div class="section" id="decoder">
<h3>Decoder<a class="headerlink" href="#decoder" title="Permalink to this heading">¶</a></h3>
<p>The decoder RNN generates the response sentence in a token-by-token
fashion. It uses the encoder’s context vectors, and internal hidden
states to generate the next word in the sequence. It continues
generating words until it outputs an <em>EOS_token</em>, representing the end
of the sentence. We use an <a class="reference external" href="https://arxiv.org/abs/1409.0473">attention
mechanism</a> in our decoder to help it
to “pay attention” to certain parts of the input when generating the
output. For our model, we implement <a class="reference external" href="https://arxiv.org/abs/1508.04025">Luong et
al.</a>’s “Global attention” module,
and use it as a submodule in our decode model.</p>
</div>
</div>
<div class="section" id="data-handling">
<h2>Data Handling<a class="headerlink" href="#data-handling" title="Permalink to this heading">¶</a></h2>
<p>Although our models conceptually deal with sequences of tokens, in
reality, they deal with numbers like all machine learning models do. In
this case, every word in the model’s vocabulary, which was established
before training, is mapped to an integer index. We use a <code class="docutils literal notranslate"><span class="pre">Voc</span></code> object
to contain the mappings from word to index, as well as the total number
of words in the vocabulary. We will load the object later before we run
the model.</p>
<p>Also, in order for us to be able to run evaluations, we must provide a
tool for processing our string inputs. The <code class="docutils literal notranslate"><span class="pre">normalizeString</span></code> function
converts all characters in a string to lowercase and removes all
non-letter characters. The <code class="docutils literal notranslate"><span class="pre">indexesFromSentence</span></code> function takes a
sentence of words and returns the corresponding sequence of word
indexes.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Voc</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD_token</span><span class="p">:</span> <span class="s2">"PAD"</span><span class="p">,</span> <span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Count SOS, EOS, PAD</span>

    <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># Remove words below a certain count threshold</span>
    <span class="k">def</span> <span class="nf">trim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">min_count</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trimmed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">keep_words</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;=</span> <span class="n">min_count</span><span class="p">:</span>
                <span class="n">keep_words</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">'keep_words </span><span class="si">{}</span><span class="s1"> / </span><span class="si">{}</span><span class="s1"> = </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_words</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">)</span>
        <span class="p">))</span>
        <span class="c1"># Reinitialize dictionaries</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD_token</span><span class="p">:</span> <span class="s2">"PAD"</span><span class="p">,</span> <span class="n">SOS_token</span><span class="p">:</span> <span class="s2">"SOS"</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">"EOS"</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_words</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># Count default tokens</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">keep_words</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>


<span class="c1"># Lowercase and remove non-letter characters</span>
<span class="k">def</span> <span class="nf">normalizeString</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"([.!?])"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" \1"</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">"[^a-zA-Z.!?]+"</span><span class="p">,</span> <span class="sa">r</span><span class="s2">" "</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">s</span>


<span class="c1"># Takes string sentence, returns sentence of word indexes</span>
<span class="k">def</span> <span class="nf">indexesFromSentence</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">voc</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">' '</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">EOS_token</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="define-encoder">
<h2>Define Encoder<a class="headerlink" href="#define-encoder" title="Permalink to this heading">¶</a></h2>
<p>We implement our encoder’s RNN with the <code class="docutils literal notranslate"><span class="pre">torch.nn.GRU</span></code> module which we
feed a batch of sentences (vectors of word embeddings) and it internally
iterates through the sentences one token at a time calculating the
hidden states. We initialize this module to be bidirectional, meaning
that we have two independent GRUs: one that iterates through the
sequences in chronological order, and another that iterates in reverse
order. We ultimately return the sum of these two GRUs’ outputs. Since
our model was trained using batching, our <code class="docutils literal notranslate"><span class="pre">EncoderRNN</span></code> model’s
<code class="docutils literal notranslate"><span class="pre">forward</span></code> function expects a padded input batch. To batch
variable-length sentences, we allow a maximum of <em>MAX_LENGTH</em> tokens in
a sentence, and all sentences in the batch that have less than
<em>MAX_LENGTH</em> tokens are padded at the end with our dedicated <em>PAD_token</em>
tokens. To use padded batches with a PyTorch RNN module, we must wrap
the forward pass call with <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_padded_sequence</span></code>
and <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pad_packed_sequence</span></code> data transformations.
Note that the <code class="docutils literal notranslate"><span class="pre">forward</span></code> function also takes an <code class="docutils literal notranslate"><span class="pre">input_lengths</span></code> list,
which contains the length of each sentence in the batch. This input is
used by the <code class="docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_padded_sequence</span></code> function when
padding.</p>
<div class="section" id="torchscript-notes">
<h3>TorchScript Notes:<a class="headerlink" href="#torchscript-notes" title="Permalink to this heading">¶</a></h3>
<p>Since the encoder’s <code class="docutils literal notranslate"><span class="pre">forward</span></code> function does not contain any
data-dependent control flow, we will use <strong>tracing</strong> to convert it to
script mode. When tracing a module, we can leave the module definition
as-is. We will initialize all models towards the end of this document
before we run evaluations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EncoderRNN</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">EncoderRNN</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a>

        <span class="c1"># Initialize GRU; the ``input_size`` and ``hidden_size`` parameters are both set to 'hidden_size'</span>
        <span class="c1">#   because our input size is a word embedding with number of features == hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" title="torch.nn.GRU"><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span></a><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                          <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">),</span> <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># type: (Tensor, Tensor, Optional[Tensor]) -&gt; Tuple[Tensor, Tensor]</span>
        <span class="c1"># Convert word indexes to embeddings</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>
        <span class="c1"># Pack padded batch of sequences for RNN module</span>
        <span class="n">packed</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-utils-rnn sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span></a><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">)</span>
        <span class="c1"># Forward pass through GRU</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">packed</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
        <span class="c1"># Unpack padding</span>
        <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-utils-rnn sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence" title="torch.nn.utils.rnn.pad_packed_sequence"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span></a><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="c1"># Sum bidirectional GRU outputs</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[:,</span> <span class="p">:</span> <span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">:]</span>
        <span class="c1"># Return output and final hidden state</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="define-decoders-attention-module">
<h2>Define Decoder’s Attention Module<a class="headerlink" href="#define-decoders-attention-module" title="Permalink to this heading">¶</a></h2>
<p>Next, we’ll define our attention module (<code class="docutils literal notranslate"><span class="pre">Attn</span></code>). Note that this
module will be used as a submodule in our decoder model. Luong et
al. consider various “score functions”, which take the current decoder
RNN output and the entire encoder output, and return attention
“energies”. This attention energies tensor is the same size as the
encoder output, and the two are ultimately multiplied, resulting in a
weighted tensor whose largest values represent the most important parts
of the query sentence at a particular time-step of decoding.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Luong attention layer</span>
<span class="k">class</span> <span class="nc">Attn</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Attn</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'dot'</span><span class="p">,</span> <span class="s1">'general'</span><span class="p">,</span> <span class="s1">'concat'</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">method</span><span class="p">,</span> <span class="s2">"is not an appropriate attention method."</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">'general'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">'concat'</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-parameter sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="torch.nn.parameter.Parameter"><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span></a><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">dot_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum" title="torch.sum"><span class="n">torch</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">encoder_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">general_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">encoder_output</span><span class="p">)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum" title="torch.sum"><span class="n">torch</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">hidden</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">concat_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_output</span><span class="p">):</span>
        <span class="n">energy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">((</span><span class="n">hidden</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">encoder_output</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">encoder_output</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">tanh</span><span class="p">()</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum" title="torch.sum"><span class="n">torch</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v</span> <span class="o">*</span> <span class="n">energy</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="c1"># Calculate the attention weights (energies) based on the given method</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">'general'</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">general_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">'concat'</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">'dot'</span><span class="p">:</span>
            <span class="n">attn_energies</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dot_score</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>

        <span class="c1"># Transpose max_length and batch_size dimensions</span>
        <span class="n">attn_energies</span> <span class="o">=</span> <span class="n">attn_energies</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="c1"># Return the softmax normalized probability scores (with added dimension)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><span class="n">F</span><span class="o">.</span><span class="n">softmax</span></a><span class="p">(</span><span class="n">attn_energies</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="define-decoder">
<h2>Define Decoder<a class="headerlink" href="#define-decoder" title="Permalink to this heading">¶</a></h2>
<p>Similarly to the <code class="docutils literal notranslate"><span class="pre">EncoderRNN</span></code>, we use the <code class="docutils literal notranslate"><span class="pre">torch.nn.GRU</span></code> module for
our decoder’s RNN. This time, however, we use a unidirectional GRU. It
is important to note that unlike the encoder, we will feed the decoder
RNN one word at a time. We start by getting the embedding of the current
word and applying a
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html?highlight=dropout#torch.nn.Dropout">dropout</a>.
Next, we forward the embedding and the last hidden state to the GRU and
obtain a current GRU output and hidden state. We then use our <code class="docutils literal notranslate"><span class="pre">Attn</span></code>
module as a layer to obtain the attention weights, which we multiply by
the encoder’s output to obtain our attended encoder output. We use this
attended encoder output as our <code class="docutils literal notranslate"><span class="pre">context</span></code> tensor, which represents a
weighted sum indicating what parts of the encoder’s output to pay
attention to. From here, we use a linear layer and softmax normalization
to select the next word in the output sequence.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># TorchScript Notes:</span>
<span class="c1"># ~~~~~~~~~~~~~~~~~~~~~~</span>
<span class="c1">#</span>
<span class="c1"># Similarly to the ``EncoderRNN``, this module does not contain any</span>
<span class="c1"># data-dependent control flow. Therefore, we can once again use</span>
<span class="c1"># **tracing** to convert this model to TorchScript after it</span>
<span class="c1"># is initialized and its parameters are loaded.</span>
<span class="c1">#</span>

<span class="k">class</span> <span class="nc">LuongAttnDecoderRNN</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attn_model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">LuongAttnDecoderRNN</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Keep for reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_model</span> <span class="o">=</span> <span class="n">attn_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="c1"># Define layers</span>
        <span class="bp">self</span><span class="o">.</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gru</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" title="torch.nn.GRU"><span class="n">nn</span><span class="o">.</span><span class="n">GRU</span></a><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">n_layers</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">dropout</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Attn</span></a><span class="p">(</span><span class="n">attn_model</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_step</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">):</span>
        <span class="c1"># Note: we run this one step (word) at a time</span>
        <span class="c1"># Get embedding of current input word</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">(</span><span class="n">input_step</span><span class="p">)</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_dropout</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="c1"># Forward through unidirectional GRU</span>
        <span class="n">rnn_output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gru</span><span class="p">(</span><span class="n">embedded</span><span class="p">,</span> <span class="n">last_hidden</span><span class="p">)</span>
        <span class="c1"># Calculate attention weights from the current GRU output</span>
        <span class="n">attn_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
        <span class="c1"># Multiply attention weights to encoder outputs to get new "weighted sum" context vector</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">attn_weights</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="c1"># Concatenate weighted context vector and GRU output using Luong eq. 5</span>
        <span class="n">rnn_output</span> <span class="o">=</span> <span class="n">rnn_output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">((</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">concat_output</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.tanh.html#torch.tanh" title="torch.tanh"><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">concat_input</span><span class="p">))</span>
        <span class="c1"># Predict next word using Luong eq. 6</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">concat_output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><span class="n">F</span><span class="o">.</span><span class="n">softmax</span></a><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># Return output and final hidden state</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span>
</pre></div>
</div>
</div>
<div class="section" id="define-evaluation">
<h2>Define Evaluation<a class="headerlink" href="#define-evaluation" title="Permalink to this heading">¶</a></h2>
<div class="section" id="greedy-search-decoder">
<h3>Greedy Search Decoder<a class="headerlink" href="#greedy-search-decoder" title="Permalink to this heading">¶</a></h3>
<p>As in the chatbot tutorial, we use a <code class="docutils literal notranslate"><span class="pre">GreedySearchDecoder</span></code> module to
facilitate the actual decoding process. This module has the trained
encoder and decoder models as attributes, and drives the process of
encoding an input sentence (a vector of word indexes), and iteratively
decoding an output response sequence one word (word index) at a time.</p>
<p>Encoding the input sequence is straightforward: simply forward the
entire sequence tensor and its corresponding lengths vector to the
<code class="docutils literal notranslate"><span class="pre">encoder</span></code>. It is important to note that this module only deals with
one input sequence at a time, <strong>NOT</strong> batches of sequences. Therefore,
when the constant <strong>1</strong> is used for declaring tensor sizes, this
corresponds to a batch size of 1. To decode a given decoder output, we
must iteratively run forward passes through our decoder model, which
outputs softmax scores corresponding to the probability of each word
being the correct next word in the decoded sequence. We initialize the
<code class="docutils literal notranslate"><span class="pre">decoder_input</span></code> to a tensor containing an <em>SOS_token</em>. After each pass
through the <code class="docutils literal notranslate"><span class="pre">decoder</span></code>, we <em>greedily</em> append the word with the highest
softmax probability to the <code class="docutils literal notranslate"><span class="pre">decoded_words</span></code> list. We also use this word
as the <code class="docutils literal notranslate"><span class="pre">decoder_input</span></code> for the next iteration. The decoding process
terminates either if the <code class="docutils literal notranslate"><span class="pre">decoded_words</span></code> list has reached a length of
<em>MAX_LENGTH</em> or if the predicted word is the <em>EOS_token</em>.</p>
</div>
<div class="section" id="id1">
<h3>TorchScript Notes:<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">forward</span></code> method of this module involves iterating over the range
of <span class="math">\([0, max\_length)\)</span> when decoding an output sequence one word at
a time. Because of this, we should use <strong>scripting</strong> to convert this
module to TorchScript. Unlike with our encoder and decoder models,
which we can trace, we must make some necessary changes to the
<code class="docutils literal notranslate"><span class="pre">GreedySearchDecoder</span></code> module in order to initialize an object without
error. In other words, we must ensure that our module adheres to the
rules of the TorchScript mechanism, and does not utilize any language
features outside of the subset of Python that TorchScript includes.</p>
<p>To get an idea of some manipulations that may be required, we will go
over the diffs between the <code class="docutils literal notranslate"><span class="pre">GreedySearchDecoder</span></code> implementation from
the chatbot tutorial and the implementation that we use in the cell
below. Note that the lines highlighted in red are lines removed from the
original implementation and the lines highlighted in green are new.</p>
<div class="figure align-center">
<img alt="diff" src="../_images/diff.png"/>
</div>
<div class="section" id="changes">
<h4>Changes:<a class="headerlink" href="#changes" title="Permalink to this heading">¶</a></h4>
<ul class="simple">
<li><p>Added <code class="docutils literal notranslate"><span class="pre">decoder_n_layers</span></code> to the constructor arguments</p>
<ul>
<li><p>This change stems from the fact that the encoder and decoder
models that we pass to this module will be a child of
<code class="docutils literal notranslate"><span class="pre">TracedModule</span></code> (not <code class="docutils literal notranslate"><span class="pre">Module</span></code>). Therefore, we cannot access the
decoder’s number of layers with <code class="docutils literal notranslate"><span class="pre">decoder.n_layers</span></code>. Instead, we
plan for this, and pass this value in during module construction.</p></li>
</ul>
</li>
<li><p>Store away new attributes as constants</p>
<ul>
<li><p>In the original implementation, we were free to use variables from
the surrounding (global) scope in our <code class="docutils literal notranslate"><span class="pre">GreedySearchDecoder</span></code>’s
<code class="docutils literal notranslate"><span class="pre">forward</span></code> method. However, now that we are using scripting, we
do not have this freedom, as the assumption with scripting is that
we cannot necessarily hold on to Python objects, especially when
exporting. An easy solution to this is to store these values from
the global scope as attributes to the module in the constructor,
and add them to a special list called <code class="docutils literal notranslate"><span class="pre">__constants__</span></code> so that
they can be used as literal values when constructing the graph in
the <code class="docutils literal notranslate"><span class="pre">forward</span></code> method. An example of this usage is on NEW line
19, where instead of using the <code class="docutils literal notranslate"><span class="pre">device</span></code> and <code class="docutils literal notranslate"><span class="pre">SOS_token</span></code> global
values, we use our constant attributes <code class="docutils literal notranslate"><span class="pre">self._device</span></code> and
<code class="docutils literal notranslate"><span class="pre">self._SOS_token</span></code>.</p></li>
</ul>
</li>
<li><p>Enforce types of <code class="docutils literal notranslate"><span class="pre">forward</span></code> method arguments</p>
<ul>
<li><p>By default, all parameters to a TorchScript function are assumed
to be Tensor. If we need to pass an argument of a different type,
we can use function type annotations as introduced in <a class="reference external" href="https://www.python.org/dev/peps/pep-3107/">PEP
3107</a>. In addition,
it is possible to declare arguments of different types using
Mypy-style type annotations (see
<a class="reference external" href="https://pytorch.org/docs/master/jit.html#types">doc</a>).</p></li>
</ul>
</li>
<li><p>Change initialization of <code class="docutils literal notranslate"><span class="pre">decoder_input</span></code></p>
<ul>
<li><p>In the original implementation, we initialized our
<code class="docutils literal notranslate"><span class="pre">decoder_input</span></code> tensor with <code class="docutils literal notranslate"><span class="pre">torch.LongTensor([[SOS_token]])</span></code>.
When scripting, we are not allowed to initialize tensors in a
literal fashion like this. Instead, we can initialize our tensor
with an explicit torch function such as <code class="docutils literal notranslate"><span class="pre">torch.ones</span></code>. In this
case, we can easily replicate the scalar <code class="docutils literal notranslate"><span class="pre">decoder_input</span></code> tensor
by multiplying 1 by our SOS_token value stored in the constant
<code class="docutils literal notranslate"><span class="pre">self._SOS_token</span></code>.</p></li>
</ul>
</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">GreedySearchDecoder</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">GreedySearchDecoder</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a>
        <span class="bp">self</span><span class="o">.</span><span class="n">_SOS_token</span> <span class="o">=</span> <span class="n">SOS_token</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_decoder_n_layers</span> <span class="o">=</span> <span class="n">decoder_n_layers</span>

    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'_device'</span><span class="p">,</span> <span class="s1">'_SOS_token'</span><span class="p">,</span> <span class="s1">'_decoder_n_layers'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_seq</span> <span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span> <span class="n">input_length</span> <span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span> <span class="n">max_length</span> <span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="c1"># Forward input through encoder model</span>
        <span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_seq</span><span class="p">,</span> <span class="n">input_length</span><span class="p">)</span>
        <span class="c1"># Prepare encoder's final hidden layer to be first hidden input to the decoder</span>
        <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="n">encoder_hidden</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">_decoder_n_layers</span><span class="p">]</span>
        <span class="c1"># Initialize decoder input with SOS_token</span>
        <span class="n">decoder_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype"><span class="n">torch</span><span class="o">.</span><span class="n">long</span></a><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_SOS_token</span>
        <span class="c1"># Initialize tensors to append decoded words to</span>
        <span class="n">all_tokens</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype"><span class="n">torch</span><span class="o">.</span><span class="n">long</span></a><span class="p">)</span>
        <span class="n">all_scores</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros" title="torch.zeros"><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span>
        <span class="c1"># Iteratively decode one word token at a time</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>
            <span class="c1"># Forward pass through decoder</span>
            <span class="n">decoder_output</span><span class="p">,</span> <span class="n">decoder_hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="p">)</span>
            <span class="c1"># Obtain most likely word token and its softmax score</span>
            <span class="n">decoder_scores</span><span class="p">,</span> <span class="n">decoder_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.max.html#torch.max" title="torch.max"><span class="n">torch</span><span class="o">.</span><span class="n">max</span></a><span class="p">(</span><span class="n">decoder_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Record token and score</span>
            <span class="n">all_tokens</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">((</span><span class="n">all_tokens</span><span class="p">,</span> <span class="n">decoder_input</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">all_scores</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">((</span><span class="n">all_scores</span><span class="p">,</span> <span class="n">decoder_scores</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Prepare current token to be next decoder input (add a dimension)</span>
            <span class="n">decoder_input</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze" title="torch.unsqueeze"><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span></a><span class="p">(</span><span class="n">decoder_input</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Return collections of word tokens and scores</span>
        <span class="k">return</span> <span class="n">all_tokens</span><span class="p">,</span> <span class="n">all_scores</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="evaluating-an-input">
<h3>Evaluating an Input<a class="headerlink" href="#evaluating-an-input" title="Permalink to this heading">¶</a></h3>
<p>Next, we define some functions for evaluating an input. The <code class="docutils literal notranslate"><span class="pre">evaluate</span></code>
function takes a normalized string sentence, processes it to a tensor of
its corresponding word indexes (with batch size of 1), and passes this
tensor to a <code class="docutils literal notranslate"><span class="pre">GreedySearchDecoder</span></code> instance called <code class="docutils literal notranslate"><span class="pre">searcher</span></code> to
handle the encoding/decoding process. The searcher returns the output
word index vector and a scores tensor corresponding to the softmax
scores for each decoded word token. The final step is to convert each
word index back to its string representation using <code class="docutils literal notranslate"><span class="pre">voc.index2word</span></code>.</p>
<p>We also define two functions for evaluating an input sentence. The
<code class="docutils literal notranslate"><span class="pre">evaluateInput</span></code> function prompts a user for an input, and evaluates
it. It will continue to ask for another input until the user enters ‘q’
or ‘quit’.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">evaluateExample</span></code> function simply takes a string input sentence as
an argument, normalizes it, evaluates it, and prints the response.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_LENGTH</span><span class="p">):</span>
    <span class="c1">### Format input sentence as a batch</span>
    <span class="c1"># words -&gt; indexes</span>
    <span class="n">indexes_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">indexesFromSentence</span><span class="p">(</span><span class="n">voc</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)]</span>
    <span class="c1"># Create lengths tensor</span>
    <span class="n">lengths</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">indexes</span><span class="p">)</span> <span class="k">for</span> <span class="n">indexes</span> <span class="ow">in</span> <span class="n">indexes_batch</span><span class="p">])</span>
    <span class="c1"># Transpose dimensions of batch to match models' expectations</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">indexes_batch</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Use appropriate device</span>
    <span class="n">input_batch</span> <span class="o">=</span> <span class="n">input_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
    <span class="n">lengths</span> <span class="o">=</span> <span class="n">lengths</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
    <span class="c1"># Decode sentence with searcher</span>
    <span class="n">tokens</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">searcher</span><span class="p">(</span><span class="n">input_batch</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">max_length</span><span class="p">)</span>
    <span class="c1"># indexes -&gt; words</span>
    <span class="n">decoded_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">voc</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">decoded_words</span>


<span class="c1"># Evaluate inputs from user input (``stdin``)</span>
<span class="k">def</span> <span class="nf">evaluateInput</span><span class="p">(</span><span class="n">searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="n">input_sentence</span> <span class="o">=</span> <span class="s1">''</span>
    <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Get input sentence</span>
            <span class="n">input_sentence</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">'&gt; '</span><span class="p">)</span>
            <span class="c1"># Check if it is quit case</span>
            <span class="k">if</span> <span class="n">input_sentence</span> <span class="o">==</span> <span class="s1">'q'</span> <span class="ow">or</span> <span class="n">input_sentence</span> <span class="o">==</span> <span class="s1">'quit'</span><span class="p">:</span> <span class="k">break</span>
            <span class="c1"># Normalize sentence</span>
            <span class="n">input_sentence</span> <span class="o">=</span> <span class="n">normalizeString</span><span class="p">(</span><span class="n">input_sentence</span><span class="p">)</span>
            <span class="c1"># Evaluate sentence</span>
            <span class="n">output_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">)</span>
            <span class="c1"># Format and print response sentence</span>
            <span class="n">output_words</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_words</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="s1">'EOS'</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">'PAD'</span><span class="p">)]</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Bot:'</span><span class="p">,</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">))</span>

        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">"Error: Encountered unknown word."</span><span class="p">)</span>

<span class="c1"># Normalize input sentence and call ``evaluate()``</span>
<span class="k">def</span> <span class="nf">evaluateExample</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"&gt; "</span> <span class="o">+</span> <span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># Normalize sentence</span>
    <span class="n">input_sentence</span> <span class="o">=</span> <span class="n">normalizeString</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="c1"># Evaluate sentence</span>
    <span class="n">output_words</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">,</span> <span class="n">input_sentence</span><span class="p">)</span>
    <span class="n">output_words</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_words</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="s1">'EOS'</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">'PAD'</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Bot:'</span><span class="p">,</span> <span class="s1">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_words</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="load-pretrained-parameters">
<h2>Load Pretrained Parameters<a class="headerlink" href="#load-pretrained-parameters" title="Permalink to this heading">¶</a></h2>
<p>No, let’s load our model!</p>
<div class="section" id="use-hosted-model">
<h3>Use hosted model<a class="headerlink" href="#use-hosted-model" title="Permalink to this heading">¶</a></h3>
<p>To load the hosted model:</p>
<ol class="arabic simple">
<li><p>Download the model <a class="reference external" href="https://download.pytorch.org/models/tutorials/4000_checkpoint.tar">here</a>.</p></li>
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">loadFilename</span></code> variable to the path to the downloaded
checkpoint file.</p></li>
<li><p>Leave the <code class="docutils literal notranslate"><span class="pre">checkpoint</span> <span class="pre">=</span> <span class="pre">torch.load(loadFilename)</span></code> line uncommented,
as the hosted model was trained on CPU.</p></li>
</ol>
</div>
<div class="section" id="use-your-own-model">
<h3>Use your own model<a class="headerlink" href="#use-your-own-model" title="Permalink to this heading">¶</a></h3>
<p>To load your own pretrained model:</p>
<ol class="arabic simple">
<li><p>Set the <code class="docutils literal notranslate"><span class="pre">loadFilename</span></code> variable to the path to the checkpoint file
that you wish to load. Note that if you followed the convention for
saving the model from the chatbot tutorial, this may involve changing
the <code class="docutils literal notranslate"><span class="pre">model_name</span></code>, <code class="docutils literal notranslate"><span class="pre">encoder_n_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">decoder_n_layers</span></code>,
<code class="docutils literal notranslate"><span class="pre">hidden_size</span></code>, and <code class="docutils literal notranslate"><span class="pre">checkpoint_iter</span></code> (as these values are used in
the model path).</p></li>
<li><p>If you trained the model on a CPU, make sure that you are opening the
checkpoint with the <code class="docutils literal notranslate"><span class="pre">checkpoint</span> <span class="pre">=</span> <span class="pre">torch.load(loadFilename)</span></code> line.
If you trained the model on a GPU and are running this tutorial on a
CPU, uncomment the
<code class="docutils literal notranslate"><span class="pre">checkpoint</span> <span class="pre">=</span> <span class="pre">torch.load(loadFilename,</span> <span class="pre">map_location=torch.device('cpu'))</span></code>
line.</p></li>
</ol>
</div>
<div class="section" id="id2">
<h3>TorchScript Notes:<a class="headerlink" href="#id2" title="Permalink to this heading">¶</a></h3>
<p>Notice that we initialize and load parameters into our encoder and
decoder models as usual. If you are using tracing mode(<code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code>)
for some part of your models, you must call <code class="docutils literal notranslate"><span class="pre">.to(device)</span></code> to set the device
options of the models and <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> to set the dropout layers to test mode
<strong>before</strong> tracing the models. <cite>TracedModule</cite> objects do not inherit the
<code class="docutils literal notranslate"><span class="pre">to</span></code> or <code class="docutils literal notranslate"><span class="pre">eval</span></code> methods. Since in this tutorial we are only using
scripting instead of tracing, we only need to do this before we do
evaluation (which is the same as we normally do in eager mode).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">save_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">"data"</span><span class="p">,</span> <span class="s2">"save"</span><span class="p">)</span>
<span class="n">corpus_name</span> <span class="o">=</span> <span class="s2">"cornell movie-dialogs corpus"</span>

<span class="c1"># Configure models</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">'cb_model'</span>
<span class="n">attn_model</span> <span class="o">=</span> <span class="s1">'dot'</span>
<span class="c1">#attn_model = 'general'``</span>
<span class="c1">#attn_model = 'concat'</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">encoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">decoder_n_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># If you're loading your own model</span>
<span class="c1"># Set checkpoint to load from</span>
<span class="n">checkpoint_iter</span> <span class="o">=</span> <span class="mi">4000</span>
</pre></div>
</div>
<p>Sample code to load from a checkpoint:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loadFilename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">corpus_name</span><span class="p">,</span>
                         <span class="s1">'</span><span class="si">{}</span><span class="s1">-</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoder_n_layers</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
                         <span class="s1">'</span><span class="si">{}</span><span class="s1">_checkpoint.tar'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">checkpoint_iter</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># If you're loading the hosted model</span>
<span class="n">loadFilename</span> <span class="o">=</span> <span class="s1">'data/4000_checkpoint.tar'</span>

<span class="c1"># Load model</span>
<span class="c1"># Force CPU device options (to match tensors in this tutorial)</span>
<span class="n">checkpoint</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="torch.load"><span class="n">torch</span><span class="o">.</span><span class="n">load</span></a><span class="p">(</span><span class="n">loadFilename</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s1">'cpu'</span><span class="p">))</span>
<span class="n">encoder_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'en'</span><span class="p">]</span>
<span class="n">decoder_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'de'</span><span class="p">]</span>
<span class="n">encoder_optimizer_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'en_opt'</span><span class="p">]</span>
<span class="n">decoder_optimizer_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'de_opt'</span><span class="p">]</span>
<span class="n">embedding_sd</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'embedding'</span><span class="p">]</span>
<span class="n">voc</span> <span class="o">=</span> <span class="n">Voc</span><span class="p">(</span><span class="n">corpus_name</span><span class="p">)</span>
<span class="n">voc</span><span class="o">.</span><span class="vm">__dict__</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'voc_dict'</span><span class="p">]</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">'Building encoder and decoder ...'</span><span class="p">)</span>
<span class="c1"># Initialize word embeddings</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span></a><span class="p">(</span><span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><span class="n">embedding</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><span class="n">embedding_sd</span><span class="p">)</span>
<span class="c1"># Initialize encoder &amp; decoder models</span>
<span class="n">encoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">EncoderRNN</span></a><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">,</span> <span class="n">encoder_n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">LuongAttnDecoderRNN</span></a><span class="p">(</span><span class="n">attn_model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="torch.nn.Embedding"><span class="n">embedding</span></a><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">,</span> <span class="n">decoder_n_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
<span class="c1"># Load trained model parameters</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><span class="n">encoder</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><span class="n">encoder_sd</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><span class="n">decoder</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><span class="n">decoder_sd</span><span class="p">)</span>
<span class="c1"># Use appropriate device</span>
<span class="n">encoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to"><span class="n">encoder</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to"><span class="n">decoder</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
<span class="c1"># Set dropout layers to ``eval`` mode</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval"><span class="n">encoder</span><span class="o">.</span><span class="n">eval</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval" title="torch.nn.Module.eval"><span class="n">decoder</span><span class="o">.</span><span class="n">eval</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Models built and ready to go!'</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:730: FutureWarning:

You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

Building encoder and decoder ...
Models built and ready to go!
</pre></div>
</div>
</div>
</div>
<div class="section" id="convert-model-to-torchscript">
<h2>Convert Model to TorchScript<a class="headerlink" href="#convert-model-to-torchscript" title="Permalink to this heading">¶</a></h2>
<div class="section" id="id3">
<h3>Encoder<a class="headerlink" href="#id3" title="Permalink to this heading">¶</a></h3>
<p>As previously mentioned, to convert the encoder model to TorchScript,
we use <strong>scripting</strong>. The encoder model takes an input sequence and
a corresponding lengths tensor. Therefore, we create an example input
sequence tensor <code class="docutils literal notranslate"><span class="pre">test_seq</span></code>, which is of appropriate size (MAX_LENGTH,
1), contains numbers in the appropriate range
<span class="math">\([0, voc.num\_words)\)</span>, and is of the appropriate type (int64). We
also create a <code class="docutils literal notranslate"><span class="pre">test_seq_length</span></code> scalar which realistically contains
the value corresponding to how many words are in the <code class="docutils literal notranslate"><span class="pre">test_seq</span></code>. The
next step is to use the <code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code> function to trace the model.
Notice that the first argument we pass is the module that we want to
trace, and the second is a tuple of arguments to the module’s
<code class="docutils literal notranslate"><span class="pre">forward</span></code> method.</p>
</div>
<div class="section" id="id4">
<h3>Decoder<a class="headerlink" href="#id4" title="Permalink to this heading">¶</a></h3>
<p>We perform the same process for tracing the decoder as we did for the
encoder. Notice that we call forward on a set of random inputs to the
traced_encoder to get the output that we need for the decoder. This is
not required, as we could also simply manufacture a tensor of the
correct shape, type, and value range. This method is possible because in
our case we do not have any constraints on the values of the tensors
because we do not have any operations that could fault on out-of-range
inputs.</p>
</div>
<div class="section" id="greedysearchdecoder">
<h3>GreedySearchDecoder<a class="headerlink" href="#greedysearchdecoder" title="Permalink to this heading">¶</a></h3>
<p>Recall that we scripted our searcher module due to the presence of
data-dependent control flow. In the case of scripting, we do necessary
language changes to make sure the implementation complies with
TorchScript. We initialize the scripted searcher the same way that we
would initialize an unscripted variant.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### Compile the whole greedy search model to TorchScript model</span>
<span class="c1"># Create artificial inputs</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq</span></a> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">MAX_LENGTH</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq_length</span></a> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq</span></a><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
<span class="c1"># Trace the model</span>
<span class="n">traced_encoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace" title="torch.jit.trace"><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span></a><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq_length</span></a><span class="p">))</span>

<span class="c1">### Convert decoder model</span>
<span class="c1"># Create and generate artificial inputs</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_encoder_outputs</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_encoder_hidden</span></a> <span class="o">=</span> <span class="n">traced_encoder</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_seq_length</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_decoder_hidden</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_encoder_hidden</span></a><span class="p">[:</span><span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">]</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_decoder_input</span></a> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">voc</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span>
<span class="c1"># Trace the model</span>
<span class="n">traced_decoder</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace" title="torch.jit.trace"><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span></a><span class="p">(</span><span class="n">decoder</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_decoder_input</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_decoder_hidden</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">test_encoder_outputs</span></a><span class="p">))</span>

<span class="c1">### Initialize searcher module by wrapping ``torch.jit.script`` call</span>
<span class="n">scripted_searcher</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-function" href="https://pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script" title="torch.jit.script"><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">GreedySearchDecoder</span></a><span class="p">(</span><span class="n">traced_encoder</span><span class="p">,</span> <span class="n">traced_decoder</span><span class="p">,</span> <span class="n">decoder</span><span class="o">.</span><span class="n">n_layers</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/opt/conda/envs/py_3.10/lib/python3.10/site-packages/torch/jit/_trace.py:168: UserWarning:

The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)
</pre></div>
</div>
</div>
</div>
<div class="section" id="print-graphs">
<h2>Print Graphs<a class="headerlink" href="#print-graphs" title="Permalink to this heading">¶</a></h2>
<p>Now that our models are in TorchScript form, we can print the graphs of
each to ensure that we captured the computational graph appropriately.
Since TorchScript allow us to recursively compile the whole model
hierarchy and inline the <code class="docutils literal notranslate"><span class="pre">encoder</span></code> and <code class="docutils literal notranslate"><span class="pre">decoder</span></code> graph into a single
graph, we just need to print the <cite>scripted_searcher</cite> graph</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'scripted_searcher graph:</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-property" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.graph" title="torch.jit.ScriptModule.graph"><span class="n">scripted_searcher</span><span class="o">.</span><span class="n">graph</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>scripted_searcher graph:
 graph(%self : __torch__.GreedySearchDecoder,
      %input_seq.1 : Tensor,
      %input_length.1 : Tensor,
      %max_length.1 : int):
  %53 : bool = prim::Constant[value=0]()
  %42 : bool = prim::Constant[value=1]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:561:8
  %18 : int = prim::Constant[value=4]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:556:68
  %17 : Device = prim::Constant[value="cpu"]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:556:48
  %14 : NoneType = prim::Constant()
  %12 : int = prim::Constant[value=2]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:554:41
  %16 : int = prim::Constant[value=1]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:556:35
  %26 : int = prim::Constant[value=0]() # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:558:34
  %encoder : __torch__.EncoderRNN = prim::GetAttr[name="encoder"](%self)
  %7 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%encoder, %input_seq.1, %input_length.1) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:552:42
  %encoder_outputs.1 : Tensor, %encoder_hidden.1 : Tensor = prim::TupleUnpack(%7)
  %decoder_hidden.1 : Tensor = aten::slice(%encoder_hidden.1, %26, %14, %12, %16) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:554:25
  %20 : int[] = prim::ListConstruct(%16, %16)
  %23 : Tensor = aten::ones(%20, %18, %14, %17, %14) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:556:24
  %decoder_input.1 : Tensor = aten::mul(%23, %16) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:556:24
  %27 : int[] = prim::ListConstruct(%26)
  %all_tokens.1 : Tensor = aten::zeros(%27, %18, %14, %17, %14) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:558:21
  %33 : int[] = prim::ListConstruct(%26)
  %all_scores.1 : Tensor = aten::zeros(%33, %14, %14, %17, %14) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:559:21
  %all_tokens : Tensor, %all_scores : Tensor, %decoder_hidden : Tensor, %decoder_input : Tensor = prim::Loop(%max_length.1, %42, %all_tokens.1, %all_scores.1, %decoder_hidden.1, %decoder_input.1) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:561:8
    block0(%43 : int, %all_tokens.11 : Tensor, %all_scores.11 : Tensor, %decoder_hidden.9 : Tensor, %decoder_input.17 : Tensor):
      %decoder : __torch__.LuongAttnDecoderRNN = prim::GetAttr[name="decoder"](%self)
      %48 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%decoder, %decoder_input.17, %decoder_hidden.9, %encoder_outputs.1) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:563:45
      %decoder_output.1 : Tensor, %decoder_hidden.5 : Tensor = prim::TupleUnpack(%48)
      %decoder_scores.1 : Tensor, %decoder_input.5 : Tensor = aten::max(%decoder_output.1, %16, %53) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:565:44
      %61 : Tensor[] = prim::ListConstruct(%all_tokens.11, %decoder_input.5)
      %all_tokens.5 : Tensor = aten::cat(%61, %26) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:567:25
      %67 : Tensor[] = prim::ListConstruct(%all_scores.11, %decoder_scores.1)
      %all_scores.5 : Tensor = aten::cat(%67, %26) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:568:25
      %decoder_input.13 : Tensor = aten::unsqueeze(%decoder_input.5, %26) # /var/lib/workspace/beginner_source/deploy_seq2seq_hybrid_frontend_tutorial.py:570:28
      -&gt; (%42, %all_tokens.5, %all_scores.5, %decoder_hidden.5, %decoder_input.13)
  %75 : (Tensor, Tensor) = prim::TupleConstruct(%all_tokens, %all_scores)
  return (%75)
</pre></div>
</div>
</div>
<div class="section" id="run-evaluation">
<h2>Run Evaluation<a class="headerlink" href="#run-evaluation" title="Permalink to this heading">¶</a></h2>
<p>Finally, we will run evaluation of the chatbot model using the TorchScript
models. If converted correctly, the models will behave exactly as they
would in their eager-mode representation.</p>
<p>By default, we evaluate a few common query sentences. If you want to
chat with the bot yourself, uncomment the <code class="docutils literal notranslate"><span class="pre">evaluateInput</span></code> line and
give it a spin.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use appropriate device</span>
<a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to" title="torch.jit.ScriptModule.to"><span class="n">scripted_searcher</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">device</span></a><span class="p">)</span>
<span class="c1"># Set dropout layers to ``eval`` mode</span>
<a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.eval" title="torch.jit.ScriptModule.eval"><span class="n">scripted_searcher</span><span class="o">.</span><span class="n">eval</span></a><span class="p">()</span>

<span class="c1"># Evaluate examples</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"hello"</span><span class="p">,</span> <span class="s2">"what's up?"</span><span class="p">,</span> <span class="s2">"who are you?"</span><span class="p">,</span> <span class="s2">"where am I?"</span><span class="p">,</span> <span class="s2">"where are you from?"</span><span class="p">]</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">evaluateExample</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">scripted_searcher</span><span class="p">,</span> <span class="n">voc</span><span class="p">)</span>

<span class="c1"># Evaluate your input by running</span>
<span class="c1"># ``evaluateInput(traced_encoder, traced_decoder, scripted_searcher, voc)``</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&gt; hello
Bot: hello .
&gt; what's up?
Bot: i m going to get my car .
&gt; who are you?
Bot: i m the owner .
&gt; where am I?
Bot: in the house .
&gt; where are you from?
Bot: south america .
</pre></div>
</div>
</div>
<div class="section" id="save-model">
<h2>Save Model<a class="headerlink" href="#save-model" title="Permalink to this heading">¶</a></h2>
<p>Now that we have successfully converted our model to TorchScript, we
will serialize it for use in a non-Python deployment environment. To do
this, we can simply save our <code class="docutils literal notranslate"><span class="pre">scripted_searcher</span></code> module, as this is
the user-facing interface for running inference against the chatbot
model. When saving a Script module, use script_module.save(PATH) instead
of torch.save(model, PATH).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-method" href="https://pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.save" title="torch.jit.ScriptModule.save"><span class="n">scripted_searcher</span><span class="o">.</span><span class="n">save</span></a><span class="p">(</span><span class="s2">"scripted_chatbot.pth"</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.727 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-deploy-seq2seq-hybrid-frontend-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/b333ee9add2489fe6da06cebde14537a/deploy_seq2seq_hybrid_frontend_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_seq2seq_hybrid_frontend_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7eba5f912646e2d2239d4e1ce08de5ec/deploy_seq2seq_hybrid_frontend_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_seq2seq_hybrid_frontend_tutorial.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<hr class="rating-hr hr-top"/>
<div class="rating-container">
<div class="rating-prompt">Rate this Tutorial</div>
<div class="stars-outer">
<i class="far fa-star" data-behavior="tutorial-rating" data-count="1" title="1 Star"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="2" title="2 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="3" title="3 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="4" title="4 Stars"></i>
<i class="far fa-star" data-behavior="tutorial-rating" data-count="5" title="5 Stars"></i>
</div>
</div>
<hr class="rating-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2024, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Deploying a Seq2Seq Model with TorchScript</a><ul>
<li><a class="reference internal" href="#what-is-torchscript">What is TorchScript?</a></li>
<li><a class="reference internal" href="#acknowledgments">Acknowledgments</a></li>
<li><a class="reference internal" href="#prepare-environment">Prepare Environment</a></li>
<li><a class="reference internal" href="#model-overview">Model Overview</a><ul>
<li><a class="reference internal" href="#encoder">Encoder</a></li>
<li><a class="reference internal" href="#decoder">Decoder</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data-handling">Data Handling</a></li>
<li><a class="reference internal" href="#define-encoder">Define Encoder</a><ul>
<li><a class="reference internal" href="#torchscript-notes">TorchScript Notes:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#define-decoders-attention-module">Define Decoder’s Attention Module</a></li>
<li><a class="reference internal" href="#define-decoder">Define Decoder</a></li>
<li><a class="reference internal" href="#define-evaluation">Define Evaluation</a><ul>
<li><a class="reference internal" href="#greedy-search-decoder">Greedy Search Decoder</a></li>
<li><a class="reference internal" href="#id1">TorchScript Notes:</a><ul>
<li><a class="reference internal" href="#changes">Changes:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#evaluating-an-input">Evaluating an Input</a></li>
</ul>
</li>
<li><a class="reference internal" href="#load-pretrained-parameters">Load Pretrained Parameters</a><ul>
<li><a class="reference internal" href="#use-hosted-model">Use hosted model</a></li>
<li><a class="reference internal" href="#use-your-own-model">Use your own model</a></li>
<li><a class="reference internal" href="#id2">TorchScript Notes:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#convert-model-to-torchscript">Convert Model to TorchScript</a><ul>
<li><a class="reference internal" href="#id3">Encoder</a></li>
<li><a class="reference internal" href="#id4">Decoder</a></li>
<li><a class="reference internal" href="#greedysearchdecoder">GreedySearchDecoder</a></li>
</ul>
</li>
<li><a class="reference internal" href="#print-graphs">Print Graphs</a></li>
<li><a class="reference internal" href="#run-evaluation">Run Evaluation</a></li>
<li><a class="reference internal" href="#save-model">Save Model</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script>
<script src="../_static/underscore.js"></script>
<script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
<script src="../_static/doctools.js"></script>
<script src="../_static/clipboard.min.js"></script>
<script src="../_static/copybutton.js"></script>
<script src="../_static/katex.min.js"></script>
<script src="../_static/auto-render.min.js"></script>
<script src="../_static/katex_autorenderer.js"></script>
<script src="../_static/design-tabs.js"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });
    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count"),
      'customEvent:Rating': $(this).attr("data-count") // send to GA custom dimension customEvent:Rating.
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Profiling PyTorch', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Edge with ExecuTorch', 'Recommendation Systems', 'Multimodality'];
</script>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">Stay up to date</li>
<li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title">PyTorch Podcasts</li>
<li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
<li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
<li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
<li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
</ul>
</div>
</div>
<div class="privacy-policy">
<ul>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
<li class="privacy-policy-links">|</li>
<li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
</ul>
</div>
<div class="copyright">
<p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg"/>
</div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Ecosystem</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/ecosystem">Tools</a>
</li>
<li>
<a href="https://pytorch.org/#community-module">Community</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Edge</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/edge">About PyTorch Edge</a>
</li>
<li>
<a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">PyTorch Blog</a>
</li>
<li>
<a href="https://pytorch.org/community-blog">Community Blog</a>
</li>
<li>
<a href="https://pytorch.org/videos">Videos</a>
</li>
<li>
<a href="https://pytorch.org/community-stories">Community Stories</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>