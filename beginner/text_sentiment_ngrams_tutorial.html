
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Text Classification with TorchText — PyTorch Tutorials 1.6.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="torchtext_translation_tutorial.html" rel="next" title="Language Translation with TorchText"/>
<link href="../intermediate/seq2seq_translation_tutorial.html" rel="prev" title="NLP From Scratch: Translation with a Sequence to Sequence Network and Attention"/>
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<div class="ecosystem-dropdown">
<a data-toggle="ecosystem-dropdown" id="dropdownMenuButton">
                Ecosystem
              </a>
<div class="ecosystem-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
<span class="dropdown-title">Tools &amp; Libraries</span>
<p>Explore the ecosystem of tools and libraries</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<div class="resources-dropdown">
<a data-toggle="resources-dropdown" id="resourcesDropdownButton">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.6.0
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image/Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">torchaudio Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Text Classification with TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation_tutorial.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Dispatcher in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_distributed_training_tutorial.html">(advanced) PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Text Classification with TorchText</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/text_sentiment_ngrams_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/text_sentiment_ngrams_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-text-sentiment-ngrams-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="text-classification-with-torchtext">
<span id="sphx-glr-beginner-text-sentiment-ngrams-tutorial-py"></span><h1>Text Classification with TorchText<a class="headerlink" href="#text-classification-with-torchtext" title="Permalink to this headline">¶</a></h1>
<p>This tutorial shows how to use the text classification datasets
in <code class="docutils literal notranslate"><span class="pre">torchtext</span></code>, including</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span> <span class="n">AG_NEWS</span><span class="p">,</span>
<span class="o">-</span> <span class="n">SogouNews</span><span class="p">,</span>
<span class="o">-</span> <span class="n">DBpedia</span><span class="p">,</span>
<span class="o">-</span> <span class="n">YelpReviewPolarity</span><span class="p">,</span>
<span class="o">-</span> <span class="n">YelpReviewFull</span><span class="p">,</span>
<span class="o">-</span> <span class="n">YahooAnswers</span><span class="p">,</span>
<span class="o">-</span> <span class="n">AmazonReviewPolarity</span><span class="p">,</span>
<span class="o">-</span> <span class="n">AmazonReviewFull</span>
</pre></div>
</div>
<p>This example shows how to train a supervised learning algorithm for
classification using one of these <code class="docutils literal notranslate"><span class="pre">TextClassification</span></code> datasets.</p>
<div class="section" id="load-data-with-ngrams">
<h2>Load data with ngrams<a class="headerlink" href="#load-data-with-ngrams" title="Permalink to this headline">¶</a></h2>
<p>A bag of ngrams feature is applied to capture some partial information
about the local word order. In practice, bi-gram or tri-gram are applied
to provide more benefits as word groups than only one word. An example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">"load data with ngrams"</span>
<span class="n">Bi</span><span class="o">-</span><span class="n">grams</span> <span class="n">results</span><span class="p">:</span> <span class="s2">"load data"</span><span class="p">,</span> <span class="s2">"data with"</span><span class="p">,</span> <span class="s2">"with ngrams"</span>
<span class="n">Tri</span><span class="o">-</span><span class="n">grams</span> <span class="n">results</span><span class="p">:</span> <span class="s2">"load data with"</span><span class="p">,</span> <span class="s2">"data with ngrams"</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">TextClassification</span></code> Dataset supports the ngrams method. By setting
ngrams to 2, the example text in the dataset will be a list of single
words plus bi-grams string.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchtext</span>
<span class="kn">from</span> <span class="nn">torchtext.datasets</span> <span class="kn">import</span> <span class="n">text_classification</span>
<span class="n">NGRAMS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="s1">'./.data'</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="s1">'./.data'</span><span class="p">)</span>
<span class="n">train_dataset</span><span class="p">,</span> <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">text_classification</span><span class="o">.</span><span class="n">DATASETS</span><span class="p">[</span><span class="s1">'AG_NEWS'</span><span class="p">](</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">'./.data'</span><span class="p">,</span> <span class="n">ngrams</span><span class="o">=</span><span class="n">NGRAMS</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Permalink to this headline">¶</a></h2>
<p>The model is composed of the
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html?highlight=embeddingbag#torch.nn.EmbeddingBag">EmbeddingBag</a>
layer and the linear layer (see the figure below). <code class="docutils literal notranslate"><span class="pre">nn.EmbeddingBag</span></code>
computes the mean value of a “bag” of embeddings. The text entries here
have different lengths. <code class="docutils literal notranslate"><span class="pre">nn.EmbeddingBag</span></code> requires no padding here
since the text lengths are saved in offsets.</p>
<p>Additionally, since <code class="docutils literal notranslate"><span class="pre">nn.EmbeddingBag</span></code> accumulates the average across
the embeddings on the fly, <code class="docutils literal notranslate"><span class="pre">nn.EmbeddingBag</span></code> can enhance the
performance and memory efficiency to process a sequence of tensors.</p>
<img alt="../_images/text_sentiment_ngrams_model.png" src="../_images/text_sentiment_ngrams_model.png"/>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="k">class</span> <span class="nc">TextSentiment</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_class</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingBag</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_class</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">initrange</span> <span class="o">=</span> <span class="mf">0.5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">):</span>
        <span class="n">embedded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="initiate-an-instance">
<h2>Initiate an instance<a class="headerlink" href="#initiate-an-instance" title="Permalink to this headline">¶</a></h2>
<p>The AG_NEWS dataset has four labels and therefore the number of classes
is four.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="p">:</span> <span class="n">World</span>
<span class="mi">2</span> <span class="p">:</span> <span class="n">Sports</span>
<span class="mi">3</span> <span class="p">:</span> <span class="n">Business</span>
<span class="mi">4</span> <span class="p">:</span> <span class="n">Sci</span><span class="o">/</span><span class="n">Tec</span>
</pre></div>
</div>
<p>The vocab size is equal to the length of vocab (including single word
and ngrams). The number of classes is equal to the number of labels,
which is four in AG_NEWS case.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">())</span>
<span class="n">EMBED_DIM</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">NUN_CLASS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="o">.</span><span class="n">get_labels</span><span class="p">())</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TextSentiment</span><span class="p">(</span><span class="n">VOCAB_SIZE</span><span class="p">,</span> <span class="n">EMBED_DIM</span><span class="p">,</span> <span class="n">NUN_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="functions-used-to-generate-batch">
<h2>Functions used to generate batch<a class="headerlink" href="#functions-used-to-generate-batch" title="Permalink to this headline">¶</a></h2>
<p>Since the text entries have different lengths, a custom function
generate_batch() is used to generate data batches and offsets. The
function is passed to <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> in <code class="docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code>.
The input to <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> is a list of tensors with the size of
batch_size, and the <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> function packs them into a
mini-batch. Pay attention here and make sure that <code class="docutils literal notranslate"><span class="pre">collate_fn</span></code> is
declared as a top level def. This ensures that the function is available
in each worker.</p>
<p>The text entries in the original data batch input are packed into a list
and concatenated as a single tensor as the input of <code class="docutils literal notranslate"><span class="pre">nn.EmbeddingBag</span></code>.
The offsets is a tensor of delimiters to represent the beginning index
of the individual sequence in the text tensor. Label is a tensor saving
the labels of individual text entries.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">entry</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">entry</span><span class="p">)</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">text</span><span class="p">]</span>
    <span class="c1"># torch.Tensor.cumsum returns the cumulative sum</span>
    <span class="c1"># of elements in the dimension dim.</span>
    <span class="c1"># torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)</span>

    <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">offsets</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</div>
<div class="section" id="define-functions-to-train-the-model-and-evaluate-results">
<h2>Define functions to train the model and evaluate results.<a class="headerlink" href="#define-functions-to-train-the-model-and-evaluate-results" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader">torch.utils.data.DataLoader</a>
is recommended for PyTorch users, and it makes data loading in parallel
easily (a tutorial is
<a class="reference external" href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">here</a>).
We use <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> here to load AG_NEWS datasets and send it to the
model for training/validation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="k">def</span> <span class="nf">train_func</span><span class="p">(</span><span class="n">sub_train_</span><span class="p">):</span>

    <span class="c1"># Train the model</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">sub_train_</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">collate_fn</span><span class="o">=</span><span class="n">generate_batch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="bp">cls</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">offsets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="bp">cls</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">train_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># Adjust the learning rate</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sub_train_</span><span class="p">),</span> <span class="n">train_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">sub_train_</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">data_</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data_</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">generate_batch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="bp">cls</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">offsets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="bp">cls</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_</span><span class="p">),</span> <span class="n">acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="split-the-dataset-and-run-the-model">
<h2>Split the dataset and run the model<a class="headerlink" href="#split-the-dataset-and-run-the-model" title="Permalink to this headline">¶</a></h2>
<p>Since the original AG_NEWS has no valid dataset, we split the training
dataset into train/valid sets with a split ratio of 0.95 (train) and
0.05 (valid). Here we use
<a class="reference external" href="https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split">torch.utils.data.dataset.random_split</a>
function in PyTorch core library.</p>
<p><a class="reference external" href="https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss">CrossEntropyLoss</a>
criterion combines nn.LogSoftmax() and nn.NLLLoss() in a single class.
It is useful when training a classification problem with C classes.
<a class="reference external" href="https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html">SGD</a>
implements stochastic gradient descent method as optimizer. The initial
learning rate is set to 4.0.
<a class="reference external" href="https://pytorch.org/docs/master/_modules/torch/optim/lr_scheduler.html#StepLR">StepLR</a>
is used here to adjust the learning rate through epochs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">torch.utils.data.dataset</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="n">N_EPOCHS</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">min_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'inf'</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">train_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.95</span><span class="p">)</span>
<span class="n">sub_train_</span><span class="p">,</span> <span class="n">sub_valid_</span> <span class="o">=</span> \
    <span class="n">random_split</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_len</span><span class="p">])</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_EPOCHS</span><span class="p">):</span>

    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_func</span><span class="p">(</span><span class="n">sub_train_</span><span class="p">)</span>
    <span class="n">valid_loss</span><span class="p">,</span> <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">sub_valid_</span><span class="p">)</span>

    <span class="n">secs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>
    <span class="n">mins</span> <span class="o">=</span> <span class="n">secs</span> <span class="o">/</span> <span class="mi">60</span>
    <span class="n">secs</span> <span class="o">=</span> <span class="n">secs</span> <span class="o">%</span> <span class="mi">60</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">" | time in </span><span class="si">%d</span><span class="s2"> minutes, </span><span class="si">%d</span><span class="s2"> seconds"</span> <span class="o">%</span><span class="p">(</span><span class="n">mins</span><span class="p">,</span> <span class="n">secs</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">(train)</span><span class="se">\t</span><span class="s1">|</span><span class="se">\t</span><span class="s1">Acc: </span><span class="si">{</span><span class="n">train_acc</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%(train)'</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{</span><span class="n">valid_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">(valid)</span><span class="se">\t</span><span class="s1">|</span><span class="se">\t</span><span class="s1">Acc: </span><span class="si">{</span><span class="n">valid_acc</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%(valid)'</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch: 1  | time in 0 minutes, 9 seconds
        Loss: 0.0259(train)     |       Acc: 85.0%(train)
        Loss: 0.0000(valid)     |       Acc: 88.5%(valid)
Epoch: 2  | time in 0 minutes, 9 seconds
        Loss: 0.0119(train)     |       Acc: 93.7%(train)
        Loss: 0.0000(valid)     |       Acc: 90.4%(valid)
Epoch: 3  | time in 0 minutes, 9 seconds
        Loss: 0.0069(train)     |       Acc: 96.4%(train)
        Loss: 0.0000(valid)     |       Acc: 90.7%(valid)
Epoch: 4  | time in 0 minutes, 9 seconds
        Loss: 0.0039(train)     |       Acc: 98.1%(train)
        Loss: 0.0000(valid)     |       Acc: 90.9%(valid)
Epoch: 5  | time in 0 minutes, 9 seconds
        Loss: 0.0023(train)     |       Acc: 99.0%(train)
        Loss: 0.0000(valid)     |       Acc: 90.5%(valid)
</pre></div>
</div>
<p>Running the model on GPU with the following information:</p>
<p>Epoch: 1 | time in 0 minutes, 11 seconds</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0263</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">84.5</span><span class="o">%</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">89.0</span><span class="o">%</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</pre></div>
</div>
<p>Epoch: 2 | time in 0 minutes, 10 seconds</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0119</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">93.6</span><span class="o">%</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0000</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">89.6</span><span class="o">%</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</pre></div>
</div>
<p>Epoch: 3 | time in 0 minutes, 9 seconds</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0069</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">96.4</span><span class="o">%</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0000</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">90.5</span><span class="o">%</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</pre></div>
</div>
<p>Epoch: 4 | time in 0 minutes, 11 seconds</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0038</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">98.2</span><span class="o">%</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0000</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">90.4</span><span class="o">%</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</pre></div>
</div>
<p>Epoch: 5 | time in 0 minutes, 11 seconds</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0022</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">99.0</span><span class="o">%</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0000</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>     <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">91.0</span><span class="o">%</span><span class="p">(</span><span class="n">valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="evaluate-the-model-with-test-dataset">
<h2>Evaluate the model with test dataset<a class="headerlink" href="#evaluate-the-model-with-test-dataset" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Checking the results of test dataset...'</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'</span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">(test)</span><span class="se">\t</span><span class="s1">|</span><span class="se">\t</span><span class="s1">Acc: </span><span class="si">{</span><span class="n">test_acc</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%(test)'</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Checking the results of test dataset...
        Loss: 0.0002(test)      |       Acc: 90.1%(test)
</pre></div>
</div>
<p>Checking the results of test dataset…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0237</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>      <span class="o">|</span>       <span class="n">Acc</span><span class="p">:</span> <span class="mf">90.5</span><span class="o">%</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="test-on-a-random-news">
<h2>Test on a random news<a class="headerlink" href="#test-on-a-random-news" title="Permalink to this headline">¶</a></h2>
<p>Use the best model so far and test a golf news. The label information is
available
<a class="reference external" href="https://pytorch.org/text/datasets.html?highlight=ag_news#torchtext.datasets.AG_NEWS">here</a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">torchtext.data.utils</span> <span class="kn">import</span> <span class="n">ngrams_iterator</span>
<span class="kn">from</span> <span class="nn">torchtext.data.utils</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>

<span class="n">ag_news_label</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span> <span class="p">:</span> <span class="s2">"World"</span><span class="p">,</span>
                 <span class="mi">2</span> <span class="p">:</span> <span class="s2">"Sports"</span><span class="p">,</span>
                 <span class="mi">3</span> <span class="p">:</span> <span class="s2">"Business"</span><span class="p">,</span>
                 <span class="mi">4</span> <span class="p">:</span> <span class="s2">"Sci/Tec"</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">ngrams</span><span class="p">):</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s2">"basic_english"</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
                            <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">ngrams_iterator</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">),</span> <span class="n">ngrams</span><span class="p">)])</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>

<span class="n">ex_text_str</span> <span class="o">=</span> <span class="s2">"MEMPHIS, Tenn. – Four days ago, Jon Rahm was </span><span class="se">\</span>
<span class="s2">    enduring the season’s worst weather conditions on Sunday at The </span><span class="se">\</span>
<span class="s2">    Open on his way to a closing 75 at Royal Portrush, which </span><span class="se">\</span>
<span class="s2">    considering the wind and the rain was a respectable showing. </span><span class="se">\</span>
<span class="s2">    Thursday’s first round at the WGC-FedEx St. Jude Invitational </span><span class="se">\</span>
<span class="s2">    was another story. With temperatures in the mid-80s and hardly any </span><span class="se">\</span>
<span class="s2">    wind, the Spaniard was 13 strokes better in a flawless round. </span><span class="se">\</span>
<span class="s2">    Thanks to his best putting performance on the PGA Tour, Rahm </span><span class="se">\</span>
<span class="s2">    finished with an 8-under 62 for a three-stroke lead, which </span><span class="se">\</span>
<span class="s2">    was even more impressive considering he’d never played the </span><span class="se">\</span>
<span class="s2">    front nine at TPC Southwind."</span>

<span class="n">vocab</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">get_vocab</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"This is a </span><span class="si">%s</span><span class="s2"> news"</span> <span class="o">%</span><span class="n">ag_news_label</span><span class="p">[</span><span class="n">predict</span><span class="p">(</span><span class="n">ex_text_str</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>This is a Sports news
</pre></div>
</div>
<p>This is a Sports news</p>
<p>You can find the code examples displayed in this note
<a class="reference external" href="https://github.com/pytorch/text/tree/master/examples/text_classification">here</a>.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  27.729 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-text-sentiment-ngrams-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/1824f32965271d21829e1739cc434729/text_sentiment_ngrams_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">text_sentiment_ngrams_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/27bd42079e7f46673b53e90153168529/text_sentiment_ngrams_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">text_sentiment_ngrams_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="torchtext_translation_tutorial.html" rel="next" title="Language Translation with TorchText">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="../intermediate/seq2seq_translation_tutorial.html" rel="prev" title="NLP From Scratch: Translation with a Sequence to Sequence Network and Attention"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="helpful-hr hr-top"/>
<div class="helpful-container">
<div class="helpful-question">Was this helpful?</div>
<div class="helpful-question yes-link" data-behavior="was-this-helpful-event" data-response="yes">Yes</div>
<div class="helpful-question no-link" data-behavior="was-this-helpful-event" data-response="no">No</div>
<div class="was-helpful-thank-you">Thank you</div>
</div>
<hr class="helpful-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Text Classification with TorchText</a><ul>
<li><a class="reference internal" href="#load-data-with-ngrams">Load data with ngrams</a></li>
<li><a class="reference internal" href="#define-the-model">Define the model</a></li>
<li><a class="reference internal" href="#initiate-an-instance">Initiate an instance</a></li>
<li><a class="reference internal" href="#functions-used-to-generate-batch">Functions used to generate batch</a></li>
<li><a class="reference internal" href="#define-functions-to-train-the-model-and-evaluate-results">Define functions to train the model and evaluate results.</a></li>
<li><a class="reference internal" href="#split-the-dataset-and-run-the-model">Split the dataset and run the model</a></li>
<li><a class="reference internal" href="#evaluate-the-model-with-test-dataset">Evaluate the model with test dataset</a></li>
<li><a class="reference internal" href="#test-on-a-random-news">Test on a random news</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
    gtag('event', $(this).attr("data-response"), {
      'event_category': 'Was this Helpful?',
      'event_label': $("h1").first().text()
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Stay Connected</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
<a class="youtube" href="https://www.youtube.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg">
</img></div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/hub">PyTorch Hub</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body></html>
