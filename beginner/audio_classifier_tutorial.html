


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Audio Classifier Tutorial &mdash; PyTorch Tutorials 1.0.0.dev20181001 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   
  <div>

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.0.0.dev20181001
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_loading_tutorial.html">Data Loading and Processing Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy_seq2seq_hybrid_frontend_tutorial.html">Deploying a Seq2Seq Model with the Hybrid Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="saving_loading_models.html">Saving and Loading Models</a></li>
</ul>
<p class="caption"><span class="caption-text">Image</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="finetuning_torchvision_models_tutorial.html">Finetuning Torchvision Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer Using PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_caffe2.html">Transfering a Model from PyTorch to Caffe2 and Mobile using ONNX</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="chatbot_tutorial.html">Chatbot Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a></li>
</ul>
<p class="caption"><span class="caption-text">Generative</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating Extensions Using numpy and scipy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
</ul>
<p class="caption"><span class="caption-text">Production Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/ONNXLive.html">ONNX Live Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a PyTorch Model in C++</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">

      <section data-toggle="wy-nav-shift" class="pytorch-content-wrap">
        <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
          <div class="pytorch-breadcrumbs-wrapper">
            















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>Audio Classifier Tutorial</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/audio_classifier_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
          </div>

          <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
            Shortcuts
          </div>
        </div>

        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-audio-classifier-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="audio-classifier-tutorial">
<span id="sphx-glr-beginner-audio-classifier-tutorial-py"></span><h1>Audio Classifier Tutorial<a class="headerlink" href="#audio-classifier-tutorial" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/winston6">Winston Herring</a></p>
<p>This tutorial will show you how to correctly format an audio dataset and
then train/test an audio classifier network on the dataset. First, let’s
import the common torch packages as well as <code class="docutils literal notranslate"><span class="pre">torchaudio</span></code>, <code class="docutils literal notranslate"><span class="pre">pandas</span></code>,
and <code class="docutils literal notranslate"><span class="pre">numpy</span></code>. <code class="docutils literal notranslate"><span class="pre">torchaudio</span></code> is available <a class="reference external" href="https://github.com/pytorch/audio">here</a>
and can be installed by following the
instructions on the website.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="kn">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>
</div>
<p>Let’s check if a CUDA GPU is available and select our device. Running
the network on a GPU will greatly decrease the training/testing runtime.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>cuda
</pre></div>
</div>
<div class="section" id="importing-the-dataset">
<h2>Importing the Dataset<a class="headerlink" href="#importing-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>We will use the UrbanSound8K dataset to train our network. It is
available for free <a class="reference external" href="https://urbansounddataset.weebly.com/">here</a> and contains
10 audio classes with over 8000 audio samples! Once you have downloaded
the compressed dataset, extract it to your current working directory.
First, we will look at the csv file that provides information about the
individual sound files. <code class="docutils literal notranslate"><span class="pre">pandas</span></code> allows us to open the csv file and
use <code class="docutils literal notranslate"><span class="pre">.iloc()</span></code> to access the data within it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">csvData</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./UrbanSound8K/metadata/UrbanSound8K.csv&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">csvData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>slice_file_name    100032-3-0-0.wav
fsID                         100032
start                             0
end                        0.317551
salience                          1
fold                              5
classID                           3
class                      dog_bark
Name: 0, dtype: object
</pre></div>
</div>
<p>The 10 audio classes in the UrbanSound8K dataset are air_conditioner,
car_horn, children_playing, dog_bark, drilling, enginge_idling,
gun_shot, jackhammer, siren, and street_music. Let’s play a couple files
and see what they sound like. The first file is street music and the
second is an air conditioner.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython.display</span> <span class="kn">as</span> <span class="nn">ipd</span>
<span class="n">ipd</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="s1">&#39;./UrbanSound8K/audio/fold1/108041-9-0-5.wav&#39;</span><span class="p">)</span>

<span class="n">ipd</span><span class="o">.</span><span class="n">Audio</span><span class="p">(</span><span class="s1">&#39;./UrbanSound8K/audio/fold5/100852-0-0-19.wav&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="formatting-the-data">
<h2>Formatting the Data<a class="headerlink" href="#formatting-the-data" title="Permalink to this headline">¶</a></h2>
<p>Now that we know the format of the csv file entries, we can construct
our dataset. We will create a rapper class for our dataset using
<code class="docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code> that will handle loading the files and
performing some formatting steps. The UrbanSound8K dataset is separated
into 10 folders. We will use the data from 9 of these folders to train
our network and then use the 10th folder to test the network. The rapper
class will store the file names, labels, and folder numbers of the audio
files in the inputted folder list when initialized. The actual loading
and formatting steps will happen in the access function <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>, we use <code class="docutils literal notranslate"><span class="pre">torchaudio.load()</span></code> to convert the wav
files to tensors. <code class="docutils literal notranslate"><span class="pre">torchaudio.load()</span></code> returns a tuple containing the
newly created tensor along with the sampling frequency of the audio file
(44.1kHz for UrbanSound8K). The dataset uses two channels for audio so
we will use <code class="docutils literal notranslate"><span class="pre">torchaudio.transforms.DownmixMono()</span></code> to convert the audio
data to one channel. Next, we need to format the audio data. The network
we will make takes an input size of 32,000, while most of the audio
files have well over 100,000 samples. The UrbanSound8K audio is sampled
at 44.1kHz, so 32,000 samples only covers around 700 milliseconds. By
downsampling the audio to aproximately 8kHz, we can represent 4 seconds
with the 32,000 samples. This downsampling is achieved by taking every
fifth sample of the original audio tensor. Not every audio tensor is
long enough to handle the downsampling so these tensors will need to be
padded with zeros. The minimum length that won’t require padding is
160,000 samples.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">UrbanSoundDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="c1">#rapper for the UrbanSound8K dataset</span>
    <span class="c1"># Argument List</span>
    <span class="c1">#  path to the UrbanSound8K csv file</span>
    <span class="c1">#  path to the UrbanSound8K audio files</span>
    <span class="c1">#  list of folders to use in the dataset</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">csv_path</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">folderList</span><span class="p">):</span>
        <span class="n">csvData</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_path</span><span class="p">)</span>
        <span class="c1">#initialize lists to hold file names, labels, and folder numbers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">file_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">folders</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1">#loop through the csv entries and only add entries from folders in the folder list</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">csvData</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">csvData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span> <span class="ow">in</span> <span class="n">folderList</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">file_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">csvData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">csvData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">folders</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">csvData</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">file_path</span> <span class="o">=</span> <span class="n">file_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mixer</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">DownmixMono</span><span class="p">()</span> <span class="c1">#UrbanSound8K uses two channels, this will convert them to one</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">folderList</span> <span class="o">=</span> <span class="n">folderList</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="c1">#format the file path and load the file</span>
        <span class="n">path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_path</span> <span class="o">+</span> <span class="s2">&quot;fold&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">folders</span><span class="p">[</span><span class="n">index</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_names</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">sound</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">normalization</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
        <span class="c1">#load returns a tensor with the sound data and the sampling frequency (44.1kHz for UrbanSound8K)</span>
        <span class="n">soundData</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mixer</span><span class="p">(</span><span class="n">sound</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="c1">#downsample the audio to ~8kHz</span>
        <span class="n">tempData</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">160000</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1">#tempData accounts for audio clips that are too short</span>
        <span class="k">if</span> <span class="n">soundData</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">160000</span><span class="p">:</span>
            <span class="n">tempData</span><span class="p">[:</span><span class="n">soundData</span><span class="o">.</span><span class="n">numel</span><span class="p">()]</span> <span class="o">=</span> <span class="n">soundData</span><span class="p">[:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tempData</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">soundData</span><span class="p">[:</span><span class="mi">160000</span><span class="p">]</span>

        <span class="n">soundData</span> <span class="o">=</span> <span class="n">tempData</span>
        <span class="n">soundFormatted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">32000</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">soundFormatted</span><span class="p">[:</span><span class="mi">32000</span><span class="p">]</span> <span class="o">=</span> <span class="n">soundData</span><span class="p">[::</span><span class="mi">5</span><span class="p">]</span> <span class="c1">#take every fifth sample of soundData</span>
        <span class="n">soundFormatted</span> <span class="o">=</span> <span class="n">soundFormatted</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">soundFormatted</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">file_names</span><span class="p">)</span>


<span class="n">csv_path</span> <span class="o">=</span> <span class="s1">&#39;./UrbanSound8K/metadata/UrbanSound8K.csv&#39;</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;./UrbanSound8K/audio/&#39;</span>

<span class="n">train_set</span> <span class="o">=</span> <span class="n">UrbanSoundDataset</span><span class="p">(</span><span class="n">csv_path</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">test_set</span> <span class="o">=</span> <span class="n">UrbanSoundDataset</span><span class="p">(</span><span class="n">csv_path</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Train set size: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test set size: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)))</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;num_workers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;pin_memory&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">}</span> <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">else</span> <span class="p">{}</span> <span class="c1">#needed for using datasets on gpu</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Train set size: 7895
Test set size: 837
</pre></div>
</div>
</div>
<div class="section" id="define-the-network">
<h2>Define the Network<a class="headerlink" href="#define-the-network" title="Permalink to this headline">¶</a></h2>
<p>For this tutorial we will use a convolutional neural network to process
the raw audio data. Usually more advanced transforms are applied to the
audio data, however CNNs can be used to accurately process the raw data.
The specific architecture is modeled after the M5 network architecture
described in <a class="reference external" href="https://arxiv.org/pdf/1610.00087.pdf">https://arxiv.org/pdf/1610.00087.pdf</a>. An important aspect
of models processing raw audio data is the receptive field of their
first layer’s filters. Our model’s first filter is length 80 so when
processing audio sampled at 8kHz the receptive field is around 10ms.
This size is similar to speech processing applications that often use
receptive fields ranging from 20ms to 40ms.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgPool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="c1">#input should be 512x30 so this outputs a 512x1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bn4</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool4</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgPool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1">#change the 512x1 to 1x512</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Net(
  (conv1): Conv1d(1, 128, kernel_size=(80,), stride=(4,))
  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,))
  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool2): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,))
  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (conv4): Conv1d(256, 512, kernel_size=(3,), stride=(1,))
  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
  (avgPool): AvgPool1d(kernel_size=(30,), stride=(30,), padding=(0,))
  (fc1): Linear(in_features=512, out_features=10, bias=True)
)
</pre></div>
</div>
<p>We will use the same optimization technique used in the paper, an Adam
optimizer with weight decay set to 0.0001. At first, we will train with
a learning rate of 0.01, but we will use a <code class="docutils literal notranslate"><span class="pre">scheduler</span></code> to decrease it
to 0.001 during training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="training-and-testing-the-network">
<h2>Training and Testing the Network<a class="headerlink" href="#training-and-testing-the-network" title="Permalink to this headline">¶</a></h2>
<p>Now let’s define a training function that will feed our training data
into the model and perform the backward pass and optimization steps.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span> <span class="c1">#set requires_grad to True for training</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#original output dimensions are batchSizex1x10</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">target</span><span class="p">)</span> <span class="c1">#the loss functions expects a batchSizex10 input</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1">#print training stats</span>
            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Train Epoch: {} [{}/{} ({:.0f}%)]</span><span class="se">\t</span><span class="s1">Loss: {:.6f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">loss</span><span class="p">))</span>
</pre></div>
</div>
<p>Now that we have a training function, we need to make one for testing
the networks accuracy. We will set the model to <code class="docutils literal notranslate"><span class="pre">eval()</span></code> mode and then
run inference on the test dataset. Calling <code class="docutils literal notranslate"><span class="pre">eval()</span></code> sets the training
variable in all modules in the network to false. Certain layers like
batch normalization and dropout layers behave differently during
training so this step is crucial for getting correct results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">2</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># get the index of the max log-probability</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Test set: Accuracy: {}/{} ({:.0f}%)</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)))</span>
</pre></div>
</div>
<p>Finally, we can train and test the network. We will train the network
for ten epochs then reduce the learn rate and train for ten more epochs.
The network will be tested after each epoch to see how the accuracy
varies during the training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">log_interval</span> <span class="o">=</span> <span class="mi">20</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">41</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">31</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;First round of training complete. Setting learn rate to 0.001.&quot;</span><span class="p">)</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 [0/7895 (0%)]    Loss: 2.316071
Train Epoch: 1 [2560/7895 (32%)]        Loss: 1.915828
Train Epoch: 1 [5120/7895 (65%)]        Loss: 1.571532
Train Epoch: 1 [7680/7895 (97%)]        Loss: 1.596640

Test set: Accuracy: 309/837 (37%)

Train Epoch: 2 [0/7895 (0%)]    Loss: 1.555788
Train Epoch: 2 [2560/7895 (32%)]        Loss: 1.665413
Train Epoch: 2 [5120/7895 (65%)]        Loss: 1.456161
Train Epoch: 2 [7680/7895 (97%)]        Loss: 1.377335

Test set: Accuracy: 342/837 (41%)

Train Epoch: 3 [0/7895 (0%)]    Loss: 1.537268
Train Epoch: 3 [2560/7895 (32%)]        Loss: 1.343822
Train Epoch: 3 [5120/7895 (65%)]        Loss: 1.266919
Train Epoch: 3 [7680/7895 (97%)]        Loss: 1.221810

Test set: Accuracy: 347/837 (41%)

Train Epoch: 4 [0/7895 (0%)]    Loss: 1.168758
Train Epoch: 4 [2560/7895 (32%)]        Loss: 1.299938
Train Epoch: 4 [5120/7895 (65%)]        Loss: 1.180796
Train Epoch: 4 [7680/7895 (97%)]        Loss: 1.187909

Test set: Accuracy: 362/837 (43%)

Train Epoch: 5 [0/7895 (0%)]    Loss: 1.210558
Train Epoch: 5 [2560/7895 (32%)]        Loss: 1.206264
Train Epoch: 5 [5120/7895 (65%)]        Loss: 1.038809
Train Epoch: 5 [7680/7895 (97%)]        Loss: 0.946322

Test set: Accuracy: 492/837 (59%)

Train Epoch: 6 [0/7895 (0%)]    Loss: 1.038682
Train Epoch: 6 [2560/7895 (32%)]        Loss: 1.030800
Train Epoch: 6 [5120/7895 (65%)]        Loss: 0.972948
Train Epoch: 6 [7680/7895 (97%)]        Loss: 1.212271

Test set: Accuracy: 355/837 (42%)

Train Epoch: 7 [0/7895 (0%)]    Loss: 0.993758
Train Epoch: 7 [2560/7895 (32%)]        Loss: 0.781278
Train Epoch: 7 [5120/7895 (65%)]        Loss: 1.049659
Train Epoch: 7 [7680/7895 (97%)]        Loss: 1.173923

Test set: Accuracy: 438/837 (52%)

Train Epoch: 8 [0/7895 (0%)]    Loss: 0.917061
Train Epoch: 8 [2560/7895 (32%)]        Loss: 0.996003
Train Epoch: 8 [5120/7895 (65%)]        Loss: 0.820250
Train Epoch: 8 [7680/7895 (97%)]        Loss: 0.883776

Test set: Accuracy: 440/837 (53%)

Train Epoch: 9 [0/7895 (0%)]    Loss: 0.970467
Train Epoch: 9 [2560/7895 (32%)]        Loss: 0.914019
Train Epoch: 9 [5120/7895 (65%)]        Loss: 0.861554
Train Epoch: 9 [7680/7895 (97%)]        Loss: 0.955244

Test set: Accuracy: 414/837 (49%)

Train Epoch: 10 [0/7895 (0%)]   Loss: 0.864850
Train Epoch: 10 [2560/7895 (32%)]       Loss: 0.818686
Train Epoch: 10 [5120/7895 (65%)]       Loss: 0.855174
Train Epoch: 10 [7680/7895 (97%)]       Loss: 0.728921

Test set: Accuracy: 398/837 (48%)

Train Epoch: 11 [0/7895 (0%)]   Loss: 0.744261
Train Epoch: 11 [2560/7895 (32%)]       Loss: 0.796921
Train Epoch: 11 [5120/7895 (65%)]       Loss: 0.917029
Train Epoch: 11 [7680/7895 (97%)]       Loss: 0.802292

Test set: Accuracy: 376/837 (45%)

Train Epoch: 12 [0/7895 (0%)]   Loss: 0.630504
Train Epoch: 12 [2560/7895 (32%)]       Loss: 0.602561
Train Epoch: 12 [5120/7895 (65%)]       Loss: 0.728997
Train Epoch: 12 [7680/7895 (97%)]       Loss: 0.758718

Test set: Accuracy: 316/837 (38%)

Train Epoch: 13 [0/7895 (0%)]   Loss: 0.816505
Train Epoch: 13 [2560/7895 (32%)]       Loss: 0.681741
Train Epoch: 13 [5120/7895 (65%)]       Loss: 0.775212
Train Epoch: 13 [7680/7895 (97%)]       Loss: 0.591799

Test set: Accuracy: 479/837 (57%)

Train Epoch: 14 [0/7895 (0%)]   Loss: 0.759443
Train Epoch: 14 [2560/7895 (32%)]       Loss: 0.747509
Train Epoch: 14 [5120/7895 (65%)]       Loss: 0.721222
Train Epoch: 14 [7680/7895 (97%)]       Loss: 0.558365

Test set: Accuracy: 459/837 (55%)

Train Epoch: 15 [0/7895 (0%)]   Loss: 0.550598
Train Epoch: 15 [2560/7895 (32%)]       Loss: 0.864282
Train Epoch: 15 [5120/7895 (65%)]       Loss: 0.626883
Train Epoch: 15 [7680/7895 (97%)]       Loss: 0.593890

Test set: Accuracy: 498/837 (59%)

Train Epoch: 16 [0/7895 (0%)]   Loss: 0.596177
Train Epoch: 16 [2560/7895 (32%)]       Loss: 0.682999
Train Epoch: 16 [5120/7895 (65%)]       Loss: 0.622926
Train Epoch: 16 [7680/7895 (97%)]       Loss: 0.641994

Test set: Accuracy: 352/837 (42%)

Train Epoch: 17 [0/7895 (0%)]   Loss: 0.841069
Train Epoch: 17 [2560/7895 (32%)]       Loss: 0.736121
Train Epoch: 17 [5120/7895 (65%)]       Loss: 0.568780
Train Epoch: 17 [7680/7895 (97%)]       Loss: 0.504084

Test set: Accuracy: 449/837 (54%)

Train Epoch: 18 [0/7895 (0%)]   Loss: 0.612329
Train Epoch: 18 [2560/7895 (32%)]       Loss: 0.702077
Train Epoch: 18 [5120/7895 (65%)]       Loss: 0.640476
Train Epoch: 18 [7680/7895 (97%)]       Loss: 0.650789

Test set: Accuracy: 431/837 (51%)

Train Epoch: 19 [0/7895 (0%)]   Loss: 0.634597
Train Epoch: 19 [2560/7895 (32%)]       Loss: 0.769773
Train Epoch: 19 [5120/7895 (65%)]       Loss: 0.458346
Train Epoch: 19 [7680/7895 (97%)]       Loss: 0.589116

Test set: Accuracy: 444/837 (53%)

Train Epoch: 20 [0/7895 (0%)]   Loss: 0.579605
Train Epoch: 20 [2560/7895 (32%)]       Loss: 0.513708
Train Epoch: 20 [5120/7895 (65%)]       Loss: 0.510323
Train Epoch: 20 [7680/7895 (97%)]       Loss: 0.628413

Test set: Accuracy: 387/837 (46%)

Train Epoch: 21 [0/7895 (0%)]   Loss: 0.429277
Train Epoch: 21 [2560/7895 (32%)]       Loss: 0.464765
Train Epoch: 21 [5120/7895 (65%)]       Loss: 0.402460
Train Epoch: 21 [7680/7895 (97%)]       Loss: 0.564761

Test set: Accuracy: 532/837 (64%)

Train Epoch: 22 [0/7895 (0%)]   Loss: 0.518983
Train Epoch: 22 [2560/7895 (32%)]       Loss: 0.369633
Train Epoch: 22 [5120/7895 (65%)]       Loss: 0.401919
Train Epoch: 22 [7680/7895 (97%)]       Loss: 0.412721

Test set: Accuracy: 549/837 (66%)

Train Epoch: 23 [0/7895 (0%)]   Loss: 0.348902
Train Epoch: 23 [2560/7895 (32%)]       Loss: 0.316755
Train Epoch: 23 [5120/7895 (65%)]       Loss: 0.482895
Train Epoch: 23 [7680/7895 (97%)]       Loss: 0.342960

Test set: Accuracy: 553/837 (66%)

Train Epoch: 24 [0/7895 (0%)]   Loss: 0.343952
Train Epoch: 24 [2560/7895 (32%)]       Loss: 0.315261
Train Epoch: 24 [5120/7895 (65%)]       Loss: 0.325087
Train Epoch: 24 [7680/7895 (97%)]       Loss: 0.440828

Test set: Accuracy: 557/837 (67%)

Train Epoch: 25 [0/7895 (0%)]   Loss: 0.344650
Train Epoch: 25 [2560/7895 (32%)]       Loss: 0.364057
Train Epoch: 25 [5120/7895 (65%)]       Loss: 0.355366
Train Epoch: 25 [7680/7895 (97%)]       Loss: 0.339151

Test set: Accuracy: 543/837 (65%)

Train Epoch: 26 [0/7895 (0%)]   Loss: 0.355143
Train Epoch: 26 [2560/7895 (32%)]       Loss: 0.280883
Train Epoch: 26 [5120/7895 (65%)]       Loss: 0.384923
Train Epoch: 26 [7680/7895 (97%)]       Loss: 0.488514

Test set: Accuracy: 531/837 (63%)

Train Epoch: 27 [0/7895 (0%)]   Loss: 0.270163
Train Epoch: 27 [2560/7895 (32%)]       Loss: 0.264634
Train Epoch: 27 [5120/7895 (65%)]       Loss: 0.287216
Train Epoch: 27 [7680/7895 (97%)]       Loss: 0.275426

Test set: Accuracy: 512/837 (61%)

Train Epoch: 28 [0/7895 (0%)]   Loss: 0.275418
Train Epoch: 28 [2560/7895 (32%)]       Loss: 0.352113
Train Epoch: 28 [5120/7895 (65%)]       Loss: 0.399425
Train Epoch: 28 [7680/7895 (97%)]       Loss: 0.283611

Test set: Accuracy: 567/837 (68%)

Train Epoch: 29 [0/7895 (0%)]   Loss: 0.370882
Train Epoch: 29 [2560/7895 (32%)]       Loss: 0.364617
Train Epoch: 29 [5120/7895 (65%)]       Loss: 0.315228
Train Epoch: 29 [7680/7895 (97%)]       Loss: 0.444828

Test set: Accuracy: 534/837 (64%)

Train Epoch: 30 [0/7895 (0%)]   Loss: 0.314538
Train Epoch: 30 [2560/7895 (32%)]       Loss: 0.341435
Train Epoch: 30 [5120/7895 (65%)]       Loss: 0.323889
Train Epoch: 30 [7680/7895 (97%)]       Loss: 0.299620

Test set: Accuracy: 519/837 (62%)

First round of training complete. Setting learn rate to 0.001.
Train Epoch: 31 [0/7895 (0%)]   Loss: 0.296868
Train Epoch: 31 [2560/7895 (32%)]       Loss: 0.329909
Train Epoch: 31 [5120/7895 (65%)]       Loss: 0.310091
Train Epoch: 31 [7680/7895 (97%)]       Loss: 0.266394

Test set: Accuracy: 568/837 (68%)

Train Epoch: 32 [0/7895 (0%)]   Loss: 0.369298
Train Epoch: 32 [2560/7895 (32%)]       Loss: 0.171444
Train Epoch: 32 [5120/7895 (65%)]       Loss: 0.288475
Train Epoch: 32 [7680/7895 (97%)]       Loss: 0.422966

Test set: Accuracy: 558/837 (67%)

Train Epoch: 33 [0/7895 (0%)]   Loss: 0.227123
Train Epoch: 33 [2560/7895 (32%)]       Loss: 0.278439
Train Epoch: 33 [5120/7895 (65%)]       Loss: 0.275937
Train Epoch: 33 [7680/7895 (97%)]       Loss: 0.217900

Test set: Accuracy: 514/837 (61%)

Train Epoch: 34 [0/7895 (0%)]   Loss: 0.271890
Train Epoch: 34 [2560/7895 (32%)]       Loss: 0.227994
Train Epoch: 34 [5120/7895 (65%)]       Loss: 0.323719
Train Epoch: 34 [7680/7895 (97%)]       Loss: 0.262640

Test set: Accuracy: 537/837 (64%)

Train Epoch: 35 [0/7895 (0%)]   Loss: 0.303807
Train Epoch: 35 [2560/7895 (32%)]       Loss: 0.359797
Train Epoch: 35 [5120/7895 (65%)]       Loss: 0.188482
Train Epoch: 35 [7680/7895 (97%)]       Loss: 0.294945

Test set: Accuracy: 514/837 (61%)

Train Epoch: 36 [0/7895 (0%)]   Loss: 0.269697
Train Epoch: 36 [2560/7895 (32%)]       Loss: 0.256108
Train Epoch: 36 [5120/7895 (65%)]       Loss: 0.370610
Train Epoch: 36 [7680/7895 (97%)]       Loss: 0.256925

Test set: Accuracy: 516/837 (62%)

Train Epoch: 37 [0/7895 (0%)]   Loss: 0.259872
Train Epoch: 37 [2560/7895 (32%)]       Loss: 0.191766
Train Epoch: 37 [5120/7895 (65%)]       Loss: 0.200444
Train Epoch: 37 [7680/7895 (97%)]       Loss: 0.317824

Test set: Accuracy: 549/837 (66%)

Train Epoch: 38 [0/7895 (0%)]   Loss: 0.205151
Train Epoch: 38 [2560/7895 (32%)]       Loss: 0.209711
Train Epoch: 38 [5120/7895 (65%)]       Loss: 0.188850
Train Epoch: 38 [7680/7895 (97%)]       Loss: 0.221374

Test set: Accuracy: 535/837 (64%)

Train Epoch: 39 [0/7895 (0%)]   Loss: 0.236096
Train Epoch: 39 [2560/7895 (32%)]       Loss: 0.217165
Train Epoch: 39 [5120/7895 (65%)]       Loss: 0.309814
Train Epoch: 39 [7680/7895 (97%)]       Loss: 0.251980

Test set: Accuracy: 521/837 (62%)

Train Epoch: 40 [0/7895 (0%)]   Loss: 0.294167
Train Epoch: 40 [2560/7895 (32%)]       Loss: 0.258405
Train Epoch: 40 [5120/7895 (65%)]       Loss: 0.202371
Train Epoch: 40 [7680/7895 (97%)]       Loss: 0.274695

Test set: Accuracy: 516/837 (62%)
</pre></div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>If trained on 9 folders, the network should be more than 50% accurate by
the end of the training process. Training on less folders will result in
a lower overall accuracy but may be necessary if long runtimes are a
problem. Greater accuracies can be achieved using deeper CNNs at the
expense of a larger memory footprint.</p>
<p>For more advanced audio applications, such as speech recognition,
recurrent neural networks (RNNs) are commonly used. There are also other
data preprocessing methods, such as finding the mel frequency cepstral
coefficients (MFCC), that can reduce the size of the dataset.</p>
<p><strong>Total running time of the script:</strong> ( 18 minutes  7.996 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-audio-classifier-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/audio_classifier_tutorial.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">audio_classifier_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/audio_classifier_tutorial.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">audio_classifier_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Audio Classifier Tutorial</a><ul>
<li><a class="reference internal" href="#importing-the-dataset">Importing the Dataset</a></li>
<li><a class="reference internal" href="#formatting-the-data">Formatting the Data</a></li>
<li><a class="reference internal" href="#define-the-network">Define the Network</a></li>
<li><a class="reference internal" href="#training-and-testing-the-network">Training and Testing the Network</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>
  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0.0.dev20181001',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    mobileMenu.bind();
    mobileTOC.bind();
    pytorchAnchors.bind();

    $(window).on("load", function() {
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
    })

    // Add class to links that have code blocks, since we cannot create links in code blocks
    $("article.pytorch-article a span.pre").each(function(e) {
      $(this).closest("a").addClass("has-code");
    });
  </script>
</body>
</html>