
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>Knowledge Distillation Tutorial — PyTorch Tutorials 2.8.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=c9393ea6" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=bffbcef7"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'beginner/knowledge_distillation_tutorial';</script>
<link href="https://docs.pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../intermediate/memory_format_tutorial.html" rel="next" title="Channels Last Memory Format in PyTorch"/>
<link href="../intermediate/scaled_dot_product_attention_tutorial.html" rel="prev" title="(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<link crossorigin="anonymous" href="/beginner/knowledge_distillation_tutorial.html" rel="canonical"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/pytorch-domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.8.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Knowledge Distillation Tutorial</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../deep-dive.html">Deep Dive</a></li>
<li aria-current="page" class="breadcrumb-item active">Knowledge...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../deep-dive.html" itemprop="item"/>
<meta content="Deep Dive" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Knowledge Distillation Tutorial" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/knowledge_distillation_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-beginner-knowledge-distillation-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="knowledge-distillation-tutorial">
<span id="sphx-glr-beginner-knowledge-distillation-tutorial-py"></span><h1>Knowledge Distillation Tutorial<a class="headerlink" href="#knowledge-distillation-tutorial" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Aug 22, 2023 | Last Updated: Jan 24, 2025 | Last Verified: Nov 05, 2024</p>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/AlexandrosChrtn">Alexandros Chariton</a></p>
<p>Knowledge distillation is a technique that enables knowledge transfer from large, computationally expensive
models to smaller ones without losing validity. This allows for deployment on less powerful
hardware, making evaluation faster and more efficient.</p>
<p>In this tutorial, we will run a number of experiments focused at improving the accuracy of a
lightweight neural network, using a more powerful network as a teacher.
The computational cost and the speed of the lightweight network will remain unaffected,
our intervention only focuses on its weights, not on its forward pass.
Applications of this technology can be found in devices such as drones or mobile phones.
In this tutorial, we do not use any external packages as everything we need is available in <code class="docutils literal notranslate"><span class="pre">torch</span></code> and
<code class="docutils literal notranslate"><span class="pre">torchvision</span></code>.</p>
<p>In this tutorial, you will learn:</p>
<ul class="simple">
<li><p>How to modify model classes to extract hidden representations and use them for further calculations</p></li>
<li><p>How to modify regular train loops in PyTorch to include additional losses on top of, for example, cross-entropy for classification</p></li>
<li><p>How to improve the performance of lightweight models by using more complex models as teachers</p></li>
</ul>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>1 GPU, 4GB of memory</p></li>
<li><p>PyTorch v2.0 or later</p></li>
<li><p>CIFAR-10 dataset (downloaded by the script and saved in a directory called <code class="docutils literal notranslate"><span class="pre">/data</span></code>)</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">datasets</span>

<span class="c1"># Check if the current `accelerator &lt;https://pytorch.org/docs/stable/torch.html#accelerators&gt;`__</span>
<span class="c1"># is available, and if not, use the CPU</span>
<span class="n">device</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-accelerator sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.accelerator.current_accelerator.html#torch.accelerator.current_accelerator" title="torch.accelerator.current_accelerator"><span class="n">torch</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">current_accelerator</span></a><span class="p">()</span><span class="o">.</span><span class="n">type</span> <span class="k">if</span> <a class="sphx-glr-backref-module-torch-accelerator sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.accelerator.is_available.html#torch.accelerator.is_available" title="torch.accelerator.is_available"><span class="n">torch</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">is_available</span></a><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> device"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Using cuda device
</pre></div>
</div>
<section id="loading-cifar-10">
<h3>Loading CIFAR-10<a class="headerlink" href="#loading-cifar-10" title="Link to this heading">#</a></h3>
<p>CIFAR-10 is a popular image dataset with ten classes. Our objective is to predict one of the following classes for each input image.</p>
<figure class="align-center" id="id1">
<img alt="../_static/img/cifar10.png" src="../_static/img/cifar10.png"/>
<figcaption>
<p><span class="caption-text">Example of CIFAR-10 images</span><a class="headerlink" href="#id1" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The input images are RGB, so they have 3 channels and are 32x32 pixels. Basically, each image is described by 3 x 32 x 32 = 3072 numbers ranging from 0 to 255.
A common practice in neural networks is to normalize the input, which is done for multiple reasons,
including avoiding saturation in commonly used activation functions and increasing numerical stability.
Our normalization process consists of subtracting the mean and dividing by the standard deviation along each channel.
The tensors “mean=[0.485, 0.456, 0.406]” and “std=[0.229, 0.224, 0.225]” were already computed,
and they represent the mean and standard deviation of each channel in the
predefined subset of CIFAR-10 intended to be the training set.
Notice how we use these values for the test set as well, without recomputing the mean and standard deviation from scratch.
This is because the network was trained on features produced by subtracting and dividing the numbers above, and we want to maintain consistency.
Furthermore, in real life, we would not be able to compute the mean and standard deviation of the test set since,
under our assumptions, this data would not be accessible at that point.</p>
<p>As a closing point, we often refer to this held-out set as the validation set, and we use a separate set,
called the test set, after optimizing a model’s performance on the validation set.
This is done to avoid selecting a model based on the greedy and biased optimization of a single metric.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.</span>
<a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">transforms_cifar</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span></a><span class="p">([</span>
    <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor" title="torchvision.transforms.ToTensor"><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span></a><span class="p">(),</span>
    <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize" title="torchvision.transforms.Normalize"><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span></a><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
<span class="p">])</span>

<span class="c1"># Loading the CIFAR-10 dataset:</span>
<a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">train_dataset</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span></a><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">transforms_cifar</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">test_dataset</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span></a><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">transforms_cifar</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>  0%|          | 0.00/170M [00:00&lt;?, ?B/s]
  0%|          | 65.5k/170M [00:00&lt;06:12, 458kB/s]
  0%|          | 131k/170M [00:00&lt;06:25, 442kB/s]
  0%|          | 197k/170M [00:00&lt;06:35, 431kB/s]
  0%|          | 262k/170M [00:00&lt;06:35, 430kB/s]
  0%|          | 328k/170M [00:00&lt;06:33, 432kB/s]
  0%|          | 393k/170M [00:00&lt;06:48, 416kB/s]
  0%|          | 459k/170M [00:01&lt;06:39, 426kB/s]
  0%|          | 524k/170M [00:01&lt;06:31, 435kB/s]
  0%|          | 590k/170M [00:01&lt;06:29, 437kB/s]
  0%|          | 655k/170M [00:01&lt;06:22, 445kB/s]
  0%|          | 721k/170M [00:01&lt;06:38, 426kB/s]
  0%|          | 786k/170M [00:01&lt;06:29, 436kB/s]
  0%|          | 852k/170M [00:01&lt;06:27, 438kB/s]
  1%|          | 918k/170M [00:02&lt;06:26, 439kB/s]
  1%|          | 983k/170M [00:02&lt;06:20, 446kB/s]
  1%|          | 1.05M/170M [00:02&lt;06:36, 428kB/s]
  1%|          | 1.11M/170M [00:02&lt;06:27, 437kB/s]
  1%|          | 1.18M/170M [00:02&lt;06:26, 438kB/s]
  1%|          | 1.25M/170M [00:02&lt;06:25, 439kB/s]
  1%|          | 1.31M/170M [00:03&lt;06:18, 447kB/s]
  1%|          | 1.38M/170M [00:03&lt;06:35, 427kB/s]
  1%|          | 1.44M/170M [00:03&lt;06:35, 428kB/s]
  1%|          | 1.51M/170M [00:03&lt;06:27, 437kB/s]
  1%|          | 1.57M/170M [00:03&lt;06:24, 439kB/s]
  1%|          | 1.64M/170M [00:03&lt;06:18, 446kB/s]
  1%|          | 1.70M/170M [00:03&lt;06:47, 414kB/s]
  1%|          | 1.77M/170M [00:04&lt;06:31, 432kB/s]
  1%|          | 1.84M/170M [00:04&lt;06:31, 431kB/s]
  1%|          | 1.90M/170M [00:04&lt;06:24, 439kB/s]
  1%|          | 1.97M/170M [00:04&lt;06:17, 446kB/s]
  1%|          | 2.03M/170M [00:04&lt;06:18, 445kB/s]
  1%|          | 2.10M/170M [00:04&lt;06:33, 428kB/s]
  1%|▏         | 2.16M/170M [00:04&lt;06:24, 438kB/s]
  1%|▏         | 2.23M/170M [00:05&lt;06:36, 425kB/s]
  1%|▏         | 2.29M/170M [00:05&lt;06:22, 440kB/s]
  1%|▏         | 2.36M/170M [00:05&lt;06:16, 446kB/s]
  1%|▏         | 2.42M/170M [00:05&lt;06:33, 428kB/s]
  1%|▏         | 2.49M/170M [00:05&lt;06:24, 437kB/s]
  1%|▏         | 2.56M/170M [00:05&lt;06:24, 437kB/s]
  2%|▏         | 2.62M/170M [00:06&lt;06:21, 440kB/s]
  2%|▏         | 2.69M/170M [00:06&lt;06:20, 441kB/s]
  2%|▏         | 2.75M/170M [00:06&lt;06:35, 424kB/s]
  2%|▏         | 2.82M/170M [00:06&lt;06:29, 431kB/s]
  2%|▏         | 2.88M/170M [00:06&lt;06:30, 429kB/s]
  2%|▏         | 2.95M/170M [00:06&lt;06:25, 434kB/s]
  2%|▏         | 3.01M/170M [00:06&lt;06:26, 433kB/s]
  2%|▏         | 3.08M/170M [00:07&lt;06:35, 423kB/s]
  2%|▏         | 3.15M/170M [00:07&lt;06:32, 427kB/s]
  2%|▏         | 3.21M/170M [00:07&lt;06:29, 430kB/s]
  2%|▏         | 3.28M/170M [00:07&lt;06:26, 433kB/s]
  2%|▏         | 3.34M/170M [00:07&lt;06:22, 437kB/s]
  2%|▏         | 3.41M/170M [00:07&lt;06:23, 435kB/s]
  2%|▏         | 3.47M/170M [00:08&lt;06:40, 417kB/s]
  2%|▏         | 3.54M/170M [00:08&lt;06:32, 426kB/s]
  2%|▏         | 3.60M/170M [00:08&lt;06:29, 428kB/s]
  2%|▏         | 3.67M/170M [00:08&lt;06:29, 428kB/s]
  2%|▏         | 3.74M/170M [00:08&lt;06:27, 430kB/s]
  2%|▏         | 3.80M/170M [00:08&lt;06:54, 402kB/s]
  2%|▏         | 3.87M/170M [00:08&lt;06:27, 430kB/s]
  2%|▏         | 3.93M/170M [00:09&lt;06:27, 429kB/s]
  2%|▏         | 4.00M/170M [00:09&lt;06:21, 437kB/s]
  2%|▏         | 4.06M/170M [00:09&lt;06:18, 440kB/s]
  2%|▏         | 4.13M/170M [00:09&lt;06:43, 413kB/s]
  2%|▏         | 4.19M/170M [00:09&lt;06:39, 416kB/s]
  2%|▏         | 4.26M/170M [00:10&lt;09:22, 295kB/s]
  3%|▎         | 4.33M/170M [00:10&lt;08:08, 340kB/s]
  3%|▎         | 4.39M/170M [00:10&lt;07:45, 357kB/s]
  3%|▎         | 4.46M/170M [00:10&lt;06:46, 408kB/s]
  3%|▎         | 4.52M/170M [00:10&lt;06:33, 422kB/s]
  3%|▎         | 4.59M/170M [00:10&lt;06:24, 432kB/s]
  3%|▎         | 4.65M/170M [00:10&lt;06:35, 419kB/s]
  3%|▎         | 4.72M/170M [00:11&lt;06:04, 455kB/s]
  3%|▎         | 4.78M/170M [00:11&lt;06:35, 419kB/s]
  3%|▎         | 4.85M/170M [00:11&lt;06:10, 447kB/s]
  3%|▎         | 4.92M/170M [00:11&lt;06:34, 419kB/s]
  3%|▎         | 4.98M/170M [00:11&lt;06:01, 457kB/s]
  3%|▎         | 5.05M/170M [00:11&lt;06:09, 448kB/s]
  3%|▎         | 5.11M/170M [00:11&lt;06:19, 436kB/s]
  3%|▎         | 5.18M/170M [00:12&lt;06:33, 420kB/s]
  3%|▎         | 5.24M/170M [00:12&lt;06:33, 420kB/s]
  3%|▎         | 5.31M/170M [00:12&lt;06:27, 426kB/s]
  3%|▎         | 5.37M/170M [00:12&lt;06:30, 423kB/s]
  3%|▎         | 5.44M/170M [00:12&lt;06:26, 427kB/s]
  3%|▎         | 5.51M/170M [00:12&lt;06:35, 417kB/s]
  3%|▎         | 5.57M/170M [00:13&lt;06:33, 419kB/s]
  3%|▎         | 5.64M/170M [00:13&lt;06:30, 422kB/s]
  3%|▎         | 5.70M/170M [00:13&lt;06:32, 420kB/s]
  3%|▎         | 5.77M/170M [00:13&lt;06:27, 425kB/s]
  3%|▎         | 5.83M/170M [00:13&lt;06:40, 411kB/s]
  3%|▎         | 5.90M/170M [00:13&lt;06:46, 404kB/s]
  3%|▎         | 5.96M/170M [00:14&lt;06:37, 414kB/s]
  4%|▎         | 6.03M/170M [00:14&lt;06:35, 416kB/s]
  4%|▎         | 6.09M/170M [00:14&lt;06:35, 415kB/s]
  4%|▎         | 6.16M/170M [00:14&lt;06:45, 406kB/s]
  4%|▎         | 6.23M/170M [00:14&lt;06:41, 409kB/s]
  4%|▎         | 6.29M/170M [00:14&lt;06:37, 413kB/s]
  4%|▎         | 6.36M/170M [00:14&lt;06:31, 419kB/s]
  4%|▍         | 6.42M/170M [00:15&lt;06:28, 422kB/s]
  4%|▍         | 6.49M/170M [00:15&lt;06:40, 409kB/s]
  4%|▍         | 6.55M/170M [00:15&lt;06:33, 417kB/s]
  4%|▍         | 6.62M/170M [00:15&lt;06:37, 412kB/s]
  4%|▍         | 6.68M/170M [00:15&lt;06:30, 420kB/s]
  4%|▍         | 6.75M/170M [00:15&lt;06:32, 418kB/s]
  4%|▍         | 6.82M/170M [00:16&lt;06:34, 414kB/s]
  4%|▍         | 6.88M/170M [00:16&lt;07:07, 382kB/s]
  4%|▍         | 6.95M/170M [00:16&lt;06:33, 415kB/s]
  4%|▍         | 7.01M/170M [00:16&lt;06:39, 409kB/s]
  4%|▍         | 7.08M/170M [00:16&lt;06:36, 412kB/s]
  4%|▍         | 7.14M/170M [00:16&lt;06:30, 419kB/s]
  4%|▍         | 7.21M/170M [00:17&lt;06:42, 406kB/s]
  4%|▍         | 7.27M/170M [00:17&lt;06:37, 411kB/s]
  4%|▍         | 7.34M/170M [00:17&lt;06:35, 413kB/s]
  4%|▍         | 7.41M/170M [00:17&lt;06:33, 415kB/s]
  4%|▍         | 7.47M/170M [00:17&lt;06:34, 414kB/s]
  4%|▍         | 7.54M/170M [00:17&lt;06:49, 398kB/s]
  4%|▍         | 7.60M/170M [00:18&lt;06:40, 406kB/s]
  4%|▍         | 7.67M/170M [00:18&lt;06:40, 407kB/s]
  5%|▍         | 7.73M/170M [00:18&lt;06:38, 409kB/s]
  5%|▍         | 7.80M/170M [00:18&lt;06:34, 413kB/s]
  5%|▍         | 7.86M/170M [00:18&lt;06:45, 401kB/s]
  5%|▍         | 7.93M/170M [00:18&lt;06:38, 408kB/s]
  5%|▍         | 8.00M/170M [00:18&lt;06:36, 410kB/s]
  5%|▍         | 8.06M/170M [00:19&lt;06:29, 417kB/s]
  5%|▍         | 8.13M/170M [00:19&lt;06:27, 419kB/s]
  5%|▍         | 8.19M/170M [00:19&lt;06:38, 408kB/s]
  5%|▍         | 8.26M/170M [00:19&lt;06:35, 410kB/s]
  5%|▍         | 8.32M/170M [00:19&lt;06:33, 413kB/s]
  5%|▍         | 8.39M/170M [00:19&lt;06:28, 417kB/s]
  5%|▍         | 8.45M/170M [00:20&lt;06:24, 422kB/s]
  5%|▍         | 8.52M/170M [00:20&lt;06:29, 416kB/s]
  5%|▌         | 8.59M/170M [00:20&lt;06:38, 407kB/s]
  5%|▌         | 8.65M/170M [00:20&lt;06:30, 414kB/s]
  5%|▌         | 8.72M/170M [00:20&lt;06:28, 417kB/s]
  5%|▌         | 8.78M/170M [00:20&lt;06:27, 417kB/s]
  5%|▌         | 8.85M/170M [00:21&lt;06:23, 421kB/s]
  5%|▌         | 8.91M/170M [00:21&lt;06:43, 401kB/s]
  5%|▌         | 8.98M/170M [00:21&lt;06:48, 396kB/s]
  5%|▌         | 9.04M/170M [00:21&lt;06:27, 417kB/s]
  5%|▌         | 9.11M/170M [00:21&lt;06:30, 413kB/s]
  5%|▌         | 9.18M/170M [00:21&lt;06:28, 415kB/s]
  5%|▌         | 9.24M/170M [00:21&lt;06:40, 403kB/s]
  5%|▌         | 9.31M/170M [00:22&lt;06:35, 407kB/s]
  5%|▌         | 9.37M/170M [00:22&lt;06:33, 410kB/s]
  6%|▌         | 9.44M/170M [00:22&lt;06:28, 414kB/s]
  6%|▌         | 9.50M/170M [00:22&lt;06:26, 417kB/s]
  6%|▌         | 9.57M/170M [00:22&lt;06:38, 404kB/s]
  6%|▌         | 9.63M/170M [00:22&lt;06:30, 412kB/s]
  6%|▌         | 9.70M/170M [00:23&lt;06:33, 409kB/s]
  6%|▌         | 9.76M/170M [00:23&lt;06:24, 418kB/s]
  6%|▌         | 9.83M/170M [00:23&lt;06:25, 416kB/s]
  6%|▌         | 9.90M/170M [00:23&lt;06:39, 402kB/s]
  6%|▌         | 9.96M/170M [00:23&lt;06:39, 402kB/s]
  6%|▌         | 10.0M/170M [00:23&lt;06:28, 413kB/s]
  6%|▌         | 10.1M/170M [00:24&lt;06:27, 414kB/s]
  6%|▌         | 10.2M/170M [00:24&lt;06:24, 417kB/s]
  6%|▌         | 10.2M/170M [00:24&lt;06:20, 421kB/s]
  6%|▌         | 10.3M/170M [00:24&lt;06:39, 401kB/s]
  6%|▌         | 10.4M/170M [00:24&lt;06:32, 408kB/s]
  6%|▌         | 10.4M/170M [00:24&lt;06:32, 408kB/s]
  6%|▌         | 10.5M/170M [00:25&lt;06:31, 409kB/s]
  6%|▌         | 10.6M/170M [00:25&lt;06:48, 391kB/s]
  6%|▌         | 10.6M/170M [00:25&lt;06:33, 407kB/s]
  6%|▋         | 10.7M/170M [00:25&lt;06:29, 411kB/s]
  6%|▋         | 10.7M/170M [00:25&lt;06:24, 416kB/s]
  6%|▋         | 10.8M/170M [00:25&lt;06:26, 413kB/s]
  6%|▋         | 10.9M/170M [00:25&lt;06:25, 414kB/s]
  6%|▋         | 10.9M/170M [00:26&lt;06:45, 394kB/s]
  6%|▋         | 11.0M/170M [00:26&lt;06:28, 411kB/s]
  6%|▋         | 11.1M/170M [00:26&lt;06:34, 404kB/s]
  7%|▋         | 11.1M/170M [00:26&lt;06:30, 408kB/s]
  7%|▋         | 11.2M/170M [00:26&lt;06:43, 395kB/s]
  7%|▋         | 11.3M/170M [00:26&lt;06:39, 399kB/s]
  7%|▋         | 11.3M/170M [00:27&lt;06:35, 403kB/s]
  7%|▋         | 11.4M/170M [00:27&lt;06:25, 413kB/s]
  7%|▋         | 11.5M/170M [00:27&lt;06:23, 415kB/s]
  7%|▋         | 11.5M/170M [00:27&lt;06:28, 409kB/s]
  7%|▋         | 11.6M/170M [00:27&lt;06:16, 422kB/s]
  7%|▋         | 11.7M/170M [00:27&lt;06:35, 402kB/s]
  7%|▋         | 11.7M/170M [00:28&lt;06:31, 406kB/s]
  7%|▋         | 11.8M/170M [00:28&lt;06:39, 397kB/s]
  7%|▋         | 11.9M/170M [00:28&lt;06:20, 417kB/s]
  7%|▋         | 11.9M/170M [00:28&lt;06:21, 415kB/s]
  7%|▋         | 12.0M/170M [00:28&lt;06:37, 399kB/s]
  7%|▋         | 12.1M/170M [00:28&lt;06:23, 413kB/s]
  7%|▋         | 12.1M/170M [00:29&lt;06:23, 413kB/s]
  7%|▋         | 12.2M/170M [00:29&lt;06:37, 398kB/s]
  7%|▋         | 12.3M/170M [00:29&lt;06:15, 421kB/s]
  7%|▋         | 12.3M/170M [00:29&lt;06:28, 407kB/s]
  7%|▋         | 12.4M/170M [00:29&lt;06:23, 413kB/s]
  7%|▋         | 12.5M/170M [00:29&lt;06:23, 412kB/s]
  7%|▋         | 12.5M/170M [00:29&lt;06:21, 414kB/s]
  7%|▋         | 12.6M/170M [00:30&lt;06:21, 414kB/s]
  7%|▋         | 12.6M/170M [00:30&lt;06:32, 402kB/s]
  7%|▋         | 12.7M/170M [00:30&lt;06:25, 410kB/s]
  7%|▋         | 12.8M/170M [00:30&lt;06:25, 409kB/s]
  8%|▊         | 12.8M/170M [00:30&lt;06:24, 410kB/s]
  8%|▊         | 12.9M/170M [00:30&lt;06:17, 417kB/s]
  8%|▊         | 13.0M/170M [00:31&lt;06:30, 404kB/s]
  8%|▊         | 13.0M/170M [00:31&lt;06:23, 411kB/s]
  8%|▊         | 13.1M/170M [00:31&lt;06:23, 411kB/s]
  8%|▊         | 13.2M/170M [00:31&lt;06:26, 407kB/s]
  8%|▊         | 13.2M/170M [00:31&lt;06:18, 416kB/s]
  8%|▊         | 13.3M/170M [00:31&lt;06:18, 415kB/s]
  8%|▊         | 13.4M/170M [00:32&lt;06:31, 401kB/s]
  8%|▊         | 13.4M/170M [00:32&lt;06:23, 409kB/s]
  8%|▊         | 13.5M/170M [00:32&lt;06:18, 415kB/s]
  8%|▊         | 13.6M/170M [00:32&lt;06:20, 413kB/s]
  8%|▊         | 13.6M/170M [00:32&lt;06:23, 409kB/s]
  8%|▊         | 13.7M/170M [00:32&lt;06:33, 398kB/s]
  8%|▊         | 13.8M/170M [00:33&lt;06:28, 403kB/s]
  8%|▊         | 13.8M/170M [00:33&lt;06:28, 403kB/s]
  8%|▊         | 13.9M/170M [00:33&lt;06:22, 410kB/s]
  8%|▊         | 14.0M/170M [00:33&lt;06:17, 414kB/s]
  8%|▊         | 14.0M/170M [00:33&lt;06:40, 391kB/s]
  8%|▊         | 14.1M/170M [00:33&lt;06:30, 401kB/s]
  8%|▊         | 14.2M/170M [00:34&lt;06:26, 404kB/s]
  8%|▊         | 14.2M/170M [00:34&lt;06:25, 406kB/s]
  8%|▊         | 14.3M/170M [00:34&lt;06:19, 412kB/s]
  8%|▊         | 14.4M/170M [00:34&lt;06:33, 397kB/s]
  8%|▊         | 14.4M/170M [00:34&lt;06:23, 407kB/s]
  8%|▊         | 14.5M/170M [00:34&lt;06:22, 407kB/s]
  9%|▊         | 14.5M/170M [00:34&lt;06:24, 406kB/s]
  9%|▊         | 14.6M/170M [00:35&lt;06:17, 413kB/s]
  9%|▊         | 14.7M/170M [00:35&lt;06:30, 399kB/s]
  9%|▊         | 14.7M/170M [00:35&lt;06:23, 406kB/s]
  9%|▊         | 14.8M/170M [00:35&lt;06:22, 407kB/s]
  9%|▊         | 14.9M/170M [00:35&lt;06:16, 413kB/s]
  9%|▉         | 14.9M/170M [00:35&lt;06:13, 416kB/s]
  9%|▉         | 15.0M/170M [00:36&lt;06:15, 414kB/s]
  9%|▉         | 15.1M/170M [00:36&lt;06:28, 400kB/s]
  9%|▉         | 15.1M/170M [00:36&lt;06:23, 406kB/s]
  9%|▉         | 15.2M/170M [00:36&lt;06:21, 407kB/s]
  9%|▉         | 15.3M/170M [00:36&lt;06:17, 411kB/s]
  9%|▉         | 15.3M/170M [00:36&lt;06:25, 403kB/s]
  9%|▉         | 15.4M/170M [00:37&lt;06:35, 392kB/s]
  9%|▉         | 15.5M/170M [00:37&lt;06:28, 399kB/s]
  9%|▉         | 15.5M/170M [00:37&lt;06:22, 405kB/s]
  9%|▉         | 15.6M/170M [00:37&lt;06:21, 406kB/s]
  9%|▉         | 15.7M/170M [00:37&lt;06:20, 407kB/s]
  9%|▉         | 15.7M/170M [00:37&lt;06:33, 394kB/s]
  9%|▉         | 15.8M/170M [00:38&lt;06:23, 404kB/s]
  9%|▉         | 15.9M/170M [00:38&lt;06:23, 403kB/s]
  9%|▉         | 15.9M/170M [00:38&lt;06:25, 401kB/s]
  9%|▉         | 16.0M/170M [00:38&lt;06:16, 410kB/s]
  9%|▉         | 16.1M/170M [00:38&lt;06:31, 394kB/s]
  9%|▉         | 16.1M/170M [00:38&lt;06:30, 396kB/s]
  9%|▉         | 16.2M/170M [00:39&lt;06:23, 402kB/s]
 10%|▉         | 16.3M/170M [00:39&lt;06:18, 408kB/s]
 10%|▉         | 16.3M/170M [00:39&lt;06:14, 412kB/s]
 10%|▉         | 16.4M/170M [00:39&lt;06:30, 395kB/s]
 10%|▉         | 16.4M/170M [00:39&lt;06:23, 402kB/s]
 10%|▉         | 16.5M/170M [00:39&lt;06:23, 401kB/s]
 10%|▉         | 16.6M/170M [00:40&lt;06:18, 407kB/s]
 10%|▉         | 16.6M/170M [00:40&lt;06:15, 410kB/s]
 10%|▉         | 16.7M/170M [00:40&lt;06:18, 406kB/s]
 10%|▉         | 16.8M/170M [00:40&lt;06:32, 392kB/s]
 10%|▉         | 16.8M/170M [00:40&lt;06:27, 397kB/s]
 10%|▉         | 16.9M/170M [00:40&lt;06:21, 403kB/s]
 10%|▉         | 17.0M/170M [00:41&lt;06:22, 402kB/s]
 10%|▉         | 17.0M/170M [00:41&lt;06:17, 406kB/s]
 10%|█         | 17.1M/170M [00:41&lt;06:36, 387kB/s]
 10%|█         | 17.2M/170M [00:41&lt;06:24, 398kB/s]
 10%|█         | 17.2M/170M [00:41&lt;06:19, 404kB/s]
 10%|█         | 17.3M/170M [00:41&lt;06:27, 395kB/s]
 10%|█         | 17.4M/170M [00:41&lt;06:19, 404kB/s]
 10%|█         | 17.4M/170M [00:42&lt;06:35, 387kB/s]
 10%|█         | 17.5M/170M [00:42&lt;06:28, 394kB/s]
 10%|█         | 17.6M/170M [00:42&lt;06:24, 397kB/s]
 10%|█         | 17.6M/170M [00:42&lt;06:24, 398kB/s]
 10%|█         | 17.7M/170M [00:42&lt;06:22, 400kB/s]
 10%|█         | 17.8M/170M [00:42&lt;06:33, 388kB/s]
 10%|█         | 17.8M/170M [00:43&lt;06:21, 400kB/s]
 10%|█         | 17.9M/170M [00:43&lt;06:22, 399kB/s]
 11%|█         | 18.0M/170M [00:43&lt;06:18, 403kB/s]
 11%|█         | 18.0M/170M [00:43&lt;06:13, 408kB/s]
 11%|█         | 18.1M/170M [00:43&lt;06:28, 392kB/s]
 11%|█         | 18.2M/170M [00:43&lt;06:33, 387kB/s]
 11%|█         | 18.2M/170M [00:44&lt;06:13, 407kB/s]
 11%|█         | 18.3M/170M [00:44&lt;06:16, 405kB/s]
 11%|█         | 18.4M/170M [00:44&lt;06:24, 396kB/s]
 11%|█         | 18.4M/170M [00:44&lt;06:10, 411kB/s]
 11%|█         | 18.5M/170M [00:44&lt;06:29, 391kB/s]
 11%|█         | 18.5M/170M [00:44&lt;06:38, 381kB/s]
 11%|█         | 18.6M/170M [00:45&lt;06:10, 410kB/s]
 11%|█         | 18.7M/170M [00:45&lt;06:14, 406kB/s]
 11%|█         | 18.7M/170M [00:45&lt;06:23, 396kB/s]
 11%|█         | 18.8M/170M [00:45&lt;06:42, 377kB/s]
 11%|█         | 18.9M/170M [00:45&lt;06:16, 403kB/s]
 11%|█         | 18.9M/170M [00:45&lt;06:19, 399kB/s]
 11%|█         | 19.0M/170M [00:46&lt;06:10, 409kB/s]
 11%|█         | 19.1M/170M [00:46&lt;06:08, 411kB/s]
 11%|█         | 19.1M/170M [00:46&lt;06:21, 397kB/s]
 11%|█▏        | 19.2M/170M [00:46&lt;06:32, 385kB/s]
 11%|█▏        | 19.3M/170M [00:46&lt;06:12, 406kB/s]
 11%|█▏        | 19.3M/170M [00:46&lt;06:10, 408kB/s]
 11%|█▏        | 19.4M/170M [00:47&lt;06:19, 398kB/s]
 11%|█▏        | 19.5M/170M [00:47&lt;06:12, 406kB/s]
 11%|█▏        | 19.5M/170M [00:47&lt;06:11, 407kB/s]
 11%|█▏        | 19.6M/170M [00:47&lt;06:10, 407kB/s]
 12%|█▏        | 19.7M/170M [00:47&lt;06:05, 412kB/s]
 12%|█▏        | 19.7M/170M [00:47&lt;06:14, 402kB/s]
 12%|█▏        | 19.8M/170M [00:48&lt;06:07, 410kB/s]
 12%|█▏        | 19.9M/170M [00:48&lt;06:19, 396kB/s]
 12%|█▏        | 19.9M/170M [00:48&lt;06:16, 400kB/s]
 12%|█▏        | 20.0M/170M [00:48&lt;06:17, 398kB/s]
 12%|█▏        | 20.1M/170M [00:48&lt;06:05, 412kB/s]
 12%|█▏        | 20.1M/170M [00:48&lt;06:05, 411kB/s]
 12%|█▏        | 20.2M/170M [00:49&lt;06:20, 395kB/s]
 12%|█▏        | 20.3M/170M [00:49&lt;06:19, 396kB/s]
 12%|█▏        | 20.3M/170M [00:49&lt;06:11, 404kB/s]
 12%|█▏        | 20.4M/170M [00:49&lt;06:15, 399kB/s]
 12%|█▏        | 20.4M/170M [00:49&lt;06:13, 401kB/s]
 12%|█▏        | 20.5M/170M [00:49&lt;06:24, 390kB/s]
 12%|█▏        | 20.6M/170M [00:50&lt;06:19, 396kB/s]
 12%|█▏        | 20.6M/170M [00:50&lt;06:17, 397kB/s]
 12%|█▏        | 20.7M/170M [00:50&lt;06:11, 403kB/s]
 12%|█▏        | 20.8M/170M [00:50&lt;06:10, 404kB/s]
 12%|█▏        | 20.8M/170M [00:50&lt;06:21, 392kB/s]
 12%|█▏        | 20.9M/170M [00:50&lt;06:14, 400kB/s]
 12%|█▏        | 21.0M/170M [00:51&lt;06:14, 399kB/s]
 12%|█▏        | 21.0M/170M [00:51&lt;06:09, 404kB/s]
 12%|█▏        | 21.1M/170M [00:51&lt;06:10, 403kB/s]
 12%|█▏        | 21.2M/170M [00:51&lt;06:22, 390kB/s]
 12%|█▏        | 21.2M/170M [00:51&lt;06:17, 395kB/s]
 12%|█▏        | 21.3M/170M [00:51&lt;06:17, 395kB/s]
 13%|█▎        | 21.4M/170M [00:51&lt;06:09, 404kB/s]
 13%|█▎        | 21.4M/170M [00:52&lt;06:11, 401kB/s]
 13%|█▎        | 21.5M/170M [00:52&lt;06:24, 387kB/s]
 13%|█▎        | 21.6M/170M [00:52&lt;06:14, 397kB/s]
 13%|█▎        | 21.6M/170M [00:52&lt;06:11, 400kB/s]
 13%|█▎        | 21.7M/170M [00:52&lt;06:07, 405kB/s]
 13%|█▎        | 21.8M/170M [00:52&lt;06:07, 405kB/s]
 13%|█▎        | 21.8M/170M [00:53&lt;06:04, 408kB/s]
 13%|█▎        | 21.9M/170M [00:53&lt;06:22, 388kB/s]
 13%|█▎        | 22.0M/170M [00:53&lt;06:17, 393kB/s]
 13%|█▎        | 22.0M/170M [00:53&lt;06:11, 400kB/s]
 13%|█▎        | 22.1M/170M [00:53&lt;06:12, 399kB/s]
 13%|█▎        | 22.2M/170M [00:53&lt;06:10, 400kB/s]
 13%|█▎        | 22.2M/170M [00:54&lt;06:20, 389kB/s]
 13%|█▎        | 22.3M/170M [00:54&lt;06:16, 394kB/s]
 13%|█▎        | 22.3M/170M [00:54&lt;06:12, 398kB/s]
 13%|█▎        | 22.4M/170M [00:54&lt;06:08, 402kB/s]
 13%|█▎        | 22.5M/170M [00:54&lt;06:11, 398kB/s]
 13%|█▎        | 22.5M/170M [00:54&lt;06:30, 378kB/s]
 13%|█▎        | 22.6M/170M [00:55&lt;06:13, 396kB/s]
 13%|█▎        | 22.7M/170M [00:55&lt;06:10, 399kB/s]
 13%|█▎        | 22.7M/170M [00:55&lt;06:05, 404kB/s]
 13%|█▎        | 22.8M/170M [00:55&lt;06:04, 406kB/s]
 13%|█▎        | 22.9M/170M [00:55&lt;06:16, 392kB/s]
 13%|█▎        | 22.9M/170M [00:55&lt;06:14, 394kB/s]
 13%|█▎        | 23.0M/170M [00:56&lt;06:10, 398kB/s]
 14%|█▎        | 23.1M/170M [00:56&lt;06:02, 406kB/s]
 14%|█▎        | 23.1M/170M [00:56&lt;06:04, 404kB/s]
 14%|█▎        | 23.2M/170M [00:56&lt;06:06, 402kB/s]
 14%|█▎        | 23.3M/170M [00:56&lt;06:24, 383kB/s]
 14%|█▎        | 23.3M/170M [00:56&lt;06:10, 397kB/s]
 14%|█▎        | 23.4M/170M [00:57&lt;06:05, 403kB/s]
 14%|█▍        | 23.5M/170M [00:57&lt;06:02, 406kB/s]
 14%|█▍        | 23.5M/170M [00:57&lt;06:02, 405kB/s]
 14%|█▍        | 23.6M/170M [00:57&lt;06:13, 393kB/s]
 14%|█▍        | 23.7M/170M [00:57&lt;06:07, 399kB/s]
 14%|█▍        | 23.7M/170M [00:57&lt;06:01, 406kB/s]
 14%|█▍        | 23.8M/170M [00:58&lt;06:03, 404kB/s]
 14%|█▍        | 23.9M/170M [00:58&lt;06:02, 404kB/s]
 14%|█▍        | 23.9M/170M [00:58&lt;06:35, 371kB/s]
 14%|█▍        | 24.0M/170M [00:58&lt;06:05, 401kB/s]
 14%|█▍        | 24.1M/170M [00:58&lt;06:06, 399kB/s]
 14%|█▍        | 24.1M/170M [00:58&lt;06:00, 407kB/s]
 14%|█▍        | 24.2M/170M [00:59&lt;05:59, 407kB/s]
 14%|█▍        | 24.2M/170M [00:59&lt;06:11, 393kB/s]
 14%|█▍        | 24.3M/170M [00:59&lt;06:07, 398kB/s]
 14%|█▍        | 24.4M/170M [00:59&lt;06:02, 403kB/s]
 14%|█▍        | 24.4M/170M [00:59&lt;05:59, 406kB/s]
 14%|█▍        | 24.5M/170M [00:59&lt;05:59, 406kB/s]
 14%|█▍        | 24.6M/170M [01:00&lt;06:11, 393kB/s]
 14%|█▍        | 24.6M/170M [01:00&lt;06:05, 399kB/s]
 14%|█▍        | 24.7M/170M [01:00&lt;06:03, 401kB/s]
 15%|█▍        | 24.8M/170M [01:00&lt;05:59, 406kB/s]
 15%|█▍        | 24.8M/170M [01:00&lt;06:01, 403kB/s]
 15%|█▍        | 24.9M/170M [01:00&lt;05:58, 407kB/s]
 15%|█▍        | 25.0M/170M [01:01&lt;06:12, 391kB/s]
 15%|█▍        | 25.0M/170M [01:01&lt;06:05, 398kB/s]
 15%|█▍        | 25.1M/170M [01:01&lt;05:58, 405kB/s]
 15%|█▍        | 25.2M/170M [01:01&lt;06:00, 403kB/s]
 15%|█▍        | 25.2M/170M [01:01&lt;05:57, 407kB/s]
 15%|█▍        | 25.3M/170M [01:01&lt;06:11, 391kB/s]
 15%|█▍        | 25.4M/170M [01:02&lt;06:16, 386kB/s]
 15%|█▍        | 25.4M/170M [01:02&lt;05:58, 405kB/s]
 15%|█▍        | 25.5M/170M [01:02&lt;06:21, 380kB/s]
 15%|█▍        | 25.6M/170M [01:02&lt;05:47, 417kB/s]
 15%|█▌        | 25.6M/170M [01:02&lt;06:01, 401kB/s]
 15%|█▌        | 25.7M/170M [01:02&lt;06:14, 387kB/s]
 15%|█▌        | 25.8M/170M [01:02&lt;05:49, 415kB/s]
 15%|█▌        | 25.8M/170M [01:03&lt;05:48, 415kB/s]
 15%|█▌        | 25.9M/170M [01:03&lt;06:08, 393kB/s]
 15%|█▌        | 26.0M/170M [01:03&lt;05:58, 403kB/s]
 15%|█▌        | 26.0M/170M [01:03&lt;05:56, 406kB/s]
 15%|█▌        | 26.1M/170M [01:03&lt;05:55, 406kB/s]
 15%|█▌        | 26.1M/170M [01:03&lt;05:55, 407kB/s]
 15%|█▌        | 26.2M/170M [01:04&lt;05:54, 407kB/s]
 15%|█▌        | 26.3M/170M [01:04&lt;06:08, 391kB/s]
 15%|█▌        | 26.3M/170M [01:04&lt;06:01, 399kB/s]
 15%|█▌        | 26.4M/170M [01:04&lt;06:07, 392kB/s]
 16%|█▌        | 26.5M/170M [01:04&lt;05:50, 411kB/s]
 16%|█▌        | 26.5M/170M [01:04&lt;05:54, 406kB/s]
 16%|█▌        | 26.6M/170M [01:05&lt;05:58, 402kB/s]
 16%|█▌        | 26.7M/170M [01:05&lt;06:14, 384kB/s]
 16%|█▌        | 26.7M/170M [01:05&lt;05:54, 405kB/s]
 16%|█▌        | 26.8M/170M [01:05&lt;05:53, 406kB/s]
 16%|█▌        | 26.9M/170M [01:05&lt;06:02, 396kB/s]
 16%|█▌        | 26.9M/170M [01:05&lt;05:53, 407kB/s]
 16%|█▌        | 27.0M/170M [01:06&lt;06:10, 387kB/s]
 16%|█▌        | 27.1M/170M [01:06&lt;05:55, 404kB/s]
 16%|█▌        | 27.1M/170M [01:06&lt;05:54, 405kB/s]
 16%|█▌        | 27.2M/170M [01:06&lt;05:53, 405kB/s]
 16%|█▌        | 27.3M/170M [01:06&lt;05:57, 401kB/s]
 16%|█▌        | 27.3M/170M [01:06&lt;06:02, 395kB/s]
 16%|█▌        | 27.4M/170M [01:07&lt;05:54, 404kB/s]
 16%|█▌        | 27.5M/170M [01:07&lt;05:55, 403kB/s]
 16%|█▌        | 27.5M/170M [01:07&lt;05:58, 399kB/s]
 16%|█▌        | 27.6M/170M [01:07&lt;05:57, 400kB/s]
 16%|█▌        | 27.7M/170M [01:07&lt;06:08, 387kB/s]
 16%|█▋        | 27.7M/170M [01:07&lt;05:56, 401kB/s]
 16%|█▋        | 27.8M/170M [01:08&lt;05:56, 401kB/s]
 16%|█▋        | 27.9M/170M [01:08&lt;05:58, 397kB/s]
 16%|█▋        | 27.9M/170M [01:08&lt;05:50, 407kB/s]
 16%|█▋        | 28.0M/170M [01:08&lt;05:50, 406kB/s]
 16%|█▋        | 28.0M/170M [01:08&lt;06:05, 390kB/s]
 16%|█▋        | 28.1M/170M [01:08&lt;05:55, 400kB/s]
 17%|█▋        | 28.2M/170M [01:09&lt;05:53, 403kB/s]
 17%|█▋        | 28.2M/170M [01:09&lt;05:54, 401kB/s]
 17%|█▋        | 28.3M/170M [01:09&lt;05:51, 405kB/s]
 17%|█▋        | 28.4M/170M [01:09&lt;06:11, 382kB/s]
 17%|█▋        | 28.4M/170M [01:09&lt;05:58, 396kB/s]
 17%|█▋        | 28.5M/170M [01:09&lt;05:51, 404kB/s]
 17%|█▋        | 28.6M/170M [01:10&lt;06:04, 390kB/s]
 17%|█▋        | 28.6M/170M [01:10&lt;05:40, 417kB/s]
 17%|█▋        | 28.7M/170M [01:10&lt;05:56, 397kB/s]
 17%|█▋        | 28.8M/170M [01:10&lt;05:51, 404kB/s]
 17%|█▋        | 28.8M/170M [01:10&lt;06:00, 393kB/s]
 17%|█▋        | 28.9M/170M [01:10&lt;05:55, 398kB/s]
 17%|█▋        | 29.0M/170M [01:11&lt;05:50, 403kB/s]
 17%|█▋        | 29.0M/170M [01:11&lt;06:03, 389kB/s]
 17%|█▋        | 29.1M/170M [01:11&lt;05:54, 398kB/s]
 17%|█▋        | 29.2M/170M [01:11&lt;05:53, 400kB/s]
 17%|█▋        | 29.2M/170M [01:11&lt;05:55, 397kB/s]
 17%|█▋        | 29.3M/170M [01:11&lt;05:49, 404kB/s]
 17%|█▋        | 29.4M/170M [01:12&lt;05:59, 393kB/s]
 17%|█▋        | 29.4M/170M [01:12&lt;05:51, 402kB/s]
 17%|█▋        | 29.5M/170M [01:12&lt;05:51, 402kB/s]
 17%|█▋        | 29.6M/170M [01:12&lt;05:49, 403kB/s]
 17%|█▋        | 29.6M/170M [01:12&lt;05:48, 405kB/s]
 17%|█▋        | 29.7M/170M [01:12&lt;05:49, 403kB/s]
 17%|█▋        | 29.8M/170M [01:13&lt;06:02, 389kB/s]
 17%|█▋        | 29.8M/170M [01:13&lt;05:52, 399kB/s]
 18%|█▊        | 29.9M/170M [01:13&lt;05:53, 398kB/s]
 18%|█▊        | 29.9M/170M [01:13&lt;05:54, 396kB/s]
 18%|█▊        | 30.0M/170M [01:13&lt;06:05, 384kB/s]
 18%|█▊        | 30.1M/170M [01:13&lt;06:12, 377kB/s]
 18%|█▊        | 30.1M/170M [01:14&lt;05:57, 392kB/s]
 18%|█▊        | 30.2M/170M [01:14&lt;05:49, 402kB/s]
 18%|█▊        | 30.3M/170M [01:14&lt;05:52, 398kB/s]
 18%|█▊        | 30.3M/170M [01:14&lt;05:46, 404kB/s]
 18%|█▊        | 30.4M/170M [01:14&lt;05:58, 391kB/s]
 18%|█▊        | 30.5M/170M [01:14&lt;05:56, 393kB/s]
 18%|█▊        | 30.5M/170M [01:14&lt;05:53, 396kB/s]
 18%|█▊        | 30.6M/170M [01:15&lt;05:53, 395kB/s]
 18%|█▊        | 30.7M/170M [01:15&lt;05:54, 395kB/s]
 18%|█▊        | 30.7M/170M [01:15&lt;06:05, 383kB/s]
 18%|█▊        | 30.8M/170M [01:15&lt;06:08, 379kB/s]
 18%|█▊        | 30.9M/170M [01:15&lt;05:48, 401kB/s]
 18%|█▊        | 30.9M/170M [01:15&lt;05:45, 404kB/s]
 18%|█▊        | 31.0M/170M [01:16&lt;05:48, 400kB/s]
 18%|█▊        | 31.1M/170M [01:16&lt;06:01, 386kB/s]
 18%|█▊        | 31.1M/170M [01:16&lt;05:55, 392kB/s]
 18%|█▊        | 31.2M/170M [01:16&lt;05:50, 397kB/s]
 18%|█▊        | 31.3M/170M [01:16&lt;05:49, 399kB/s]
 18%|█▊        | 31.3M/170M [01:16&lt;05:46, 401kB/s]
 18%|█▊        | 31.4M/170M [01:17&lt;05:49, 398kB/s]
 18%|█▊        | 31.5M/170M [01:17&lt;06:02, 383kB/s]
 18%|█▊        | 31.5M/170M [01:17&lt;05:55, 391kB/s]
 19%|█▊        | 31.6M/170M [01:17&lt;05:50, 396kB/s]
 19%|█▊        | 31.7M/170M [01:17&lt;05:49, 397kB/s]
 19%|█▊        | 31.7M/170M [01:17&lt;05:46, 400kB/s]
 19%|█▊        | 31.8M/170M [01:18&lt;06:15, 370kB/s]
 19%|█▊        | 31.9M/170M [01:18&lt;06:01, 383kB/s]
 19%|█▊        | 31.9M/170M [01:18&lt;05:55, 390kB/s]
 19%|█▉        | 32.0M/170M [01:18&lt;06:01, 383kB/s]
 19%|█▉        | 32.0M/170M [01:18&lt;05:52, 393kB/s]
 19%|█▉        | 32.1M/170M [01:19&lt;06:02, 382kB/s]
 19%|█▉        | 32.2M/170M [01:19&lt;06:01, 382kB/s]
 19%|█▉        | 32.2M/170M [01:19&lt;06:14, 369kB/s]
 19%|█▉        | 32.3M/170M [01:19&lt;05:46, 399kB/s]
 19%|█▉        | 32.4M/170M [01:19&lt;05:43, 402kB/s]
 19%|█▉        | 32.4M/170M [01:19&lt;05:56, 387kB/s]
 19%|█▉        | 32.5M/170M [01:20&lt;05:51, 393kB/s]
 19%|█▉        | 32.6M/170M [01:20&lt;05:46, 398kB/s]
 19%|█▉        | 32.6M/170M [01:20&lt;05:45, 399kB/s]
 19%|█▉        | 32.7M/170M [01:20&lt;05:42, 402kB/s]
 19%|█▉        | 32.8M/170M [01:20&lt;05:56, 386kB/s]
 19%|█▉        | 32.8M/170M [01:20&lt;06:08, 374kB/s]
 19%|█▉        | 32.9M/170M [01:21&lt;05:42, 402kB/s]
 19%|█▉        | 33.0M/170M [01:21&lt;05:40, 404kB/s]
 19%|█▉        | 33.0M/170M [01:21&lt;05:44, 399kB/s]
 19%|█▉        | 33.1M/170M [01:21&lt;05:52, 390kB/s]
 19%|█▉        | 33.2M/170M [01:21&lt;05:50, 391kB/s]
 19%|█▉        | 33.2M/170M [01:21&lt;05:50, 392kB/s]
 20%|█▉        | 33.3M/170M [01:22&lt;05:58, 383kB/s]
 20%|█▉        | 33.4M/170M [01:22&lt;05:39, 404kB/s]
 20%|█▉        | 33.4M/170M [01:22&lt;05:40, 403kB/s]
 20%|█▉        | 33.5M/170M [01:22&lt;05:53, 387kB/s]
 20%|█▉        | 33.6M/170M [01:22&lt;05:48, 393kB/s]
 20%|█▉        | 33.6M/170M [01:22&lt;05:43, 398kB/s]
 20%|█▉        | 33.7M/170M [01:23&lt;05:44, 397kB/s]
 20%|█▉        | 33.8M/170M [01:23&lt;05:56, 384kB/s]
 20%|█▉        | 33.8M/170M [01:23&lt;06:06, 373kB/s]
 20%|█▉        | 33.9M/170M [01:23&lt;05:43, 398kB/s]
 20%|█▉        | 33.9M/170M [01:23&lt;05:41, 399kB/s]
 20%|█▉        | 34.0M/170M [01:23&lt;05:49, 390kB/s]
 20%|█▉        | 34.1M/170M [01:24&lt;05:39, 402kB/s]
 20%|██        | 34.1M/170M [01:24&lt;05:48, 391kB/s]
 20%|██        | 34.2M/170M [01:24&lt;05:44, 395kB/s]
 20%|██        | 34.3M/170M [01:24&lt;05:44, 395kB/s]
 20%|██        | 34.3M/170M [01:24&lt;05:40, 400kB/s]
 20%|██        | 34.4M/170M [01:24&lt;05:50, 388kB/s]
 20%|██        | 34.5M/170M [01:25&lt;05:46, 393kB/s]
 20%|██        | 34.5M/170M [01:25&lt;05:42, 397kB/s]
 20%|██        | 34.6M/170M [01:25&lt;05:43, 396kB/s]
 20%|██        | 34.7M/170M [01:25&lt;05:39, 400kB/s]
 20%|██        | 34.7M/170M [01:25&lt;05:40, 399kB/s]
 20%|██        | 34.8M/170M [01:25&lt;05:36, 403kB/s]
 20%|██        | 34.9M/170M [01:26&lt;05:59, 378kB/s]
 20%|██        | 34.9M/170M [01:26&lt;05:42, 396kB/s]
 21%|██        | 35.0M/170M [01:26&lt;05:35, 403kB/s]
 21%|██        | 35.1M/170M [01:26&lt;05:36, 403kB/s]
 21%|██        | 35.1M/170M [01:26&lt;05:45, 392kB/s]
 21%|██        | 35.2M/170M [01:26&lt;05:46, 390kB/s]
 21%|██        | 35.3M/170M [01:27&lt;05:44, 392kB/s]
 21%|██        | 35.3M/170M [01:27&lt;05:45, 391kB/s]
 21%|██        | 35.4M/170M [01:27&lt;05:39, 398kB/s]
 21%|██        | 35.5M/170M [01:27&lt;05:39, 398kB/s]
 21%|██        | 35.5M/170M [01:27&lt;05:49, 387kB/s]
 21%|██        | 35.6M/170M [01:27&lt;05:44, 392kB/s]
 21%|██        | 35.7M/170M [01:28&lt;05:40, 396kB/s]
 21%|██        | 35.7M/170M [01:28&lt;05:35, 401kB/s]
 21%|██        | 35.8M/170M [01:28&lt;05:32, 405kB/s]
 21%|██        | 35.8M/170M [01:28&lt;05:41, 394kB/s]
 21%|██        | 35.9M/170M [01:28&lt;05:36, 400kB/s]
 21%|██        | 36.0M/170M [01:28&lt;05:38, 397kB/s]
 21%|██        | 36.0M/170M [01:28&lt;05:32, 404kB/s]
 21%|██        | 36.1M/170M [01:29&lt;05:29, 408kB/s]
 21%|██        | 36.2M/170M [01:29&lt;05:31, 405kB/s]
 21%|██▏       | 36.2M/170M [01:29&lt;05:39, 395kB/s]
 21%|██▏       | 36.3M/170M [01:29&lt;05:36, 398kB/s]
 21%|██▏       | 36.4M/170M [01:29&lt;05:32, 404kB/s]
 21%|██▏       | 36.4M/170M [01:29&lt;05:32, 404kB/s]
 21%|██▏       | 36.5M/170M [01:30&lt;05:33, 402kB/s]
 21%|██▏       | 36.6M/170M [01:30&lt;05:42, 390kB/s]
 21%|██▏       | 36.6M/170M [01:30&lt;05:38, 395kB/s]
 22%|██▏       | 36.7M/170M [01:30&lt;05:33, 401kB/s]
 22%|██▏       | 36.8M/170M [01:30&lt;05:30, 405kB/s]
 22%|██▏       | 36.8M/170M [01:30&lt;05:29, 405kB/s]
 22%|██▏       | 36.9M/170M [01:31&lt;05:39, 394kB/s]
 22%|██▏       | 37.0M/170M [01:31&lt;05:34, 400kB/s]
 22%|██▏       | 37.0M/170M [01:31&lt;05:34, 399kB/s]
 22%|██▏       | 37.1M/170M [01:31&lt;05:29, 405kB/s]
 22%|██▏       | 37.2M/170M [01:31&lt;05:33, 399kB/s]
 22%|██▏       | 37.2M/170M [01:31&lt;06:00, 370kB/s]
 22%|██▏       | 37.3M/170M [01:32&lt;05:33, 400kB/s]
 22%|██▏       | 37.4M/170M [01:32&lt;05:33, 399kB/s]
 22%|██▏       | 37.4M/170M [01:32&lt;05:30, 403kB/s]
 22%|██▏       | 37.5M/170M [01:32&lt;05:27, 406kB/s]
 22%|██▏       | 37.6M/170M [01:32&lt;05:38, 393kB/s]
 22%|██▏       | 37.6M/170M [01:32&lt;05:37, 394kB/s]
 22%|██▏       | 37.7M/170M [01:33&lt;05:36, 395kB/s]
 22%|██▏       | 37.7M/170M [01:33&lt;05:31, 400kB/s]
 22%|██▏       | 37.8M/170M [01:33&lt;05:32, 399kB/s]
 22%|██▏       | 37.9M/170M [01:33&lt;05:32, 398kB/s]
 22%|██▏       | 37.9M/170M [01:33&lt;05:57, 371kB/s]
 22%|██▏       | 38.0M/170M [01:33&lt;05:32, 399kB/s]
 22%|██▏       | 38.1M/170M [01:34&lt;05:29, 402kB/s]
 22%|██▏       | 38.1M/170M [01:34&lt;05:30, 400kB/s]
 22%|██▏       | 38.2M/170M [01:34&lt;05:29, 402kB/s]
 22%|██▏       | 38.3M/170M [01:34&lt;05:39, 389kB/s]
 22%|██▏       | 38.3M/170M [01:34&lt;05:38, 391kB/s]
 23%|██▎       | 38.4M/170M [01:34&lt;05:43, 384kB/s]
 23%|██▎       | 38.5M/170M [01:35&lt;05:29, 401kB/s]
 23%|██▎       | 38.5M/170M [01:35&lt;05:32, 397kB/s]
 23%|██▎       | 38.6M/170M [01:35&lt;05:46, 381kB/s]
 23%|██▎       | 38.7M/170M [01:35&lt;05:38, 389kB/s]
 23%|██▎       | 38.7M/170M [01:35&lt;05:35, 393kB/s]
 23%|██▎       | 38.8M/170M [01:35&lt;05:30, 399kB/s]
 23%|██▎       | 38.9M/170M [01:36&lt;05:29, 400kB/s]
 23%|██▎       | 38.9M/170M [01:36&lt;05:38, 388kB/s]
 23%|██▎       | 39.0M/170M [01:36&lt;05:36, 391kB/s]
 23%|██▎       | 39.1M/170M [01:36&lt;05:34, 393kB/s]
 23%|██▎       | 39.1M/170M [01:36&lt;05:27, 402kB/s]
 23%|██▎       | 39.2M/170M [01:36&lt;05:27, 400kB/s]
 23%|██▎       | 39.3M/170M [01:37&lt;05:37, 389kB/s]
 23%|██▎       | 39.3M/170M [01:37&lt;05:33, 393kB/s]
 23%|██▎       | 39.4M/170M [01:37&lt;05:27, 400kB/s]
 23%|██▎       | 39.5M/170M [01:37&lt;05:30, 397kB/s]
 23%|██▎       | 39.5M/170M [01:37&lt;05:25, 402kB/s]
 23%|██▎       | 39.6M/170M [01:37&lt;05:25, 402kB/s]
 23%|██▎       | 39.6M/170M [01:38&lt;05:37, 388kB/s]
 23%|██▎       | 39.7M/170M [01:38&lt;05:32, 393kB/s]
 23%|██▎       | 39.8M/170M [01:38&lt;05:29, 397kB/s]
 23%|██▎       | 39.8M/170M [01:38&lt;05:24, 402kB/s]
 23%|██▎       | 39.9M/170M [01:38&lt;05:23, 404kB/s]
 23%|██▎       | 40.0M/170M [01:38&lt;05:32, 392kB/s]
 23%|██▎       | 40.0M/170M [01:39&lt;05:48, 374kB/s]
 24%|██▎       | 40.1M/170M [01:39&lt;05:21, 406kB/s]
 24%|██▎       | 40.2M/170M [01:39&lt;05:20, 406kB/s]
 24%|██▎       | 40.2M/170M [01:39&lt;05:21, 405kB/s]
 24%|██▎       | 40.3M/170M [01:39&lt;05:32, 391kB/s]
 24%|██▎       | 40.4M/170M [01:39&lt;05:31, 392kB/s]
 24%|██▎       | 40.4M/170M [01:40&lt;05:28, 396kB/s]
 24%|██▍       | 40.5M/170M [01:40&lt;05:23, 402kB/s]
 24%|██▍       | 40.6M/170M [01:40&lt;05:21, 405kB/s]
 24%|██▍       | 40.6M/170M [01:40&lt;05:51, 370kB/s]
 24%|██▍       | 40.7M/170M [01:40&lt;05:18, 407kB/s]
 24%|██▍       | 40.8M/170M [01:40&lt;05:21, 404kB/s]
 24%|██▍       | 40.8M/170M [01:41&lt;05:16, 409kB/s]
 24%|██▍       | 40.9M/170M [01:41&lt;05:15, 410kB/s]
 24%|██▍       | 41.0M/170M [01:41&lt;05:32, 389kB/s]
 24%|██▍       | 41.0M/170M [01:41&lt;05:29, 393kB/s]
 24%|██▍       | 41.1M/170M [01:41&lt;05:29, 393kB/s]
 24%|██▍       | 41.2M/170M [01:41&lt;05:22, 402kB/s]
 24%|██▍       | 41.2M/170M [01:42&lt;05:34, 387kB/s]
 24%|██▍       | 41.3M/170M [01:42&lt;05:16, 408kB/s]
 24%|██▍       | 41.4M/170M [01:42&lt;05:32, 389kB/s]
 24%|██▍       | 41.4M/170M [01:42&lt;05:26, 395kB/s]
 24%|██▍       | 41.5M/170M [01:42&lt;05:24, 398kB/s]
 24%|██▍       | 41.5M/170M [01:42&lt;05:23, 399kB/s]
 24%|██▍       | 41.6M/170M [01:43&lt;05:21, 401kB/s]
 24%|██▍       | 41.7M/170M [01:43&lt;05:36, 383kB/s]
 24%|██▍       | 41.7M/170M [01:43&lt;05:27, 393kB/s]
 25%|██▍       | 41.8M/170M [01:43&lt;05:26, 394kB/s]
 25%|██▍       | 41.9M/170M [01:43&lt;05:23, 398kB/s]
 25%|██▍       | 41.9M/170M [01:43&lt;05:33, 385kB/s]
 25%|██▍       | 42.0M/170M [01:44&lt;05:35, 383kB/s]
 25%|██▍       | 42.1M/170M [01:44&lt;05:22, 398kB/s]
 25%|██▍       | 42.1M/170M [01:44&lt;05:21, 399kB/s]
 25%|██▍       | 42.2M/170M [01:44&lt;05:20, 400kB/s]
 25%|██▍       | 42.3M/170M [01:44&lt;05:20, 400kB/s]
 25%|██▍       | 42.3M/170M [01:44&lt;05:34, 383kB/s]
 25%|██▍       | 42.4M/170M [01:45&lt;05:27, 391kB/s]
 25%|██▍       | 42.5M/170M [01:45&lt;05:24, 394kB/s]
 25%|██▍       | 42.5M/170M [01:45&lt;05:25, 393kB/s]
 25%|██▍       | 42.6M/170M [01:45&lt;05:21, 398kB/s]
 25%|██▌       | 42.7M/170M [01:45&lt;05:30, 387kB/s]
 25%|██▌       | 42.7M/170M [01:45&lt;05:31, 386kB/s]
 25%|██▌       | 42.8M/170M [01:46&lt;05:18, 401kB/s]
 25%|██▌       | 42.9M/170M [01:46&lt;05:18, 401kB/s]
 25%|██▌       | 42.9M/170M [01:46&lt;05:17, 402kB/s]
 25%|██▌       | 43.0M/170M [01:46&lt;05:16, 402kB/s]
 25%|██▌       | 43.1M/170M [01:46&lt;05:27, 389kB/s]
 25%|██▌       | 43.1M/170M [01:46&lt;05:23, 394kB/s]
 25%|██▌       | 43.2M/170M [01:47&lt;05:23, 393kB/s]
 25%|██▌       | 43.3M/170M [01:47&lt;05:23, 393kB/s]
 25%|██▌       | 43.3M/170M [01:47&lt;05:19, 398kB/s]
 25%|██▌       | 43.4M/170M [01:47&lt;05:45, 368kB/s]
 25%|██▌       | 43.5M/170M [01:47&lt;05:16, 401kB/s]
 26%|██▌       | 43.5M/170M [01:47&lt;05:21, 395kB/s]
 26%|██▌       | 43.6M/170M [01:48&lt;05:19, 397kB/s]
 26%|██▌       | 43.6M/170M [01:48&lt;05:20, 395kB/s]
 26%|██▌       | 43.7M/170M [01:48&lt;05:31, 382kB/s]
 26%|██▌       | 43.8M/170M [01:48&lt;05:23, 392kB/s]
 26%|██▌       | 43.8M/170M [01:48&lt;05:21, 394kB/s]
 26%|██▌       | 43.9M/170M [01:48&lt;05:20, 395kB/s]
 26%|██▌       | 44.0M/170M [01:49&lt;05:17, 398kB/s]
 26%|██▌       | 44.0M/170M [01:49&lt;05:29, 384kB/s]
 26%|██▌       | 44.1M/170M [01:49&lt;05:23, 391kB/s]
 26%|██▌       | 44.2M/170M [01:49&lt;05:24, 389kB/s]
 26%|██▌       | 44.2M/170M [01:49&lt;05:22, 391kB/s]
 26%|██▌       | 44.3M/170M [01:49&lt;05:17, 397kB/s]
 26%|██▌       | 44.4M/170M [01:50&lt;05:16, 399kB/s]
 26%|██▌       | 44.4M/170M [01:50&lt;05:28, 384kB/s]
 26%|██▌       | 44.5M/170M [01:50&lt;05:22, 391kB/s]
 26%|██▌       | 44.6M/170M [01:50&lt;05:17, 397kB/s]
 26%|██▌       | 44.6M/170M [01:50&lt;05:16, 397kB/s]
 26%|██▌       | 44.7M/170M [01:50&lt;05:13, 401kB/s]
 26%|██▋       | 44.8M/170M [01:51&lt;05:24, 388kB/s]
 26%|██▋       | 44.8M/170M [01:51&lt;05:16, 397kB/s]
 26%|██▋       | 44.9M/170M [01:51&lt;05:13, 400kB/s]
 26%|██▋       | 45.0M/170M [01:51&lt;05:16, 397kB/s]
 26%|██▋       | 45.0M/170M [01:51&lt;05:11, 403kB/s]
 26%|██▋       | 45.1M/170M [01:51&lt;05:22, 389kB/s]
 26%|██▋       | 45.2M/170M [01:52&lt;05:18, 393kB/s]
 27%|██▋       | 45.2M/170M [01:52&lt;05:16, 395kB/s]
 27%|██▋       | 45.3M/170M [01:52&lt;05:14, 398kB/s]
 27%|██▋       | 45.4M/170M [01:52&lt;05:14, 398kB/s]
 27%|██▋       | 45.4M/170M [01:52&lt;05:35, 373kB/s]
 27%|██▋       | 45.5M/170M [01:52&lt;05:18, 393kB/s]
 27%|██▋       | 45.5M/170M [01:53&lt;05:16, 395kB/s]
 27%|██▋       | 45.6M/170M [01:53&lt;05:15, 396kB/s]
 27%|██▋       | 45.7M/170M [01:53&lt;05:15, 396kB/s]
 27%|██▋       | 45.7M/170M [01:53&lt;05:24, 384kB/s]
 27%|██▋       | 45.8M/170M [01:53&lt;05:20, 389kB/s]
 27%|██▋       | 45.9M/170M [01:53&lt;05:15, 395kB/s]
 27%|██▋       | 45.9M/170M [01:54&lt;05:16, 394kB/s]
 27%|██▋       | 46.0M/170M [01:54&lt;05:10, 401kB/s]
 27%|██▋       | 46.1M/170M [01:54&lt;05:12, 398kB/s]
 27%|██▋       | 46.1M/170M [01:54&lt;05:26, 380kB/s]
 27%|██▋       | 46.2M/170M [01:54&lt;05:18, 391kB/s]
 27%|██▋       | 46.3M/170M [01:54&lt;05:15, 393kB/s]
 27%|██▋       | 46.3M/170M [01:55&lt;05:16, 393kB/s]
 27%|██▋       | 46.4M/170M [01:55&lt;05:12, 397kB/s]
 27%|██▋       | 46.5M/170M [01:55&lt;05:25, 381kB/s]
 27%|██▋       | 46.5M/170M [01:55&lt;05:22, 384kB/s]
 27%|██▋       | 46.6M/170M [01:55&lt;05:23, 384kB/s]
 27%|██▋       | 46.7M/170M [01:55&lt;05:26, 379kB/s]
 27%|██▋       | 46.7M/170M [01:56&lt;05:07, 402kB/s]
 27%|██▋       | 46.8M/170M [01:56&lt;05:18, 388kB/s]
 27%|██▋       | 46.9M/170M [01:56&lt;05:13, 394kB/s]
 28%|██▊       | 46.9M/170M [01:56&lt;05:12, 396kB/s]
 28%|██▊       | 47.0M/170M [01:56&lt;05:11, 396kB/s]
 28%|██▊       | 47.1M/170M [01:56&lt;05:16, 390kB/s]
 28%|██▊       | 47.1M/170M [01:57&lt;05:39, 364kB/s]
 28%|██▊       | 47.2M/170M [01:57&lt;05:13, 393kB/s]
 28%|██▊       | 47.3M/170M [01:57&lt;05:14, 392kB/s]
 28%|██▊       | 47.3M/170M [01:57&lt;05:12, 395kB/s]
 28%|██▊       | 47.4M/170M [01:57&lt;05:08, 399kB/s]
 28%|██▊       | 47.4M/170M [01:57&lt;05:23, 380kB/s]
 28%|██▊       | 47.5M/170M [01:58&lt;05:18, 386kB/s]
 28%|██▊       | 47.6M/170M [01:58&lt;05:13, 392kB/s]
 28%|██▊       | 47.6M/170M [01:58&lt;05:08, 398kB/s]
 28%|██▊       | 47.7M/170M [01:58&lt;05:24, 379kB/s]
 28%|██▊       | 47.8M/170M [01:58&lt;05:00, 408kB/s]
 28%|██▊       | 47.8M/170M [01:58&lt;05:18, 385kB/s]
 28%|██▊       | 47.9M/170M [01:59&lt;05:10, 394kB/s]
 28%|██▊       | 48.0M/170M [01:59&lt;05:08, 397kB/s]
 28%|██▊       | 48.0M/170M [01:59&lt;05:10, 395kB/s]
 28%|██▊       | 48.1M/170M [01:59&lt;05:04, 402kB/s]
 28%|██▊       | 48.2M/170M [01:59&lt;05:15, 388kB/s]
 28%|██▊       | 48.2M/170M [01:59&lt;05:10, 394kB/s]
 28%|██▊       | 48.3M/170M [02:00&lt;05:09, 395kB/s]
 28%|██▊       | 48.4M/170M [02:00&lt;05:05, 399kB/s]
 28%|██▊       | 48.4M/170M [02:00&lt;05:03, 403kB/s]
 28%|██▊       | 48.5M/170M [02:00&lt;05:26, 374kB/s]
 28%|██▊       | 48.6M/170M [02:00&lt;05:06, 398kB/s]
 29%|██▊       | 48.6M/170M [02:00&lt;05:06, 397kB/s]
 29%|██▊       | 48.7M/170M [02:01&lt;05:23, 376kB/s]
 29%|██▊       | 48.8M/170M [02:01&lt;04:59, 406kB/s]
 29%|██▊       | 48.8M/170M [02:01&lt;05:10, 392kB/s]
 29%|██▊       | 48.9M/170M [02:01&lt;05:08, 394kB/s]
 29%|██▊       | 49.0M/170M [02:01&lt;05:11, 390kB/s]
 29%|██▉       | 49.0M/170M [02:01&lt;05:07, 396kB/s]
 29%|██▉       | 49.1M/170M [02:02&lt;05:07, 395kB/s]
 29%|██▉       | 49.2M/170M [02:02&lt;05:17, 382kB/s]
 29%|██▉       | 49.2M/170M [02:02&lt;05:11, 389kB/s]
 29%|██▉       | 49.3M/170M [02:02&lt;05:10, 390kB/s]
 29%|██▉       | 49.3M/170M [02:02&lt;04:59, 404kB/s]
 29%|██▉       | 49.4M/170M [02:02&lt;05:02, 401kB/s]
 29%|██▉       | 49.5M/170M [02:03&lt;05:10, 390kB/s]
 29%|██▉       | 49.5M/170M [02:03&lt;05:20, 377kB/s]
 29%|██▉       | 49.6M/170M [02:03&lt;05:00, 402kB/s]
 29%|██▉       | 49.7M/170M [02:03&lt;05:02, 399kB/s]
 29%|██▉       | 49.7M/170M [02:03&lt;05:14, 385kB/s]
 29%|██▉       | 49.8M/170M [02:03&lt;04:58, 405kB/s]
 29%|██▉       | 49.9M/170M [02:04&lt;05:07, 393kB/s]
 29%|██▉       | 49.9M/170M [02:04&lt;05:06, 394kB/s]
 29%|██▉       | 50.0M/170M [02:04&lt;05:05, 394kB/s]
 29%|██▉       | 50.1M/170M [02:04&lt;05:02, 398kB/s]
 29%|██▉       | 50.1M/170M [02:04&lt;05:12, 386kB/s]
 29%|██▉       | 50.2M/170M [02:04&lt;05:04, 395kB/s]
 29%|██▉       | 50.3M/170M [02:05&lt;05:03, 396kB/s]
 30%|██▉       | 50.3M/170M [02:05&lt;05:02, 398kB/s]
 30%|██▉       | 50.4M/170M [02:05&lt;05:00, 399kB/s]
 30%|██▉       | 50.5M/170M [02:05&lt;05:02, 396kB/s]
 30%|██▉       | 50.5M/170M [02:05&lt;05:10, 386kB/s]
 30%|██▉       | 50.6M/170M [02:05&lt;05:24, 370kB/s]
 30%|██▉       | 50.7M/170M [02:06&lt;05:00, 399kB/s]
 30%|██▉       | 50.7M/170M [02:06&lt;04:56, 404kB/s]
 30%|██▉       | 50.8M/170M [02:06&lt;04:56, 403kB/s]
 30%|██▉       | 50.9M/170M [02:06&lt;05:09, 387kB/s]
 30%|██▉       | 50.9M/170M [02:06&lt;05:06, 391kB/s]
 30%|██▉       | 51.0M/170M [02:06&lt;05:02, 396kB/s]
 30%|██▉       | 51.1M/170M [02:07&lt;04:58, 400kB/s]
 30%|██▉       | 51.1M/170M [02:07&lt;04:58, 400kB/s]
 30%|███       | 51.2M/170M [02:07&lt;04:58, 399kB/s]
 30%|███       | 51.2M/170M [02:07&lt;05:07, 388kB/s]
 30%|███       | 51.3M/170M [02:07&lt;05:05, 390kB/s]
 30%|███       | 51.4M/170M [02:07&lt;05:02, 394kB/s]
 30%|███       | 51.4M/170M [02:08&lt;05:03, 392kB/s]
 30%|███       | 51.5M/170M [02:08&lt;05:04, 391kB/s]
 30%|███       | 51.6M/170M [02:08&lt;05:12, 380kB/s]
 30%|███       | 51.6M/170M [02:08&lt;05:07, 387kB/s]
 30%|███       | 51.7M/170M [02:08&lt;05:04, 390kB/s]
 30%|███       | 51.8M/170M [02:08&lt;05:02, 393kB/s]
 30%|███       | 51.8M/170M [02:09&lt;04:59, 397kB/s]
 30%|███       | 51.9M/170M [02:09&lt;05:07, 385kB/s]
 30%|███       | 52.0M/170M [02:09&lt;05:03, 391kB/s]
 31%|███       | 52.0M/170M [02:09&lt;05:24, 365kB/s]
 31%|███       | 52.1M/170M [02:09&lt;05:03, 390kB/s]
 31%|███       | 52.2M/170M [02:09&lt;05:00, 394kB/s]
 31%|███       | 52.2M/170M [02:10&lt;05:08, 383kB/s]
 31%|███       | 52.3M/170M [02:10&lt;05:07, 384kB/s]
 31%|███       | 52.4M/170M [02:10&lt;04:59, 394kB/s]
 31%|███       | 52.4M/170M [02:10&lt;04:53, 402kB/s]
 31%|███       | 52.5M/170M [02:10&lt;04:51, 405kB/s]
 31%|███       | 52.6M/170M [02:10&lt;04:54, 401kB/s]
 31%|███       | 52.6M/170M [02:11&lt;05:02, 390kB/s]
 31%|███       | 52.7M/170M [02:11&lt;05:01, 390kB/s]
 31%|███       | 52.8M/170M [02:11&lt;04:58, 395kB/s]
 31%|███       | 52.8M/170M [02:11&lt;04:57, 395kB/s]
 31%|███       | 52.9M/170M [02:11&lt;04:56, 397kB/s]
 31%|███       | 53.0M/170M [02:11&lt;05:13, 375kB/s]
 31%|███       | 53.0M/170M [02:12&lt;05:06, 383kB/s]
 31%|███       | 53.1M/170M [02:12&lt;05:00, 390kB/s]
 31%|███       | 53.1M/170M [02:12&lt;05:00, 391kB/s]
 31%|███       | 53.2M/170M [02:12&lt;04:58, 393kB/s]
 31%|███▏      | 53.3M/170M [02:12&lt;05:06, 383kB/s]
 31%|███▏      | 53.3M/170M [02:12&lt;05:04, 385kB/s]
 31%|███▏      | 53.4M/170M [02:13&lt;05:15, 372kB/s]
 31%|███▏      | 53.5M/170M [02:13&lt;04:50, 402kB/s]
 31%|███▏      | 53.5M/170M [02:13&lt;04:49, 404kB/s]
 31%|███▏      | 53.6M/170M [02:13&lt;05:05, 383kB/s]
 31%|███▏      | 53.7M/170M [02:13&lt;04:59, 390kB/s]
 32%|███▏      | 53.7M/170M [02:13&lt;04:59, 389kB/s]
 32%|███▏      | 53.8M/170M [02:14&lt;04:56, 394kB/s]
 32%|███▏      | 53.9M/170M [02:14&lt;04:56, 394kB/s]
 32%|███▏      | 53.9M/170M [02:14&lt;05:05, 382kB/s]
 32%|███▏      | 54.0M/170M [02:14&lt;05:03, 384kB/s]
 32%|███▏      | 54.1M/170M [02:14&lt;05:00, 387kB/s]
 32%|███▏      | 54.1M/170M [02:14&lt;04:59, 389kB/s]
 32%|███▏      | 54.2M/170M [02:15&lt;04:55, 393kB/s]
 32%|███▏      | 54.3M/170M [02:15&lt;04:56, 392kB/s]
 32%|███▏      | 54.3M/170M [02:15&lt;05:05, 380kB/s]
 32%|███▏      | 54.4M/170M [02:15&lt;05:02, 384kB/s]
 32%|███▏      | 54.5M/170M [02:15&lt;04:58, 389kB/s]
 32%|███▏      | 54.5M/170M [02:15&lt;04:58, 389kB/s]
 32%|███▏      | 54.6M/170M [02:16&lt;05:01, 385kB/s]
 32%|███▏      | 54.7M/170M [02:16&lt;05:07, 377kB/s]
 32%|███▏      | 54.7M/170M [02:16&lt;05:05, 379kB/s]
 32%|███▏      | 54.8M/170M [02:16&lt;04:59, 386kB/s]
 32%|███▏      | 54.9M/170M [02:16&lt;04:57, 388kB/s]
 32%|███▏      | 54.9M/170M [02:17&lt;04:56, 390kB/s]
 32%|███▏      | 55.0M/170M [02:17&lt;05:10, 372kB/s]
 32%|███▏      | 55.1M/170M [02:17&lt;05:23, 357kB/s]
 32%|███▏      | 55.1M/170M [02:17&lt;04:57, 387kB/s]
 32%|███▏      | 55.2M/170M [02:17&lt;04:57, 387kB/s]
 32%|███▏      | 55.2M/170M [02:17&lt;05:03, 379kB/s]
 32%|███▏      | 55.3M/170M [02:18&lt;05:09, 372kB/s]
 32%|███▏      | 55.4M/170M [02:18&lt;05:00, 383kB/s]
 33%|███▎      | 55.4M/170M [02:18&lt;04:57, 387kB/s]
 33%|███▎      | 55.5M/170M [02:18&lt;04:53, 392kB/s]
 33%|███▎      | 55.6M/170M [02:18&lt;04:54, 391kB/s]
 33%|███▎      | 55.6M/170M [02:18&lt;05:04, 378kB/s]
 33%|███▎      | 55.7M/170M [02:19&lt;05:03, 379kB/s]
 33%|███▎      | 55.8M/170M [02:19&lt;04:58, 384kB/s]
 33%|███▎      | 55.8M/170M [02:19&lt;04:54, 389kB/s]
 33%|███▎      | 55.9M/170M [02:19&lt;04:51, 393kB/s]
 33%|███▎      | 56.0M/170M [02:19&lt;04:50, 394kB/s]
 33%|███▎      | 56.0M/170M [02:19&lt;04:59, 382kB/s]
 33%|███▎      | 56.1M/170M [02:20&lt;04:54, 388kB/s]
 33%|███▎      | 56.2M/170M [02:20&lt;04:57, 384kB/s]
 33%|███▎      | 56.2M/170M [02:20&lt;05:03, 377kB/s]
 33%|███▎      | 56.3M/170M [02:20&lt;04:49, 395kB/s]
 33%|███▎      | 56.4M/170M [02:20&lt;04:59, 381kB/s]
 33%|███▎      | 56.4M/170M [02:20&lt;05:07, 371kB/s]
 33%|███▎      | 56.5M/170M [02:21&lt;04:54, 387kB/s]
 33%|███▎      | 56.6M/170M [02:21&lt;05:07, 371kB/s]
 33%|███▎      | 56.6M/170M [02:21&lt;04:42, 404kB/s]
 33%|███▎      | 56.7M/170M [02:21&lt;04:52, 389kB/s]
 33%|███▎      | 56.8M/170M [02:21&lt;04:57, 382kB/s]
 33%|███▎      | 56.8M/170M [02:22&lt;05:04, 374kB/s]
 33%|███▎      | 56.9M/170M [02:22&lt;04:45, 398kB/s]
 33%|███▎      | 57.0M/170M [02:22&lt;04:44, 400kB/s]
 33%|███▎      | 57.0M/170M [02:22&lt;04:54, 385kB/s]
 33%|███▎      | 57.1M/170M [02:22&lt;04:54, 386kB/s]
 34%|███▎      | 57.1M/170M [02:22&lt;04:52, 388kB/s]
 34%|███▎      | 57.2M/170M [02:23&lt;04:55, 383kB/s]
 34%|███▎      | 57.3M/170M [02:23&lt;04:49, 391kB/s]
 34%|███▎      | 57.3M/170M [02:23&lt;05:01, 375kB/s]
 34%|███▎      | 57.4M/170M [02:23&lt;04:57, 380kB/s]
 34%|███▎      | 57.5M/170M [02:23&lt;05:00, 376kB/s]
 34%|███▎      | 57.5M/170M [02:23&lt;04:47, 393kB/s]
 34%|███▍      | 57.6M/170M [02:24&lt;04:53, 385kB/s]
 34%|███▍      | 57.7M/170M [02:24&lt;04:49, 390kB/s]
 34%|███▍      | 57.7M/170M [02:24&lt;05:00, 375kB/s]
 34%|███▍      | 57.8M/170M [02:24&lt;04:53, 384kB/s]
 34%|███▍      | 57.9M/170M [02:24&lt;04:53, 384kB/s]
 34%|███▍      | 57.9M/170M [02:24&lt;05:00, 374kB/s]
 34%|███▍      | 58.0M/170M [02:25&lt;04:46, 393kB/s]
 34%|███▍      | 58.1M/170M [02:25&lt;04:55, 380kB/s]
 34%|███▍      | 58.1M/170M [02:25&lt;04:53, 383kB/s]
 34%|███▍      | 58.2M/170M [02:25&lt;04:47, 391kB/s]
 34%|███▍      | 58.3M/170M [02:25&lt;04:47, 391kB/s]
 34%|███▍      | 58.3M/170M [02:25&lt;04:50, 385kB/s]
 34%|███▍      | 58.4M/170M [02:26&lt;04:54, 381kB/s]
 34%|███▍      | 58.5M/170M [02:26&lt;04:48, 389kB/s]
 34%|███▍      | 58.5M/170M [02:26&lt;04:46, 391kB/s]
 34%|███▍      | 58.6M/170M [02:26&lt;05:00, 372kB/s]
 34%|███▍      | 58.7M/170M [02:26&lt;04:38, 402kB/s]
 34%|███▍      | 58.7M/170M [02:26&lt;04:51, 383kB/s]
 34%|███▍      | 58.8M/170M [02:27&lt;04:47, 389kB/s]
 35%|███▍      | 58.9M/170M [02:27&lt;04:44, 392kB/s]
 35%|███▍      | 58.9M/170M [02:27&lt;04:44, 393kB/s]
 35%|███▍      | 59.0M/170M [02:27&lt;04:41, 396kB/s]
 35%|███▍      | 59.0M/170M [02:27&lt;04:52, 381kB/s]
 35%|███▍      | 59.1M/170M [02:27&lt;04:49, 384kB/s]
 35%|███▍      | 59.2M/170M [02:28&lt;04:45, 389kB/s]
 35%|███▍      | 59.2M/170M [02:28&lt;04:44, 391kB/s]
 35%|███▍      | 59.3M/170M [02:28&lt;04:48, 385kB/s]
 35%|███▍      | 59.4M/170M [02:28&lt;04:44, 391kB/s]
 35%|███▍      | 59.4M/170M [02:28&lt;04:56, 374kB/s]
 35%|███▍      | 59.5M/170M [02:28&lt;04:51, 381kB/s]
 35%|███▍      | 59.6M/170M [02:29&lt;04:46, 387kB/s]
 35%|███▍      | 59.6M/170M [02:29&lt;04:47, 385kB/s]
 35%|███▌      | 59.7M/170M [02:29&lt;04:42, 393kB/s]
 35%|███▌      | 59.8M/170M [02:29&lt;04:54, 376kB/s]
 35%|███▌      | 59.8M/170M [02:29&lt;04:48, 384kB/s]
 35%|███▌      | 59.9M/170M [02:29&lt;04:46, 387kB/s]
 35%|███▌      | 60.0M/170M [02:30&lt;04:44, 389kB/s]
 35%|███▌      | 60.0M/170M [02:30&lt;04:41, 393kB/s]
 35%|███▌      | 60.1M/170M [02:30&lt;04:51, 378kB/s]
 35%|███▌      | 60.2M/170M [02:30&lt;04:47, 384kB/s]
 35%|███▌      | 60.2M/170M [02:30&lt;04:44, 387kB/s]
 35%|███▌      | 60.3M/170M [02:30&lt;04:43, 389kB/s]
 35%|███▌      | 60.4M/170M [02:31&lt;04:39, 393kB/s]
 35%|███▌      | 60.4M/170M [02:31&lt;04:52, 376kB/s]
 35%|███▌      | 60.5M/170M [02:31&lt;05:03, 362kB/s]
 36%|███▌      | 60.6M/170M [02:31&lt;04:39, 394kB/s]
 36%|███▌      | 60.6M/170M [02:31&lt;04:39, 393kB/s]
 36%|███▌      | 60.7M/170M [02:32&lt;04:45, 385kB/s]
 36%|███▌      | 60.8M/170M [02:32&lt;04:35, 398kB/s]
 36%|███▌      | 60.8M/170M [02:32&lt;04:54, 373kB/s]
 36%|███▌      | 60.9M/170M [02:32&lt;04:49, 379kB/s]
 36%|███▌      | 60.9M/170M [02:32&lt;04:44, 385kB/s]
 36%|███▌      | 61.0M/170M [02:32&lt;04:42, 387kB/s]
 36%|███▌      | 61.1M/170M [02:33&lt;04:39, 391kB/s]
 36%|███▌      | 61.1M/170M [02:33&lt;04:49, 377kB/s]
 36%|███▌      | 61.2M/170M [02:33&lt;04:45, 383kB/s]
 36%|███▌      | 61.3M/170M [02:33&lt;04:44, 383kB/s]
 36%|███▌      | 61.3M/170M [02:33&lt;04:45, 383kB/s]
 36%|███▌      | 61.4M/170M [02:33&lt;04:43, 385kB/s]
 36%|███▌      | 61.5M/170M [02:34&lt;04:52, 372kB/s]
 36%|███▌      | 61.5M/170M [02:34&lt;04:45, 382kB/s]
 36%|███▌      | 61.6M/170M [02:34&lt;04:46, 380kB/s]
 36%|███▌      | 61.7M/170M [02:34&lt;04:42, 385kB/s]
 36%|███▌      | 61.7M/170M [02:34&lt;04:38, 390kB/s]
 36%|███▌      | 61.8M/170M [02:34&lt;04:49, 375kB/s]
 36%|███▋      | 61.9M/170M [02:35&lt;04:44, 382kB/s]
 36%|███▋      | 61.9M/170M [02:35&lt;04:42, 384kB/s]
 36%|███▋      | 62.0M/170M [02:35&lt;04:42, 384kB/s]
 36%|███▋      | 62.1M/170M [02:35&lt;04:38, 389kB/s]
 36%|███▋      | 62.1M/170M [02:35&lt;04:48, 376kB/s]
 36%|███▋      | 62.2M/170M [02:35&lt;04:43, 382kB/s]
 37%|███▋      | 62.3M/170M [02:36&lt;04:39, 387kB/s]
 37%|███▋      | 62.3M/170M [02:36&lt;04:37, 389kB/s]
 37%|███▋      | 62.4M/170M [02:36&lt;04:35, 392kB/s]
 37%|███▋      | 62.5M/170M [02:36&lt;04:33, 395kB/s]
 37%|███▋      | 62.5M/170M [02:36&lt;04:45, 379kB/s]
 37%|███▋      | 62.6M/170M [02:36&lt;04:41, 383kB/s]
 37%|███▋      | 62.7M/170M [02:37&lt;04:38, 388kB/s]
 37%|███▋      | 62.7M/170M [02:37&lt;04:36, 389kB/s]
 37%|███▋      | 62.8M/170M [02:37&lt;04:34, 393kB/s]
 37%|███▋      | 62.8M/170M [02:37&lt;04:45, 377kB/s]
 37%|███▋      | 62.9M/170M [02:37&lt;04:38, 387kB/s]
 37%|███▋      | 63.0M/170M [02:37&lt;04:35, 391kB/s]
 37%|███▋      | 63.0M/170M [02:38&lt;04:35, 390kB/s]
 37%|███▋      | 63.1M/170M [02:38&lt;04:45, 377kB/s]
 37%|███▋      | 63.2M/170M [02:38&lt;04:47, 373kB/s]
 37%|███▋      | 63.2M/170M [02:38&lt;04:34, 391kB/s]
 37%|███▋      | 63.3M/170M [02:38&lt;04:48, 371kB/s]
 37%|███▋      | 63.4M/170M [02:38&lt;04:27, 400kB/s]
 37%|███▋      | 63.4M/170M [02:39&lt;04:27, 400kB/s]
 37%|███▋      | 63.5M/170M [02:39&lt;04:41, 380kB/s]
 37%|███▋      | 63.6M/170M [02:39&lt;04:47, 372kB/s]
 37%|███▋      | 63.6M/170M [02:39&lt;04:32, 393kB/s]
 37%|███▋      | 63.7M/170M [02:39&lt;04:46, 373kB/s]
 37%|███▋      | 63.8M/170M [02:40&lt;04:25, 402kB/s]
 37%|███▋      | 63.8M/170M [02:40&lt;04:36, 386kB/s]
 37%|███▋      | 63.9M/170M [02:40&lt;04:49, 368kB/s]
 38%|███▊      | 64.0M/170M [02:40&lt;04:29, 396kB/s]
 38%|███▊      | 64.0M/170M [02:40&lt;04:27, 399kB/s]
 38%|███▊      | 64.1M/170M [02:40&lt;04:31, 392kB/s]
 38%|███▊      | 64.2M/170M [02:41&lt;04:38, 382kB/s]
 38%|███▊      | 64.2M/170M [02:41&lt;04:36, 384kB/s]
 38%|███▊      | 64.3M/170M [02:41&lt;04:36, 384kB/s]
 38%|███▊      | 64.4M/170M [02:41&lt;04:42, 375kB/s]
 38%|███▊      | 64.4M/170M [02:41&lt;04:27, 396kB/s]
 38%|███▊      | 64.5M/170M [02:41&lt;04:42, 375kB/s]
 38%|███▊      | 64.6M/170M [02:42&lt;04:29, 393kB/s]
 38%|███▊      | 64.6M/170M [02:42&lt;04:28, 395kB/s]
 38%|███▊      | 64.7M/170M [02:42&lt;04:46, 369kB/s]
 38%|███▊      | 64.7M/170M [02:42&lt;04:23, 402kB/s]
 38%|███▊      | 64.8M/170M [02:42&lt;04:22, 402kB/s]
 38%|███▊      | 64.9M/170M [02:42&lt;04:34, 385kB/s]
 38%|███▊      | 64.9M/170M [02:43&lt;04:43, 373kB/s]
 38%|███▊      | 65.0M/170M [02:43&lt;04:29, 392kB/s]
 38%|███▊      | 65.1M/170M [02:43&lt;04:35, 383kB/s]
 38%|███▊      | 65.1M/170M [02:43&lt;04:25, 397kB/s]
 38%|███▊      | 65.2M/170M [02:43&lt;04:33, 386kB/s]
 38%|███▊      | 65.3M/170M [02:43&lt;04:31, 388kB/s]
 38%|███▊      | 65.3M/170M [02:44&lt;04:33, 384kB/s]
 38%|███▊      | 65.4M/170M [02:44&lt;04:26, 394kB/s]
 38%|███▊      | 65.5M/170M [02:44&lt;04:30, 389kB/s]
 38%|███▊      | 65.5M/170M [02:44&lt;04:37, 378kB/s]
 38%|███▊      | 65.6M/170M [02:44&lt;04:30, 388kB/s]
 39%|███▊      | 65.7M/170M [02:44&lt;04:29, 390kB/s]
 39%|███▊      | 65.7M/170M [02:45&lt;04:27, 391kB/s]
 39%|███▊      | 65.8M/170M [02:45&lt;04:28, 390kB/s]
 39%|███▊      | 65.9M/170M [02:45&lt;04:28, 389kB/s]
 39%|███▊      | 65.9M/170M [02:45&lt;04:37, 376kB/s]
 39%|███▊      | 66.0M/170M [02:45&lt;04:34, 381kB/s]
 39%|███▊      | 66.1M/170M [02:45&lt;04:29, 387kB/s]
 39%|███▉      | 66.1M/170M [02:46&lt;04:30, 386kB/s]
 39%|███▉      | 66.2M/170M [02:46&lt;04:28, 389kB/s]
 39%|███▉      | 66.3M/170M [02:46&lt;04:35, 379kB/s]
 39%|███▉      | 66.3M/170M [02:46&lt;04:31, 383kB/s]
 39%|███▉      | 66.4M/170M [02:46&lt;04:29, 387kB/s]
 39%|███▉      | 66.5M/170M [02:46&lt;04:31, 383kB/s]
 39%|███▉      | 66.5M/170M [02:47&lt;04:21, 398kB/s]
 39%|███▉      | 66.6M/170M [02:47&lt;04:29, 385kB/s]
 39%|███▉      | 66.7M/170M [02:47&lt;04:25, 391kB/s]
 39%|███▉      | 66.7M/170M [02:47&lt;04:24, 392kB/s]
 39%|███▉      | 66.8M/170M [02:47&lt;04:21, 397kB/s]
 39%|███▉      | 66.8M/170M [02:47&lt;04:20, 397kB/s]
 39%|███▉      | 66.9M/170M [02:48&lt;04:30, 384kB/s]
 39%|███▉      | 67.0M/170M [02:48&lt;04:30, 382kB/s]
 39%|███▉      | 67.0M/170M [02:48&lt;04:25, 390kB/s]
 39%|███▉      | 67.1M/170M [02:48&lt;04:22, 395kB/s]
 39%|███▉      | 67.2M/170M [02:48&lt;04:22, 394kB/s]
 39%|███▉      | 67.2M/170M [02:48&lt;04:29, 383kB/s]
 39%|███▉      | 67.3M/170M [02:49&lt;04:26, 387kB/s]
 40%|███▉      | 67.4M/170M [02:49&lt;04:22, 393kB/s]
 40%|███▉      | 67.4M/170M [02:49&lt;04:20, 396kB/s]
 40%|███▉      | 67.5M/170M [02:49&lt;04:23, 390kB/s]
 40%|███▉      | 67.6M/170M [02:49&lt;04:20, 396kB/s]
 40%|███▉      | 67.6M/170M [02:50&lt;04:29, 382kB/s]
 40%|███▉      | 67.7M/170M [02:50&lt;04:25, 387kB/s]
 40%|███▉      | 67.8M/170M [02:50&lt;04:21, 393kB/s]
 40%|███▉      | 67.8M/170M [02:50&lt;04:21, 393kB/s]
 40%|███▉      | 67.9M/170M [02:50&lt;04:19, 395kB/s]
 40%|███▉      | 68.0M/170M [02:50&lt;04:26, 384kB/s]
 40%|███▉      | 68.0M/170M [02:51&lt;04:25, 386kB/s]
 40%|███▉      | 68.1M/170M [02:51&lt;04:23, 388kB/s]
 40%|███▉      | 68.2M/170M [02:51&lt;04:19, 394kB/s]
 40%|████      | 68.2M/170M [02:51&lt;04:22, 390kB/s]
 40%|████      | 68.3M/170M [02:51&lt;04:29, 379kB/s]
 40%|████      | 68.4M/170M [02:51&lt;04:23, 388kB/s]
 40%|████      | 68.4M/170M [02:52&lt;04:24, 386kB/s]
 40%|████      | 68.5M/170M [02:52&lt;04:18, 394kB/s]
 40%|████      | 68.6M/170M [02:52&lt;04:20, 392kB/s]
 40%|████      | 68.6M/170M [02:52&lt;04:31, 375kB/s]
 40%|████      | 68.7M/170M [02:52&lt;04:28, 380kB/s]
 40%|████      | 68.7M/170M [02:52&lt;04:27, 380kB/s]
 40%|████      | 68.8M/170M [02:53&lt;04:18, 394kB/s]
 40%|████      | 68.9M/170M [02:53&lt;04:19, 391kB/s]
 40%|████      | 68.9M/170M [02:53&lt;04:19, 392kB/s]
 40%|████      | 69.0M/170M [02:53&lt;04:29, 376kB/s]
 41%|████      | 69.1M/170M [02:53&lt;04:26, 380kB/s]
 41%|████      | 69.1M/170M [02:53&lt;04:23, 385kB/s]
 41%|████      | 69.2M/170M [02:54&lt;04:23, 384kB/s]
 41%|████      | 69.3M/170M [02:54&lt;04:21, 387kB/s]
 41%|████      | 69.3M/170M [02:54&lt;04:28, 377kB/s]
 41%|████      | 69.4M/170M [02:54&lt;04:24, 383kB/s]
 41%|████      | 69.5M/170M [02:54&lt;04:24, 382kB/s]
 41%|████      | 69.5M/170M [02:54&lt;04:21, 386kB/s]
 41%|████      | 69.6M/170M [02:55&lt;04:23, 383kB/s]
 41%|████      | 69.7M/170M [02:55&lt;04:34, 368kB/s]
 41%|████      | 69.7M/170M [02:55&lt;04:28, 375kB/s]
 41%|████      | 69.8M/170M [02:55&lt;04:28, 376kB/s]
 41%|████      | 69.9M/170M [02:55&lt;04:23, 381kB/s]
 41%|████      | 69.9M/170M [02:55&lt;04:24, 380kB/s]
 41%|████      | 70.0M/170M [02:56&lt;04:40, 358kB/s]
 41%|████      | 70.1M/170M [02:56&lt;04:26, 377kB/s]
 41%|████      | 70.1M/170M [02:56&lt;04:25, 377kB/s]
 41%|████      | 70.2M/170M [02:56&lt;04:23, 380kB/s]
 41%|████      | 70.3M/170M [02:56&lt;04:24, 379kB/s]
 41%|████      | 70.3M/170M [02:57&lt;04:30, 371kB/s]
 41%|████▏     | 70.4M/170M [02:57&lt;04:31, 369kB/s]
 41%|████▏     | 70.5M/170M [02:57&lt;04:26, 375kB/s]
 41%|████▏     | 70.5M/170M [02:57&lt;04:21, 382kB/s]
 41%|████▏     | 70.6M/170M [02:57&lt;04:22, 380kB/s]
 41%|████▏     | 70.6M/170M [02:57&lt;04:24, 378kB/s]
 41%|████▏     | 70.7M/170M [02:58&lt;04:30, 369kB/s]
 42%|████▏     | 70.8M/170M [02:58&lt;04:28, 372kB/s]
 42%|████▏     | 70.8M/170M [02:58&lt;04:24, 376kB/s]
 42%|████▏     | 70.9M/170M [02:58&lt;04:22, 380kB/s]
 42%|████▏     | 71.0M/170M [02:58&lt;04:20, 383kB/s]
 42%|████▏     | 71.0M/170M [02:58&lt;04:28, 370kB/s]
 42%|████▏     | 71.1M/170M [02:59&lt;04:25, 374kB/s]
 42%|████▏     | 71.2M/170M [02:59&lt;04:23, 377kB/s]
 42%|████▏     | 71.2M/170M [02:59&lt;04:23, 377kB/s]
 42%|████▏     | 71.3M/170M [02:59&lt;04:25, 373kB/s]
 42%|████▏     | 71.4M/170M [02:59&lt;04:32, 363kB/s]
 42%|████▏     | 71.4M/170M [03:00&lt;04:22, 377kB/s]
 42%|████▏     | 71.5M/170M [03:00&lt;04:29, 367kB/s]
 42%|████▏     | 71.6M/170M [03:00&lt;04:15, 387kB/s]
 42%|████▏     | 71.6M/170M [03:00&lt;04:17, 384kB/s]
 42%|████▏     | 71.7M/170M [03:00&lt;04:38, 355kB/s]
 42%|████▏     | 71.8M/170M [03:00&lt;04:17, 384kB/s]
 42%|████▏     | 71.8M/170M [03:01&lt;04:19, 381kB/s]
 42%|████▏     | 71.9M/170M [03:01&lt;04:28, 368kB/s]
 42%|████▏     | 72.0M/170M [03:01&lt;04:09, 395kB/s]
 42%|████▏     | 72.0M/170M [03:01&lt;04:21, 377kB/s]
 42%|████▏     | 72.1M/170M [03:01&lt;04:24, 372kB/s]
 42%|████▏     | 72.2M/170M [03:01&lt;04:14, 386kB/s]
 42%|████▏     | 72.2M/170M [03:02&lt;04:16, 382kB/s]
 42%|████▏     | 72.3M/170M [03:02&lt;04:16, 383kB/s]
 42%|████▏     | 72.4M/170M [03:02&lt;04:15, 384kB/s]
 42%|████▏     | 72.4M/170M [03:02&lt;04:27, 367kB/s]
 43%|████▎     | 72.5M/170M [03:02&lt;04:21, 375kB/s]
 43%|████▎     | 72.5M/170M [03:02&lt;04:18, 378kB/s]
 43%|████▎     | 72.6M/170M [03:03&lt;04:26, 367kB/s]
 43%|████▎     | 72.7M/170M [03:03&lt;04:14, 384kB/s]
 43%|████▎     | 72.7M/170M [03:03&lt;04:24, 370kB/s]
 43%|████▎     | 72.8M/170M [03:03&lt;04:27, 366kB/s]
 43%|████▎     | 72.9M/170M [03:03&lt;04:13, 385kB/s]
 43%|████▎     | 72.9M/170M [03:03&lt;04:13, 384kB/s]
 43%|████▎     | 73.0M/170M [03:04&lt;04:13, 385kB/s]
 43%|████▎     | 73.1M/170M [03:04&lt;04:23, 370kB/s]
 43%|████▎     | 73.1M/170M [03:04&lt;04:17, 377kB/s]
 43%|████▎     | 73.2M/170M [03:04&lt;04:17, 377kB/s]
 43%|████▎     | 73.3M/170M [03:04&lt;04:16, 379kB/s]
 43%|████▎     | 73.3M/170M [03:05&lt;04:13, 383kB/s]
 43%|████▎     | 73.4M/170M [03:05&lt;04:24, 367kB/s]
 43%|████▎     | 73.5M/170M [03:05&lt;04:26, 365kB/s]
 43%|████▎     | 73.5M/170M [03:05&lt;04:14, 381kB/s]
 43%|████▎     | 73.6M/170M [03:05&lt;04:15, 379kB/s]
 43%|████▎     | 73.7M/170M [03:05&lt;04:11, 385kB/s]
 43%|████▎     | 73.7M/170M [03:06&lt;04:22, 369kB/s]
 43%|████▎     | 73.8M/170M [03:06&lt;04:20, 371kB/s]
 43%|████▎     | 73.9M/170M [03:06&lt;04:15, 378kB/s]
 43%|████▎     | 73.9M/170M [03:06&lt;04:15, 378kB/s]
 43%|████▎     | 74.0M/170M [03:06&lt;04:15, 378kB/s]
 43%|████▎     | 74.1M/170M [03:06&lt;04:16, 376kB/s]
 43%|████▎     | 74.1M/170M [03:07&lt;04:23, 365kB/s]
 44%|████▎     | 74.2M/170M [03:07&lt;04:18, 372kB/s]
 44%|████▎     | 74.3M/170M [03:07&lt;04:16, 375kB/s]
 44%|████▎     | 74.3M/170M [03:07&lt;04:13, 379kB/s]
 44%|████▎     | 74.4M/170M [03:07&lt;04:11, 382kB/s]
 44%|████▎     | 74.4M/170M [03:08&lt;04:21, 368kB/s]
 44%|████▎     | 74.5M/170M [03:08&lt;04:16, 375kB/s]
 44%|████▎     | 74.6M/170M [03:08&lt;04:13, 379kB/s]
 44%|████▍     | 74.6M/170M [03:08&lt;04:15, 375kB/s]
 44%|████▍     | 74.7M/170M [03:08&lt;04:11, 381kB/s]
 44%|████▍     | 74.8M/170M [03:08&lt;04:22, 364kB/s]
 44%|████▍     | 74.8M/170M [03:09&lt;04:15, 374kB/s]
 44%|████▍     | 74.9M/170M [03:09&lt;04:14, 375kB/s]
 44%|████▍     | 75.0M/170M [03:09&lt;04:14, 376kB/s]
 44%|████▍     | 75.0M/170M [03:09&lt;04:29, 355kB/s]
 44%|████▍     | 75.1M/170M [03:09&lt;04:53, 325kB/s]
 44%|████▍     | 75.2M/170M [03:10&lt;04:37, 343kB/s]
 44%|████▍     | 75.2M/170M [03:10&lt;04:31, 351kB/s]
 44%|████▍     | 75.3M/170M [03:10&lt;04:16, 371kB/s]
 44%|████▍     | 75.4M/170M [03:10&lt;04:11, 378kB/s]
 44%|████▍     | 75.4M/170M [03:10&lt;04:25, 359kB/s]
 44%|████▍     | 75.5M/170M [03:10&lt;04:21, 364kB/s]
 44%|████▍     | 75.6M/170M [03:11&lt;04:14, 373kB/s]
 44%|████▍     | 75.6M/170M [03:11&lt;04:10, 378kB/s]
 44%|████▍     | 75.7M/170M [03:11&lt;04:10, 379kB/s]
 44%|████▍     | 75.8M/170M [03:11&lt;04:06, 384kB/s]
 44%|████▍     | 75.8M/170M [03:11&lt;04:15, 370kB/s]
 45%|████▍     | 75.9M/170M [03:11&lt;04:09, 379kB/s]
 45%|████▍     | 76.0M/170M [03:12&lt;04:09, 379kB/s]
 45%|████▍     | 76.0M/170M [03:12&lt;04:09, 379kB/s]
 45%|████▍     | 76.1M/170M [03:12&lt;04:05, 384kB/s]
 45%|████▍     | 76.2M/170M [03:12&lt;04:14, 370kB/s]
 45%|████▍     | 76.2M/170M [03:12&lt;04:12, 374kB/s]
 45%|████▍     | 76.3M/170M [03:12&lt;04:11, 374kB/s]
 45%|████▍     | 76.3M/170M [03:13&lt;04:10, 377kB/s]
 45%|████▍     | 76.4M/170M [03:13&lt;04:07, 381kB/s]
 45%|████▍     | 76.5M/170M [03:13&lt;04:15, 368kB/s]
 45%|████▍     | 76.5M/170M [03:13&lt;04:11, 374kB/s]
 45%|████▍     | 76.6M/170M [03:13&lt;04:08, 378kB/s]
 45%|████▍     | 76.7M/170M [03:14&lt;04:07, 378kB/s]
 45%|████▌     | 76.7M/170M [03:14&lt;04:05, 381kB/s]
 45%|████▌     | 76.8M/170M [03:14&lt;04:20, 359kB/s]
 45%|████▌     | 76.9M/170M [03:14&lt;04:07, 379kB/s]
 45%|████▌     | 76.9M/170M [03:14&lt;04:02, 386kB/s]
 45%|████▌     | 77.0M/170M [03:14&lt;04:01, 387kB/s]
 45%|████▌     | 77.1M/170M [03:15&lt;04:04, 381kB/s]
 45%|████▌     | 77.1M/170M [03:15&lt;04:02, 385kB/s]
 45%|████▌     | 77.2M/170M [03:15&lt;04:11, 371kB/s]
 45%|████▌     | 77.3M/170M [03:15&lt;04:11, 371kB/s]
 45%|████▌     | 77.3M/170M [03:15&lt;04:08, 375kB/s]
 45%|████▌     | 77.4M/170M [03:15&lt;04:08, 375kB/s]
 45%|████▌     | 77.5M/170M [03:16&lt;04:04, 380kB/s]
 45%|████▌     | 77.5M/170M [03:16&lt;04:13, 366kB/s]
 46%|████▌     | 77.6M/170M [03:16&lt;04:09, 372kB/s]
 46%|████▌     | 77.7M/170M [03:16&lt;04:04, 379kB/s]
 46%|████▌     | 77.7M/170M [03:16&lt;04:03, 381kB/s]
 46%|████▌     | 77.8M/170M [03:16&lt;04:02, 382kB/s]
 46%|████▌     | 77.9M/170M [03:17&lt;04:10, 370kB/s]
 46%|████▌     | 77.9M/170M [03:17&lt;04:03, 379kB/s]
 46%|████▌     | 78.0M/170M [03:17&lt;04:04, 379kB/s]
 46%|████▌     | 78.1M/170M [03:17&lt;04:05, 377kB/s]
 46%|████▌     | 78.1M/170M [03:17&lt;04:00, 384kB/s]
 46%|████▌     | 78.2M/170M [03:18&lt;04:11, 368kB/s]
 46%|████▌     | 78.2M/170M [03:18&lt;04:05, 375kB/s]
 46%|████▌     | 78.3M/170M [03:18&lt;04:04, 377kB/s]
 46%|████▌     | 78.4M/170M [03:18&lt;04:01, 382kB/s]
 46%|████▌     | 78.4M/170M [03:18&lt;04:01, 381kB/s]
 46%|████▌     | 78.5M/170M [03:18&lt;04:17, 358kB/s]
 46%|████▌     | 78.6M/170M [03:19&lt;04:04, 376kB/s]
 46%|████▌     | 78.6M/170M [03:19&lt;04:03, 376kB/s]
 46%|████▌     | 78.7M/170M [03:19&lt;04:00, 382kB/s]
 46%|████▌     | 78.8M/170M [03:19&lt;04:00, 381kB/s]
 46%|████▌     | 78.8M/170M [03:19&lt;03:56, 387kB/s]
 46%|████▋     | 78.9M/170M [03:19&lt;04:04, 375kB/s]
 46%|████▋     | 79.0M/170M [03:20&lt;04:03, 376kB/s]
 46%|████▋     | 79.0M/170M [03:20&lt;03:59, 381kB/s]
 46%|████▋     | 79.1M/170M [03:20&lt;03:57, 385kB/s]
 46%|████▋     | 79.2M/170M [03:20&lt;03:58, 383kB/s]
 46%|████▋     | 79.2M/170M [03:20&lt;04:03, 374kB/s]
 47%|████▋     | 79.3M/170M [03:20&lt;04:03, 374kB/s]
 47%|████▋     | 79.4M/170M [03:21&lt;04:02, 376kB/s]
 47%|████▋     | 79.4M/170M [03:21&lt;03:57, 383kB/s]
 47%|████▋     | 79.5M/170M [03:21&lt;03:55, 386kB/s]
 47%|████▋     | 79.6M/170M [03:21&lt;04:03, 374kB/s]
 47%|████▋     | 79.6M/170M [03:21&lt;04:01, 376kB/s]
 47%|████▋     | 79.7M/170M [03:22&lt;03:57, 382kB/s]
 47%|████▋     | 79.8M/170M [03:22&lt;04:05, 370kB/s]
 47%|████▋     | 79.8M/170M [03:22&lt;03:52, 390kB/s]
 47%|████▋     | 79.9M/170M [03:22&lt;04:01, 375kB/s]
 47%|████▋     | 80.0M/170M [03:22&lt;03:59, 378kB/s]
 47%|████▋     | 80.0M/170M [03:22&lt;03:56, 382kB/s]
 47%|████▋     | 80.1M/170M [03:23&lt;03:57, 380kB/s]
 47%|████▋     | 80.2M/170M [03:23&lt;03:57, 380kB/s]
 47%|████▋     | 80.2M/170M [03:23&lt;04:04, 370kB/s]
 47%|████▋     | 80.3M/170M [03:23&lt;04:05, 367kB/s]
 47%|████▋     | 80.3M/170M [03:23&lt;04:05, 368kB/s]
 47%|████▋     | 80.4M/170M [03:23&lt;03:50, 391kB/s]
 47%|████▋     | 80.5M/170M [03:24&lt;03:57, 379kB/s]
 47%|████▋     | 80.5M/170M [03:24&lt;03:49, 392kB/s]
 47%|████▋     | 80.6M/170M [03:24&lt;03:57, 379kB/s]
 47%|████▋     | 80.7M/170M [03:24&lt;04:01, 373kB/s]
 47%|████▋     | 80.7M/170M [03:24&lt;03:51, 387kB/s]
 47%|████▋     | 80.8M/170M [03:24&lt;03:54, 383kB/s]
 47%|████▋     | 80.9M/170M [03:25&lt;03:52, 385kB/s]
 47%|████▋     | 80.9M/170M [03:25&lt;03:59, 374kB/s]
 48%|████▊     | 81.0M/170M [03:25&lt;03:58, 375kB/s]
 48%|████▊     | 81.1M/170M [03:25&lt;03:57, 377kB/s]
 48%|████▊     | 81.1M/170M [03:25&lt;04:01, 369kB/s]
 48%|████▊     | 81.2M/170M [03:25&lt;03:49, 389kB/s]
 48%|████▊     | 81.3M/170M [03:26&lt;03:57, 375kB/s]
 48%|████▊     | 81.3M/170M [03:26&lt;03:57, 375kB/s]
 48%|████▊     | 81.4M/170M [03:26&lt;03:53, 382kB/s]
 48%|████▊     | 81.5M/170M [03:26&lt;03:49, 388kB/s]
 48%|████▊     | 81.5M/170M [03:26&lt;03:50, 387kB/s]
 48%|████▊     | 81.6M/170M [03:27&lt;03:59, 371kB/s]
 48%|████▊     | 81.7M/170M [03:27&lt;03:57, 373kB/s]
 48%|████▊     | 81.7M/170M [03:27&lt;03:54, 378kB/s]
 48%|████▊     | 81.8M/170M [03:27&lt;03:50, 384kB/s]
 48%|████▊     | 81.9M/170M [03:27&lt;03:50, 384kB/s]
 48%|████▊     | 81.9M/170M [03:27&lt;04:00, 368kB/s]
 48%|████▊     | 82.0M/170M [03:28&lt;03:55, 375kB/s]
 48%|████▊     | 82.1M/170M [03:28&lt;03:57, 372kB/s]
 48%|████▊     | 82.1M/170M [03:28&lt;03:52, 380kB/s]
 48%|████▊     | 82.2M/170M [03:28&lt;03:49, 385kB/s]
 48%|████▊     | 82.2M/170M [03:28&lt;03:50, 382kB/s]
 48%|████▊     | 82.3M/170M [03:28&lt;03:55, 374kB/s]
 48%|████▊     | 82.4M/170M [03:29&lt;03:55, 374kB/s]
 48%|████▊     | 82.4M/170M [03:29&lt;03:49, 383kB/s]
 48%|████▊     | 82.5M/170M [03:29&lt;03:49, 383kB/s]
 48%|████▊     | 82.6M/170M [03:29&lt;03:51, 380kB/s]
 48%|████▊     | 82.6M/170M [03:29&lt;03:55, 373kB/s]
 49%|████▊     | 82.7M/170M [03:29&lt;03:53, 376kB/s]
 49%|████▊     | 82.8M/170M [03:30&lt;03:50, 380kB/s]
 49%|████▊     | 82.8M/170M [03:30&lt;03:45, 388kB/s]
 49%|████▊     | 82.9M/170M [03:30&lt;03:45, 388kB/s]
 49%|████▊     | 83.0M/170M [03:30&lt;03:54, 374kB/s]
 49%|████▊     | 83.0M/170M [03:30&lt;03:49, 381kB/s]
 49%|████▊     | 83.1M/170M [03:30&lt;03:48, 383kB/s]
 49%|████▉     | 83.2M/170M [03:31&lt;03:45, 387kB/s]
 49%|████▉     | 83.2M/170M [03:31&lt;03:46, 386kB/s]
 49%|████▉     | 83.3M/170M [03:31&lt;03:52, 375kB/s]
 49%|████▉     | 83.4M/170M [03:31&lt;03:51, 377kB/s]
 49%|████▉     | 83.4M/170M [03:31&lt;03:52, 375kB/s]
 49%|████▉     | 83.5M/170M [03:32&lt;03:46, 383kB/s]
 49%|████▉     | 83.6M/170M [03:32&lt;03:47, 382kB/s]
 49%|████▉     | 83.6M/170M [03:32&lt;03:51, 376kB/s]
 49%|████▉     | 83.7M/170M [03:32&lt;03:48, 380kB/s]
 49%|████▉     | 83.8M/170M [03:32&lt;03:46, 383kB/s]
 49%|████▉     | 83.8M/170M [03:32&lt;03:43, 387kB/s]
 49%|████▉     | 83.9M/170M [03:33&lt;03:43, 388kB/s]
 49%|████▉     | 84.0M/170M [03:33&lt;03:43, 388kB/s]
 49%|████▉     | 84.0M/170M [03:33&lt;03:50, 375kB/s]
 49%|████▉     | 84.1M/170M [03:33&lt;03:47, 379kB/s]
 49%|████▉     | 84.1M/170M [03:33&lt;03:45, 383kB/s]
 49%|████▉     | 84.2M/170M [03:33&lt;03:43, 387kB/s]
 49%|████▉     | 84.3M/170M [03:34&lt;03:42, 387kB/s]
 49%|████▉     | 84.3M/170M [03:34&lt;03:52, 371kB/s]
 50%|████▉     | 84.4M/170M [03:34&lt;03:46, 379kB/s]
 50%|████▉     | 84.5M/170M [03:34&lt;03:45, 381kB/s]
 50%|████▉     | 84.5M/170M [03:34&lt;03:44, 384kB/s]
 50%|████▉     | 84.6M/170M [03:34&lt;03:42, 386kB/s]
 50%|████▉     | 84.7M/170M [03:35&lt;03:47, 377kB/s]
 50%|████▉     | 84.7M/170M [03:35&lt;03:46, 379kB/s]
 50%|████▉     | 84.8M/170M [03:35&lt;03:43, 383kB/s]
 50%|████▉     | 84.9M/170M [03:35&lt;03:41, 387kB/s]
 50%|████▉     | 84.9M/170M [03:35&lt;03:41, 386kB/s]
 50%|████▉     | 85.0M/170M [03:35&lt;03:47, 376kB/s]
 50%|████▉     | 85.1M/170M [03:36&lt;03:46, 377kB/s]
 50%|████▉     | 85.1M/170M [03:36&lt;03:46, 376kB/s]
 50%|████▉     | 85.2M/170M [03:36&lt;03:38, 390kB/s]
 50%|█████     | 85.3M/170M [03:36&lt;03:40, 387kB/s]
 50%|█████     | 85.3M/170M [03:36&lt;03:39, 388kB/s]
 50%|█████     | 85.4M/170M [03:37&lt;03:45, 377kB/s]
 50%|█████     | 85.5M/170M [03:37&lt;03:42, 382kB/s]
 50%|█████     | 85.5M/170M [03:37&lt;03:39, 386kB/s]
 50%|█████     | 85.6M/170M [03:37&lt;03:39, 388kB/s]
 50%|█████     | 85.7M/170M [03:37&lt;03:37, 391kB/s]
 50%|█████     | 85.7M/170M [03:37&lt;03:44, 378kB/s]
 50%|█████     | 85.8M/170M [03:38&lt;03:42, 381kB/s]
 50%|█████     | 85.9M/170M [03:38&lt;03:39, 385kB/s]
 50%|█████     | 85.9M/170M [03:38&lt;03:37, 389kB/s]
 50%|█████     | 86.0M/170M [03:38&lt;03:36, 390kB/s]
 50%|█████     | 86.0M/170M [03:38&lt;03:43, 378kB/s]
 51%|█████     | 86.1M/170M [03:38&lt;03:40, 382kB/s]
 51%|█████     | 86.2M/170M [03:39&lt;03:44, 375kB/s]
 51%|█████     | 86.2M/170M [03:39&lt;03:35, 391kB/s]
 51%|█████     | 86.3M/170M [03:39&lt;03:36, 389kB/s]
 51%|█████     | 86.4M/170M [03:39&lt;03:43, 377kB/s]
 51%|█████     | 86.4M/170M [03:39&lt;03:40, 382kB/s]
 51%|█████     | 86.5M/170M [03:39&lt;03:39, 383kB/s]
 51%|█████     | 86.6M/170M [03:40&lt;03:37, 385kB/s]
 51%|█████     | 86.6M/170M [03:40&lt;03:35, 390kB/s]
 51%|█████     | 86.7M/170M [03:40&lt;03:57, 353kB/s]
 51%|█████     | 86.8M/170M [03:40&lt;03:39, 382kB/s]
 51%|█████     | 86.8M/170M [03:40&lt;03:36, 386kB/s]
 51%|█████     | 86.9M/170M [03:40&lt;03:37, 384kB/s]
 51%|█████     | 87.0M/170M [03:41&lt;03:44, 372kB/s]
 51%|█████     | 87.0M/170M [03:41&lt;03:29, 399kB/s]
 51%|█████     | 87.1M/170M [03:41&lt;03:39, 380kB/s]
 51%|█████     | 87.2M/170M [03:41&lt;03:37, 383kB/s]
 51%|█████     | 87.2M/170M [03:41&lt;03:38, 381kB/s]
 51%|█████     | 87.3M/170M [03:41&lt;03:37, 383kB/s]
 51%|█████     | 87.4M/170M [03:42&lt;03:36, 385kB/s]
 51%|█████▏    | 87.4M/170M [03:42&lt;03:41, 375kB/s]
 51%|█████▏    | 87.5M/170M [03:42&lt;03:38, 379kB/s]
 51%|█████▏    | 87.6M/170M [03:42&lt;03:42, 373kB/s]
 51%|█████▏    | 87.6M/170M [03:42&lt;03:44, 370kB/s]
 51%|█████▏    | 87.7M/170M [03:43&lt;03:32, 389kB/s]
 51%|█████▏    | 87.8M/170M [03:43&lt;03:42, 371kB/s]
 52%|█████▏    | 87.8M/170M [03:43&lt;03:39, 376kB/s]
 52%|█████▏    | 87.9M/170M [03:43&lt;03:37, 380kB/s]
 52%|█████▏    | 87.9M/170M [03:43&lt;03:36, 381kB/s]
 52%|█████▏    | 88.0M/170M [03:43&lt;03:34, 384kB/s]
 52%|█████▏    | 88.1M/170M [03:44&lt;03:42, 371kB/s]
 52%|█████▏    | 88.1M/170M [03:44&lt;03:53, 352kB/s]
 52%|█████▏    | 88.2M/170M [03:44&lt;03:35, 382kB/s]
 52%|█████▏    | 88.3M/170M [03:44&lt;03:33, 385kB/s]
 52%|█████▏    | 88.3M/170M [03:44&lt;03:39, 374kB/s]
 52%|█████▏    | 88.4M/170M [03:44&lt;03:38, 377kB/s]
 52%|█████▏    | 88.5M/170M [03:45&lt;03:37, 378kB/s]
 52%|█████▏    | 88.5M/170M [03:45&lt;03:34, 382kB/s]
 52%|█████▏    | 88.6M/170M [03:45&lt;03:33, 384kB/s]
 52%|█████▏    | 88.7M/170M [03:45&lt;03:34, 381kB/s]
 52%|█████▏    | 88.7M/170M [03:45&lt;03:39, 372kB/s]
 52%|█████▏    | 88.8M/170M [03:45&lt;03:37, 376kB/s]
 52%|█████▏    | 88.9M/170M [03:46&lt;03:33, 382kB/s]
 52%|█████▏    | 88.9M/170M [03:46&lt;03:35, 378kB/s]
 52%|█████▏    | 89.0M/170M [03:46&lt;03:34, 380kB/s]
 52%|█████▏    | 89.1M/170M [03:46&lt;03:31, 386kB/s]
 52%|█████▏    | 89.1M/170M [03:46&lt;03:41, 367kB/s]
 52%|█████▏    | 89.2M/170M [03:47&lt;03:36, 376kB/s]
 52%|█████▏    | 89.3M/170M [03:47&lt;03:35, 377kB/s]
 52%|█████▏    | 89.3M/170M [03:47&lt;03:35, 377kB/s]
 52%|█████▏    | 89.4M/170M [03:47&lt;03:37, 372kB/s]
 52%|█████▏    | 89.5M/170M [03:47&lt;03:40, 367kB/s]
 53%|█████▎    | 89.5M/170M [03:47&lt;03:31, 382kB/s]
 53%|█████▎    | 89.6M/170M [03:48&lt;03:32, 380kB/s]
 53%|█████▎    | 89.7M/170M [03:48&lt;03:31, 383kB/s]
 53%|█████▎    | 89.7M/170M [03:48&lt;03:27, 389kB/s]
 53%|█████▎    | 89.8M/170M [03:48&lt;03:37, 371kB/s]
 53%|█████▎    | 89.8M/170M [03:48&lt;03:34, 375kB/s]
 53%|█████▎    | 89.9M/170M [03:48&lt;03:31, 381kB/s]
 53%|█████▎    | 90.0M/170M [03:49&lt;03:31, 380kB/s]
 53%|█████▎    | 90.0M/170M [03:49&lt;03:30, 382kB/s]
 53%|█████▎    | 90.1M/170M [03:49&lt;03:45, 356kB/s]
 53%|█████▎    | 90.2M/170M [03:49&lt;03:33, 376kB/s]
 53%|█████▎    | 90.2M/170M [03:49&lt;03:31, 380kB/s]
 53%|█████▎    | 90.3M/170M [03:49&lt;03:29, 382kB/s]
 53%|█████▎    | 90.4M/170M [03:50&lt;03:29, 383kB/s]
 53%|█████▎    | 90.4M/170M [03:50&lt;03:27, 386kB/s]
 53%|█████▎    | 90.5M/170M [03:50&lt;03:34, 372kB/s]
 53%|█████▎    | 90.6M/170M [03:50&lt;03:29, 381kB/s]
 53%|█████▎    | 90.6M/170M [03:50&lt;03:29, 381kB/s]
 53%|█████▎    | 90.7M/170M [03:51&lt;03:31, 378kB/s]
 53%|█████▎    | 90.8M/170M [03:51&lt;03:27, 385kB/s]
 53%|█████▎    | 90.8M/170M [03:51&lt;03:36, 368kB/s]
 53%|█████▎    | 90.9M/170M [03:51&lt;03:32, 375kB/s]
 53%|█████▎    | 91.0M/170M [03:51&lt;03:31, 376kB/s]
 53%|█████▎    | 91.0M/170M [03:51&lt;03:29, 380kB/s]
 53%|█████▎    | 91.1M/170M [03:52&lt;03:26, 384kB/s]
 53%|█████▎    | 91.2M/170M [03:52&lt;03:32, 373kB/s]
 54%|█████▎    | 91.2M/170M [03:52&lt;03:29, 378kB/s]
 54%|█████▎    | 91.3M/170M [03:52&lt;03:28, 380kB/s]
 54%|█████▎    | 91.4M/170M [03:52&lt;03:28, 379kB/s]
 54%|█████▎    | 91.4M/170M [03:52&lt;03:26, 383kB/s]
 54%|█████▎    | 91.5M/170M [03:53&lt;03:34, 369kB/s]
 54%|█████▎    | 91.6M/170M [03:53&lt;03:31, 373kB/s]
 54%|█████▎    | 91.6M/170M [03:53&lt;03:29, 377kB/s]
 54%|█████▍    | 91.7M/170M [03:53&lt;03:28, 379kB/s]
 54%|█████▍    | 91.8M/170M [03:53&lt;03:27, 379kB/s]
 54%|█████▍    | 91.8M/170M [03:53&lt;03:33, 369kB/s]
 54%|█████▍    | 91.9M/170M [03:54&lt;03:30, 373kB/s]
 54%|█████▍    | 91.9M/170M [03:54&lt;03:32, 369kB/s]
 54%|█████▍    | 92.0M/170M [03:54&lt;03:24, 383kB/s]
 54%|█████▍    | 92.1M/170M [03:54&lt;03:23, 385kB/s]
 54%|█████▍    | 92.1M/170M [03:54&lt;03:23, 385kB/s]
 54%|█████▍    | 92.2M/170M [03:55&lt;03:31, 370kB/s]
 54%|█████▍    | 92.3M/170M [03:55&lt;03:28, 376kB/s]
 54%|█████▍    | 92.3M/170M [03:55&lt;03:25, 381kB/s]
 54%|█████▍    | 92.4M/170M [03:55&lt;03:24, 381kB/s]
 54%|█████▍    | 92.5M/170M [03:55&lt;03:24, 382kB/s]
 54%|█████▍    | 92.5M/170M [03:55&lt;03:31, 369kB/s]
 54%|█████▍    | 92.6M/170M [03:56&lt;03:27, 376kB/s]
 54%|█████▍    | 92.7M/170M [03:56&lt;03:26, 376kB/s]
 54%|█████▍    | 92.7M/170M [03:56&lt;03:26, 377kB/s]
 54%|█████▍    | 92.8M/170M [03:56&lt;03:26, 376kB/s]
 54%|█████▍    | 92.9M/170M [03:56&lt;03:29, 370kB/s]
 55%|█████▍    | 92.9M/170M [03:56&lt;03:25, 378kB/s]
 55%|█████▍    | 93.0M/170M [03:57&lt;03:26, 375kB/s]
 55%|█████▍    | 93.1M/170M [03:57&lt;03:23, 380kB/s]
 55%|█████▍    | 93.1M/170M [03:57&lt;03:19, 387kB/s]
 55%|█████▍    | 93.2M/170M [03:57&lt;03:29, 369kB/s]
 55%|█████▍    | 93.3M/170M [03:57&lt;03:26, 374kB/s]
 55%|█████▍    | 93.3M/170M [03:57&lt;03:31, 366kB/s]
 55%|█████▍    | 93.4M/170M [03:58&lt;03:21, 382kB/s]
 55%|█████▍    | 93.5M/170M [03:58&lt;03:22, 380kB/s]
 55%|█████▍    | 93.5M/170M [03:58&lt;03:21, 383kB/s]
 55%|█████▍    | 93.6M/170M [03:58&lt;03:29, 367kB/s]
 55%|█████▍    | 93.7M/170M [03:58&lt;03:26, 371kB/s]
 55%|█████▍    | 93.7M/170M [03:59&lt;03:23, 377kB/s]
 55%|█████▌    | 93.8M/170M [03:59&lt;03:30, 365kB/s]
 55%|█████▌    | 93.8M/170M [03:59&lt;03:18, 385kB/s]
 55%|█████▌    | 93.9M/170M [03:59&lt;03:29, 365kB/s]
 55%|█████▌    | 94.0M/170M [03:59&lt;03:25, 371kB/s]
 55%|█████▌    | 94.0M/170M [03:59&lt;03:23, 376kB/s]
 55%|█████▌    | 94.1M/170M [04:00&lt;03:22, 377kB/s]
 55%|█████▌    | 94.2M/170M [04:00&lt;03:21, 378kB/s]
 55%|█████▌    | 94.2M/170M [04:00&lt;03:31, 361kB/s]
 55%|█████▌    | 94.3M/170M [04:00&lt;03:25, 371kB/s]
 55%|█████▌    | 94.4M/170M [04:00&lt;03:25, 371kB/s]
 55%|█████▌    | 94.4M/170M [04:00&lt;03:22, 376kB/s]
 55%|█████▌    | 94.5M/170M [04:01&lt;03:21, 377kB/s]
 55%|█████▌    | 94.6M/170M [04:01&lt;03:28, 365kB/s]
 56%|█████▌    | 94.6M/170M [04:01&lt;03:26, 367kB/s]
 56%|█████▌    | 94.7M/170M [04:01&lt;03:23, 373kB/s]
 56%|█████▌    | 94.8M/170M [04:01&lt;03:33, 355kB/s]
 56%|█████▌    | 94.8M/170M [04:02&lt;03:16, 385kB/s]
 56%|█████▌    | 94.9M/170M [04:02&lt;03:26, 366kB/s]
 56%|█████▌    | 95.0M/170M [04:02&lt;03:28, 363kB/s]
 56%|█████▌    | 95.0M/170M [04:02&lt;03:28, 362kB/s]
 56%|█████▌    | 95.1M/170M [04:02&lt;03:16, 383kB/s]
 56%|█████▌    | 95.2M/170M [04:02&lt;03:27, 363kB/s]
 56%|█████▌    | 95.2M/170M [04:03&lt;03:13, 388kB/s]
 56%|█████▌    | 95.3M/170M [04:03&lt;03:22, 372kB/s]
 56%|█████▌    | 95.4M/170M [04:03&lt;03:21, 373kB/s]
 56%|█████▌    | 95.4M/170M [04:03&lt;03:19, 376kB/s]
 56%|█████▌    | 95.5M/170M [04:03&lt;03:19, 375kB/s]
 56%|█████▌    | 95.6M/170M [04:03&lt;03:18, 377kB/s]
 56%|█████▌    | 95.6M/170M [04:04&lt;03:25, 365kB/s]
 56%|█████▌    | 95.7M/170M [04:04&lt;03:32, 352kB/s]
 56%|█████▌    | 95.7M/170M [04:04&lt;03:18, 377kB/s]
 56%|█████▌    | 95.8M/170M [04:04&lt;03:17, 378kB/s]
 56%|█████▌    | 95.9M/170M [04:04&lt;03:18, 376kB/s]
 56%|█████▋    | 95.9M/170M [04:05&lt;03:20, 371kB/s]
 56%|█████▋    | 96.0M/170M [04:05&lt;03:19, 373kB/s]
 56%|█████▋    | 96.1M/170M [04:05&lt;03:18, 374kB/s]
 56%|█████▋    | 96.1M/170M [04:05&lt;03:18, 375kB/s]
 56%|█████▋    | 96.2M/170M [04:05&lt;03:17, 376kB/s]
 56%|█████▋    | 96.3M/170M [04:05&lt;03:23, 365kB/s]
 57%|█████▋    | 96.3M/170M [04:06&lt;03:21, 367kB/s]
 57%|█████▋    | 96.4M/170M [04:06&lt;03:26, 358kB/s]
 57%|█████▋    | 96.5M/170M [04:06&lt;03:15, 379kB/s]
 57%|█████▋    | 96.5M/170M [04:06&lt;03:15, 379kB/s]
 57%|█████▋    | 96.6M/170M [04:06&lt;03:21, 366kB/s]
 57%|█████▋    | 96.7M/170M [04:06&lt;03:19, 370kB/s]
 57%|█████▋    | 96.7M/170M [04:07&lt;03:18, 371kB/s]
 57%|█████▋    | 96.8M/170M [04:07&lt;03:14, 378kB/s]
 57%|█████▋    | 96.9M/170M [04:07&lt;03:17, 373kB/s]
 57%|█████▋    | 96.9M/170M [04:07&lt;03:13, 379kB/s]
 57%|█████▋    | 97.0M/170M [04:07&lt;03:19, 368kB/s]
 57%|█████▋    | 97.1M/170M [04:08&lt;03:19, 369kB/s]
 57%|█████▋    | 97.1M/170M [04:08&lt;03:16, 374kB/s]
 57%|█████▋    | 97.2M/170M [04:08&lt;03:16, 373kB/s]
 57%|█████▋    | 97.3M/170M [04:08&lt;03:15, 375kB/s]
 57%|█████▋    | 97.3M/170M [04:08&lt;03:20, 365kB/s]
 57%|█████▋    | 97.4M/170M [04:08&lt;03:19, 366kB/s]
 57%|█████▋    | 97.5M/170M [04:09&lt;03:18, 368kB/s]
 57%|█████▋    | 97.5M/170M [04:09&lt;03:14, 375kB/s]
 57%|█████▋    | 97.6M/170M [04:09&lt;03:15, 373kB/s]
 57%|█████▋    | 97.6M/170M [04:09&lt;03:37, 335kB/s]
 57%|█████▋    | 97.7M/170M [04:09&lt;03:30, 346kB/s]
 57%|█████▋    | 97.8M/170M [04:10&lt;03:25, 354kB/s]
 57%|█████▋    | 97.8M/170M [04:10&lt;03:28, 349kB/s]
 57%|█████▋    | 97.9M/170M [04:10&lt;03:19, 363kB/s]
 57%|█████▋    | 98.0M/170M [04:10&lt;03:15, 371kB/s]
 58%|█████▊    | 98.0M/170M [04:10&lt;03:15, 371kB/s]
 58%|█████▊    | 98.1M/170M [04:10&lt;03:13, 373kB/s]
 58%|█████▊    | 98.2M/170M [04:11&lt;03:16, 368kB/s]
 58%|█████▊    | 98.2M/170M [04:11&lt;03:09, 382kB/s]
 58%|█████▊    | 98.3M/170M [04:11&lt;03:14, 370kB/s]
 58%|█████▊    | 98.4M/170M [04:11&lt;03:14, 370kB/s]
 58%|█████▊    | 98.4M/170M [04:11&lt;03:11, 376kB/s]
 58%|█████▊    | 98.5M/170M [04:11&lt;03:08, 382kB/s]
 58%|█████▊    | 98.6M/170M [04:12&lt;03:09, 379kB/s]
 58%|█████▊    | 98.6M/170M [04:12&lt;03:09, 379kB/s]
 58%|█████▊    | 98.7M/170M [04:12&lt;03:15, 368kB/s]
 58%|█████▊    | 98.8M/170M [04:12&lt;03:14, 369kB/s]
 58%|█████▊    | 98.8M/170M [04:12&lt;03:11, 375kB/s]
 58%|█████▊    | 98.9M/170M [04:13&lt;03:21, 356kB/s]
 58%|█████▊    | 99.0M/170M [04:13&lt;03:05, 385kB/s]
 58%|█████▊    | 99.0M/170M [04:13&lt;03:12, 371kB/s]
 58%|█████▊    | 99.1M/170M [04:13&lt;03:11, 372kB/s]
 58%|█████▊    | 99.2M/170M [04:13&lt;03:10, 375kB/s]
 58%|█████▊    | 99.2M/170M [04:13&lt;03:08, 379kB/s]
 58%|█████▊    | 99.3M/170M [04:14&lt;03:08, 377kB/s]
 58%|█████▊    | 99.4M/170M [04:14&lt;03:19, 357kB/s]
 58%|█████▊    | 99.4M/170M [04:14&lt;03:18, 358kB/s]
 58%|█████▊    | 99.5M/170M [04:14&lt;03:07, 380kB/s]
 58%|█████▊    | 99.5M/170M [04:14&lt;03:06, 381kB/s]
 58%|█████▊    | 99.6M/170M [04:14&lt;03:06, 380kB/s]
 58%|█████▊    | 99.7M/170M [04:15&lt;03:11, 369kB/s]
 59%|█████▊    | 99.7M/170M [04:15&lt;03:12, 367kB/s]
 59%|█████▊    | 99.8M/170M [04:15&lt;03:10, 371kB/s]
 59%|█████▊    | 99.9M/170M [04:15&lt;03:06, 379kB/s]
 59%|█████▊    | 99.9M/170M [04:15&lt;03:07, 377kB/s]
 59%|█████▊    | 100M/170M [04:15&lt;03:11, 367kB/s]
 59%|█████▊    | 100M/170M [04:16&lt;03:19, 352kB/s]
 59%|█████▊    | 100M/170M [04:16&lt;03:03, 382kB/s]
 59%|█████▉    | 100M/170M [04:16&lt;03:05, 379kB/s]
 59%|█████▉    | 100M/170M [04:16&lt;03:05, 379kB/s]
 59%|█████▉    | 100M/170M [04:16&lt;03:04, 380kB/s]
 59%|█████▉    | 100M/170M [04:17&lt;03:09, 370kB/s]
 59%|█████▉    | 100M/170M [04:17&lt;03:06, 375kB/s]
 59%|█████▉    | 101M/170M [04:17&lt;03:07, 373kB/s]
 59%|█████▉    | 101M/170M [04:17&lt;03:03, 380kB/s]
 59%|█████▉    | 101M/170M [04:17&lt;03:02, 383kB/s]
 59%|█████▉    | 101M/170M [04:17&lt;03:11, 364kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:09, 369kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:06, 373kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:04, 378kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:10, 365kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:10, 365kB/s]
 59%|█████▉    | 101M/170M [04:18&lt;03:06, 372kB/s]
 59%|█████▉    | 101M/170M [04:19&lt;03:04, 375kB/s]
 59%|█████▉    | 101M/170M [04:19&lt;03:02, 378kB/s]
 59%|█████▉    | 101M/170M [04:19&lt;03:02, 379kB/s]
 59%|█████▉    | 101M/170M [04:19&lt;03:09, 365kB/s]
 60%|█████▉    | 101M/170M [04:19&lt;03:05, 372kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:04, 374kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:01, 380kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:02, 378kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:10, 362kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:09, 363kB/s]
 60%|█████▉    | 102M/170M [04:20&lt;03:02, 376kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:00, 379kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:00, 380kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:00, 380kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:06, 366kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:03, 373kB/s]
 60%|█████▉    | 102M/170M [04:21&lt;03:04, 370kB/s]
 60%|██████    | 102M/170M [04:22&lt;02:58, 382kB/s]
 60%|██████    | 102M/170M [04:22&lt;02:58, 382kB/s]
 60%|██████    | 102M/170M [04:22&lt;03:04, 369kB/s]
 60%|██████    | 102M/170M [04:22&lt;03:02, 372kB/s]
 60%|██████    | 103M/170M [04:22&lt;03:00, 375kB/s]
 60%|██████    | 103M/170M [04:22&lt;02:58, 379kB/s]
 60%|██████    | 103M/170M [04:23&lt;03:07, 363kB/s]
 60%|██████    | 103M/170M [04:23&lt;03:08, 359kB/s]
 60%|██████    | 103M/170M [04:23&lt;02:59, 378kB/s]
 60%|██████    | 103M/170M [04:23&lt;03:05, 364kB/s]
 60%|██████    | 103M/170M [04:23&lt;02:55, 384kB/s]
 60%|██████    | 103M/170M [04:24&lt;02:55, 385kB/s]
 60%|██████    | 103M/170M [04:24&lt;03:02, 368kB/s]
 61%|██████    | 103M/170M [04:24&lt;03:05, 364kB/s]
 61%|██████    | 103M/170M [04:24&lt;02:55, 383kB/s]
 61%|██████    | 103M/170M [04:24&lt;02:56, 381kB/s]
 61%|██████    | 103M/170M [04:24&lt;02:57, 379kB/s]
 61%|██████    | 103M/170M [04:25&lt;02:57, 378kB/s]
 61%|██████    | 103M/170M [04:25&lt;03:03, 364kB/s]
 61%|██████    | 104M/170M [04:25&lt;02:59, 373kB/s]
 61%|██████    | 104M/170M [04:25&lt;03:04, 362kB/s]
 61%|██████    | 104M/170M [04:25&lt;02:56, 378kB/s]
 61%|██████    | 104M/170M [04:25&lt;02:55, 381kB/s]
 61%|██████    | 104M/170M [04:26&lt;03:02, 365kB/s]
 61%|██████    | 104M/170M [04:26&lt;02:58, 374kB/s]
 61%|██████    | 104M/170M [04:26&lt;02:57, 374kB/s]
 61%|██████    | 104M/170M [04:26&lt;02:56, 376kB/s]
 61%|██████    | 104M/170M [04:26&lt;03:02, 364kB/s]
 61%|██████    | 104M/170M [04:27&lt;02:58, 371kB/s]
 61%|██████    | 104M/170M [04:27&lt;02:54, 379kB/s]
 61%|██████    | 104M/170M [04:27&lt;02:55, 377kB/s]
 61%|██████    | 104M/170M [04:27&lt;02:55, 378kB/s]
 61%|██████    | 104M/170M [04:27&lt;02:53, 382kB/s]
 61%|██████▏   | 104M/170M [04:27&lt;03:01, 365kB/s]
 61%|██████▏   | 105M/170M [04:28&lt;02:58, 369kB/s]
 61%|██████▏   | 105M/170M [04:28&lt;02:55, 376kB/s]
 61%|██████▏   | 105M/170M [04:28&lt;02:57, 371kB/s]
 61%|██████▏   | 105M/170M [04:28&lt;03:04, 357kB/s]
 61%|██████▏   | 105M/170M [04:28&lt;03:03, 359kB/s]
 62%|██████▏   | 105M/170M [04:28&lt;02:55, 375kB/s]
 62%|██████▏   | 105M/170M [04:29&lt;02:52, 379kB/s]
 62%|██████▏   | 105M/170M [04:29&lt;02:51, 381kB/s]
 62%|██████▏   | 105M/170M [04:29&lt;02:52, 380kB/s]
 62%|██████▏   | 105M/170M [04:29&lt;02:51, 382kB/s]
 62%|██████▏   | 105M/170M [04:29&lt;02:57, 368kB/s]
 62%|██████▏   | 105M/170M [04:30&lt;02:53, 375kB/s]
 62%|██████▏   | 105M/170M [04:30&lt;02:53, 375kB/s]
 62%|██████▏   | 105M/170M [04:30&lt;02:55, 371kB/s]
 62%|██████▏   | 105M/170M [04:30&lt;02:51, 379kB/s]
 62%|██████▏   | 106M/170M [04:30&lt;02:58, 365kB/s]
 62%|██████▏   | 106M/170M [04:30&lt;02:54, 372kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:52, 376kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:51, 377kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:50, 380kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:55, 368kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:51, 377kB/s]
 62%|██████▏   | 106M/170M [04:31&lt;02:52, 374kB/s]
 62%|██████▏   | 106M/170M [04:32&lt;02:50, 378kB/s]
 62%|██████▏   | 106M/170M [04:32&lt;02:47, 384kB/s]
 62%|██████▏   | 106M/170M [04:32&lt;02:54, 369kB/s]
 62%|██████▏   | 106M/170M [04:32&lt;02:54, 369kB/s]
 62%|██████▏   | 106M/170M [04:32&lt;02:50, 377kB/s]
 62%|██████▏   | 106M/170M [04:33&lt;02:50, 376kB/s]
 62%|██████▏   | 106M/170M [04:33&lt;02:54, 367kB/s]
 62%|██████▏   | 106M/170M [04:33&lt;03:02, 350kB/s]
 63%|██████▎   | 107M/170M [04:33&lt;02:53, 369kB/s]
 63%|██████▎   | 107M/170M [04:33&lt;02:49, 377kB/s]
 63%|██████▎   | 107M/170M [04:33&lt;02:47, 381kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:49, 377kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:46, 382kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:51, 370kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:49, 375kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:48, 377kB/s]
 63%|██████▎   | 107M/170M [04:34&lt;02:48, 377kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;02:46, 380kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;03:00, 350kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;02:45, 382kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;02:45, 382kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;02:44, 383kB/s]
 63%|██████▎   | 107M/170M [04:35&lt;02:42, 388kB/s]
 63%|██████▎   | 108M/170M [04:36&lt;02:48, 374kB/s]
 63%|██████▎   | 108M/170M [04:36&lt;02:46, 378kB/s]
 63%|██████▎   | 108M/170M [04:36&lt;02:45, 380kB/s]
 63%|██████▎   | 108M/170M [04:36&lt;02:44, 382kB/s]
 63%|██████▎   | 108M/170M [04:36&lt;02:42, 385kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:49, 370kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:46, 376kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:46, 376kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:43, 381kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:43, 382kB/s]
 63%|██████▎   | 108M/170M [04:37&lt;02:48, 371kB/s]
 63%|██████▎   | 108M/170M [04:38&lt;02:47, 371kB/s]
 64%|██████▎   | 108M/170M [04:38&lt;02:44, 378kB/s]
 64%|██████▎   | 108M/170M [04:38&lt;02:44, 377kB/s]
 64%|██████▎   | 108M/170M [04:38&lt;02:43, 378kB/s]
 64%|██████▎   | 109M/170M [04:38&lt;02:47, 371kB/s]
 64%|██████▎   | 109M/170M [04:38&lt;02:47, 370kB/s]
 64%|██████▎   | 109M/170M [04:39&lt;02:45, 374kB/s]
 64%|██████▍   | 109M/170M [04:39&lt;02:43, 379kB/s]
 64%|██████▍   | 109M/170M [04:39&lt;02:42, 380kB/s]
 64%|██████▍   | 109M/170M [04:39&lt;02:41, 381kB/s]
 64%|██████▍   | 109M/170M [04:39&lt;02:46, 369kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:53, 354kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:41, 381kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:41, 379kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:41, 381kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:47, 366kB/s]
 64%|██████▍   | 109M/170M [04:40&lt;02:43, 373kB/s]
 64%|██████▍   | 109M/170M [04:41&lt;02:44, 371kB/s]
 64%|██████▍   | 109M/170M [04:41&lt;02:42, 375kB/s]
 64%|██████▍   | 110M/170M [04:41&lt;02:40, 381kB/s]
 64%|██████▍   | 110M/170M [04:41&lt;02:45, 367kB/s]
 64%|██████▍   | 110M/170M [04:41&lt;02:44, 369kB/s]
 64%|██████▍   | 110M/170M [04:41&lt;02:42, 373kB/s]
 64%|██████▍   | 110M/170M [04:42&lt;02:45, 367kB/s]
 64%|██████▍   | 110M/170M [04:42&lt;02:40, 377kB/s]
 64%|██████▍   | 110M/170M [04:42&lt;02:39, 381kB/s]
 64%|██████▍   | 110M/170M [04:42&lt;02:44, 369kB/s]
 65%|██████▍   | 110M/170M [04:42&lt;02:41, 375kB/s]
 65%|██████▍   | 110M/170M [04:42&lt;02:39, 379kB/s]
 65%|██████▍   | 110M/170M [04:43&lt;02:40, 377kB/s]
 65%|██████▍   | 110M/170M [04:43&lt;02:48, 358kB/s]
 65%|██████▍   | 110M/170M [04:43&lt;02:49, 355kB/s]
 65%|██████▍   | 110M/170M [04:43&lt;02:39, 377kB/s]
 65%|██████▍   | 110M/170M [04:43&lt;02:39, 377kB/s]
 65%|██████▍   | 110M/170M [04:44&lt;02:37, 381kB/s]
 65%|██████▍   | 111M/170M [04:44&lt;02:34, 387kB/s]
 65%|██████▍   | 111M/170M [04:44&lt;02:41, 371kB/s]
 65%|██████▍   | 111M/170M [04:44&lt;02:40, 373kB/s]
 65%|██████▍   | 111M/170M [04:44&lt;02:45, 361kB/s]
 65%|██████▍   | 111M/170M [04:44&lt;02:35, 383kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:33, 388kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:39, 374kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:42, 367kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:34, 384kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:38, 374kB/s]
 65%|██████▌   | 111M/170M [04:45&lt;02:32, 388kB/s]
 65%|██████▌   | 111M/170M [04:46&lt;02:39, 371kB/s]
 65%|██████▌   | 111M/170M [04:46&lt;02:38, 374kB/s]
 65%|██████▌   | 111M/170M [04:46&lt;02:36, 378kB/s]
 65%|██████▌   | 111M/170M [04:46&lt;02:34, 383kB/s]
 65%|██████▌   | 112M/170M [04:46&lt;02:34, 380kB/s]
 65%|██████▌   | 112M/170M [04:46&lt;02:33, 383kB/s]
 65%|██████▌   | 112M/170M [04:47&lt;02:37, 374kB/s]
 66%|██████▌   | 112M/170M [04:47&lt;02:36, 375kB/s]
 66%|██████▌   | 112M/170M [04:47&lt;02:33, 381kB/s]
 66%|██████▌   | 112M/170M [04:47&lt;02:34, 380kB/s]
 66%|██████▌   | 112M/170M [04:47&lt;02:33, 382kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:37, 371kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:37, 372kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:42, 360kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:29, 389kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:30, 386kB/s]
 66%|██████▌   | 112M/170M [04:48&lt;02:35, 373kB/s]
 66%|██████▌   | 112M/170M [04:49&lt;02:32, 381kB/s]
 66%|██████▌   | 112M/170M [04:49&lt;02:32, 381kB/s]
 66%|██████▌   | 113M/170M [04:49&lt;02:30, 385kB/s]
 66%|██████▌   | 113M/170M [04:49&lt;02:29, 387kB/s]
 66%|██████▌   | 113M/170M [04:49&lt;02:33, 376kB/s]
 66%|██████▌   | 113M/170M [04:49&lt;02:33, 376kB/s]
 66%|██████▌   | 113M/170M [04:50&lt;02:31, 382kB/s]
 66%|██████▌   | 113M/170M [04:50&lt;02:28, 389kB/s]
 66%|██████▌   | 113M/170M [04:50&lt;02:29, 385kB/s]
 66%|██████▋   | 113M/170M [04:50&lt;02:32, 377kB/s]
 66%|██████▋   | 113M/170M [04:50&lt;02:31, 380kB/s]
 66%|██████▋   | 113M/170M [04:50&lt;02:31, 379kB/s]
 66%|██████▋   | 113M/170M [04:51&lt;02:29, 384kB/s]
 66%|██████▋   | 113M/170M [04:51&lt;02:28, 386kB/s]
 66%|██████▋   | 113M/170M [04:51&lt;02:28, 386kB/s]
 66%|██████▋   | 113M/170M [04:51&lt;02:32, 374kB/s]
 67%|██████▋   | 113M/170M [04:51&lt;02:30, 378kB/s]
 67%|██████▋   | 114M/170M [04:51&lt;02:28, 384kB/s]
 67%|██████▋   | 114M/170M [04:52&lt;02:27, 385kB/s]
 67%|██████▋   | 114M/170M [04:52&lt;02:27, 385kB/s]
 67%|██████▋   | 114M/170M [04:52&lt;02:32, 373kB/s]
 67%|██████▋   | 114M/170M [04:52&lt;02:31, 375kB/s]
 67%|██████▋   | 114M/170M [04:52&lt;02:30, 377kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:27, 383kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:28, 382kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:36, 360kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:29, 378kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:29, 377kB/s]
 67%|██████▋   | 114M/170M [04:53&lt;02:27, 381kB/s]
 67%|██████▋   | 114M/170M [04:54&lt;02:28, 378kB/s]
 67%|██████▋   | 114M/170M [04:54&lt;02:30, 374kB/s]
 67%|██████▋   | 114M/170M [04:54&lt;02:30, 372kB/s]
 67%|██████▋   | 114M/170M [04:54&lt;02:28, 377kB/s]
 67%|██████▋   | 115M/170M [04:54&lt;02:26, 382kB/s]
 67%|██████▋   | 115M/170M [04:54&lt;02:26, 382kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:30, 371kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:28, 374kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:27, 378kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:25, 382kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:25, 382kB/s]
 67%|██████▋   | 115M/170M [04:55&lt;02:25, 380kB/s]
 67%|██████▋   | 115M/170M [04:56&lt;02:29, 370kB/s]
 68%|██████▊   | 115M/170M [04:56&lt;02:28, 374kB/s]
 68%|██████▊   | 115M/170M [04:56&lt;02:29, 371kB/s]
 68%|██████▊   | 115M/170M [04:56&lt;02:24, 383kB/s]
 68%|██████▊   | 115M/170M [04:56&lt;02:22, 386kB/s]
 68%|██████▊   | 115M/170M [04:57&lt;02:31, 364kB/s]
 68%|██████▊   | 115M/170M [04:57&lt;02:28, 371kB/s]
 68%|██████▊   | 116M/170M [04:57&lt;02:25, 377kB/s]
 68%|██████▊   | 116M/170M [04:57&lt;02:23, 382kB/s]
 68%|██████▊   | 116M/170M [04:57&lt;02:23, 382kB/s]
 68%|██████▊   | 116M/170M [04:57&lt;02:28, 370kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:24, 377kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:23, 379kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:22, 384kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:20, 387kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:24, 376kB/s]
 68%|██████▊   | 116M/170M [04:58&lt;02:24, 376kB/s]
 68%|██████▊   | 116M/170M [04:59&lt;02:22, 381kB/s]
 68%|██████▊   | 116M/170M [04:59&lt;02:21, 384kB/s]
 68%|██████▊   | 116M/170M [04:59&lt;02:21, 383kB/s]
 68%|██████▊   | 116M/170M [04:59&lt;02:27, 368kB/s]
 68%|██████▊   | 116M/170M [04:59&lt;02:24, 374kB/s]
 68%|██████▊   | 117M/170M [04:59&lt;02:23, 377kB/s]
 68%|██████▊   | 117M/170M [05:00&lt;02:20, 383kB/s]
 68%|██████▊   | 117M/170M [05:00&lt;02:20, 384kB/s]
 68%|██████▊   | 117M/170M [05:00&lt;02:19, 385kB/s]
 68%|██████▊   | 117M/170M [05:00&lt;02:25, 368kB/s]
 69%|██████▊   | 117M/170M [05:00&lt;02:21, 378kB/s]
 69%|██████▊   | 117M/170M [05:01&lt;02:22, 377kB/s]
 69%|██████▊   | 117M/170M [05:01&lt;02:19, 383kB/s]
 69%|██████▊   | 117M/170M [05:01&lt;02:18, 387kB/s]
 69%|██████▊   | 117M/170M [05:01&lt;02:23, 371kB/s]
 69%|██████▊   | 117M/170M [05:01&lt;02:22, 375kB/s]
 69%|██████▉   | 117M/170M [05:01&lt;02:20, 380kB/s]
 69%|██████▉   | 117M/170M [05:02&lt;02:18, 384kB/s]
 69%|██████▉   | 117M/170M [05:02&lt;02:17, 385kB/s]
 69%|██████▉   | 117M/170M [05:02&lt;02:22, 372kB/s]
 69%|██████▉   | 118M/170M [05:02&lt;02:20, 376kB/s]
 69%|██████▉   | 118M/170M [05:02&lt;02:26, 362kB/s]
 69%|██████▉   | 118M/170M [05:02&lt;02:16, 388kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:17, 384kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:26, 359kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:19, 377kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:18, 380kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:17, 381kB/s]
 69%|██████▉   | 118M/170M [05:03&lt;02:20, 372kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:16, 384kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:20, 372kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:24, 362kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:15, 386kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:22, 365kB/s]
 69%|██████▉   | 118M/170M [05:04&lt;02:12, 393kB/s]
 69%|██████▉   | 118M/170M [05:05&lt;02:18, 376kB/s]
 70%|██████▉   | 119M/170M [05:05&lt;02:18, 376kB/s]
 70%|██████▉   | 119M/170M [05:05&lt;02:20, 368kB/s]
 70%|██████▉   | 119M/170M [05:05&lt;02:12, 390kB/s]
 70%|██████▉   | 119M/170M [05:05&lt;02:17, 378kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:19, 370kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:15, 381kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:15, 381kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:19, 370kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:12, 387kB/s]
 70%|██████▉   | 119M/170M [05:06&lt;02:17, 373kB/s]
 70%|██████▉   | 119M/170M [05:07&lt;02:18, 370kB/s]
 70%|██████▉   | 119M/170M [05:07&lt;02:15, 378kB/s]
 70%|██████▉   | 119M/170M [05:07&lt;02:14, 379kB/s]
 70%|███████   | 119M/170M [05:07&lt;02:16, 375kB/s]
 70%|███████   | 119M/170M [05:07&lt;02:16, 372kB/s]
 70%|███████   | 120M/170M [05:07&lt;02:15, 377kB/s]
 70%|███████   | 120M/170M [05:08&lt;02:15, 377kB/s]
 70%|███████   | 120M/170M [05:08&lt;02:12, 383kB/s]
 70%|███████   | 120M/170M [05:08&lt;02:12, 382kB/s]
 70%|███████   | 120M/170M [05:08&lt;02:11, 387kB/s]
 70%|███████   | 120M/170M [05:08&lt;02:16, 372kB/s]
 70%|███████   | 120M/170M [05:09&lt;02:13, 380kB/s]
 70%|███████   | 120M/170M [05:09&lt;02:13, 378kB/s]
 70%|███████   | 120M/170M [05:09&lt;02:13, 377kB/s]
 70%|███████   | 120M/170M [05:09&lt;02:11, 384kB/s]
 70%|███████   | 120M/170M [05:09&lt;02:19, 362kB/s]
 71%|███████   | 120M/170M [05:09&lt;02:15, 370kB/s]
 71%|███████   | 120M/170M [05:10&lt;02:09, 389kB/s]
 71%|███████   | 120M/170M [05:10&lt;02:08, 390kB/s]
 71%|███████   | 120M/170M [05:10&lt;02:10, 384kB/s]
 71%|███████   | 121M/170M [05:10&lt;02:15, 369kB/s]
 71%|███████   | 121M/170M [05:10&lt;02:12, 378kB/s]
 71%|███████   | 121M/170M [05:10&lt;02:10, 382kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:22, 349kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:16, 365kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:19, 356kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:16, 364kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:12, 374kB/s]
 71%|███████   | 121M/170M [05:11&lt;02:11, 376kB/s]
 71%|███████   | 121M/170M [05:12&lt;02:09, 382kB/s]
 71%|███████   | 121M/170M [05:12&lt;02:13, 368kB/s]
 71%|███████   | 121M/170M [05:12&lt;02:12, 372kB/s]
 71%|███████   | 121M/170M [05:12&lt;02:10, 376kB/s]
 71%|███████   | 121M/170M [05:12&lt;02:09, 379kB/s]
 71%|███████   | 121M/170M [05:13&lt;02:09, 380kB/s]
 71%|███████▏  | 122M/170M [05:13&lt;02:07, 384kB/s]
 71%|███████▏  | 122M/170M [05:13&lt;02:12, 370kB/s]
 71%|███████▏  | 122M/170M [05:13&lt;02:09, 376kB/s]
 71%|███████▏  | 122M/170M [05:13&lt;02:09, 376kB/s]
 71%|███████▏  | 122M/170M [05:13&lt;02:08, 378kB/s]
 71%|███████▏  | 122M/170M [05:14&lt;02:12, 367kB/s]
 71%|███████▏  | 122M/170M [05:14&lt;02:13, 365kB/s]
 72%|███████▏  | 122M/170M [05:14&lt;02:07, 381kB/s]
 72%|███████▏  | 122M/170M [05:14&lt;02:07, 380kB/s]
 72%|███████▏  | 122M/170M [05:14&lt;02:06, 383kB/s]
 72%|███████▏  | 122M/170M [05:14&lt;02:04, 389kB/s]
 72%|███████▏  | 122M/170M [05:15&lt;02:09, 374kB/s]
 72%|███████▏  | 122M/170M [05:15&lt;02:07, 379kB/s]
 72%|███████▏  | 122M/170M [05:15&lt;02:06, 379kB/s]
 72%|███████▏  | 122M/170M [05:15&lt;02:07, 378kB/s]
 72%|███████▏  | 122M/170M [05:15&lt;02:06, 381kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:10, 367kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:08, 371kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:07, 376kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:06, 377kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:06, 378kB/s]
 72%|███████▏  | 123M/170M [05:16&lt;02:08, 370kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:12, 359kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:04, 380kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:04, 380kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:04, 380kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:02, 385kB/s]
 72%|███████▏  | 123M/170M [05:17&lt;02:07, 370kB/s]
 72%|███████▏  | 123M/170M [05:18&lt;02:06, 372kB/s]
 72%|███████▏  | 123M/170M [05:18&lt;02:06, 373kB/s]
 72%|███████▏  | 123M/170M [05:18&lt;02:05, 375kB/s]
 72%|███████▏  | 124M/170M [05:18&lt;02:05, 375kB/s]
 72%|███████▏  | 124M/170M [05:18&lt;02:11, 357kB/s]
 73%|███████▎  | 124M/170M [05:18&lt;02:05, 374kB/s]
 73%|███████▎  | 124M/170M [05:19&lt;02:04, 375kB/s]
 73%|███████▎  | 124M/170M [05:19&lt;02:04, 376kB/s]
 73%|███████▎  | 124M/170M [05:19&lt;02:02, 382kB/s]
 73%|███████▎  | 124M/170M [05:19&lt;02:07, 366kB/s]
 73%|███████▎  | 124M/170M [05:19&lt;02:04, 372kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:04, 373kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:04, 374kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:02, 377kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:07, 363kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:05, 369kB/s]
 73%|███████▎  | 124M/170M [05:20&lt;02:05, 368kB/s]
 73%|███████▎  | 124M/170M [05:21&lt;02:08, 358kB/s]
 73%|███████▎  | 125M/170M [05:21&lt;02:07, 360kB/s]
 73%|███████▎  | 125M/170M [05:21&lt;02:04, 369kB/s]
 73%|███████▎  | 125M/170M [05:21&lt;02:02, 374kB/s]
 73%|███████▎  | 125M/170M [05:21&lt;02:01, 377kB/s]
 73%|███████▎  | 125M/170M [05:21&lt;02:00, 378kB/s]
 73%|███████▎  | 125M/170M [05:22&lt;02:00, 379kB/s]
 73%|███████▎  | 125M/170M [05:22&lt;02:01, 374kB/s]
 73%|███████▎  | 125M/170M [05:22&lt;02:04, 367kB/s]
 73%|███████▎  | 125M/170M [05:22&lt;02:01, 374kB/s]
 73%|███████▎  | 125M/170M [05:22&lt;02:02, 371kB/s]
 73%|███████▎  | 125M/170M [05:23&lt;02:00, 375kB/s]
 73%|███████▎  | 125M/170M [05:23&lt;01:59, 380kB/s]
 73%|███████▎  | 125M/170M [05:23&lt;02:03, 366kB/s]
 74%|███████▎  | 125M/170M [05:23&lt;02:03, 367kB/s]
 74%|███████▎  | 125M/170M [05:23&lt;02:03, 365kB/s]
 74%|███████▎  | 126M/170M [05:23&lt;02:03, 364kB/s]
 74%|███████▎  | 126M/170M [05:24&lt;01:59, 375kB/s]
 74%|███████▎  | 126M/170M [05:24&lt;02:04, 362kB/s]
 74%|███████▎  | 126M/170M [05:24&lt;02:08, 347kB/s]
 74%|███████▍  | 126M/170M [05:24&lt;01:58, 376kB/s]
 74%|███████▍  | 126M/170M [05:24&lt;01:59, 373kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;02:03, 361kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;02:04, 357kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;02:00, 371kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;02:01, 367kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;01:56, 381kB/s]
 74%|███████▍  | 126M/170M [05:25&lt;01:57, 378kB/s]
 74%|███████▍  | 126M/170M [05:26&lt;01:59, 369kB/s]
 74%|███████▍  | 126M/170M [05:26&lt;02:01, 363kB/s]
 74%|███████▍  | 126M/170M [05:26&lt;01:57, 376kB/s]
 74%|███████▍  | 126M/170M [05:26&lt;01:57, 374kB/s]
 74%|███████▍  | 127M/170M [05:26&lt;01:58, 370kB/s]
 74%|███████▍  | 127M/170M [05:26&lt;01:56, 377kB/s]
 74%|███████▍  | 127M/170M [05:27&lt;01:59, 366kB/s]
 74%|███████▍  | 127M/170M [05:27&lt;01:59, 365kB/s]
 74%|███████▍  | 127M/170M [05:27&lt;01:58, 370kB/s]
 74%|███████▍  | 127M/170M [05:27&lt;01:56, 374kB/s]
 74%|███████▍  | 127M/170M [05:27&lt;01:55, 378kB/s]
 74%|███████▍  | 127M/170M [05:28&lt;01:58, 368kB/s]
 75%|███████▍  | 127M/170M [05:28&lt;01:57, 370kB/s]
 75%|███████▍  | 127M/170M [05:28&lt;01:56, 373kB/s]
 75%|███████▍  | 127M/170M [05:28&lt;01:54, 378kB/s]
 75%|███████▍  | 127M/170M [05:28&lt;01:54, 376kB/s]
 75%|███████▍  | 127M/170M [05:28&lt;01:57, 366kB/s]
 75%|███████▍  | 127M/170M [05:29&lt;01:56, 370kB/s]
 75%|███████▍  | 127M/170M [05:29&lt;01:56, 370kB/s]
 75%|███████▍  | 128M/170M [05:29&lt;01:54, 375kB/s]
 75%|███████▍  | 128M/170M [05:29&lt;01:54, 375kB/s]
 75%|███████▍  | 128M/170M [05:29&lt;01:57, 365kB/s]
 75%|███████▍  | 128M/170M [05:29&lt;01:56, 369kB/s]
 75%|███████▍  | 128M/170M [05:30&lt;01:55, 370kB/s]
 75%|███████▍  | 128M/170M [05:30&lt;01:53, 376kB/s]
 75%|███████▌  | 128M/170M [05:30&lt;01:53, 376kB/s]
 75%|███████▌  | 128M/170M [05:30&lt;01:53, 375kB/s]
 75%|███████▌  | 128M/170M [05:30&lt;01:56, 365kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:56, 364kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:53, 371kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:53, 371kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:53, 371kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:58, 355kB/s]
 75%|███████▌  | 128M/170M [05:31&lt;01:58, 353kB/s]
 75%|███████▌  | 129M/170M [05:32&lt;01:52, 373kB/s]
 75%|███████▌  | 129M/170M [05:32&lt;01:51, 377kB/s]
 75%|███████▌  | 129M/170M [05:32&lt;01:50, 379kB/s]
 75%|███████▌  | 129M/170M [05:32&lt;01:53, 369kB/s]
 76%|███████▌  | 129M/170M [05:32&lt;01:52, 370kB/s]
 76%|███████▌  | 129M/170M [05:32&lt;01:52, 370kB/s]
 76%|███████▌  | 129M/170M [05:33&lt;01:50, 377kB/s]
 76%|███████▌  | 129M/170M [05:33&lt;01:50, 374kB/s]
 76%|███████▌  | 129M/170M [05:33&lt;01:53, 364kB/s]
 76%|███████▌  | 129M/170M [05:33&lt;01:53, 364kB/s]
 76%|███████▌  | 129M/170M [05:33&lt;01:52, 369kB/s]
 76%|███████▌  | 129M/170M [05:34&lt;01:49, 376kB/s]
 76%|███████▌  | 129M/170M [05:34&lt;01:50, 374kB/s]
 76%|███████▌  | 129M/170M [05:34&lt;01:53, 363kB/s]
 76%|███████▌  | 129M/170M [05:34&lt;01:52, 366kB/s]
 76%|███████▌  | 129M/170M [05:34&lt;01:51, 368kB/s]
 76%|███████▌  | 130M/170M [05:34&lt;01:49, 374kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:51, 367kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:51, 366kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:50, 368kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:49, 373kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:49, 372kB/s]
 76%|███████▌  | 130M/170M [05:35&lt;01:47, 377kB/s]
 76%|███████▋  | 130M/170M [05:36&lt;01:47, 375kB/s]
 76%|███████▋  | 130M/170M [05:36&lt;01:51, 364kB/s]
 76%|███████▋  | 130M/170M [05:36&lt;01:49, 368kB/s]
 76%|███████▋  | 130M/170M [05:36&lt;01:47, 373kB/s]
 76%|███████▋  | 130M/170M [05:36&lt;01:46, 376kB/s]
 76%|███████▋  | 130M/170M [05:37&lt;01:46, 376kB/s]
 76%|███████▋  | 130M/170M [05:37&lt;01:50, 364kB/s]
 77%|███████▋  | 130M/170M [05:37&lt;01:48, 368kB/s]
 77%|███████▋  | 131M/170M [05:37&lt;01:54, 350kB/s]
 77%|███████▋  | 131M/170M [05:37&lt;01:44, 380kB/s]
 77%|███████▋  | 131M/170M [05:37&lt;01:45, 379kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:48, 366kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:47, 369kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:46, 372kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:45, 376kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:44, 378kB/s]
 77%|███████▋  | 131M/170M [05:38&lt;01:47, 368kB/s]
 77%|███████▋  | 131M/170M [05:39&lt;01:46, 369kB/s]
 77%|███████▋  | 131M/170M [05:39&lt;01:45, 373kB/s]
 77%|███████▋  | 131M/170M [05:39&lt;01:43, 379kB/s]
 77%|███████▋  | 131M/170M [05:39&lt;01:43, 377kB/s]
 77%|███████▋  | 131M/170M [05:39&lt;01:44, 376kB/s]
 77%|███████▋  | 131M/170M [05:40&lt;01:46, 367kB/s]
 77%|███████▋  | 132M/170M [05:40&lt;01:44, 371kB/s]
 77%|███████▋  | 132M/170M [05:40&lt;01:44, 372kB/s]
 77%|███████▋  | 132M/170M [05:40&lt;01:42, 379kB/s]
 77%|███████▋  | 132M/170M [05:40&lt;01:42, 380kB/s]
 77%|███████▋  | 132M/170M [05:40&lt;01:45, 366kB/s]
 77%|███████▋  | 132M/170M [05:41&lt;01:47, 358kB/s]
 77%|███████▋  | 132M/170M [05:41&lt;01:46, 361kB/s]
 77%|███████▋  | 132M/170M [05:41&lt;01:40, 384kB/s]
 77%|███████▋  | 132M/170M [05:41&lt;01:40, 384kB/s]
 77%|███████▋  | 132M/170M [05:41&lt;01:44, 368kB/s]
 78%|███████▊  | 132M/170M [05:41&lt;01:43, 370kB/s]
 78%|███████▊  | 132M/170M [05:42&lt;01:42, 373kB/s]
 78%|███████▊  | 132M/170M [05:42&lt;01:42, 372kB/s]
 78%|███████▊  | 132M/170M [05:42&lt;01:41, 376kB/s]
 78%|███████▊  | 132M/170M [05:42&lt;01:44, 364kB/s]
 78%|███████▊  | 133M/170M [05:42&lt;01:42, 369kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:47, 352kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:39, 382kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:39, 378kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:47, 349kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:40, 374kB/s]
 78%|███████▊  | 133M/170M [05:43&lt;01:39, 378kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:44, 360kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:37, 386kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:37, 383kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:41, 366kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:40, 370kB/s]
 78%|███████▊  | 133M/170M [05:44&lt;01:40, 371kB/s]
 78%|███████▊  | 133M/170M [05:45&lt;01:40, 369kB/s]
 78%|███████▊  | 133M/170M [05:45&lt;01:44, 355kB/s]
 78%|███████▊  | 133M/170M [05:45&lt;01:44, 353kB/s]
 78%|███████▊  | 134M/170M [05:45&lt;01:39, 372kB/s]
 78%|███████▊  | 134M/170M [05:45&lt;01:40, 366kB/s]
 78%|███████▊  | 134M/170M [05:46&lt;01:36, 380kB/s]
 78%|███████▊  | 134M/170M [05:46&lt;01:36, 380kB/s]
 78%|███████▊  | 134M/170M [05:46&lt;01:40, 366kB/s]
 79%|███████▊  | 134M/170M [05:46&lt;01:39, 367kB/s]
 79%|███████▊  | 134M/170M [05:46&lt;01:37, 373kB/s]
 79%|███████▊  | 134M/170M [05:46&lt;01:37, 373kB/s]
 79%|███████▊  | 134M/170M [05:47&lt;01:39, 366kB/s]
 79%|███████▊  | 134M/170M [05:47&lt;01:41, 359kB/s]
 79%|███████▊  | 134M/170M [05:47&lt;01:38, 370kB/s]
 79%|███████▉  | 134M/170M [05:47&lt;01:36, 377kB/s]
 79%|███████▉  | 134M/170M [05:47&lt;01:35, 377kB/s]
 79%|███████▉  | 134M/170M [05:47&lt;01:36, 376kB/s]
 79%|███████▉  | 134M/170M [05:48&lt;01:35, 377kB/s]
 79%|███████▉  | 135M/170M [05:48&lt;01:38, 364kB/s]
 79%|███████▉  | 135M/170M [05:48&lt;01:37, 370kB/s]
 79%|███████▉  | 135M/170M [05:48&lt;01:37, 367kB/s]
 79%|███████▉  | 135M/170M [05:48&lt;01:37, 369kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:35, 372kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:44, 339kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:34, 376kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:34, 375kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:34, 375kB/s]
 79%|███████▉  | 135M/170M [05:49&lt;01:35, 372kB/s]
 79%|███████▉  | 135M/170M [05:50&lt;01:37, 364kB/s]
 79%|███████▉  | 135M/170M [05:50&lt;01:35, 371kB/s]
 79%|███████▉  | 135M/170M [05:50&lt;01:34, 372kB/s]
 79%|███████▉  | 135M/170M [05:50&lt;01:34, 373kB/s]
 79%|███████▉  | 135M/170M [05:50&lt;01:32, 377kB/s]
 79%|███████▉  | 136M/170M [05:51&lt;01:36, 361kB/s]
 80%|███████▉  | 136M/170M [05:51&lt;01:35, 364kB/s]
 80%|███████▉  | 136M/170M [05:51&lt;01:33, 372kB/s]
 80%|███████▉  | 136M/170M [05:51&lt;01:33, 371kB/s]
 80%|███████▉  | 136M/170M [05:51&lt;01:33, 371kB/s]
 80%|███████▉  | 136M/170M [05:51&lt;01:39, 347kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:33, 370kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:31, 376kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:31, 375kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:31, 375kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:30, 378kB/s]
 80%|███████▉  | 136M/170M [05:52&lt;01:35, 360kB/s]
 80%|███████▉  | 136M/170M [05:53&lt;01:33, 365kB/s]
 80%|███████▉  | 136M/170M [05:53&lt;01:32, 368kB/s]
 80%|████████  | 136M/170M [05:53&lt;01:32, 368kB/s]
 80%|████████  | 137M/170M [05:53&lt;01:30, 375kB/s]
 80%|████████  | 137M/170M [05:53&lt;01:34, 360kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:31, 370kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:30, 372kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:30, 374kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:29, 375kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:33, 361kB/s]
 80%|████████  | 137M/170M [05:54&lt;01:31, 368kB/s]
 80%|████████  | 137M/170M [05:55&lt;01:30, 369kB/s]
 80%|████████  | 137M/170M [05:55&lt;01:32, 363kB/s]
 80%|████████  | 137M/170M [05:55&lt;01:32, 361kB/s]
 80%|████████  | 137M/170M [05:55&lt;01:31, 363kB/s]
 81%|████████  | 137M/170M [05:55&lt;01:30, 368kB/s]
 81%|████████  | 137M/170M [05:56&lt;01:29, 371kB/s]
 81%|████████  | 137M/170M [05:56&lt;01:29, 370kB/s]
 81%|████████  | 137M/170M [05:56&lt;01:29, 370kB/s]
 81%|████████  | 138M/170M [05:56&lt;01:31, 359kB/s]
 81%|████████  | 138M/170M [05:56&lt;01:30, 362kB/s]
 81%|████████  | 138M/170M [05:56&lt;01:28, 369kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:28, 369kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:28, 369kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:28, 368kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:31, 358kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:28, 365kB/s]
 81%|████████  | 138M/170M [05:57&lt;01:28, 364kB/s]
 81%|████████  | 138M/170M [05:58&lt;01:31, 352kB/s]
 81%|████████  | 138M/170M [05:58&lt;01:26, 375kB/s]
 81%|████████  | 138M/170M [05:58&lt;01:29, 360kB/s]
 81%|████████  | 138M/170M [05:58&lt;01:29, 361kB/s]
 81%|████████  | 138M/170M [05:58&lt;01:28, 365kB/s]
 81%|████████  | 138M/170M [05:59&lt;01:26, 368kB/s]
 81%|████████▏ | 139M/170M [05:59&lt;01:25, 372kB/s]
 81%|████████▏ | 139M/170M [05:59&lt;01:29, 358kB/s]
 81%|████████▏ | 139M/170M [05:59&lt;01:27, 365kB/s]
 81%|████████▏ | 139M/170M [05:59&lt;01:26, 365kB/s]
 81%|████████▏ | 139M/170M [05:59&lt;01:30, 350kB/s]
 81%|████████▏ | 139M/170M [06:00&lt;01:24, 375kB/s]
 81%|████████▏ | 139M/170M [06:00&lt;01:27, 359kB/s]
 82%|████████▏ | 139M/170M [06:00&lt;01:26, 365kB/s]
 82%|████████▏ | 139M/170M [06:00&lt;01:25, 369kB/s]
 82%|████████▏ | 139M/170M [06:00&lt;01:25, 369kB/s]
 82%|████████▏ | 139M/170M [06:01&lt;01:24, 371kB/s]
 82%|████████▏ | 139M/170M [06:01&lt;01:26, 359kB/s]
 82%|████████▏ | 139M/170M [06:01&lt;01:26, 362kB/s]
 82%|████████▏ | 139M/170M [06:01&lt;01:24, 368kB/s]
 82%|████████▏ | 139M/170M [06:01&lt;01:23, 370kB/s]
 82%|████████▏ | 140M/170M [06:01&lt;01:26, 359kB/s]
 82%|████████▏ | 140M/170M [06:02&lt;01:26, 356kB/s]
 82%|████████▏ | 140M/170M [06:02&lt;01:25, 361kB/s]
 82%|████████▏ | 140M/170M [06:02&lt;01:24, 364kB/s]
 82%|████████▏ | 140M/170M [06:02&lt;01:25, 361kB/s]
 82%|████████▏ | 140M/170M [06:02&lt;01:23, 365kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:23, 368kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:27, 347kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:24, 359kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:24, 361kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:23, 364kB/s]
 82%|████████▏ | 140M/170M [06:03&lt;01:22, 365kB/s]
 82%|████████▏ | 140M/170M [06:04&lt;01:25, 352kB/s]
 82%|████████▏ | 140M/170M [06:04&lt;01:24, 355kB/s]
 82%|████████▏ | 140M/170M [06:04&lt;01:23, 360kB/s]
 82%|████████▏ | 141M/170M [06:04&lt;01:22, 364kB/s]
 82%|████████▏ | 141M/170M [06:04&lt;01:20, 369kB/s]
 82%|████████▏ | 141M/170M [06:05&lt;01:23, 356kB/s]
 83%|████████▎ | 141M/170M [06:05&lt;01:23, 357kB/s]
 83%|████████▎ | 141M/170M [06:05&lt;01:22, 360kB/s]
 83%|████████▎ | 141M/170M [06:05&lt;01:21, 364kB/s]
 83%|████████▎ | 141M/170M [06:05&lt;01:21, 364kB/s]
 83%|████████▎ | 141M/170M [06:05&lt;01:22, 356kB/s]
 83%|████████▎ | 141M/170M [06:06&lt;01:22, 356kB/s]
 83%|████████▎ | 141M/170M [06:06&lt;01:20, 363kB/s]
 83%|████████▎ | 141M/170M [06:06&lt;01:20, 366kB/s]
 83%|████████▎ | 141M/170M [06:06&lt;01:20, 366kB/s]
 83%|████████▎ | 141M/170M [06:06&lt;01:20, 365kB/s]
 83%|████████▎ | 141M/170M [06:07&lt;01:22, 351kB/s]
 83%|████████▎ | 141M/170M [06:07&lt;01:21, 358kB/s]
 83%|████████▎ | 141M/170M [06:07&lt;01:20, 359kB/s]
 83%|████████▎ | 142M/170M [06:07&lt;01:19, 363kB/s]
 83%|████████▎ | 142M/170M [06:07&lt;01:18, 368kB/s]
 83%|████████▎ | 142M/170M [06:07&lt;01:22, 347kB/s]
 83%|████████▎ | 142M/170M [06:08&lt;01:19, 361kB/s]
 83%|████████▎ | 142M/170M [06:08&lt;01:19, 362kB/s]
 83%|████████▎ | 142M/170M [06:08&lt;01:18, 366kB/s]
 83%|████████▎ | 142M/170M [06:08&lt;01:17, 368kB/s]
 83%|████████▎ | 142M/170M [06:08&lt;01:19, 358kB/s]
 83%|████████▎ | 142M/170M [06:09&lt;01:18, 361kB/s]
 83%|████████▎ | 142M/170M [06:09&lt;01:18, 363kB/s]
 83%|████████▎ | 142M/170M [06:09&lt;01:19, 357kB/s]
 83%|████████▎ | 142M/170M [06:09&lt;01:16, 369kB/s]
 83%|████████▎ | 142M/170M [06:09&lt;01:19, 354kB/s]
 84%|████████▎ | 142M/170M [06:09&lt;01:18, 359kB/s]
 84%|████████▎ | 142M/170M [06:10&lt;01:17, 363kB/s]
 84%|████████▎ | 143M/170M [06:10&lt;01:15, 370kB/s]
 84%|████████▎ | 143M/170M [06:10&lt;01:16, 366kB/s]
 84%|████████▎ | 143M/170M [06:10&lt;01:15, 367kB/s]
 84%|████████▎ | 143M/170M [06:10&lt;01:18, 355kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:17, 359kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:15, 367kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:15, 366kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:14, 367kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:16, 357kB/s]
 84%|████████▍ | 143M/170M [06:11&lt;01:16, 356kB/s]
 84%|████████▍ | 143M/170M [06:12&lt;01:15, 360kB/s]
 84%|████████▍ | 143M/170M [06:12&lt;01:14, 366kB/s]
 84%|████████▍ | 143M/170M [06:12&lt;01:14, 365kB/s]
 84%|████████▍ | 143M/170M [06:12&lt;01:16, 357kB/s]
 84%|████████▍ | 143M/170M [06:12&lt;01:15, 360kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:18, 344kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:11, 374kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:12, 371kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:14, 360kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:14, 360kB/s]
 84%|████████▍ | 144M/170M [06:13&lt;01:13, 363kB/s]
 84%|████████▍ | 144M/170M [06:14&lt;01:12, 367kB/s]
 84%|████████▍ | 144M/170M [06:14&lt;01:11, 369kB/s]
 84%|████████▍ | 144M/170M [06:14&lt;01:13, 360kB/s]
 85%|████████▍ | 144M/170M [06:14&lt;01:13, 361kB/s]
 85%|████████▍ | 144M/170M [06:14&lt;01:12, 362kB/s]
 85%|████████▍ | 144M/170M [06:14&lt;01:11, 368kB/s]
 85%|████████▍ | 144M/170M [06:15&lt;01:11, 369kB/s]
 85%|████████▍ | 144M/170M [06:15&lt;01:10, 369kB/s]
 85%|████████▍ | 144M/170M [06:15&lt;01:12, 357kB/s]
 85%|████████▍ | 145M/170M [06:15&lt;01:11, 362kB/s]
 85%|████████▍ | 145M/170M [06:15&lt;01:12, 359kB/s]
 85%|████████▍ | 145M/170M [06:16&lt;01:10, 366kB/s]
 85%|████████▍ | 145M/170M [06:16&lt;01:11, 363kB/s]
 85%|████████▍ | 145M/170M [06:16&lt;01:12, 355kB/s]
 85%|████████▍ | 145M/170M [06:16&lt;01:11, 358kB/s]
 85%|████████▍ | 145M/170M [06:16&lt;01:10, 362kB/s]
 85%|████████▌ | 145M/170M [06:16&lt;01:09, 368kB/s]
 85%|████████▌ | 145M/170M [06:17&lt;01:09, 366kB/s]
 85%|████████▌ | 145M/170M [06:17&lt;01:09, 363kB/s]
 85%|████████▌ | 145M/170M [06:17&lt;01:08, 368kB/s]
 85%|████████▌ | 145M/170M [06:17&lt;01:08, 369kB/s]
 85%|████████▌ | 145M/170M [06:17&lt;01:07, 372kB/s]
 85%|████████▌ | 145M/170M [06:18&lt;01:07, 371kB/s]
 85%|████████▌ | 145M/170M [06:18&lt;01:09, 359kB/s]
 85%|████████▌ | 145M/170M [06:18&lt;01:09, 361kB/s]
 85%|████████▌ | 146M/170M [06:18&lt;01:08, 366kB/s]
 85%|████████▌ | 146M/170M [06:18&lt;01:06, 372kB/s]
 85%|████████▌ | 146M/170M [06:18&lt;01:07, 369kB/s]
 85%|████████▌ | 146M/170M [06:19&lt;01:08, 362kB/s]
 86%|████████▌ | 146M/170M [06:19&lt;01:11, 344kB/s]
 86%|████████▌ | 146M/170M [06:19&lt;01:06, 372kB/s]
 86%|████████▌ | 146M/170M [06:19&lt;01:05, 374kB/s]
 86%|████████▌ | 146M/170M [06:19&lt;01:06, 369kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:06, 370kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:08, 358kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:07, 362kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:07, 360kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:05, 366kB/s]
 86%|████████▌ | 146M/170M [06:20&lt;01:05, 365kB/s]
 86%|████████▌ | 146M/170M [06:21&lt;01:08, 353kB/s]
 86%|████████▌ | 147M/170M [06:21&lt;01:08, 347kB/s]
 86%|████████▌ | 147M/170M [06:21&lt;01:08, 349kB/s]
 86%|████████▌ | 147M/170M [06:21&lt;01:05, 366kB/s]
 86%|████████▌ | 147M/170M [06:21&lt;01:04, 368kB/s]
 86%|████████▌ | 147M/170M [06:22&lt;01:06, 356kB/s]
 86%|████████▌ | 147M/170M [06:22&lt;01:05, 359kB/s]
 86%|████████▌ | 147M/170M [06:22&lt;01:05, 362kB/s]
 86%|████████▌ | 147M/170M [06:22&lt;01:04, 365kB/s]
 86%|████████▋ | 147M/170M [06:22&lt;01:04, 365kB/s]
 86%|████████▋ | 147M/170M [06:22&lt;01:05, 355kB/s]
 86%|████████▋ | 147M/170M [06:23&lt;01:05, 355kB/s]
 86%|████████▋ | 147M/170M [06:23&lt;01:05, 357kB/s]
 86%|████████▋ | 147M/170M [06:23&lt;01:05, 355kB/s]
 86%|████████▋ | 147M/170M [06:23&lt;01:03, 366kB/s]
 86%|████████▋ | 147M/170M [06:23&lt;01:05, 352kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:04, 355kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:03, 359kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:03, 362kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:02, 365kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:02, 364kB/s]
 87%|████████▋ | 148M/170M [06:24&lt;01:04, 353kB/s]
 87%|████████▋ | 148M/170M [06:25&lt;01:03, 355kB/s]
 87%|████████▋ | 148M/170M [06:25&lt;01:02, 360kB/s]
 87%|████████▋ | 148M/170M [06:25&lt;01:01, 363kB/s]
 87%|████████▋ | 148M/170M [06:25&lt;01:01, 363kB/s]
 87%|████████▋ | 148M/170M [06:25&lt;01:03, 352kB/s]
 87%|████████▋ | 148M/170M [06:26&lt;01:02, 357kB/s]
 87%|████████▋ | 148M/170M [06:26&lt;01:01, 360kB/s]
 87%|████████▋ | 148M/170M [06:26&lt;01:00, 364kB/s]
 87%|████████▋ | 148M/170M [06:26&lt;01:00, 363kB/s]
 87%|████████▋ | 149M/170M [06:26&lt;01:02, 351kB/s]
 87%|████████▋ | 149M/170M [06:26&lt;01:01, 354kB/s]
 87%|████████▋ | 149M/170M [06:27&lt;01:00, 359kB/s]
 87%|████████▋ | 149M/170M [06:27&lt;00:59, 365kB/s]
 87%|████████▋ | 149M/170M [06:27&lt;00:59, 366kB/s]
 87%|████████▋ | 149M/170M [06:27&lt;01:01, 350kB/s]
 87%|████████▋ | 149M/170M [06:27&lt;01:03, 339kB/s]
 87%|████████▋ | 149M/170M [06:28&lt;00:59, 361kB/s]
 87%|████████▋ | 149M/170M [06:28&lt;00:58, 368kB/s]
 87%|████████▋ | 149M/170M [06:28&lt;01:00, 354kB/s]
 87%|████████▋ | 149M/170M [06:28&lt;01:01, 349kB/s]
 88%|████████▊ | 149M/170M [06:28&lt;00:58, 361kB/s]
 88%|████████▊ | 149M/170M [06:28&lt;00:58, 361kB/s]
 88%|████████▊ | 149M/170M [06:29&lt;00:59, 353kB/s]
 88%|████████▊ | 149M/170M [06:29&lt;00:57, 367kB/s]
 88%|████████▊ | 149M/170M [06:29&lt;00:56, 371kB/s]
 88%|████████▊ | 150M/170M [06:29&lt;00:59, 350kB/s]
 88%|████████▊ | 150M/170M [06:29&lt;00:58, 360kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:57, 360kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:57, 360kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:58, 356kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:58, 354kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:56, 362kB/s]
 88%|████████▊ | 150M/170M [06:30&lt;00:56, 362kB/s]
 88%|████████▊ | 150M/170M [06:31&lt;00:56, 363kB/s]
 88%|████████▊ | 150M/170M [06:31&lt;00:55, 368kB/s]
 88%|████████▊ | 150M/170M [06:31&lt;00:57, 353kB/s]
 88%|████████▊ | 150M/170M [06:31&lt;00:56, 356kB/s]
 88%|████████▊ | 150M/170M [06:31&lt;00:55, 363kB/s]
 88%|████████▊ | 150M/170M [06:32&lt;00:55, 363kB/s]
 88%|████████▊ | 150M/170M [06:32&lt;00:54, 364kB/s]
 88%|████████▊ | 151M/170M [06:32&lt;00:56, 356kB/s]
 88%|████████▊ | 151M/170M [06:32&lt;00:55, 358kB/s]
 88%|████████▊ | 151M/170M [06:32&lt;00:54, 364kB/s]
 88%|████████▊ | 151M/170M [06:32&lt;00:54, 364kB/s]
 88%|████████▊ | 151M/170M [06:33&lt;00:55, 355kB/s]
 88%|████████▊ | 151M/170M [06:33&lt;00:54, 362kB/s]
 89%|████████▊ | 151M/170M [06:33&lt;00:56, 348kB/s]
 89%|████████▊ | 151M/170M [06:33&lt;00:54, 356kB/s]
 89%|████████▊ | 151M/170M [06:33&lt;00:53, 361kB/s]
 89%|████████▊ | 151M/170M [06:34&lt;00:54, 359kB/s]
 89%|████████▊ | 151M/170M [06:34&lt;00:52, 364kB/s]
 89%|████████▊ | 151M/170M [06:34&lt;00:55, 349kB/s]
 89%|████████▉ | 151M/170M [06:34&lt;00:53, 358kB/s]
 89%|████████▉ | 151M/170M [06:34&lt;00:54, 352kB/s]
 89%|████████▉ | 151M/170M [06:35&lt;00:54, 349kB/s]
 89%|████████▉ | 152M/170M [06:35&lt;00:51, 369kB/s]
 89%|████████▉ | 152M/170M [06:35&lt;00:53, 351kB/s]
 89%|████████▉ | 152M/170M [06:35&lt;00:52, 359kB/s]
 89%|████████▉ | 152M/170M [06:35&lt;00:52, 359kB/s]
 89%|████████▉ | 152M/170M [06:35&lt;00:52, 360kB/s]
 89%|████████▉ | 152M/170M [06:36&lt;00:51, 366kB/s]
 89%|████████▉ | 152M/170M [06:36&lt;00:53, 349kB/s]
 89%|████████▉ | 152M/170M [06:36&lt;00:52, 350kB/s]
 89%|████████▉ | 152M/170M [06:36&lt;00:50, 364kB/s]
 89%|████████▉ | 152M/170M [06:36&lt;00:50, 367kB/s]
 89%|████████▉ | 152M/170M [06:37&lt;00:50, 362kB/s]
 89%|████████▉ | 152M/170M [06:37&lt;00:52, 351kB/s]
 89%|████████▉ | 152M/170M [06:37&lt;00:51, 354kB/s]
 89%|████████▉ | 152M/170M [06:37&lt;00:50, 361kB/s]
 89%|████████▉ | 152M/170M [06:37&lt;00:50, 361kB/s]
 89%|████████▉ | 153M/170M [06:37&lt;00:49, 360kB/s]
 89%|████████▉ | 153M/170M [06:38&lt;00:49, 366kB/s]
 90%|████████▉ | 153M/170M [06:38&lt;00:51, 349kB/s]
 90%|████████▉ | 153M/170M [06:38&lt;00:49, 356kB/s]
 90%|████████▉ | 153M/170M [06:38&lt;00:49, 358kB/s]
 90%|████████▉ | 153M/170M [06:38&lt;00:49, 357kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:48, 363kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:50, 350kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:49, 355kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:49, 355kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:48, 355kB/s]
 90%|████████▉ | 153M/170M [06:39&lt;00:47, 360kB/s]
 90%|████████▉ | 153M/170M [06:40&lt;00:52, 329kB/s]
 90%|████████▉ | 153M/170M [06:40&lt;00:47, 359kB/s]
 90%|████████▉ | 153M/170M [06:40&lt;00:47, 358kB/s]
 90%|█████████ | 153M/170M [06:40&lt;00:47, 361kB/s]
 90%|█████████ | 154M/170M [06:40&lt;00:46, 362kB/s]
 90%|█████████ | 154M/170M [06:41&lt;00:48, 346kB/s]
 90%|█████████ | 154M/170M [06:41&lt;00:48, 348kB/s]
 90%|█████████ | 154M/170M [06:41&lt;00:47, 352kB/s]
 90%|█████████ | 154M/170M [06:41&lt;00:49, 338kB/s]
 90%|█████████ | 154M/170M [06:41&lt;00:45, 362kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:47, 350kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:46, 353kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:46, 356kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:45, 356kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:45, 355kB/s]
 90%|█████████ | 154M/170M [06:42&lt;00:45, 357kB/s]
 91%|█████████ | 154M/170M [06:43&lt;00:47, 339kB/s]
 91%|█████████ | 154M/170M [06:43&lt;00:45, 355kB/s]
 91%|█████████ | 154M/170M [06:43&lt;00:45, 355kB/s]
 91%|█████████ | 155M/170M [06:43&lt;00:44, 358kB/s]
 91%|█████████ | 155M/170M [06:43&lt;00:44, 358kB/s]
 91%|█████████ | 155M/170M [06:44&lt;00:46, 344kB/s]
 91%|█████████ | 155M/170M [06:44&lt;00:45, 349kB/s]
 91%|█████████ | 155M/170M [06:44&lt;00:44, 353kB/s]
 91%|█████████ | 155M/170M [06:44&lt;00:44, 354kB/s]
 91%|█████████ | 155M/170M [06:44&lt;00:43, 354kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:45, 344kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:44, 347kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:44, 349kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:43, 353kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:42, 358kB/s]
 91%|█████████ | 155M/170M [06:45&lt;00:43, 345kB/s]
 91%|█████████ | 155M/170M [06:46&lt;00:43, 348kB/s]
 91%|█████████ | 155M/170M [06:46&lt;00:42, 353kB/s]
 91%|█████████ | 156M/170M [06:46&lt;00:42, 354kB/s]
 91%|█████████▏| 156M/170M [06:46&lt;00:41, 357kB/s]
 91%|█████████▏| 156M/170M [06:46&lt;00:43, 345kB/s]
 91%|█████████▏| 156M/170M [06:47&lt;00:44, 334kB/s]
 91%|█████████▏| 156M/170M [06:47&lt;00:40, 361kB/s]
 91%|█████████▏| 156M/170M [06:47&lt;00:40, 362kB/s]
 91%|█████████▏| 156M/170M [06:47&lt;00:40, 361kB/s]
 91%|█████████▏| 156M/170M [06:47&lt;00:40, 363kB/s]
 92%|█████████▏| 156M/170M [06:47&lt;00:41, 347kB/s]
 92%|█████████▏| 156M/170M [06:48&lt;00:40, 352kB/s]
 92%|█████████▏| 156M/170M [06:48&lt;00:40, 351kB/s]
 92%|█████████▏| 156M/170M [06:48&lt;00:41, 341kB/s]
 92%|█████████▏| 156M/170M [06:48&lt;00:38, 368kB/s]
 92%|█████████▏| 156M/170M [06:48&lt;00:39, 354kB/s]
 92%|█████████▏| 156M/170M [06:49&lt;00:39, 356kB/s]
 92%|█████████▏| 156M/170M [06:49&lt;00:38, 359kB/s]
 92%|█████████▏| 157M/170M [06:49&lt;00:38, 361kB/s]
 92%|█████████▏| 157M/170M [06:49&lt;00:38, 363kB/s]
 92%|█████████▏| 157M/170M [06:49&lt;00:39, 353kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:40, 341kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:37, 364kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:36, 368kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:37, 366kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:38, 353kB/s]
 92%|█████████▏| 157M/170M [06:50&lt;00:37, 356kB/s]
 92%|█████████▏| 157M/170M [06:51&lt;00:36, 361kB/s]
 92%|█████████▏| 157M/170M [06:51&lt;00:36, 360kB/s]
 92%|█████████▏| 157M/170M [06:51&lt;00:36, 364kB/s]
 92%|█████████▏| 157M/170M [06:51&lt;00:37, 350kB/s]
 92%|█████████▏| 157M/170M [06:51&lt;00:36, 359kB/s]
 92%|█████████▏| 157M/170M [06:52&lt;00:36, 361kB/s]
 92%|█████████▏| 158M/170M [06:52&lt;00:35, 366kB/s]
 92%|█████████▏| 158M/170M [06:52&lt;00:35, 366kB/s]
 92%|█████████▏| 158M/170M [06:52&lt;00:35, 366kB/s]
 93%|█████████▎| 158M/170M [06:52&lt;00:35, 356kB/s]
 93%|█████████▎| 158M/170M [06:52&lt;00:35, 359kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:35, 360kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:34, 366kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:34, 366kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:34, 355kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:34, 358kB/s]
 93%|█████████▎| 158M/170M [06:53&lt;00:34, 360kB/s]
 93%|█████████▎| 158M/170M [06:54&lt;00:34, 359kB/s]
 93%|█████████▎| 158M/170M [06:54&lt;00:34, 350kB/s]
 93%|█████████▎| 158M/170M [06:54&lt;00:33, 359kB/s]
 93%|█████████▎| 158M/170M [06:54&lt;00:33, 362kB/s]
 93%|█████████▎| 159M/170M [06:54&lt;00:34, 347kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:31, 373kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:31, 372kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:32, 360kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:32, 360kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:32, 361kB/s]
 93%|█████████▎| 159M/170M [06:55&lt;00:31, 368kB/s]
 93%|█████████▎| 159M/170M [06:56&lt;00:31, 366kB/s]
 93%|█████████▎| 159M/170M [06:56&lt;00:31, 365kB/s]
 93%|█████████▎| 159M/170M [06:56&lt;00:32, 355kB/s]
 93%|█████████▎| 159M/170M [06:56&lt;00:31, 358kB/s]
 93%|█████████▎| 159M/170M [06:56&lt;00:31, 360kB/s]
 93%|█████████▎| 159M/170M [06:57&lt;00:30, 365kB/s]
 93%|█████████▎| 159M/170M [06:57&lt;00:30, 367kB/s]
 94%|█████████▎| 159M/170M [06:57&lt;00:31, 355kB/s]
 94%|█████████▎| 160M/170M [06:57&lt;00:30, 357kB/s]
 94%|█████████▎| 160M/170M [06:57&lt;00:30, 359kB/s]
 94%|█████████▎| 160M/170M [06:57&lt;00:29, 365kB/s]
 94%|█████████▎| 160M/170M [06:58&lt;00:29, 365kB/s]
 94%|█████████▎| 160M/170M [06:58&lt;00:30, 355kB/s]
 94%|█████████▍| 160M/170M [06:58&lt;00:29, 358kB/s]
 94%|█████████▍| 160M/170M [06:58&lt;00:29, 362kB/s]
 94%|█████████▍| 160M/170M [06:58&lt;00:28, 365kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:28, 364kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:29, 354kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:28, 356kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:28, 359kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:27, 364kB/s]
 94%|█████████▍| 160M/170M [06:59&lt;00:27, 365kB/s]
 94%|█████████▍| 160M/170M [07:00&lt;00:28, 353kB/s]
 94%|█████████▍| 160M/170M [07:00&lt;00:28, 354kB/s]
 94%|█████████▍| 161M/170M [07:00&lt;00:27, 361kB/s]
 94%|█████████▍| 161M/170M [07:00&lt;00:27, 365kB/s]
 94%|█████████▍| 161M/170M [07:00&lt;00:26, 367kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:26, 367kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:27, 356kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:26, 359kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:26, 358kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:26, 364kB/s]
 94%|█████████▍| 161M/170M [07:01&lt;00:25, 363kB/s]
 95%|█████████▍| 161M/170M [07:02&lt;00:27, 334kB/s]
 95%|█████████▍| 161M/170M [07:02&lt;00:25, 362kB/s]
 95%|█████████▍| 161M/170M [07:02&lt;00:25, 363kB/s]
 95%|█████████▍| 161M/170M [07:02&lt;00:25, 366kB/s]
 95%|█████████▍| 161M/170M [07:02&lt;00:24, 367kB/s]
 95%|█████████▍| 161M/170M [07:03&lt;00:25, 352kB/s]
 95%|█████████▍| 162M/170M [07:03&lt;00:25, 351kB/s]
 95%|█████████▍| 162M/170M [07:03&lt;00:24, 359kB/s]
 95%|█████████▍| 162M/170M [07:03&lt;00:25, 342kB/s]
 95%|█████████▍| 162M/170M [07:03&lt;00:23, 369kB/s]
 95%|█████████▍| 162M/170M [07:04&lt;00:24, 357kB/s]
 95%|█████████▍| 162M/170M [07:04&lt;00:24, 356kB/s]
 95%|█████████▍| 162M/170M [07:04&lt;00:23, 360kB/s]
 95%|█████████▌| 162M/170M [07:04&lt;00:23, 365kB/s]
 95%|█████████▌| 162M/170M [07:04&lt;00:23, 361kB/s]
 95%|█████████▌| 162M/170M [07:04&lt;00:23, 354kB/s]
 95%|█████████▌| 162M/170M [07:05&lt;00:23, 354kB/s]
 95%|█████████▌| 162M/170M [07:05&lt;00:23, 353kB/s]
 95%|█████████▌| 162M/170M [07:05&lt;00:22, 365kB/s]
 95%|█████████▌| 162M/170M [07:05&lt;00:22, 361kB/s]
 95%|█████████▌| 162M/170M [07:05&lt;00:22, 363kB/s]
 95%|█████████▌| 163M/170M [07:06&lt;00:22, 352kB/s]
 95%|█████████▌| 163M/170M [07:06&lt;00:22, 357kB/s]
 95%|█████████▌| 163M/170M [07:06&lt;00:22, 356kB/s]
 95%|█████████▌| 163M/170M [07:06&lt;00:21, 359kB/s]
 95%|█████████▌| 163M/170M [07:06&lt;00:21, 359kB/s]
 96%|█████████▌| 163M/170M [07:06&lt;00:21, 353kB/s]
 96%|█████████▌| 163M/170M [07:07&lt;00:21, 357kB/s]
 96%|█████████▌| 163M/170M [07:07&lt;00:21, 356kB/s]
 96%|█████████▌| 163M/170M [07:07&lt;00:20, 363kB/s]
 96%|█████████▌| 163M/170M [07:07&lt;00:20, 362kB/s]
 96%|█████████▌| 163M/170M [07:07&lt;00:20, 349kB/s]
 96%|█████████▌| 163M/170M [07:08&lt;00:20, 353kB/s]
 96%|█████████▌| 163M/170M [07:08&lt;00:20, 357kB/s]
 96%|█████████▌| 163M/170M [07:08&lt;00:19, 362kB/s]
 96%|█████████▌| 163M/170M [07:08&lt;00:19, 359kB/s]
 96%|█████████▌| 164M/170M [07:08&lt;00:19, 350kB/s]
 96%|█████████▌| 164M/170M [07:08&lt;00:20, 340kB/s]
 96%|█████████▌| 164M/170M [07:09&lt;00:18, 366kB/s]
 96%|█████████▌| 164M/170M [07:09&lt;00:18, 367kB/s]
 96%|█████████▌| 164M/170M [07:09&lt;00:18, 363kB/s]
 96%|█████████▌| 164M/170M [07:09&lt;00:20, 327kB/s]
 96%|█████████▌| 164M/170M [07:09&lt;00:18, 352kB/s]
 96%|█████████▌| 164M/170M [07:10&lt;00:17, 363kB/s]
 96%|█████████▌| 164M/170M [07:10&lt;00:17, 366kB/s]
 96%|█████████▌| 164M/170M [07:10&lt;00:17, 365kB/s]
 96%|█████████▋| 164M/170M [07:10&lt;00:17, 367kB/s]
 96%|█████████▋| 164M/170M [07:10&lt;00:18, 330kB/s]
 96%|█████████▋| 164M/170M [07:11&lt;00:18, 328kB/s]
 96%|█████████▋| 164M/170M [07:11&lt;00:17, 354kB/s]
 96%|█████████▋| 164M/170M [07:11&lt;00:16, 361kB/s]
 96%|█████████▋| 164M/170M [07:11&lt;00:17, 351kB/s]
 97%|█████████▋| 165M/170M [07:11&lt;00:17, 348kB/s]
 97%|█████████▋| 165M/170M [07:11&lt;00:16, 362kB/s]
 97%|█████████▋| 165M/170M [07:12&lt;00:15, 365kB/s]
 97%|█████████▋| 165M/170M [07:12&lt;00:15, 367kB/s]
 97%|█████████▋| 165M/170M [07:12&lt;00:15, 367kB/s]
 97%|█████████▋| 165M/170M [07:12&lt;00:15, 355kB/s]
 97%|█████████▋| 165M/170M [07:12&lt;00:15, 358kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:15, 360kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:14, 362kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:14, 371kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:14, 356kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:14, 358kB/s]
 97%|█████████▋| 165M/170M [07:13&lt;00:14, 364kB/s]
 97%|█████████▋| 165M/170M [07:14&lt;00:14, 363kB/s]
 97%|█████████▋| 165M/170M [07:14&lt;00:13, 362kB/s]
 97%|█████████▋| 166M/170M [07:14&lt;00:14, 350kB/s]
 97%|█████████▋| 166M/170M [07:14&lt;00:13, 356kB/s]
 97%|█████████▋| 166M/170M [07:14&lt;00:13, 363kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:13, 362kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:12, 362kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:12, 367kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:12, 351kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:12, 356kB/s]
 97%|█████████▋| 166M/170M [07:15&lt;00:12, 355kB/s]
 97%|█████████▋| 166M/170M [07:16&lt;00:12, 361kB/s]
 97%|█████████▋| 166M/170M [07:16&lt;00:11, 366kB/s]
 98%|█████████▊| 166M/170M [07:16&lt;00:12, 351kB/s]
 98%|█████████▊| 166M/170M [07:16&lt;00:11, 353kB/s]
 98%|█████████▊| 166M/170M [07:16&lt;00:11, 348kB/s]
 98%|█████████▊| 166M/170M [07:17&lt;00:11, 358kB/s]
 98%|█████████▊| 167M/170M [07:17&lt;00:10, 361kB/s]
 98%|█████████▊| 167M/170M [07:17&lt;00:11, 350kB/s]
 98%|█████████▊| 167M/170M [07:17&lt;00:10, 353kB/s]
 98%|█████████▊| 167M/170M [07:17&lt;00:10, 360kB/s]
 98%|█████████▊| 167M/170M [07:17&lt;00:10, 359kB/s]
 98%|█████████▊| 167M/170M [07:18&lt;00:10, 349kB/s]
 98%|█████████▊| 167M/170M [07:18&lt;00:10, 350kB/s]
 98%|█████████▊| 167M/170M [07:18&lt;00:09, 358kB/s]
 98%|█████████▊| 167M/170M [07:18&lt;00:09, 364kB/s]
 98%|█████████▊| 167M/170M [07:18&lt;00:09, 362kB/s]
 98%|█████████▊| 167M/170M [07:19&lt;00:09, 363kB/s]
 98%|█████████▊| 167M/170M [07:19&lt;00:08, 367kB/s]
 98%|█████████▊| 167M/170M [07:19&lt;00:09, 352kB/s]
 98%|█████████▊| 167M/170M [07:19&lt;00:08, 353kB/s]
 98%|█████████▊| 167M/170M [07:19&lt;00:08, 353kB/s]
 98%|█████████▊| 168M/170M [07:19&lt;00:08, 361kB/s]
 98%|█████████▊| 168M/170M [07:20&lt;00:08, 364kB/s]
 98%|█████████▊| 168M/170M [07:20&lt;00:08, 353kB/s]
 98%|█████████▊| 168M/170M [07:20&lt;00:07, 361kB/s]
 98%|█████████▊| 168M/170M [07:20&lt;00:07, 362kB/s]
 98%|█████████▊| 168M/170M [07:20&lt;00:07, 362kB/s]
 98%|█████████▊| 168M/170M [07:21&lt;00:07, 368kB/s]
 99%|█████████▊| 168M/170M [07:21&lt;00:07, 352kB/s]
 99%|█████████▊| 168M/170M [07:21&lt;00:06, 353kB/s]
 99%|█████████▊| 168M/170M [07:21&lt;00:06, 359kB/s]
 99%|█████████▊| 168M/170M [07:21&lt;00:06, 359kB/s]
 99%|█████████▊| 168M/170M [07:21&lt;00:06, 365kB/s]
 99%|█████████▊| 168M/170M [07:22&lt;00:06, 350kB/s]
 99%|█████████▊| 168M/170M [07:22&lt;00:06, 346kB/s]
 99%|█████████▉| 168M/170M [07:22&lt;00:05, 363kB/s]
 99%|█████████▉| 168M/170M [07:22&lt;00:05, 361kB/s]
 99%|█████████▉| 169M/170M [07:22&lt;00:05, 361kB/s]
 99%|█████████▉| 169M/170M [07:23&lt;00:05, 353kB/s]
 99%|█████████▉| 169M/170M [07:23&lt;00:05, 350kB/s]
 99%|█████████▉| 169M/170M [07:23&lt;00:04, 356kB/s]
 99%|█████████▉| 169M/170M [07:23&lt;00:04, 358kB/s]
 99%|█████████▉| 169M/170M [07:23&lt;00:04, 357kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:04, 363kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:04, 347kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:04, 341kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:03, 362kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:03, 363kB/s]
 99%|█████████▉| 169M/170M [07:24&lt;00:03, 366kB/s]
 99%|█████████▉| 169M/170M [07:25&lt;00:03, 353kB/s]
 99%|█████████▉| 169M/170M [07:25&lt;00:03, 359kB/s]
 99%|█████████▉| 169M/170M [07:25&lt;00:02, 358kB/s]
 99%|█████████▉| 170M/170M [07:25&lt;00:02, 364kB/s]
 99%|█████████▉| 170M/170M [07:25&lt;00:02, 349kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:02, 349kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:02, 357kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:01, 359kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:01, 362kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:01, 366kB/s]
100%|█████████▉| 170M/170M [07:26&lt;00:01, 349kB/s]
100%|█████████▉| 170M/170M [07:27&lt;00:01, 353kB/s]
100%|█████████▉| 170M/170M [07:27&lt;00:01, 355kB/s]
100%|█████████▉| 170M/170M [07:27&lt;00:00, 354kB/s]
100%|█████████▉| 170M/170M [07:27&lt;00:00, 359kB/s]
100%|█████████▉| 170M/170M [07:27&lt;00:00, 350kB/s]
100%|█████████▉| 170M/170M [07:28&lt;00:00, 350kB/s]
100%|█████████▉| 170M/170M [07:28&lt;00:00, 359kB/s]
100%|██████████| 170M/170M [07:28&lt;00:00, 380kB/s]
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This section is for CPU users only who are interested in quick results. Use this option only if you’re interested in a small scale experiment. Keep in mind the code should run fairly quickly using any GPU. Select only the first <code class="docutils literal notranslate"><span class="pre">num_images_to_keep</span></code> images from the train/test dataset</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#from torch.utils.data import Subset</span>
<span class="c1">#num_images_to_keep = 2000</span>
<span class="c1">#train_dataset = Subset(train_dataset, range(min(num_images_to_keep, 50_000)))</span>
<span class="c1">#test_dataset = Subset(test_dataset, range(min(num_images_to_keep, 10_000)))</span>
</pre></div>
</div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Dataloaders</span>
<a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">train_dataset</span></a><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">test_dataset</span></a><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="defining-model-classes-and-utility-functions">
<h3>Defining model classes and utility functions<a class="headerlink" href="#defining-model-classes-and-utility-functions" title="Link to this heading">#</a></h3>
<p>Next, we need to define our model classes. Several user-defined parameters need to be set here. We use two different architectures, keeping the number of filters fixed across our experiments to ensure fair comparisons.
Both architectures are Convolutional Neural Networks (CNNs) with a different number of convolutional layers that serve as feature extractors, followed by a classifier with 10 classes.
The number of filters and neurons is smaller for the students.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Deeper neural network class to be used as teacher:</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DeepNN</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">DeepNN</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="c1"># Lightweight neural network class to be used as student:</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LightNN</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">LightNN</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<p>We employ 2 functions to help us produce and evaluate the results on our original classification task.
One function is called <code class="docutils literal notranslate"><span class="pre">train</span></code> and takes the following arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: A model instance to train (update its weights) via this function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_loader</span></code>: We defined our <code class="docutils literal notranslate"><span class="pre">train_loader</span></code> above, and its job is to feed the data into the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: How many times we loop over the dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>: The learning rate determines how large our steps towards convergence should be. Too large or too small steps can be detrimental.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device</span></code>: Determines the device to run the workload on. Can be either CPU or GPU depending on availability.</p></li>
</ul>
<p>Our test function is similar, but it will be invoked with <code class="docutils literal notranslate"><span class="pre">test_loader</span></code> to load images from the test set.</p>
<figure class="align-center" id="id2">
<img alt="../_static/img/knowledge_distillation/ce_only.png" src="../_static/img/knowledge_distillation/ce_only.png"/>
<figcaption>
<p><span class="caption-text">Train both networks with Cross-Entropy. The student will be used as a baseline:</span><a class="headerlink" href="#id2" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">criterion</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">:</span>
            <span class="c1"># inputs: A collection of batch_size images</span>
            <span class="c1"># labels: A vector of dimensionality batch_size with integers denoting class of each image</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes</span>
            <span class="c1"># labels: The actual labels of the images. Vector of dimensionality batch_size</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.max.html#torch.max" title="torch.max"><span class="n">torch</span><span class="o">.</span><span class="n">max</span></a><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
</section>
<section id="cross-entropy-runs">
<h3>Cross-entropy runs<a class="headerlink" href="#cross-entropy-runs" title="Link to this heading">#</a></h3>
<p>For reproducibility, we need to set the torch manual seed. We train networks using different methods, so to compare them fairly,
it makes sense to initialize the networks with the same weights.
Start by training the teacher network using cross-entropy:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">nn_deep</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">DeepNN</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">train</span><span class="p">(</span><span class="n">nn_deep</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_accuracy_deep</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">nn_deep</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="c1"># Instantiate the lightweight network:</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">nn_light</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">LightNN</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Loss: 1.3271830167306964
Epoch 2/10, Loss: 0.8552837539511873
Epoch 3/10, Loss: 0.6703156300670351
Epoch 4/10, Loss: 0.5238153989357717
Epoch 5/10, Loss: 0.4080631322872913
Epoch 6/10, Loss: 0.30342950422288206
Epoch 7/10, Loss: 0.21514463859141025
Epoch 8/10, Loss: 0.16292207244107182
Epoch 9/10, Loss: 0.13193816674487366
Epoch 10/10, Loss: 0.12099153160229516
Test Accuracy: 75.70%
</pre></div>
</div>
<p>We instantiate one more lightweight network model to compare their performances.
Back propagation is sensitive to weight initialization,
so we need to make sure these two networks have the exact same initialization.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">new_nn_light</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">LightNN</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>To ensure we have created a copy of the first network, we inspect the norm of its first layer.
If it matches, then we are safe to conclude that the networks are indeed the same.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the norm of the first layer of the initial lightweight model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Norm of 1st layer of nn_light:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><span class="n">torch</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn_light</span><span class="o">.</span><span class="n">features</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<span class="c1"># Print the norm of the first layer of the new lightweight model</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Norm of 1st layer of new_nn_light:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><span class="n">torch</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">new_nn_light</span><span class="o">.</span><span class="n">features</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Norm of 1st layer of nn_light: 2.327361822128296
Norm of 1st layer of new_nn_light: 2.327361822128296
</pre></div>
</div>
<p>Print the total number of parameters in each model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">total_params_deep</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{:,}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters"><span class="n">nn_deep</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"DeepNN parameters: </span><span class="si">{</span><span class="n">total_params_deep</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">total_params_light</span> <span class="o">=</span> <span class="s2">"</span><span class="si">{:,}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters" title="torch.nn.Module.parameters"><span class="n">nn_light</span><span class="o">.</span><span class="n">parameters</span></a><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"LightNN parameters: </span><span class="si">{</span><span class="n">total_params_light</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DeepNN parameters: 1,186,986
LightNN parameters: 267,738
</pre></div>
</div>
<p>Train and test the lightweight network with cross entropy loss:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_accuracy_light_ce</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Loss: 1.4671805133600064
Epoch 2/10, Loss: 1.1543215095539532
Epoch 3/10, Loss: 1.0236207388551033
Epoch 4/10, Loss: 0.9234162407457981
Epoch 5/10, Loss: 0.8482010568804144
Epoch 6/10, Loss: 0.7826402989189948
Epoch 7/10, Loss: 0.716707373519078
Epoch 8/10, Loss: 0.6562516083345389
Epoch 9/10, Loss: 0.6045231478445975
Epoch 10/10, Loss: 0.5522129790252431
Test Accuracy: 70.20%
</pre></div>
</div>
<p>As we can see, based on test accuracy, we can now compare the deeper network that is to be used as a teacher with the lightweight network that is our supposed student. So far, our student has not intervened with the teacher, therefore this performance is achieved by the student itself.
The metrics so far can be seen with the following lines:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Teacher accuracy: </span><span class="si">{</span><span class="n">test_accuracy_deep</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy: </span><span class="si">{</span><span class="n">test_accuracy_light_ce</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Teacher accuracy: 75.70%
Student accuracy: 70.20%
</pre></div>
</div>
</section>
<section id="knowledge-distillation-run">
<h3>Knowledge distillation run<a class="headerlink" href="#knowledge-distillation-run" title="Link to this heading">#</a></h3>
<p>Now let’s try to improve the test accuracy of the student network by incorporating the teacher.
Knowledge distillation is a straightforward technique to achieve this,
based on the fact that both networks output a probability distribution over our classes.
Therefore, the two networks share the same number of output neurons.
The method works by incorporating an additional loss into the traditional cross entropy loss,
which is based on the softmax output of the teacher network.
The assumption is that the output activations of a properly trained teacher network carry additional information that can be leveraged by a student network during training.
The original work suggests that utilizing ratios of smaller probabilities in the soft targets can help achieve the underlying objective of deep neural networks,
which is to create a similarity structure over the data where similar objects are mapped closer together.
For example, in CIFAR-10, a truck could be mistaken for an automobile or airplane,
if its wheels are present, but it is less likely to be mistaken for a dog.
Therefore, it makes sense to assume that valuable information resides not only in the top prediction of a properly trained model but in the entire output distribution.
However, cross entropy alone does not sufficiently exploit this information as the activations for non-predicted classes
tend to be so small that propagated gradients do not meaningfully change the weights to construct this desirable vector space.</p>
<p>As we continue defining our first helper function that introduces a teacher-student dynamic, we need to include a few extra parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">T</span></code>: Temperature controls the smoothness of the output distributions. Larger <code class="docutils literal notranslate"><span class="pre">T</span></code> leads to smoother distributions, thus smaller probabilities get a larger boost.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">soft_target_loss_weight</span></code>: A weight assigned to the extra objective we’re about to include.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ce_loss_weight</span></code>: A weight assigned to cross-entropy. Tuning these weights pushes the network towards optimizing for either objective.</p></li>
</ul>
<figure class="align-center" id="id3">
<img alt="../_static/img/knowledge_distillation/distillation_output_loss.png" src="../_static/img/knowledge_distillation/distillation_output_loss.png"/>
<figcaption>
<p><span class="caption-text">Distillation loss is calculated from the logits of the networks. It only returns gradients to the student:</span><a class="headerlink" href="#id3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_knowledge_distillation</span><span class="p">(</span><span class="n">teacher</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">soft_target_loss_weight</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">ce_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">teacher</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Teacher set to evaluation mode</span>
    <span class="n">student</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Student to train mode</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights</span>
            <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="n">teacher_logits</span> <span class="o">=</span> <span class="n">teacher</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Forward pass with the student model</span>
            <span class="n">student_logits</span> <span class="o">=</span> <span class="n">student</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1">#Soften the student logits by applying softmax first and log() second</span>
            <span class="n">soft_targets</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span></a><span class="p">(</span><span class="n">teacher_logits</span> <span class="o">/</span> <span class="n">T</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">soft_prob</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax" title="torch.nn.functional.log_softmax"><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span></a><span class="p">(</span><span class="n">student_logits</span> <span class="o">/</span> <span class="n">T</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper "Distilling the knowledge in a neural network"</span>
            <span class="n">soft_targets_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sum.html#torch.sum" title="torch.sum"><span class="n">torch</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">soft_targets</span> <span class="o">*</span> <span class="p">(</span><span class="n">soft_targets</span><span class="o">.</span><span class="n">log</span><span class="p">()</span> <span class="o">-</span> <span class="n">soft_prob</span><span class="p">))</span> <span class="o">/</span> <span class="n">soft_prob</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">T</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

            <span class="c1"># Calculate the true label loss</span>
            <span class="n">label_loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># Weighted sum of the two losses</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">soft_target_loss_weight</span> <span class="o">*</span> <span class="n">soft_targets_loss</span> <span class="o">+</span> <span class="n">ce_loss_weight</span> <span class="o">*</span> <span class="n">label_loss</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.</span>
<span class="n">train_knowledge_distillation</span><span class="p">(</span><span class="n">teacher</span><span class="o">=</span><span class="n">nn_deep</span><span class="p">,</span> <span class="n">student</span><span class="o">=</span><span class="n">new_nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">soft_target_loss_weight</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_accuracy_light_ce_and_kd</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">new_nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="c1"># Compare the student test accuracy with and without the teacher, after distillation</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Teacher accuracy: </span><span class="si">{</span><span class="n">test_accuracy_deep</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy without teacher: </span><span class="si">{</span><span class="n">test_accuracy_light_ce</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy with CE + KD: </span><span class="si">{</span><span class="n">test_accuracy_light_ce_and_kd</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Loss: 2.382784129103736
Epoch 2/10, Loss: 1.8663179859176011
Epoch 3/10, Loss: 1.6426248407119985
Epoch 4/10, Loss: 1.4837263118275597
Epoch 5/10, Loss: 1.357022206344263
Epoch 6/10, Loss: 1.2425179967794882
Epoch 7/10, Loss: 1.1478852298863405
Epoch 8/10, Loss: 1.0633694465507937
Epoch 9/10, Loss: 0.9885236020283321
Epoch 10/10, Loss: 0.9223598107657469
Test Accuracy: 70.79%
Teacher accuracy: 75.70%
Student accuracy without teacher: 70.20%
Student accuracy with CE + KD: 70.79%
</pre></div>
</div>
</section>
<section id="cosine-loss-minimization-run">
<h3>Cosine loss minimization run<a class="headerlink" href="#cosine-loss-minimization-run" title="Link to this heading">#</a></h3>
<p>Feel free to play around with the temperature parameter that controls the softness of the softmax function and the loss coefficients.
In neural networks, it is easy to include additional loss functions to the main objectives to achieve goals like better generalization.
Let’s try including an objective for the student, but now let’s focus on their hidden states rather than their output layers.
Our goal is to convey information from the teacher’s representation to the student by including a naive loss function,
whose minimization implies that the flattened vectors that are subsequently passed to the classifiers have become more <em>similar</em> as the loss decreases.
Of course, the teacher does not update its weights, so the minimization depends only on the student’s weights.
The rationale behind this method is that we are operating under the assumption that the teacher model has a better internal representation that is
unlikely to be achieved by the student without external intervention, therefore we artificially push the student to mimic the internal representation of the teacher.
Whether or not this will end up helping the student is not straightforward, though, because pushing the lightweight network
to reach this point could be a good thing, assuming that we have found an internal representation that leads to better test accuracy,
but it could also be harmful because the networks have different architectures and the student does not have the same learning capacity as the teacher.
In other words, there is no reason for these two vectors, the student’s and the teacher’s to match per component.
The student could reach an internal representation that is a permutation of the teacher’s and it would be just as efficient.
Nonetheless, we can still run a quick experiment to figure out the impact of this method.
We will be using the <code class="docutils literal notranslate"><span class="pre">CosineEmbeddingLoss</span></code> which is given by the following formula:</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="../_static/img/knowledge_distillation/cosine_embedding_loss.png"><img alt="../_static/img/knowledge_distillation/cosine_embedding_loss.png" src="../_static/img/knowledge_distillation/cosine_embedding_loss.png" style="width: 450px;"/></a>
<figcaption>
<p><span class="caption-text">Formula for CosineEmbeddingLoss</span><a class="headerlink" href="#id4" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Obviously, there is one thing that we need to resolve first.
When we applied distillation to the output layer we mentioned that both networks have the same number of neurons, equal to the number of classes.
However, this is not the case for the layer following our convolutional layers. Here, the teacher has more neurons than the student
after the flattening of the final convolutional layer. Our loss function accepts two vectors of equal dimensionality as inputs,
therefore we need to somehow match them. We will solve this by including an average pooling layer after the teacher’s convolutional layer to reduce its dimensionality to match that of the student.</p>
<p>To proceed, we will modify our model classes, or create new ones.
Now, the forward function returns not only the logits of the network but also the flattened hidden representation after the convolutional layer. We include the aforementioned pooling for the modified teacher.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ModifiedDeepNNCosine</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedDeepNNCosine</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">flattened_conv_output</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">flattened_conv_output</span><span class="p">)</span>
        <span class="n">flattened_conv_output_after_pooling</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.avg_pool1d.html#torch.nn.functional.avg_pool1d" title="torch.nn.functional.avg_pool1d"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool1d</span></a><span class="p">(</span><span class="n">flattened_conv_output</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">flattened_conv_output_after_pooling</span>

<span class="c1"># Create a similar student class where we return a tuple. We do not apply pooling after flattening.</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ModifiedLightNNCosine</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedLightNNCosine</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">flattened_conv_output</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">flattened_conv_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">flattened_conv_output</span>

<span class="c1"># We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance</span>
<span class="n">modified_nn_deep</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedDeepNNCosine</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><span class="n">modified_nn_deep</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><span class="n">nn_deep</span><span class="o">.</span><span class="n">state_dict</span></a><span class="p">())</span>

<span class="c1"># Once again ensure the norm of the first layer is the same for both networks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Norm of 1st layer for deep_nn:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><span class="n">torch</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn_deep</span><span class="o">.</span><span class="n">features</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Norm of 1st layer for modified_deep_nn:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><span class="n">torch</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">modified_nn_deep</span><span class="o">.</span><span class="n">features</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

<span class="c1"># Initialize a modified lightweight network with the same seed as our other lightweight instances. This will be trained from scratch to examine the effectiveness of cosine loss minimization.</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">modified_nn_light</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedLightNNCosine</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Norm of 1st layer:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.norm.html#torch.norm" title="torch.norm"><span class="n">torch</span><span class="o">.</span><span class="n">norm</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">modified_nn_light</span><span class="o">.</span><span class="n">features</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Norm of 1st layer for deep_nn: 7.484958648681641
Norm of 1st layer for modified_deep_nn: 7.484958648681641
Norm of 1st layer: 2.327361822128296
</pre></div>
</div>
<p>Naturally, we need to change the train loop because now the model returns a tuple <code class="docutils literal notranslate"><span class="pre">(logits,</span> <span class="pre">hidden_representation)</span></code>. Using a sample input tensor
we can print their shapes.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a sample input tensor</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">sample_input</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Batch size: 128, Filters: 3, Image size: 32x32</span>

<span class="c1"># Pass the input through the student</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">logits</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">hidden_representation</span></a> <span class="o">=</span> <span class="n">modified_nn_light</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">sample_input</span></a><span class="p">)</span>

<span class="c1"># Print the shapes of the tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Student logits shape:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">logits</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span> <span class="c1"># batch_size x total_classes</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Student hidden representation shape:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">hidden_representation</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span> <span class="c1"># batch_size x hidden_representation_size</span>

<span class="c1"># Pass the input through the teacher</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">logits</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">hidden_representation</span></a> <span class="o">=</span> <span class="n">modified_nn_deep</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">sample_input</span></a><span class="p">)</span>

<span class="c1"># Print the shapes of the tensors</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Teacher logits shape:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">logits</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span> <span class="c1"># batch_size x total_classes</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Teacher hidden representation shape:"</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">hidden_representation</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span> <span class="c1"># batch_size x hidden_representation_size</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Student logits shape: torch.Size([128, 10])
Student hidden representation shape: torch.Size([128, 1024])
Teacher logits shape: torch.Size([128, 10])
Teacher hidden representation shape: torch.Size([128, 1024])
</pre></div>
</div>
<p>In our case, <code class="docutils literal notranslate"><span class="pre">hidden_representation_size</span></code> is <code class="docutils literal notranslate"><span class="pre">1024</span></code>. This is the flattened feature map of the final convolutional layer of the student and as you can see,
it is the input for its classifier. It is <code class="docutils literal notranslate"><span class="pre">1024</span></code> for the teacher too, because we made it so with <code class="docutils literal notranslate"><span class="pre">avg_pool1d</span></code> from <code class="docutils literal notranslate"><span class="pre">2048</span></code>.
The loss applied here only affects the weights of the student prior to the loss calculation. In other words, it does not affect the classifier of the student.
The modified training loop is the following:</p>
<figure class="align-center" id="id5">
<img alt="../_static/img/knowledge_distillation/cosine_loss_distillation.png" src="../_static/img/knowledge_distillation/cosine_loss_distillation.png"/>
<figcaption>
<p><span class="caption-text">In Cosine Loss minimization, we want to maximize the cosine similarity of the two representations by returning gradients to the student:</span><a class="headerlink" href="#id5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_cosine_loss</span><span class="p">(</span><span class="n">teacher</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">hidden_rep_loss_weight</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">ce_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span>
    <span class="n">cosine_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss" title="torch.nn.CosineEmbeddingLoss"><span class="n">nn</span><span class="o">.</span><span class="n">CosineEmbeddingLoss</span></a><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">teacher</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">student</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">teacher</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Teacher set to evaluation mode</span>
    <span class="n">student</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Student to train mode</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Forward pass with the teacher model and keep only the hidden representation</span>
            <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">teacher_hidden_representation</span> <span class="o">=</span> <span class="n">teacher</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Forward pass with the student model</span>
            <span class="n">student_logits</span><span class="p">,</span> <span class="n">student_hidden_representation</span> <span class="o">=</span> <span class="n">student</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.</span>
            <span class="n">hidden_rep_loss</span> <span class="o">=</span> <span class="n">cosine_loss</span><span class="p">(</span><span class="n">student_hidden_representation</span><span class="p">,</span> <span class="n">teacher_hidden_representation</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

            <span class="c1"># Calculate the true label loss</span>
            <span class="n">label_loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># Weighted sum of the two losses</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">hidden_rep_loss_weight</span> <span class="o">*</span> <span class="n">hidden_rep_loss</span> <span class="o">+</span> <span class="n">ce_loss_weight</span> <span class="o">*</span> <span class="n">label_loss</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
<p>We need to modify our test function for the same reason. Here we ignore the hidden representation returned by the model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">test_multiple_outputs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">outputs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="c1"># Disregard the second tensor of the tuple</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.max.html#torch.max" title="torch.max"><span class="n">torch</span><span class="o">.</span><span class="n">max</span></a><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Test Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>
</div>
<p>In this case, we could easily include both knowledge distillation and cosine loss minimization in the same function. It is common to combine methods to achieve better performance in teacher-student paradigms.
For now, we can run a simple train-test session.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train and test the lightweight network with cross entropy loss</span>
<span class="n">train_cosine_loss</span><span class="p">(</span><span class="n">teacher</span><span class="o">=</span><span class="n">modified_nn_deep</span><span class="p">,</span> <span class="n">student</span><span class="o">=</span><span class="n">modified_nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">hidden_rep_loss_weight</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_accuracy_light_ce_and_cosine_loss</span> <span class="o">=</span> <span class="n">test_multiple_outputs</span><span class="p">(</span><span class="n">modified_nn_light</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Loss: 1.3022451111117896
Epoch 2/10, Loss: 1.069513086315311
Epoch 3/10, Loss: 0.9664173464640937
Epoch 4/10, Loss: 0.8912734627113927
Epoch 5/10, Loss: 0.8368349814658884
Epoch 6/10, Loss: 0.7920724071200241
Epoch 7/10, Loss: 0.7531237022956009
Epoch 8/10, Loss: 0.7154772927998887
Epoch 9/10, Loss: 0.6751815193449445
Epoch 10/10, Loss: 0.6528371971891359
Test Accuracy: 70.17%
</pre></div>
</div>
</section>
<section id="intermediate-regressor-run">
<h3>Intermediate regressor run<a class="headerlink" href="#intermediate-regressor-run" title="Link to this heading">#</a></h3>
<p>Our naive minimization does not guarantee better results for several reasons, one being the dimensionality of the vectors.
Cosine similarity generally works better than Euclidean distance for vectors of higher dimensionality,
but we were dealing with vectors with 1024 components each, so it is much harder to extract meaningful similarities.
Furthermore, as we mentioned, pushing towards a match of the hidden representation of the teacher and the student is not supported by theory.
There are no good reasons why we should be aiming for a 1:1 match of these vectors.
We will provide a final example of training intervention by including an extra network called regressor.
The objective is to first extract the feature map of the teacher after a convolutional layer,
then extract a feature map of the student after a convolutional layer, and finally try to match these maps.
However, this time, we will introduce a regressor between the networks to facilitate the matching process.
The regressor will be trainable and ideally will do a better job than our naive cosine loss minimization scheme.
Its main job is to match the dimensionality of these feature maps so that we can properly define a loss function between the teacher and the student.
Defining such a loss function provides a teaching “path,” which is basically a flow to back-propagate gradients that will change the student’s weights.
Focusing on the output of the convolutional layers right before each classifier for our original networks, we have the following shapes:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pass the sample input only from the convolutional feature extractor</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">convolutional_fe_output_student</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn_light</span><span class="o">.</span><span class="n">features</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">sample_input</span></a><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">convolutional_fe_output_teacher</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn_deep</span><span class="o">.</span><span class="n">features</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">sample_input</span></a><span class="p">)</span>

<span class="c1"># Print their shapes</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Student's feature extractor output shape: "</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">convolutional_fe_output_student</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Teacher's feature extractor output shape: "</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">convolutional_fe_output_teacher</span><span class="o">.</span><span class="n">shape</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Student's feature extractor output shape:  torch.Size([128, 16, 8, 8])
Teacher's feature extractor output shape:  torch.Size([128, 32, 8, 8])
</pre></div>
</div>
<p>We have 32 filters for the teacher and 16 filters for the student.
We will include a trainable layer that converts the feature map of the student to the shape of the feature map of the teacher.
In practice, we modify the lightweight class to return the hidden state after an intermediate regressor that matches the sizes of the convolutional
feature maps and the teacher class to return the output of the final convolutional layer without pooling or flattening.</p>
<figure class="align-center" id="id6">
<img alt="../_static/img/knowledge_distillation/fitnets_knowledge_distill.png" src="../_static/img/knowledge_distillation/fitnets_knowledge_distill.png"/>
<figcaption>
<p><span class="caption-text">The trainable layer matches the shapes of the intermediate tensors and Mean Squared Error (MSE) is properly defined:</span><a class="headerlink" href="#id6" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ModifiedDeepNNRegressor</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedDeepNNRegressor</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">conv_feature_map</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">conv_feature_map</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ModifiedLightNNRegressor</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedLightNNRegressor</span></a><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span></a><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="c1"># Include an extra regressor (in our case linear)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="torch.nn.Sequential"><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span></a><span class="p">(</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="torch.nn.ReLU"><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span></a><span class="p">(),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="torch.nn.Dropout"><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>
            <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">regressor_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten" title="torch.flatten"><span class="n">torch</span><span class="o">.</span><span class="n">flatten</span></a><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">regressor_output</span>
</pre></div>
</div>
<p>After that, we have to update our train loop again. This time, we extract the regressor output of the student, the feature map of the teacher,
we calculate the <code class="docutils literal notranslate"><span class="pre">MSE</span></code> on these tensors (they have the exact same shape so it’s properly defined) and we back propagate gradients based on that loss,
in addition to the regular cross entropy loss of the classification task.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train_mse_loss</span><span class="p">(</span><span class="n">teacher</span><span class="p">,</span> <span class="n">student</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">feature_map_weight</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">ce_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span>
    <span class="n">mse_loss</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss" title="torch.nn.MSELoss"><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span></a><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam" title="torch.optim.Adam"><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span></a><span class="p">(</span><span class="n">student</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="n">teacher</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">student</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">teacher</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Teacher set to evaluation mode</span>
    <span class="n">student</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Student to train mode</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># Again ignore teacher logits</span>
            <span class="k">with</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span></a><span class="p">():</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">teacher_feature_map</span> <span class="o">=</span> <span class="n">teacher</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Forward pass with the student model</span>
            <span class="n">student_logits</span><span class="p">,</span> <span class="n">regressor_feature_map</span> <span class="o">=</span> <span class="n">student</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Calculate the loss</span>
            <span class="n">hidden_rep_loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">regressor_feature_map</span><span class="p">,</span> <span class="n">teacher_feature_map</span><span class="p">)</span>

            <span class="c1"># Calculate the true label loss</span>
            <span class="n">label_loss</span> <span class="o">=</span> <span class="n">ce_loss</span><span class="p">(</span><span class="n">student_logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

            <span class="c1"># Weighted sum of the two losses</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">feature_map_weight</span> <span class="o">*</span> <span class="n">hidden_rep_loss</span> <span class="o">+</span> <span class="n">ce_loss_weight</span> <span class="o">*</span> <span class="n">label_loss</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Notice how our test function remains the same here with the one we used in our previous case. We only care about the actual outputs because we measure accuracy.</span>

<span class="c1"># Initialize a ModifiedLightNNRegressor</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span></a><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">modified_nn_light_reg</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedLightNNRegressor</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance</span>
<span class="n">modified_nn_deep_reg</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">ModifiedDeepNNRegressor</span></a><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><span class="n">modified_nn_deep_reg</span><span class="o">.</span><span class="n">load_state_dict</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><span class="n">nn_deep</span><span class="o">.</span><span class="n">state_dict</span></a><span class="p">())</span>

<span class="c1"># Train and test once again</span>
<span class="n">train_mse_loss</span><span class="p">(</span><span class="n">teacher</span><span class="o">=</span><span class="n">modified_nn_deep_reg</span><span class="p">,</span> <span class="n">student</span><span class="o">=</span><span class="n">modified_nn_light_reg</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="o">=</span><a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">train_loader</span></a><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">feature_map_weight</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">ce_loss_weight</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">test_accuracy_light_ce_and_mse_loss</span> <span class="o">=</span> <span class="n">test_multiple_outputs</span><span class="p">(</span><span class="n">modified_nn_light_reg</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">test_loader</span></a><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Epoch 1/10, Loss: 1.6838112078664247
Epoch 2/10, Loss: 1.3166023142197554
Epoch 3/10, Loss: 1.1786157706814349
Epoch 4/10, Loss: 1.0872286506321118
Epoch 5/10, Loss: 1.011615929396256
Epoch 6/10, Loss: 0.9495215641568079
Epoch 7/10, Loss: 0.8970692712632592
Epoch 8/10, Loss: 0.8469349098632403
Epoch 9/10, Loss: 0.807100487639532
Epoch 10/10, Loss: 0.7707832170569379
Test Accuracy: 70.94%
</pre></div>
</div>
<p>It is expected that the final method will work better than <code class="docutils literal notranslate"><span class="pre">CosineLoss</span></code> because now we have allowed a trainable layer between the teacher and the student,
which gives the student some wiggle room when it comes to learning, rather than pushing the student to copy the teacher’s representation.
Including the extra network is the idea behind hint-based distillation.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Teacher accuracy: </span><span class="si">{</span><span class="n">test_accuracy_deep</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy without teacher: </span><span class="si">{</span><span class="n">test_accuracy_light_ce</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy with CE + KD: </span><span class="si">{</span><span class="n">test_accuracy_light_ce_and_kd</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy with CE + CosineLoss: </span><span class="si">{</span><span class="n">test_accuracy_light_ce_and_cosine_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Student accuracy with CE + RegressorMSE: </span><span class="si">{</span><span class="n">test_accuracy_light_ce_and_mse_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Teacher accuracy: 75.70%
Student accuracy without teacher: 70.20%
Student accuracy with CE + KD: 70.79%
Student accuracy with CE + CosineLoss: 70.17%
Student accuracy with CE + RegressorMSE: 70.94%
</pre></div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>None of the methods above increases the number of parameters for the network or inference time,
so the performance increase comes at the little cost of calculating gradients during training.
In ML applications, we mostly care about inference time because training happens before the model deployment.
If our lightweight model is still too heavy for deployment, we can apply different ideas, such as post-training quantization.
Additional losses can be applied in many tasks, not just classification, and you can experiment with quantities like coefficients,
temperature, or number of neurons. Feel free to tune any numbers in the tutorial above,
but keep in mind, if you change the number of neurons / filters chances are a shape mismatch might occur.</p>
<p>For more information, see:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/1503.02531">Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network. In: Neural Information Processing System Deep Learning Workshop (2015)</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1412.6550">Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.: Fitnets: Hints for thin deep nets. In: Proceedings of the International Conference on Learning Representations (2015)</a></p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (11 minutes 41.284 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-knowledge-distillation-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/a19d8941b0ebb13c102e41c7e24bc5fb/knowledge_distillation_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">knowledge_distillation_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/19879e6777280194639314bd79851483/knowledge_distillation_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">knowledge_distillation_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/f86d5d7abef2752e3e8b0f49e14af85c/knowledge_distillation_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">knowledge_distillation_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="../intermediate/scaled_dot_product_attention_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</p>
</div>
</a>
<a class="right-next" href="../intermediate/memory_format_tutorial.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Channels Last Memory Format in PyTorch</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="../intermediate/scaled_dot_product_attention_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</p>
</div>
</a>
<a class="right-next" href="../intermediate/memory_format_tutorial.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Channels Last Memory Format in PyTorch</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-cifar-10">Loading CIFAR-10</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-model-classes-and-utility-functions">Defining model classes and utility functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-entropy-runs">Cross-entropy runs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#knowledge-distillation-run">Knowledge distillation run</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cosine-loss-minimization-run">Cosine loss minimization run</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intermediate-regressor-run">Intermediate regressor run</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Knowledge Distillation Tutorial",
       "headline": "Knowledge Distillation Tutorial",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/beginner/knowledge_distillation_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. Knowledge Distillation Tutorial# Author: Alexandros Chariton Knowledge distillation is a technique that enables knowledge transfer from large, computationally expensive models to smaller ones without losing validity. This allows for deployment on less powerful hardware, making evaluation faster and more efficient. In this tutorial, we will run a number of experiments focused at improving the accuracy of a lightweight neural network, using a more powerful network as a teacher. The computational cost and the speed of the lightweight network will remain unaffected, our intervention only focuses on its weights, not on its forward pass. Applications of this technology can be found in devices such as drones or mobile phones. In this tutorial, we do not use any external packages as everything we need is available in torch and torchvision. In this tutorial, you will learn: How to modify model classes to extract hidden representations and use them for further calculations How to modify regular train loops in PyTorch to include additional losses on top of, for example, cross-entropy for classification How to improve the performance of lightweight models by using more complex models as teachers Prerequisites# 1 GPU, 4GB of memory PyTorch v2.0 or later CIFAR-10 dataset (downloaded by the script and saved in a directory called /data) import torch import torch.nn as nn import torch.optim as optim import torchvision.transforms as transforms import torchvision.datasets as datasets # Check if the current `accelerator \u003chttps://pytorch.org/docs/stable/torch.html#accelerators\u003e`__ # is available, and if not, use the CPU device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\" print(f\"Using {device} device\") Using cuda device Loading CIFAR-10# CIFAR-10 is a popular image dataset with ten classes. Our objective is to predict one of the following classes for each input image. Example of CIFAR-10 images# The input images are RGB, so they have 3 channels and are 32x32 pixels. Basically, each image is described by 3 x 32 x 32 = 3072 numbers ranging from 0 to 255. A common practice in neural networks is to normalize the input, which is done for multiple reasons, including avoiding saturation in commonly used activation functions and increasing numerical stability. Our normalization process consists of subtracting the mean and dividing by the standard deviation along each channel. The tensors \u201cmean=[0.485, 0.456, 0.406]\u201d and \u201cstd=[0.229, 0.224, 0.225]\u201d were already computed, and they represent the mean and standard deviation of each channel in the predefined subset of CIFAR-10 intended to be the training set. Notice how we use these values for the test set as well, without recomputing the mean and standard deviation from scratch. This is because the network was trained on features produced by subtracting and dividing the numbers above, and we want to maintain consistency. Furthermore, in real life, we would not be able to compute the mean and standard deviation of the test set since, under our assumptions, this data would not be accessible at that point. As a closing point, we often refer to this held-out set as the validation set, and we use a separate set, called the test set, after optimizing a model\u2019s performance on the validation set. This is done to avoid selecting a model based on the greedy and biased optimization of a single metric. # Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128. transforms_cifar = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) # Loading the CIFAR-10 dataset: train_dataset = datasets.CIFAR10(root=\u0027./data\u0027, train=True, download=True, transform=transforms_cifar) test_dataset = datasets.CIFAR10(root=\u0027./data\u0027, train=False, download=True, transform=transforms_cifar) 0%| | 0.00/170M [00:00\u003c?, ?B/s] 0%| | 65.5k/170M [00:00\u003c06:12, 458kB/s] 0%| | 131k/170M [00:00\u003c06:25, 442kB/s] 0%| | 197k/170M [00:00\u003c06:35, 431kB/s] 0%| | 262k/170M [00:00\u003c06:35, 430kB/s] 0%| | 328k/170M [00:00\u003c06:33, 432kB/s] 0%| | 393k/170M [00:00\u003c06:48, 416kB/s] 0%| | 459k/170M [00:01\u003c06:39, 426kB/s] 0%| | 524k/170M [00:01\u003c06:31, 435kB/s] 0%| | 590k/170M [00:01\u003c06:29, 437kB/s] 0%| | 655k/170M [00:01\u003c06:22, 445kB/s] 0%| | 721k/170M [00:01\u003c06:38, 426kB/s] 0%| | 786k/170M [00:01\u003c06:29, 436kB/s] 0%| | 852k/170M [00:01\u003c06:27, 438kB/s] 1%| | 918k/170M [00:02\u003c06:26, 439kB/s] 1%| | 983k/170M [00:02\u003c06:20, 446kB/s] 1%| | 1.05M/170M [00:02\u003c06:36, 428kB/s] 1%| | 1.11M/170M [00:02\u003c06:27, 437kB/s] 1%| | 1.18M/170M [00:02\u003c06:26, 438kB/s] 1%| | 1.25M/170M [00:02\u003c06:25, 439kB/s] 1%| | 1.31M/170M [00:03\u003c06:18, 447kB/s] 1%| | 1.38M/170M [00:03\u003c06:35, 427kB/s] 1%| | 1.44M/170M [00:03\u003c06:35, 428kB/s] 1%| | 1.51M/170M [00:03\u003c06:27, 437kB/s] 1%| | 1.57M/170M [00:03\u003c06:24, 439kB/s] 1%| | 1.64M/170M [00:03\u003c06:18, 446kB/s] 1%| | 1.70M/170M [00:03\u003c06:47, 414kB/s] 1%| | 1.77M/170M [00:04\u003c06:31, 432kB/s] 1%| | 1.84M/170M [00:04\u003c06:31, 431kB/s] 1%| | 1.90M/170M [00:04\u003c06:24, 439kB/s] 1%| | 1.97M/170M [00:04\u003c06:17, 446kB/s] 1%| | 2.03M/170M [00:04\u003c06:18, 445kB/s] 1%| | 2.10M/170M [00:04\u003c06:33, 428kB/s] 1%|\u258f | 2.16M/170M [00:04\u003c06:24, 438kB/s] 1%|\u258f | 2.23M/170M [00:05\u003c06:36, 425kB/s] 1%|\u258f | 2.29M/170M [00:05\u003c06:22, 440kB/s] 1%|\u258f | 2.36M/170M [00:05\u003c06:16, 446kB/s] 1%|\u258f | 2.42M/170M [00:05\u003c06:33, 428kB/s] 1%|\u258f | 2.49M/170M [00:05\u003c06:24, 437kB/s] 1%|\u258f | 2.56M/170M [00:05\u003c06:24, 437kB/s] 2%|\u258f | 2.62M/170M [00:06\u003c06:21, 440kB/s] 2%|\u258f | 2.69M/170M [00:06\u003c06:20, 441kB/s] 2%|\u258f | 2.75M/170M [00:06\u003c06:35, 424kB/s] 2%|\u258f | 2.82M/170M [00:06\u003c06:29, 431kB/s] 2%|\u258f | 2.88M/170M [00:06\u003c06:30, 429kB/s] 2%|\u258f | 2.95M/170M [00:06\u003c06:25, 434kB/s] 2%|\u258f | 3.01M/170M [00:06\u003c06:26, 433kB/s] 2%|\u258f | 3.08M/170M [00:07\u003c06:35, 423kB/s] 2%|\u258f | 3.15M/170M [00:07\u003c06:32, 427kB/s] 2%|\u258f | 3.21M/170M [00:07\u003c06:29, 430kB/s] 2%|\u258f | 3.28M/170M [00:07\u003c06:26, 433kB/s] 2%|\u258f | 3.34M/170M [00:07\u003c06:22, 437kB/s] 2%|\u258f | 3.41M/170M [00:07\u003c06:23, 435kB/s] 2%|\u258f | 3.47M/170M [00:08\u003c06:40, 417kB/s] 2%|\u258f | 3.54M/170M [00:08\u003c06:32, 426kB/s] 2%|\u258f | 3.60M/170M [00:08\u003c06:29, 428kB/s] 2%|\u258f | 3.67M/170M [00:08\u003c06:29, 428kB/s] 2%|\u258f | 3.74M/170M [00:08\u003c06:27, 430kB/s] 2%|\u258f | 3.80M/170M [00:08\u003c06:54, 402kB/s] 2%|\u258f | 3.87M/170M [00:08\u003c06:27, 430kB/s] 2%|\u258f | 3.93M/170M [00:09\u003c06:27, 429kB/s] 2%|\u258f | 4.00M/170M [00:09\u003c06:21, 437kB/s] 2%|\u258f | 4.06M/170M [00:09\u003c06:18, 440kB/s] 2%|\u258f | 4.13M/170M [00:09\u003c06:43, 413kB/s] 2%|\u258f | 4.19M/170M [00:09\u003c06:39, 416kB/s] 2%|\u258f | 4.26M/170M [00:10\u003c09:22, 295kB/s] 3%|\u258e | 4.33M/170M [00:10\u003c08:08, 340kB/s] 3%|\u258e | 4.39M/170M [00:10\u003c07:45, 357kB/s] 3%|\u258e | 4.46M/170M [00:10\u003c06:46, 408kB/s] 3%|\u258e | 4.52M/170M [00:10\u003c06:33, 422kB/s] 3%|\u258e | 4.59M/170M [00:10\u003c06:24, 432kB/s] 3%|\u258e | 4.65M/170M [00:10\u003c06:35, 419kB/s] 3%|\u258e | 4.72M/170M [00:11\u003c06:04, 455kB/s] 3%|\u258e | 4.78M/170M [00:11\u003c06:35, 419kB/s] 3%|\u258e | 4.85M/170M [00:11\u003c06:10, 447kB/s] 3%|\u258e | 4.92M/170M [00:11\u003c06:34, 419kB/s] 3%|\u258e | 4.98M/170M [00:11\u003c06:01, 457kB/s] 3%|\u258e | 5.05M/170M [00:11\u003c06:09, 448kB/s] 3%|\u258e | 5.11M/170M [00:11\u003c06:19, 436kB/s] 3%|\u258e | 5.18M/170M [00:12\u003c06:33, 420kB/s] 3%|\u258e | 5.24M/170M [00:12\u003c06:33, 420kB/s] 3%|\u258e | 5.31M/170M [00:12\u003c06:27, 426kB/s] 3%|\u258e | 5.37M/170M [00:12\u003c06:30, 423kB/s] 3%|\u258e | 5.44M/170M [00:12\u003c06:26, 427kB/s] 3%|\u258e | 5.51M/170M [00:12\u003c06:35, 417kB/s] 3%|\u258e | 5.57M/170M [00:13\u003c06:33, 419kB/s] 3%|\u258e | 5.64M/170M [00:13\u003c06:30, 422kB/s] 3%|\u258e | 5.70M/170M [00:13\u003c06:32, 420kB/s] 3%|\u258e | 5.77M/170M [00:13\u003c06:27, 425kB/s] 3%|\u258e | 5.83M/170M [00:13\u003c06:40, 411kB/s] 3%|\u258e | 5.90M/170M [00:13\u003c06:46, 404kB/s] 3%|\u258e | 5.96M/170M [00:14\u003c06:37, 414kB/s] 4%|\u258e | 6.03M/170M [00:14\u003c06:35, 416kB/s] 4%|\u258e | 6.09M/170M [00:14\u003c06:35, 415kB/s] 4%|\u258e | 6.16M/170M [00:14\u003c06:45, 406kB/s] 4%|\u258e | 6.23M/170M [00:14\u003c06:41, 409kB/s] 4%|\u258e | 6.29M/170M [00:14\u003c06:37, 413kB/s] 4%|\u258e | 6.36M/170M [00:14\u003c06:31, 419kB/s] 4%|\u258d | 6.42M/170M [00:15\u003c06:28, 422kB/s] 4%|\u258d | 6.49M/170M [00:15\u003c06:40, 409kB/s] 4%|\u258d | 6.55M/170M [00:15\u003c06:33, 417kB/s] 4%|\u258d | 6.62M/170M [00:15\u003c06:37, 412kB/s] 4%|\u258d | 6.68M/170M [00:15\u003c06:30, 420kB/s] 4%|\u258d | 6.75M/170M [00:15\u003c06:32, 418kB/s] 4%|\u258d | 6.82M/170M [00:16\u003c06:34, 414kB/s] 4%|\u258d | 6.88M/170M [00:16\u003c07:07, 382kB/s] 4%|\u258d | 6.95M/170M [00:16\u003c06:33, 415kB/s] 4%|\u258d | 7.01M/170M [00:16\u003c06:39, 409kB/s] 4%|\u258d | 7.08M/170M [00:16\u003c06:36, 412kB/s] 4%|\u258d | 7.14M/170M [00:16\u003c06:30, 419kB/s] 4%|\u258d | 7.21M/170M [00:17\u003c06:42, 406kB/s] 4%|\u258d | 7.27M/170M [00:17\u003c06:37, 411kB/s] 4%|\u258d | 7.34M/170M [00:17\u003c06:35, 413kB/s] 4%|\u258d | 7.41M/170M [00:17\u003c06:33, 415kB/s] 4%|\u258d | 7.47M/170M [00:17\u003c06:34, 414kB/s] 4%|\u258d | 7.54M/170M [00:17\u003c06:49, 398kB/s] 4%|\u258d | 7.60M/170M [00:18\u003c06:40, 406kB/s] 4%|\u258d | 7.67M/170M [00:18\u003c06:40, 407kB/s] 5%|\u258d | 7.73M/170M [00:18\u003c06:38, 409kB/s] 5%|\u258d | 7.80M/170M [00:18\u003c06:34, 413kB/s] 5%|\u258d | 7.86M/170M [00:18\u003c06:45, 401kB/s] 5%|\u258d | 7.93M/170M [00:18\u003c06:38, 408kB/s] 5%|\u258d | 8.00M/170M [00:18\u003c06:36, 410kB/s] 5%|\u258d | 8.06M/170M [00:19\u003c06:29, 417kB/s] 5%|\u258d | 8.13M/170M [00:19\u003c06:27, 419kB/s] 5%|\u258d | 8.19M/170M [00:19\u003c06:38, 408kB/s] 5%|\u258d | 8.26M/170M [00:19\u003c06:35, 410kB/s] 5%|\u258d | 8.32M/170M [00:19\u003c06:33, 413kB/s] 5%|\u258d | 8.39M/170M [00:19\u003c06:28, 417kB/s] 5%|\u258d | 8.45M/170M [00:20\u003c06:24, 422kB/s] 5%|\u258d | 8.52M/170M [00:20\u003c06:29, 416kB/s] 5%|\u258c | 8.59M/170M [00:20\u003c06:38, 407kB/s] 5%|\u258c | 8.65M/170M [00:20\u003c06:30, 414kB/s] 5%|\u258c | 8.72M/170M [00:20\u003c06:28, 417kB/s] 5%|\u258c | 8.78M/170M [00:20\u003c06:27, 417kB/s] 5%|\u258c | 8.85M/170M [00:21\u003c06:23, 421kB/s] 5%|\u258c | 8.91M/170M [00:21\u003c06:43, 401kB/s] 5%|\u258c | 8.98M/170M [00:21\u003c06:48, 396kB/s] 5%|\u258c | 9.04M/170M [00:21\u003c06:27, 417kB/s] 5%|\u258c | 9.11M/170M [00:21\u003c06:30, 413kB/s] 5%|\u258c | 9.18M/170M [00:21\u003c06:28, 415kB/s] 5%|\u258c | 9.24M/170M [00:21\u003c06:40, 403kB/s] 5%|\u258c | 9.31M/170M [00:22\u003c06:35, 407kB/s] 5%|\u258c | 9.37M/170M [00:22\u003c06:33, 410kB/s] 6%|\u258c | 9.44M/170M [00:22\u003c06:28, 414kB/s] 6%|\u258c | 9.50M/170M [00:22\u003c06:26, 417kB/s] 6%|\u258c | 9.57M/170M [00:22\u003c06:38, 404kB/s] 6%|\u258c | 9.63M/170M [00:22\u003c06:30, 412kB/s] 6%|\u258c | 9.70M/170M [00:23\u003c06:33, 409kB/s] 6%|\u258c | 9.76M/170M [00:23\u003c06:24, 418kB/s] 6%|\u258c | 9.83M/170M [00:23\u003c06:25, 416kB/s] 6%|\u258c | 9.90M/170M [00:23\u003c06:39, 402kB/s] 6%|\u258c | 9.96M/170M [00:23\u003c06:39, 402kB/s] 6%|\u258c | 10.0M/170M [00:23\u003c06:28, 413kB/s] 6%|\u258c | 10.1M/170M [00:24\u003c06:27, 414kB/s] 6%|\u258c | 10.2M/170M [00:24\u003c06:24, 417kB/s] 6%|\u258c | 10.2M/170M [00:24\u003c06:20, 421kB/s] 6%|\u258c | 10.3M/170M [00:24\u003c06:39, 401kB/s] 6%|\u258c | 10.4M/170M [00:24\u003c06:32, 408kB/s] 6%|\u258c | 10.4M/170M [00:24\u003c06:32, 408kB/s] 6%|\u258c | 10.5M/170M [00:25\u003c06:31, 409kB/s] 6%|\u258c | 10.6M/170M [00:25\u003c06:48, 391kB/s] 6%|\u258c | 10.6M/170M [00:25\u003c06:33, 407kB/s] 6%|\u258b | 10.7M/170M [00:25\u003c06:29, 411kB/s] 6%|\u258b | 10.7M/170M [00:25\u003c06:24, 416kB/s] 6%|\u258b | 10.8M/170M [00:25\u003c06:26, 413kB/s] 6%|\u258b | 10.9M/170M [00:25\u003c06:25, 414kB/s] 6%|\u258b | 10.9M/170M [00:26\u003c06:45, 394kB/s] 6%|\u258b | 11.0M/170M [00:26\u003c06:28, 411kB/s] 6%|\u258b | 11.1M/170M [00:26\u003c06:34, 404kB/s] 7%|\u258b | 11.1M/170M [00:26\u003c06:30, 408kB/s] 7%|\u258b | 11.2M/170M [00:26\u003c06:43, 395kB/s] 7%|\u258b | 11.3M/170M [00:26\u003c06:39, 399kB/s] 7%|\u258b | 11.3M/170M [00:27\u003c06:35, 403kB/s] 7%|\u258b | 11.4M/170M [00:27\u003c06:25, 413kB/s] 7%|\u258b | 11.5M/170M [00:27\u003c06:23, 415kB/s] 7%|\u258b | 11.5M/170M [00:27\u003c06:28, 409kB/s] 7%|\u258b | 11.6M/170M [00:27\u003c06:16, 422kB/s] 7%|\u258b | 11.7M/170M [00:27\u003c06:35, 402kB/s] 7%|\u258b | 11.7M/170M [00:28\u003c06:31, 406kB/s] 7%|\u258b | 11.8M/170M [00:28\u003c06:39, 397kB/s] 7%|\u258b | 11.9M/170M [00:28\u003c06:20, 417kB/s] 7%|\u258b | 11.9M/170M [00:28\u003c06:21, 415kB/s] 7%|\u258b | 12.0M/170M [00:28\u003c06:37, 399kB/s] 7%|\u258b | 12.1M/170M [00:28\u003c06:23, 413kB/s] 7%|\u258b | 12.1M/170M [00:29\u003c06:23, 413kB/s] 7%|\u258b | 12.2M/170M [00:29\u003c06:37, 398kB/s] 7%|\u258b | 12.3M/170M [00:29\u003c06:15, 421kB/s] 7%|\u258b | 12.3M/170M [00:29\u003c06:28, 407kB/s] 7%|\u258b | 12.4M/170M [00:29\u003c06:23, 413kB/s] 7%|\u258b | 12.5M/170M [00:29\u003c06:23, 412kB/s] 7%|\u258b | 12.5M/170M [00:29\u003c06:21, 414kB/s] 7%|\u258b | 12.6M/170M [00:30\u003c06:21, 414kB/s] 7%|\u258b | 12.6M/170M [00:30\u003c06:32, 402kB/s] 7%|\u258b | 12.7M/170M [00:30\u003c06:25, 410kB/s] 7%|\u258b | 12.8M/170M [00:30\u003c06:25, 409kB/s] 8%|\u258a | 12.8M/170M [00:30\u003c06:24, 410kB/s] 8%|\u258a | 12.9M/170M [00:30\u003c06:17, 417kB/s] 8%|\u258a | 13.0M/170M [00:31\u003c06:30, 404kB/s] 8%|\u258a | 13.0M/170M [00:31\u003c06:23, 411kB/s] 8%|\u258a | 13.1M/170M [00:31\u003c06:23, 411kB/s] 8%|\u258a | 13.2M/170M [00:31\u003c06:26, 407kB/s] 8%|\u258a | 13.2M/170M [00:31\u003c06:18, 416kB/s] 8%|\u258a | 13.3M/170M [00:31\u003c06:18, 415kB/s] 8%|\u258a | 13.4M/170M [00:32\u003c06:31, 401kB/s] 8%|\u258a | 13.4M/170M [00:32\u003c06:23, 409kB/s] 8%|\u258a | 13.5M/170M [00:32\u003c06:18, 415kB/s] 8%|\u258a | 13.6M/170M [00:32\u003c06:20, 413kB/s] 8%|\u258a | 13.6M/170M [00:32\u003c06:23, 409kB/s] 8%|\u258a | 13.7M/170M [00:32\u003c06:33, 398kB/s] 8%|\u258a | 13.8M/170M [00:33\u003c06:28, 403kB/s] 8%|\u258a | 13.8M/170M [00:33\u003c06:28, 403kB/s] 8%|\u258a | 13.9M/170M [00:33\u003c06:22, 410kB/s] 8%|\u258a | 14.0M/170M [00:33\u003c06:17, 414kB/s] 8%|\u258a | 14.0M/170M [00:33\u003c06:40, 391kB/s] 8%|\u258a | 14.1M/170M [00:33\u003c06:30, 401kB/s] 8%|\u258a | 14.2M/170M [00:34\u003c06:26, 404kB/s] 8%|\u258a | 14.2M/170M [00:34\u003c06:25, 406kB/s] 8%|\u258a | 14.3M/170M [00:34\u003c06:19, 412kB/s] 8%|\u258a | 14.4M/170M [00:34\u003c06:33, 397kB/s] 8%|\u258a | 14.4M/170M [00:34\u003c06:23, 407kB/s] 8%|\u258a | 14.5M/170M [00:34\u003c06:22, 407kB/s] 9%|\u258a | 14.5M/170M [00:34\u003c06:24, 406kB/s] 9%|\u258a | 14.6M/170M [00:35\u003c06:17, 413kB/s] 9%|\u258a | 14.7M/170M [00:35\u003c06:30, 399kB/s] 9%|\u258a | 14.7M/170M [00:35\u003c06:23, 406kB/s] 9%|\u258a | 14.8M/170M [00:35\u003c06:22, 407kB/s] 9%|\u258a | 14.9M/170M [00:35\u003c06:16, 413kB/s] 9%|\u2589 | 14.9M/170M [00:35\u003c06:13, 416kB/s] 9%|\u2589 | 15.0M/170M [00:36\u003c06:15, 414kB/s] 9%|\u2589 | 15.1M/170M [00:36\u003c06:28, 400kB/s] 9%|\u2589 | 15.1M/170M [00:36\u003c06:23, 406kB/s] 9%|\u2589 | 15.2M/170M [00:36\u003c06:21, 407kB/s] 9%|\u2589 | 15.3M/170M [00:36\u003c06:17, 411kB/s] 9%|\u2589 | 15.3M/170M [00:36\u003c06:25, 403kB/s] 9%|\u2589 | 15.4M/170M [00:37\u003c06:35, 392kB/s] 9%|\u2589 | 15.5M/170M [00:37\u003c06:28, 399kB/s] 9%|\u2589 | 15.5M/170M [00:37\u003c06:22, 405kB/s] 9%|\u2589 | 15.6M/170M [00:37\u003c06:21, 406kB/s] 9%|\u2589 | 15.7M/170M [00:37\u003c06:20, 407kB/s] 9%|\u2589 | 15.7M/170M [00:37\u003c06:33, 394kB/s] 9%|\u2589 | 15.8M/170M [00:38\u003c06:23, 404kB/s] 9%|\u2589 | 15.9M/170M [00:38\u003c06:23, 403kB/s] 9%|\u2589 | 15.9M/170M [00:38\u003c06:25, 401kB/s] 9%|\u2589 | 16.0M/170M [00:38\u003c06:16, 410kB/s] 9%|\u2589 | 16.1M/170M [00:38\u003c06:31, 394kB/s] 9%|\u2589 | 16.1M/170M [00:38\u003c06:30, 396kB/s] 9%|\u2589 | 16.2M/170M [00:39\u003c06:23, 402kB/s] 10%|\u2589 | 16.3M/170M [00:39\u003c06:18, 408kB/s] 10%|\u2589 | 16.3M/170M [00:39\u003c06:14, 412kB/s] 10%|\u2589 | 16.4M/170M [00:39\u003c06:30, 395kB/s] 10%|\u2589 | 16.4M/170M [00:39\u003c06:23, 402kB/s] 10%|\u2589 | 16.5M/170M [00:39\u003c06:23, 401kB/s] 10%|\u2589 | 16.6M/170M [00:40\u003c06:18, 407kB/s] 10%|\u2589 | 16.6M/170M [00:40\u003c06:15, 410kB/s] 10%|\u2589 | 16.7M/170M [00:40\u003c06:18, 406kB/s] 10%|\u2589 | 16.8M/170M [00:40\u003c06:32, 392kB/s] 10%|\u2589 | 16.8M/170M [00:40\u003c06:27, 397kB/s] 10%|\u2589 | 16.9M/170M [00:40\u003c06:21, 403kB/s] 10%|\u2589 | 17.0M/170M [00:41\u003c06:22, 402kB/s] 10%|\u2589 | 17.0M/170M [00:41\u003c06:17, 406kB/s] 10%|\u2588 | 17.1M/170M [00:41\u003c06:36, 387kB/s] 10%|\u2588 | 17.2M/170M [00:41\u003c06:24, 398kB/s] 10%|\u2588 | 17.2M/170M [00:41\u003c06:19, 404kB/s] 10%|\u2588 | 17.3M/170M [00:41\u003c06:27, 395kB/s] 10%|\u2588 | 17.4M/170M [00:41\u003c06:19, 404kB/s] 10%|\u2588 | 17.4M/170M [00:42\u003c06:35, 387kB/s] 10%|\u2588 | 17.5M/170M [00:42\u003c06:28, 394kB/s] 10%|\u2588 | 17.6M/170M [00:42\u003c06:24, 397kB/s] 10%|\u2588 | 17.6M/170M [00:42\u003c06:24, 398kB/s] 10%|\u2588 | 17.7M/170M [00:42\u003c06:22, 400kB/s] 10%|\u2588 | 17.8M/170M [00:42\u003c06:33, 388kB/s] 10%|\u2588 | 17.8M/170M [00:43\u003c06:21, 400kB/s] 10%|\u2588 | 17.9M/170M [00:43\u003c06:22, 399kB/s] 11%|\u2588 | 18.0M/170M [00:43\u003c06:18, 403kB/s] 11%|\u2588 | 18.0M/170M [00:43\u003c06:13, 408kB/s] 11%|\u2588 | 18.1M/170M [00:43\u003c06:28, 392kB/s] 11%|\u2588 | 18.2M/170M [00:43\u003c06:33, 387kB/s] 11%|\u2588 | 18.2M/170M [00:44\u003c06:13, 407kB/s] 11%|\u2588 | 18.3M/170M [00:44\u003c06:16, 405kB/s] 11%|\u2588 | 18.4M/170M [00:44\u003c06:24, 396kB/s] 11%|\u2588 | 18.4M/170M [00:44\u003c06:10, 411kB/s] 11%|\u2588 | 18.5M/170M [00:44\u003c06:29, 391kB/s] 11%|\u2588 | 18.5M/170M [00:44\u003c06:38, 381kB/s] 11%|\u2588 | 18.6M/170M [00:45\u003c06:10, 410kB/s] 11%|\u2588 | 18.7M/170M [00:45\u003c06:14, 406kB/s] 11%|\u2588 | 18.7M/170M [00:45\u003c06:23, 396kB/s] 11%|\u2588 | 18.8M/170M [00:45\u003c06:42, 377kB/s] 11%|\u2588 | 18.9M/170M [00:45\u003c06:16, 403kB/s] 11%|\u2588 | 18.9M/170M [00:45\u003c06:19, 399kB/s] 11%|\u2588 | 19.0M/170M [00:46\u003c06:10, 409kB/s] 11%|\u2588 | 19.1M/170M [00:46\u003c06:08, 411kB/s] 11%|\u2588 | 19.1M/170M [00:46\u003c06:21, 397kB/s] 11%|\u2588\u258f | 19.2M/170M [00:46\u003c06:32, 385kB/s] 11%|\u2588\u258f | 19.3M/170M [00:46\u003c06:12, 406kB/s] 11%|\u2588\u258f | 19.3M/170M [00:46\u003c06:10, 408kB/s] 11%|\u2588\u258f | 19.4M/170M [00:47\u003c06:19, 398kB/s] 11%|\u2588\u258f | 19.5M/170M [00:47\u003c06:12, 406kB/s] 11%|\u2588\u258f | 19.5M/170M [00:47\u003c06:11, 407kB/s] 11%|\u2588\u258f | 19.6M/170M [00:47\u003c06:10, 407kB/s] 12%|\u2588\u258f | 19.7M/170M [00:47\u003c06:05, 412kB/s] 12%|\u2588\u258f | 19.7M/170M [00:47\u003c06:14, 402kB/s] 12%|\u2588\u258f | 19.8M/170M [00:48\u003c06:07, 410kB/s] 12%|\u2588\u258f | 19.9M/170M [00:48\u003c06:19, 396kB/s] 12%|\u2588\u258f | 19.9M/170M [00:48\u003c06:16, 400kB/s] 12%|\u2588\u258f | 20.0M/170M [00:48\u003c06:17, 398kB/s] 12%|\u2588\u258f | 20.1M/170M [00:48\u003c06:05, 412kB/s] 12%|\u2588\u258f | 20.1M/170M [00:48\u003c06:05, 411kB/s] 12%|\u2588\u258f | 20.2M/170M [00:49\u003c06:20, 395kB/s] 12%|\u2588\u258f | 20.3M/170M [00:49\u003c06:19, 396kB/s] 12%|\u2588\u258f | 20.3M/170M [00:49\u003c06:11, 404kB/s] 12%|\u2588\u258f | 20.4M/170M [00:49\u003c06:15, 399kB/s] 12%|\u2588\u258f | 20.4M/170M [00:49\u003c06:13, 401kB/s] 12%|\u2588\u258f | 20.5M/170M [00:49\u003c06:24, 390kB/s] 12%|\u2588\u258f | 20.6M/170M [00:50\u003c06:19, 396kB/s] 12%|\u2588\u258f | 20.6M/170M [00:50\u003c06:17, 397kB/s] 12%|\u2588\u258f | 20.7M/170M [00:50\u003c06:11, 403kB/s] 12%|\u2588\u258f | 20.8M/170M [00:50\u003c06:10, 404kB/s] 12%|\u2588\u258f | 20.8M/170M [00:50\u003c06:21, 392kB/s] 12%|\u2588\u258f | 20.9M/170M [00:50\u003c06:14, 400kB/s] 12%|\u2588\u258f | 21.0M/170M [00:51\u003c06:14, 399kB/s] 12%|\u2588\u258f | 21.0M/170M [00:51\u003c06:09, 404kB/s] 12%|\u2588\u258f | 21.1M/170M [00:51\u003c06:10, 403kB/s] 12%|\u2588\u258f | 21.2M/170M [00:51\u003c06:22, 390kB/s] 12%|\u2588\u258f | 21.2M/170M [00:51\u003c06:17, 395kB/s] 12%|\u2588\u258f | 21.3M/170M [00:51\u003c06:17, 395kB/s] 13%|\u2588\u258e | 21.4M/170M [00:51\u003c06:09, 404kB/s] 13%|\u2588\u258e | 21.4M/170M [00:52\u003c06:11, 401kB/s] 13%|\u2588\u258e | 21.5M/170M [00:52\u003c06:24, 387kB/s] 13%|\u2588\u258e | 21.6M/170M [00:52\u003c06:14, 397kB/s] 13%|\u2588\u258e | 21.6M/170M [00:52\u003c06:11, 400kB/s] 13%|\u2588\u258e | 21.7M/170M [00:52\u003c06:07, 405kB/s] 13%|\u2588\u258e | 21.8M/170M [00:52\u003c06:07, 405kB/s] 13%|\u2588\u258e | 21.8M/170M [00:53\u003c06:04, 408kB/s] 13%|\u2588\u258e | 21.9M/170M [00:53\u003c06:22, 388kB/s] 13%|\u2588\u258e | 22.0M/170M [00:53\u003c06:17, 393kB/s] 13%|\u2588\u258e | 22.0M/170M [00:53\u003c06:11, 400kB/s] 13%|\u2588\u258e | 22.1M/170M [00:53\u003c06:12, 399kB/s] 13%|\u2588\u258e | 22.2M/170M [00:53\u003c06:10, 400kB/s] 13%|\u2588\u258e | 22.2M/170M [00:54\u003c06:20, 389kB/s] 13%|\u2588\u258e | 22.3M/170M [00:54\u003c06:16, 394kB/s] 13%|\u2588\u258e | 22.3M/170M [00:54\u003c06:12, 398kB/s] 13%|\u2588\u258e | 22.4M/170M [00:54\u003c06:08, 402kB/s] 13%|\u2588\u258e | 22.5M/170M [00:54\u003c06:11, 398kB/s] 13%|\u2588\u258e | 22.5M/170M [00:54\u003c06:30, 378kB/s] 13%|\u2588\u258e | 22.6M/170M [00:55\u003c06:13, 396kB/s] 13%|\u2588\u258e | 22.7M/170M [00:55\u003c06:10, 399kB/s] 13%|\u2588\u258e | 22.7M/170M [00:55\u003c06:05, 404kB/s] 13%|\u2588\u258e | 22.8M/170M [00:55\u003c06:04, 406kB/s] 13%|\u2588\u258e | 22.9M/170M [00:55\u003c06:16, 392kB/s] 13%|\u2588\u258e | 22.9M/170M [00:55\u003c06:14, 394kB/s] 13%|\u2588\u258e | 23.0M/170M [00:56\u003c06:10, 398kB/s] 14%|\u2588\u258e | 23.1M/170M [00:56\u003c06:02, 406kB/s] 14%|\u2588\u258e | 23.1M/170M [00:56\u003c06:04, 404kB/s] 14%|\u2588\u258e | 23.2M/170M [00:56\u003c06:06, 402kB/s] 14%|\u2588\u258e | 23.3M/170M [00:56\u003c06:24, 383kB/s] 14%|\u2588\u258e | 23.3M/170M [00:56\u003c06:10, 397kB/s] 14%|\u2588\u258e | 23.4M/170M [00:57\u003c06:05, 403kB/s] 14%|\u2588\u258d | 23.5M/170M [00:57\u003c06:02, 406kB/s] 14%|\u2588\u258d | 23.5M/170M [00:57\u003c06:02, 405kB/s] 14%|\u2588\u258d | 23.6M/170M [00:57\u003c06:13, 393kB/s] 14%|\u2588\u258d | 23.7M/170M [00:57\u003c06:07, 399kB/s] 14%|\u2588\u258d | 23.7M/170M [00:57\u003c06:01, 406kB/s] 14%|\u2588\u258d | 23.8M/170M [00:58\u003c06:03, 404kB/s] 14%|\u2588\u258d | 23.9M/170M [00:58\u003c06:02, 404kB/s] 14%|\u2588\u258d | 23.9M/170M [00:58\u003c06:35, 371kB/s] 14%|\u2588\u258d | 24.0M/170M [00:58\u003c06:05, 401kB/s] 14%|\u2588\u258d | 24.1M/170M [00:58\u003c06:06, 399kB/s] 14%|\u2588\u258d | 24.1M/170M [00:58\u003c06:00, 407kB/s] 14%|\u2588\u258d | 24.2M/170M [00:59\u003c05:59, 407kB/s] 14%|\u2588\u258d | 24.2M/170M [00:59\u003c06:11, 393kB/s] 14%|\u2588\u258d | 24.3M/170M [00:59\u003c06:07, 398kB/s] 14%|\u2588\u258d | 24.4M/170M [00:59\u003c06:02, 403kB/s] 14%|\u2588\u258d | 24.4M/170M [00:59\u003c05:59, 406kB/s] 14%|\u2588\u258d | 24.5M/170M [00:59\u003c05:59, 406kB/s] 14%|\u2588\u258d | 24.6M/170M [01:00\u003c06:11, 393kB/s] 14%|\u2588\u258d | 24.6M/170M [01:00\u003c06:05, 399kB/s] 14%|\u2588\u258d | 24.7M/170M [01:00\u003c06:03, 401kB/s] 15%|\u2588\u258d | 24.8M/170M [01:00\u003c05:59, 406kB/s] 15%|\u2588\u258d | 24.8M/170M [01:00\u003c06:01, 403kB/s] 15%|\u2588\u258d | 24.9M/170M [01:00\u003c05:58, 407kB/s] 15%|\u2588\u258d | 25.0M/170M [01:01\u003c06:12, 391kB/s] 15%|\u2588\u258d | 25.0M/170M [01:01\u003c06:05, 398kB/s] 15%|\u2588\u258d | 25.1M/170M [01:01\u003c05:58, 405kB/s] 15%|\u2588\u258d | 25.2M/170M [01:01\u003c06:00, 403kB/s] 15%|\u2588\u258d | 25.2M/170M [01:01\u003c05:57, 407kB/s] 15%|\u2588\u258d | 25.3M/170M [01:01\u003c06:11, 391kB/s] 15%|\u2588\u258d | 25.4M/170M [01:02\u003c06:16, 386kB/s] 15%|\u2588\u258d | 25.4M/170M [01:02\u003c05:58, 405kB/s] 15%|\u2588\u258d | 25.5M/170M [01:02\u003c06:21, 380kB/s] 15%|\u2588\u258d | 25.6M/170M [01:02\u003c05:47, 417kB/s] 15%|\u2588\u258c | 25.6M/170M [01:02\u003c06:01, 401kB/s] 15%|\u2588\u258c | 25.7M/170M [01:02\u003c06:14, 387kB/s] 15%|\u2588\u258c | 25.8M/170M [01:02\u003c05:49, 415kB/s] 15%|\u2588\u258c | 25.8M/170M [01:03\u003c05:48, 415kB/s] 15%|\u2588\u258c | 25.9M/170M [01:03\u003c06:08, 393kB/s] 15%|\u2588\u258c | 26.0M/170M [01:03\u003c05:58, 403kB/s] 15%|\u2588\u258c | 26.0M/170M [01:03\u003c05:56, 406kB/s] 15%|\u2588\u258c | 26.1M/170M [01:03\u003c05:55, 406kB/s] 15%|\u2588\u258c | 26.1M/170M [01:03\u003c05:55, 407kB/s] 15%|\u2588\u258c | 26.2M/170M [01:04\u003c05:54, 407kB/s] 15%|\u2588\u258c | 26.3M/170M [01:04\u003c06:08, 391kB/s] 15%|\u2588\u258c | 26.3M/170M [01:04\u003c06:01, 399kB/s] 15%|\u2588\u258c | 26.4M/170M [01:04\u003c06:07, 392kB/s] 16%|\u2588\u258c | 26.5M/170M [01:04\u003c05:50, 411kB/s] 16%|\u2588\u258c | 26.5M/170M [01:04\u003c05:54, 406kB/s] 16%|\u2588\u258c | 26.6M/170M [01:05\u003c05:58, 402kB/s] 16%|\u2588\u258c | 26.7M/170M [01:05\u003c06:14, 384kB/s] 16%|\u2588\u258c | 26.7M/170M [01:05\u003c05:54, 405kB/s] 16%|\u2588\u258c | 26.8M/170M [01:05\u003c05:53, 406kB/s] 16%|\u2588\u258c | 26.9M/170M [01:05\u003c06:02, 396kB/s] 16%|\u2588\u258c | 26.9M/170M [01:05\u003c05:53, 407kB/s] 16%|\u2588\u258c | 27.0M/170M [01:06\u003c06:10, 387kB/s] 16%|\u2588\u258c | 27.1M/170M [01:06\u003c05:55, 404kB/s] 16%|\u2588\u258c | 27.1M/170M [01:06\u003c05:54, 405kB/s] 16%|\u2588\u258c | 27.2M/170M [01:06\u003c05:53, 405kB/s] 16%|\u2588\u258c | 27.3M/170M [01:06\u003c05:57, 401kB/s] 16%|\u2588\u258c | 27.3M/170M [01:06\u003c06:02, 395kB/s] 16%|\u2588\u258c | 27.4M/170M [01:07\u003c05:54, 404kB/s] 16%|\u2588\u258c | 27.5M/170M [01:07\u003c05:55, 403kB/s] 16%|\u2588\u258c | 27.5M/170M [01:07\u003c05:58, 399kB/s] 16%|\u2588\u258c | 27.6M/170M [01:07\u003c05:57, 400kB/s] 16%|\u2588\u258c | 27.7M/170M [01:07\u003c06:08, 387kB/s] 16%|\u2588\u258b | 27.7M/170M [01:07\u003c05:56, 401kB/s] 16%|\u2588\u258b | 27.8M/170M [01:08\u003c05:56, 401kB/s] 16%|\u2588\u258b | 27.9M/170M [01:08\u003c05:58, 397kB/s] 16%|\u2588\u258b | 27.9M/170M [01:08\u003c05:50, 407kB/s] 16%|\u2588\u258b | 28.0M/170M [01:08\u003c05:50, 406kB/s] 16%|\u2588\u258b | 28.0M/170M [01:08\u003c06:05, 390kB/s] 16%|\u2588\u258b | 28.1M/170M [01:08\u003c05:55, 400kB/s] 17%|\u2588\u258b | 28.2M/170M [01:09\u003c05:53, 403kB/s] 17%|\u2588\u258b | 28.2M/170M [01:09\u003c05:54, 401kB/s] 17%|\u2588\u258b | 28.3M/170M [01:09\u003c05:51, 405kB/s] 17%|\u2588\u258b | 28.4M/170M [01:09\u003c06:11, 382kB/s] 17%|\u2588\u258b | 28.4M/170M [01:09\u003c05:58, 396kB/s] 17%|\u2588\u258b | 28.5M/170M [01:09\u003c05:51, 404kB/s] 17%|\u2588\u258b | 28.6M/170M [01:10\u003c06:04, 390kB/s] 17%|\u2588\u258b | 28.6M/170M [01:10\u003c05:40, 417kB/s] 17%|\u2588\u258b | 28.7M/170M [01:10\u003c05:56, 397kB/s] 17%|\u2588\u258b | 28.8M/170M [01:10\u003c05:51, 404kB/s] 17%|\u2588\u258b | 28.8M/170M [01:10\u003c06:00, 393kB/s] 17%|\u2588\u258b | 28.9M/170M [01:10\u003c05:55, 398kB/s] 17%|\u2588\u258b | 29.0M/170M [01:11\u003c05:50, 403kB/s] 17%|\u2588\u258b | 29.0M/170M [01:11\u003c06:03, 389kB/s] 17%|\u2588\u258b | 29.1M/170M [01:11\u003c05:54, 398kB/s] 17%|\u2588\u258b | 29.2M/170M [01:11\u003c05:53, 400kB/s] 17%|\u2588\u258b | 29.2M/170M [01:11\u003c05:55, 397kB/s] 17%|\u2588\u258b | 29.3M/170M [01:11\u003c05:49, 404kB/s] 17%|\u2588\u258b | 29.4M/170M [01:12\u003c05:59, 393kB/s] 17%|\u2588\u258b | 29.4M/170M [01:12\u003c05:51, 402kB/s] 17%|\u2588\u258b | 29.5M/170M [01:12\u003c05:51, 402kB/s] 17%|\u2588\u258b | 29.6M/170M [01:12\u003c05:49, 403kB/s] 17%|\u2588\u258b | 29.6M/170M [01:12\u003c05:48, 405kB/s] 17%|\u2588\u258b | 29.7M/170M [01:12\u003c05:49, 403kB/s] 17%|\u2588\u258b | 29.8M/170M [01:13\u003c06:02, 389kB/s] 17%|\u2588\u258b | 29.8M/170M [01:13\u003c05:52, 399kB/s] 18%|\u2588\u258a | 29.9M/170M [01:13\u003c05:53, 398kB/s] 18%|\u2588\u258a | 29.9M/170M [01:13\u003c05:54, 396kB/s] 18%|\u2588\u258a | 30.0M/170M [01:13\u003c06:05, 384kB/s] 18%|\u2588\u258a | 30.1M/170M [01:13\u003c06:12, 377kB/s] 18%|\u2588\u258a | 30.1M/170M [01:14\u003c05:57, 392kB/s] 18%|\u2588\u258a | 30.2M/170M [01:14\u003c05:49, 402kB/s] 18%|\u2588\u258a | 30.3M/170M [01:14\u003c05:52, 398kB/s] 18%|\u2588\u258a | 30.3M/170M [01:14\u003c05:46, 404kB/s] 18%|\u2588\u258a | 30.4M/170M [01:14\u003c05:58, 391kB/s] 18%|\u2588\u258a | 30.5M/170M [01:14\u003c05:56, 393kB/s] 18%|\u2588\u258a | 30.5M/170M [01:14\u003c05:53, 396kB/s] 18%|\u2588\u258a | 30.6M/170M [01:15\u003c05:53, 395kB/s] 18%|\u2588\u258a | 30.7M/170M [01:15\u003c05:54, 395kB/s] 18%|\u2588\u258a | 30.7M/170M [01:15\u003c06:05, 383kB/s] 18%|\u2588\u258a | 30.8M/170M [01:15\u003c06:08, 379kB/s] 18%|\u2588\u258a | 30.9M/170M [01:15\u003c05:48, 401kB/s] 18%|\u2588\u258a | 30.9M/170M [01:15\u003c05:45, 404kB/s] 18%|\u2588\u258a | 31.0M/170M [01:16\u003c05:48, 400kB/s] 18%|\u2588\u258a | 31.1M/170M [01:16\u003c06:01, 386kB/s] 18%|\u2588\u258a | 31.1M/170M [01:16\u003c05:55, 392kB/s] 18%|\u2588\u258a | 31.2M/170M [01:16\u003c05:50, 397kB/s] 18%|\u2588\u258a | 31.3M/170M [01:16\u003c05:49, 399kB/s] 18%|\u2588\u258a | 31.3M/170M [01:16\u003c05:46, 401kB/s] 18%|\u2588\u258a | 31.4M/170M [01:17\u003c05:49, 398kB/s] 18%|\u2588\u258a | 31.5M/170M [01:17\u003c06:02, 383kB/s] 18%|\u2588\u258a | 31.5M/170M [01:17\u003c05:55, 391kB/s] 19%|\u2588\u258a | 31.6M/170M [01:17\u003c05:50, 396kB/s] 19%|\u2588\u258a | 31.7M/170M [01:17\u003c05:49, 397kB/s] 19%|\u2588\u258a | 31.7M/170M [01:17\u003c05:46, 400kB/s] 19%|\u2588\u258a | 31.8M/170M [01:18\u003c06:15, 370kB/s] 19%|\u2588\u258a | 31.9M/170M [01:18\u003c06:01, 383kB/s] 19%|\u2588\u258a | 31.9M/170M [01:18\u003c05:55, 390kB/s] 19%|\u2588\u2589 | 32.0M/170M [01:18\u003c06:01, 383kB/s] 19%|\u2588\u2589 | 32.0M/170M [01:18\u003c05:52, 393kB/s] 19%|\u2588\u2589 | 32.1M/170M [01:19\u003c06:02, 382kB/s] 19%|\u2588\u2589 | 32.2M/170M [01:19\u003c06:01, 382kB/s] 19%|\u2588\u2589 | 32.2M/170M [01:19\u003c06:14, 369kB/s] 19%|\u2588\u2589 | 32.3M/170M [01:19\u003c05:46, 399kB/s] 19%|\u2588\u2589 | 32.4M/170M [01:19\u003c05:43, 402kB/s] 19%|\u2588\u2589 | 32.4M/170M [01:19\u003c05:56, 387kB/s] 19%|\u2588\u2589 | 32.5M/170M [01:20\u003c05:51, 393kB/s] 19%|\u2588\u2589 | 32.6M/170M [01:20\u003c05:46, 398kB/s] 19%|\u2588\u2589 | 32.6M/170M [01:20\u003c05:45, 399kB/s] 19%|\u2588\u2589 | 32.7M/170M [01:20\u003c05:42, 402kB/s] 19%|\u2588\u2589 | 32.8M/170M [01:20\u003c05:56, 386kB/s] 19%|\u2588\u2589 | 32.8M/170M [01:20\u003c06:08, 374kB/s] 19%|\u2588\u2589 | 32.9M/170M [01:21\u003c05:42, 402kB/s] 19%|\u2588\u2589 | 33.0M/170M [01:21\u003c05:40, 404kB/s] 19%|\u2588\u2589 | 33.0M/170M [01:21\u003c05:44, 399kB/s] 19%|\u2588\u2589 | 33.1M/170M [01:21\u003c05:52, 390kB/s] 19%|\u2588\u2589 | 33.2M/170M [01:21\u003c05:50, 391kB/s] 19%|\u2588\u2589 | 33.2M/170M [01:21\u003c05:50, 392kB/s] 20%|\u2588\u2589 | 33.3M/170M [01:22\u003c05:58, 383kB/s] 20%|\u2588\u2589 | 33.4M/170M [01:22\u003c05:39, 404kB/s] 20%|\u2588\u2589 | 33.4M/170M [01:22\u003c05:40, 403kB/s] 20%|\u2588\u2589 | 33.5M/170M [01:22\u003c05:53, 387kB/s] 20%|\u2588\u2589 | 33.6M/170M [01:22\u003c05:48, 393kB/s] 20%|\u2588\u2589 | 33.6M/170M [01:22\u003c05:43, 398kB/s] 20%|\u2588\u2589 | 33.7M/170M [01:23\u003c05:44, 397kB/s] 20%|\u2588\u2589 | 33.8M/170M [01:23\u003c05:56, 384kB/s] 20%|\u2588\u2589 | 33.8M/170M [01:23\u003c06:06, 373kB/s] 20%|\u2588\u2589 | 33.9M/170M [01:23\u003c05:43, 398kB/s] 20%|\u2588\u2589 | 33.9M/170M [01:23\u003c05:41, 399kB/s] 20%|\u2588\u2589 | 34.0M/170M [01:23\u003c05:49, 390kB/s] 20%|\u2588\u2589 | 34.1M/170M [01:24\u003c05:39, 402kB/s] 20%|\u2588\u2588 | 34.1M/170M [01:24\u003c05:48, 391kB/s] 20%|\u2588\u2588 | 34.2M/170M [01:24\u003c05:44, 395kB/s] 20%|\u2588\u2588 | 34.3M/170M [01:24\u003c05:44, 395kB/s] 20%|\u2588\u2588 | 34.3M/170M [01:24\u003c05:40, 400kB/s] 20%|\u2588\u2588 | 34.4M/170M [01:24\u003c05:50, 388kB/s] 20%|\u2588\u2588 | 34.5M/170M [01:25\u003c05:46, 393kB/s] 20%|\u2588\u2588 | 34.5M/170M [01:25\u003c05:42, 397kB/s] 20%|\u2588\u2588 | 34.6M/170M [01:25\u003c05:43, 396kB/s] 20%|\u2588\u2588 | 34.7M/170M [01:25\u003c05:39, 400kB/s] 20%|\u2588\u2588 | 34.7M/170M [01:25\u003c05:40, 399kB/s] 20%|\u2588\u2588 | 34.8M/170M [01:25\u003c05:36, 403kB/s] 20%|\u2588\u2588 | 34.9M/170M [01:26\u003c05:59, 378kB/s] 20%|\u2588\u2588 | 34.9M/170M [01:26\u003c05:42, 396kB/s] 21%|\u2588\u2588 | 35.0M/170M [01:26\u003c05:35, 403kB/s] 21%|\u2588\u2588 | 35.1M/170M [01:26\u003c05:36, 403kB/s] 21%|\u2588\u2588 | 35.1M/170M [01:26\u003c05:45, 392kB/s] 21%|\u2588\u2588 | 35.2M/170M [01:26\u003c05:46, 390kB/s] 21%|\u2588\u2588 | 35.3M/170M [01:27\u003c05:44, 392kB/s] 21%|\u2588\u2588 | 35.3M/170M [01:27\u003c05:45, 391kB/s] 21%|\u2588\u2588 | 35.4M/170M [01:27\u003c05:39, 398kB/s] 21%|\u2588\u2588 | 35.5M/170M [01:27\u003c05:39, 398kB/s] 21%|\u2588\u2588 | 35.5M/170M [01:27\u003c05:49, 387kB/s] 21%|\u2588\u2588 | 35.6M/170M [01:27\u003c05:44, 392kB/s] 21%|\u2588\u2588 | 35.7M/170M [01:28\u003c05:40, 396kB/s] 21%|\u2588\u2588 | 35.7M/170M [01:28\u003c05:35, 401kB/s] 21%|\u2588\u2588 | 35.8M/170M [01:28\u003c05:32, 405kB/s] 21%|\u2588\u2588 | 35.8M/170M [01:28\u003c05:41, 394kB/s] 21%|\u2588\u2588 | 35.9M/170M [01:28\u003c05:36, 400kB/s] 21%|\u2588\u2588 | 36.0M/170M [01:28\u003c05:38, 397kB/s] 21%|\u2588\u2588 | 36.0M/170M [01:28\u003c05:32, 404kB/s] 21%|\u2588\u2588 | 36.1M/170M [01:29\u003c05:29, 408kB/s] 21%|\u2588\u2588 | 36.2M/170M [01:29\u003c05:31, 405kB/s] 21%|\u2588\u2588\u258f | 36.2M/170M [01:29\u003c05:39, 395kB/s] 21%|\u2588\u2588\u258f | 36.3M/170M [01:29\u003c05:36, 398kB/s] 21%|\u2588\u2588\u258f | 36.4M/170M [01:29\u003c05:32, 404kB/s] 21%|\u2588\u2588\u258f | 36.4M/170M [01:29\u003c05:32, 404kB/s] 21%|\u2588\u2588\u258f | 36.5M/170M [01:30\u003c05:33, 402kB/s] 21%|\u2588\u2588\u258f | 36.6M/170M [01:30\u003c05:42, 390kB/s] 21%|\u2588\u2588\u258f | 36.6M/170M [01:30\u003c05:38, 395kB/s] 22%|\u2588\u2588\u258f | 36.7M/170M [01:30\u003c05:33, 401kB/s] 22%|\u2588\u2588\u258f | 36.8M/170M [01:30\u003c05:30, 405kB/s] 22%|\u2588\u2588\u258f | 36.8M/170M [01:30\u003c05:29, 405kB/s] 22%|\u2588\u2588\u258f | 36.9M/170M [01:31\u003c05:39, 394kB/s] 22%|\u2588\u2588\u258f | 37.0M/170M [01:31\u003c05:34, 400kB/s] 22%|\u2588\u2588\u258f | 37.0M/170M [01:31\u003c05:34, 399kB/s] 22%|\u2588\u2588\u258f | 37.1M/170M [01:31\u003c05:29, 405kB/s] 22%|\u2588\u2588\u258f | 37.2M/170M [01:31\u003c05:33, 399kB/s] 22%|\u2588\u2588\u258f | 37.2M/170M [01:31\u003c06:00, 370kB/s] 22%|\u2588\u2588\u258f | 37.3M/170M [01:32\u003c05:33, 400kB/s] 22%|\u2588\u2588\u258f | 37.4M/170M [01:32\u003c05:33, 399kB/s] 22%|\u2588\u2588\u258f | 37.4M/170M [01:32\u003c05:30, 403kB/s] 22%|\u2588\u2588\u258f | 37.5M/170M [01:32\u003c05:27, 406kB/s] 22%|\u2588\u2588\u258f | 37.6M/170M [01:32\u003c05:38, 393kB/s] 22%|\u2588\u2588\u258f | 37.6M/170M [01:32\u003c05:37, 394kB/s] 22%|\u2588\u2588\u258f | 37.7M/170M [01:33\u003c05:36, 395kB/s] 22%|\u2588\u2588\u258f | 37.7M/170M [01:33\u003c05:31, 400kB/s] 22%|\u2588\u2588\u258f | 37.8M/170M [01:33\u003c05:32, 399kB/s] 22%|\u2588\u2588\u258f | 37.9M/170M [01:33\u003c05:32, 398kB/s] 22%|\u2588\u2588\u258f | 37.9M/170M [01:33\u003c05:57, 371kB/s] 22%|\u2588\u2588\u258f | 38.0M/170M [01:33\u003c05:32, 399kB/s] 22%|\u2588\u2588\u258f | 38.1M/170M [01:34\u003c05:29, 402kB/s] 22%|\u2588\u2588\u258f | 38.1M/170M [01:34\u003c05:30, 400kB/s] 22%|\u2588\u2588\u258f | 38.2M/170M [01:34\u003c05:29, 402kB/s] 22%|\u2588\u2588\u258f | 38.3M/170M [01:34\u003c05:39, 389kB/s] 22%|\u2588\u2588\u258f | 38.3M/170M [01:34\u003c05:38, 391kB/s] 23%|\u2588\u2588\u258e | 38.4M/170M [01:34\u003c05:43, 384kB/s] 23%|\u2588\u2588\u258e | 38.5M/170M [01:35\u003c05:29, 401kB/s] 23%|\u2588\u2588\u258e | 38.5M/170M [01:35\u003c05:32, 397kB/s] 23%|\u2588\u2588\u258e | 38.6M/170M [01:35\u003c05:46, 381kB/s] 23%|\u2588\u2588\u258e | 38.7M/170M [01:35\u003c05:38, 389kB/s] 23%|\u2588\u2588\u258e | 38.7M/170M [01:35\u003c05:35, 393kB/s] 23%|\u2588\u2588\u258e | 38.8M/170M [01:35\u003c05:30, 399kB/s] 23%|\u2588\u2588\u258e | 38.9M/170M [01:36\u003c05:29, 400kB/s] 23%|\u2588\u2588\u258e | 38.9M/170M [01:36\u003c05:38, 388kB/s] 23%|\u2588\u2588\u258e | 39.0M/170M [01:36\u003c05:36, 391kB/s] 23%|\u2588\u2588\u258e | 39.1M/170M [01:36\u003c05:34, 393kB/s] 23%|\u2588\u2588\u258e | 39.1M/170M [01:36\u003c05:27, 402kB/s] 23%|\u2588\u2588\u258e | 39.2M/170M [01:36\u003c05:27, 400kB/s] 23%|\u2588\u2588\u258e | 39.3M/170M [01:37\u003c05:37, 389kB/s] 23%|\u2588\u2588\u258e | 39.3M/170M [01:37\u003c05:33, 393kB/s] 23%|\u2588\u2588\u258e | 39.4M/170M [01:37\u003c05:27, 400kB/s] 23%|\u2588\u2588\u258e | 39.5M/170M [01:37\u003c05:30, 397kB/s] 23%|\u2588\u2588\u258e | 39.5M/170M [01:37\u003c05:25, 402kB/s] 23%|\u2588\u2588\u258e | 39.6M/170M [01:37\u003c05:25, 402kB/s] 23%|\u2588\u2588\u258e | 39.6M/170M [01:38\u003c05:37, 388kB/s] 23%|\u2588\u2588\u258e | 39.7M/170M [01:38\u003c05:32, 393kB/s] 23%|\u2588\u2588\u258e | 39.8M/170M [01:38\u003c05:29, 397kB/s] 23%|\u2588\u2588\u258e | 39.8M/170M [01:38\u003c05:24, 402kB/s] 23%|\u2588\u2588\u258e | 39.9M/170M [01:38\u003c05:23, 404kB/s] 23%|\u2588\u2588\u258e | 40.0M/170M [01:38\u003c05:32, 392kB/s] 23%|\u2588\u2588\u258e | 40.0M/170M [01:39\u003c05:48, 374kB/s] 24%|\u2588\u2588\u258e | 40.1M/170M [01:39\u003c05:21, 406kB/s] 24%|\u2588\u2588\u258e | 40.2M/170M [01:39\u003c05:20, 406kB/s] 24%|\u2588\u2588\u258e | 40.2M/170M [01:39\u003c05:21, 405kB/s] 24%|\u2588\u2588\u258e | 40.3M/170M [01:39\u003c05:32, 391kB/s] 24%|\u2588\u2588\u258e | 40.4M/170M [01:39\u003c05:31, 392kB/s] 24%|\u2588\u2588\u258e | 40.4M/170M [01:40\u003c05:28, 396kB/s] 24%|\u2588\u2588\u258d | 40.5M/170M [01:40\u003c05:23, 402kB/s] 24%|\u2588\u2588\u258d | 40.6M/170M [01:40\u003c05:21, 405kB/s] 24%|\u2588\u2588\u258d | 40.6M/170M [01:40\u003c05:51, 370kB/s] 24%|\u2588\u2588\u258d | 40.7M/170M [01:40\u003c05:18, 407kB/s] 24%|\u2588\u2588\u258d | 40.8M/170M [01:40\u003c05:21, 404kB/s] 24%|\u2588\u2588\u258d | 40.8M/170M [01:41\u003c05:16, 409kB/s] 24%|\u2588\u2588\u258d | 40.9M/170M [01:41\u003c05:15, 410kB/s] 24%|\u2588\u2588\u258d | 41.0M/170M [01:41\u003c05:32, 389kB/s] 24%|\u2588\u2588\u258d | 41.0M/170M [01:41\u003c05:29, 393kB/s] 24%|\u2588\u2588\u258d | 41.1M/170M [01:41\u003c05:29, 393kB/s] 24%|\u2588\u2588\u258d | 41.2M/170M [01:41\u003c05:22, 402kB/s] 24%|\u2588\u2588\u258d | 41.2M/170M [01:42\u003c05:34, 387kB/s] 24%|\u2588\u2588\u258d | 41.3M/170M [01:42\u003c05:16, 408kB/s] 24%|\u2588\u2588\u258d | 41.4M/170M [01:42\u003c05:32, 389kB/s] 24%|\u2588\u2588\u258d | 41.4M/170M [01:42\u003c05:26, 395kB/s] 24%|\u2588\u2588\u258d | 41.5M/170M [01:42\u003c05:24, 398kB/s] 24%|\u2588\u2588\u258d | 41.5M/170M [01:42\u003c05:23, 399kB/s] 24%|\u2588\u2588\u258d | 41.6M/170M [01:43\u003c05:21, 401kB/s] 24%|\u2588\u2588\u258d | 41.7M/170M [01:43\u003c05:36, 383kB/s] 24%|\u2588\u2588\u258d | 41.7M/170M [01:43\u003c05:27, 393kB/s] 25%|\u2588\u2588\u258d | 41.8M/170M [01:43\u003c05:26, 394kB/s] 25%|\u2588\u2588\u258d | 41.9M/170M [01:43\u003c05:23, 398kB/s] 25%|\u2588\u2588\u258d | 41.9M/170M [01:43\u003c05:33, 385kB/s] 25%|\u2588\u2588\u258d | 42.0M/170M [01:44\u003c05:35, 383kB/s] 25%|\u2588\u2588\u258d | 42.1M/170M [01:44\u003c05:22, 398kB/s] 25%|\u2588\u2588\u258d | 42.1M/170M [01:44\u003c05:21, 399kB/s] 25%|\u2588\u2588\u258d | 42.2M/170M [01:44\u003c05:20, 400kB/s] 25%|\u2588\u2588\u258d | 42.3M/170M [01:44\u003c05:20, 400kB/s] 25%|\u2588\u2588\u258d | 42.3M/170M [01:44\u003c05:34, 383kB/s] 25%|\u2588\u2588\u258d | 42.4M/170M [01:45\u003c05:27, 391kB/s] 25%|\u2588\u2588\u258d | 42.5M/170M [01:45\u003c05:24, 394kB/s] 25%|\u2588\u2588\u258d | 42.5M/170M [01:45\u003c05:25, 393kB/s] 25%|\u2588\u2588\u258d | 42.6M/170M [01:45\u003c05:21, 398kB/s] 25%|\u2588\u2588\u258c | 42.7M/170M [01:45\u003c05:30, 387kB/s] 25%|\u2588\u2588\u258c | 42.7M/170M [01:45\u003c05:31, 386kB/s] 25%|\u2588\u2588\u258c | 42.8M/170M [01:46\u003c05:18, 401kB/s] 25%|\u2588\u2588\u258c | 42.9M/170M [01:46\u003c05:18, 401kB/s] 25%|\u2588\u2588\u258c | 42.9M/170M [01:46\u003c05:17, 402kB/s] 25%|\u2588\u2588\u258c | 43.0M/170M [01:46\u003c05:16, 402kB/s] 25%|\u2588\u2588\u258c | 43.1M/170M [01:46\u003c05:27, 389kB/s] 25%|\u2588\u2588\u258c | 43.1M/170M [01:46\u003c05:23, 394kB/s] 25%|\u2588\u2588\u258c | 43.2M/170M [01:47\u003c05:23, 393kB/s] 25%|\u2588\u2588\u258c | 43.3M/170M [01:47\u003c05:23, 393kB/s] 25%|\u2588\u2588\u258c | 43.3M/170M [01:47\u003c05:19, 398kB/s] 25%|\u2588\u2588\u258c | 43.4M/170M [01:47\u003c05:45, 368kB/s] 25%|\u2588\u2588\u258c | 43.5M/170M [01:47\u003c05:16, 401kB/s] 26%|\u2588\u2588\u258c | 43.5M/170M [01:47\u003c05:21, 395kB/s] 26%|\u2588\u2588\u258c | 43.6M/170M [01:48\u003c05:19, 397kB/s] 26%|\u2588\u2588\u258c | 43.6M/170M [01:48\u003c05:20, 395kB/s] 26%|\u2588\u2588\u258c | 43.7M/170M [01:48\u003c05:31, 382kB/s] 26%|\u2588\u2588\u258c | 43.8M/170M [01:48\u003c05:23, 392kB/s] 26%|\u2588\u2588\u258c | 43.8M/170M [01:48\u003c05:21, 394kB/s] 26%|\u2588\u2588\u258c | 43.9M/170M [01:48\u003c05:20, 395kB/s] 26%|\u2588\u2588\u258c | 44.0M/170M [01:49\u003c05:17, 398kB/s] 26%|\u2588\u2588\u258c | 44.0M/170M [01:49\u003c05:29, 384kB/s] 26%|\u2588\u2588\u258c | 44.1M/170M [01:49\u003c05:23, 391kB/s] 26%|\u2588\u2588\u258c | 44.2M/170M [01:49\u003c05:24, 389kB/s] 26%|\u2588\u2588\u258c | 44.2M/170M [01:49\u003c05:22, 391kB/s] 26%|\u2588\u2588\u258c | 44.3M/170M [01:49\u003c05:17, 397kB/s] 26%|\u2588\u2588\u258c | 44.4M/170M [01:50\u003c05:16, 399kB/s] 26%|\u2588\u2588\u258c | 44.4M/170M [01:50\u003c05:28, 384kB/s] 26%|\u2588\u2588\u258c | 44.5M/170M [01:50\u003c05:22, 391kB/s] 26%|\u2588\u2588\u258c | 44.6M/170M [01:50\u003c05:17, 397kB/s] 26%|\u2588\u2588\u258c | 44.6M/170M [01:50\u003c05:16, 397kB/s] 26%|\u2588\u2588\u258c | 44.7M/170M [01:50\u003c05:13, 401kB/s] 26%|\u2588\u2588\u258b | 44.8M/170M [01:51\u003c05:24, 388kB/s] 26%|\u2588\u2588\u258b | 44.8M/170M [01:51\u003c05:16, 397kB/s] 26%|\u2588\u2588\u258b | 44.9M/170M [01:51\u003c05:13, 400kB/s] 26%|\u2588\u2588\u258b | 45.0M/170M [01:51\u003c05:16, 397kB/s] 26%|\u2588\u2588\u258b | 45.0M/170M [01:51\u003c05:11, 403kB/s] 26%|\u2588\u2588\u258b | 45.1M/170M [01:51\u003c05:22, 389kB/s] 26%|\u2588\u2588\u258b | 45.2M/170M [01:52\u003c05:18, 393kB/s] 27%|\u2588\u2588\u258b | 45.2M/170M [01:52\u003c05:16, 395kB/s] 27%|\u2588\u2588\u258b | 45.3M/170M [01:52\u003c05:14, 398kB/s] 27%|\u2588\u2588\u258b | 45.4M/170M [01:52\u003c05:14, 398kB/s] 27%|\u2588\u2588\u258b | 45.4M/170M [01:52\u003c05:35, 373kB/s] 27%|\u2588\u2588\u258b | 45.5M/170M [01:52\u003c05:18, 393kB/s] 27%|\u2588\u2588\u258b | 45.5M/170M [01:53\u003c05:16, 395kB/s] 27%|\u2588\u2588\u258b | 45.6M/170M [01:53\u003c05:15, 396kB/s] 27%|\u2588\u2588\u258b | 45.7M/170M [01:53\u003c05:15, 396kB/s] 27%|\u2588\u2588\u258b | 45.7M/170M [01:53\u003c05:24, 384kB/s] 27%|\u2588\u2588\u258b | 45.8M/170M [01:53\u003c05:20, 389kB/s] 27%|\u2588\u2588\u258b | 45.9M/170M [01:53\u003c05:15, 395kB/s] 27%|\u2588\u2588\u258b | 45.9M/170M [01:54\u003c05:16, 394kB/s] 27%|\u2588\u2588\u258b | 46.0M/170M [01:54\u003c05:10, 401kB/s] 27%|\u2588\u2588\u258b | 46.1M/170M [01:54\u003c05:12, 398kB/s] 27%|\u2588\u2588\u258b | 46.1M/170M [01:54\u003c05:26, 380kB/s] 27%|\u2588\u2588\u258b | 46.2M/170M [01:54\u003c05:18, 391kB/s] 27%|\u2588\u2588\u258b | 46.3M/170M [01:54\u003c05:15, 393kB/s] 27%|\u2588\u2588\u258b | 46.3M/170M [01:55\u003c05:16, 393kB/s] 27%|\u2588\u2588\u258b | 46.4M/170M [01:55\u003c05:12, 397kB/s] 27%|\u2588\u2588\u258b | 46.5M/170M [01:55\u003c05:25, 381kB/s] 27%|\u2588\u2588\u258b | 46.5M/170M [01:55\u003c05:22, 384kB/s] 27%|\u2588\u2588\u258b | 46.6M/170M [01:55\u003c05:23, 384kB/s] 27%|\u2588\u2588\u258b | 46.7M/170M [01:55\u003c05:26, 379kB/s] 27%|\u2588\u2588\u258b | 46.7M/170M [01:56\u003c05:07, 402kB/s] 27%|\u2588\u2588\u258b | 46.8M/170M [01:56\u003c05:18, 388kB/s] 27%|\u2588\u2588\u258b | 46.9M/170M [01:56\u003c05:13, 394kB/s] 28%|\u2588\u2588\u258a | 46.9M/170M [01:56\u003c05:12, 396kB/s] 28%|\u2588\u2588\u258a | 47.0M/170M [01:56\u003c05:11, 396kB/s] 28%|\u2588\u2588\u258a | 47.1M/170M [01:56\u003c05:16, 390kB/s] 28%|\u2588\u2588\u258a | 47.1M/170M [01:57\u003c05:39, 364kB/s] 28%|\u2588\u2588\u258a | 47.2M/170M [01:57\u003c05:13, 393kB/s] 28%|\u2588\u2588\u258a | 47.3M/170M [01:57\u003c05:14, 392kB/s] 28%|\u2588\u2588\u258a | 47.3M/170M [01:57\u003c05:12, 395kB/s] 28%|\u2588\u2588\u258a | 47.4M/170M [01:57\u003c05:08, 399kB/s] 28%|\u2588\u2588\u258a | 47.4M/170M [01:57\u003c05:23, 380kB/s] 28%|\u2588\u2588\u258a | 47.5M/170M [01:58\u003c05:18, 386kB/s] 28%|\u2588\u2588\u258a | 47.6M/170M [01:58\u003c05:13, 392kB/s] 28%|\u2588\u2588\u258a | 47.6M/170M [01:58\u003c05:08, 398kB/s] 28%|\u2588\u2588\u258a | 47.7M/170M [01:58\u003c05:24, 379kB/s] 28%|\u2588\u2588\u258a | 47.8M/170M [01:58\u003c05:00, 408kB/s] 28%|\u2588\u2588\u258a | 47.8M/170M [01:58\u003c05:18, 385kB/s] 28%|\u2588\u2588\u258a | 47.9M/170M [01:59\u003c05:10, 394kB/s] 28%|\u2588\u2588\u258a | 48.0M/170M [01:59\u003c05:08, 397kB/s] 28%|\u2588\u2588\u258a | 48.0M/170M [01:59\u003c05:10, 395kB/s] 28%|\u2588\u2588\u258a | 48.1M/170M [01:59\u003c05:04, 402kB/s] 28%|\u2588\u2588\u258a | 48.2M/170M [01:59\u003c05:15, 388kB/s] 28%|\u2588\u2588\u258a | 48.2M/170M [01:59\u003c05:10, 394kB/s] 28%|\u2588\u2588\u258a | 48.3M/170M [02:00\u003c05:09, 395kB/s] 28%|\u2588\u2588\u258a | 48.4M/170M [02:00\u003c05:05, 399kB/s] 28%|\u2588\u2588\u258a | 48.4M/170M [02:00\u003c05:03, 403kB/s] 28%|\u2588\u2588\u258a | 48.5M/170M [02:00\u003c05:26, 374kB/s] 28%|\u2588\u2588\u258a | 48.6M/170M [02:00\u003c05:06, 398kB/s] 29%|\u2588\u2588\u258a | 48.6M/170M [02:00\u003c05:06, 397kB/s] 29%|\u2588\u2588\u258a | 48.7M/170M [02:01\u003c05:23, 376kB/s] 29%|\u2588\u2588\u258a | 48.8M/170M [02:01\u003c04:59, 406kB/s] 29%|\u2588\u2588\u258a | 48.8M/170M [02:01\u003c05:10, 392kB/s] 29%|\u2588\u2588\u258a | 48.9M/170M [02:01\u003c05:08, 394kB/s] 29%|\u2588\u2588\u258a | 49.0M/170M [02:01\u003c05:11, 390kB/s] 29%|\u2588\u2588\u2589 | 49.0M/170M [02:01\u003c05:07, 396kB/s] 29%|\u2588\u2588\u2589 | 49.1M/170M [02:02\u003c05:07, 395kB/s] 29%|\u2588\u2588\u2589 | 49.2M/170M [02:02\u003c05:17, 382kB/s] 29%|\u2588\u2588\u2589 | 49.2M/170M [02:02\u003c05:11, 389kB/s] 29%|\u2588\u2588\u2589 | 49.3M/170M [02:02\u003c05:10, 390kB/s] 29%|\u2588\u2588\u2589 | 49.3M/170M [02:02\u003c04:59, 404kB/s] 29%|\u2588\u2588\u2589 | 49.4M/170M [02:02\u003c05:02, 401kB/s] 29%|\u2588\u2588\u2589 | 49.5M/170M [02:03\u003c05:10, 390kB/s] 29%|\u2588\u2588\u2589 | 49.5M/170M [02:03\u003c05:20, 377kB/s] 29%|\u2588\u2588\u2589 | 49.6M/170M [02:03\u003c05:00, 402kB/s] 29%|\u2588\u2588\u2589 | 49.7M/170M [02:03\u003c05:02, 399kB/s] 29%|\u2588\u2588\u2589 | 49.7M/170M [02:03\u003c05:14, 385kB/s] 29%|\u2588\u2588\u2589 | 49.8M/170M [02:03\u003c04:58, 405kB/s] 29%|\u2588\u2588\u2589 | 49.9M/170M [02:04\u003c05:07, 393kB/s] 29%|\u2588\u2588\u2589 | 49.9M/170M [02:04\u003c05:06, 394kB/s] 29%|\u2588\u2588\u2589 | 50.0M/170M [02:04\u003c05:05, 394kB/s] 29%|\u2588\u2588\u2589 | 50.1M/170M [02:04\u003c05:02, 398kB/s] 29%|\u2588\u2588\u2589 | 50.1M/170M [02:04\u003c05:12, 386kB/s] 29%|\u2588\u2588\u2589 | 50.2M/170M [02:04\u003c05:04, 395kB/s] 29%|\u2588\u2588\u2589 | 50.3M/170M [02:05\u003c05:03, 396kB/s] 30%|\u2588\u2588\u2589 | 50.3M/170M [02:05\u003c05:02, 398kB/s] 30%|\u2588\u2588\u2589 | 50.4M/170M [02:05\u003c05:00, 399kB/s] 30%|\u2588\u2588\u2589 | 50.5M/170M [02:05\u003c05:02, 396kB/s] 30%|\u2588\u2588\u2589 | 50.5M/170M [02:05\u003c05:10, 386kB/s] 30%|\u2588\u2588\u2589 | 50.6M/170M [02:05\u003c05:24, 370kB/s] 30%|\u2588\u2588\u2589 | 50.7M/170M [02:06\u003c05:00, 399kB/s] 30%|\u2588\u2588\u2589 | 50.7M/170M [02:06\u003c04:56, 404kB/s] 30%|\u2588\u2588\u2589 | 50.8M/170M [02:06\u003c04:56, 403kB/s] 30%|\u2588\u2588\u2589 | 50.9M/170M [02:06\u003c05:09, 387kB/s] 30%|\u2588\u2588\u2589 | 50.9M/170M [02:06\u003c05:06, 391kB/s] 30%|\u2588\u2588\u2589 | 51.0M/170M [02:06\u003c05:02, 396kB/s] 30%|\u2588\u2588\u2589 | 51.1M/170M [02:07\u003c04:58, 400kB/s] 30%|\u2588\u2588\u2589 | 51.1M/170M [02:07\u003c04:58, 400kB/s] 30%|\u2588\u2588\u2588 | 51.2M/170M [02:07\u003c04:58, 399kB/s] 30%|\u2588\u2588\u2588 | 51.2M/170M [02:07\u003c05:07, 388kB/s] 30%|\u2588\u2588\u2588 | 51.3M/170M [02:07\u003c05:05, 390kB/s] 30%|\u2588\u2588\u2588 | 51.4M/170M [02:07\u003c05:02, 394kB/s] 30%|\u2588\u2588\u2588 | 51.4M/170M [02:08\u003c05:03, 392kB/s] 30%|\u2588\u2588\u2588 | 51.5M/170M [02:08\u003c05:04, 391kB/s] 30%|\u2588\u2588\u2588 | 51.6M/170M [02:08\u003c05:12, 380kB/s] 30%|\u2588\u2588\u2588 | 51.6M/170M [02:08\u003c05:07, 387kB/s] 30%|\u2588\u2588\u2588 | 51.7M/170M [02:08\u003c05:04, 390kB/s] 30%|\u2588\u2588\u2588 | 51.8M/170M [02:08\u003c05:02, 393kB/s] 30%|\u2588\u2588\u2588 | 51.8M/170M [02:09\u003c04:59, 397kB/s] 30%|\u2588\u2588\u2588 | 51.9M/170M [02:09\u003c05:07, 385kB/s] 30%|\u2588\u2588\u2588 | 52.0M/170M [02:09\u003c05:03, 391kB/s] 31%|\u2588\u2588\u2588 | 52.0M/170M [02:09\u003c05:24, 365kB/s] 31%|\u2588\u2588\u2588 | 52.1M/170M [02:09\u003c05:03, 390kB/s] 31%|\u2588\u2588\u2588 | 52.2M/170M [02:09\u003c05:00, 394kB/s] 31%|\u2588\u2588\u2588 | 52.2M/170M [02:10\u003c05:08, 383kB/s] 31%|\u2588\u2588\u2588 | 52.3M/170M [02:10\u003c05:07, 384kB/s] 31%|\u2588\u2588\u2588 | 52.4M/170M [02:10\u003c04:59, 394kB/s] 31%|\u2588\u2588\u2588 | 52.4M/170M [02:10\u003c04:53, 402kB/s] 31%|\u2588\u2588\u2588 | 52.5M/170M [02:10\u003c04:51, 405kB/s] 31%|\u2588\u2588\u2588 | 52.6M/170M [02:10\u003c04:54, 401kB/s] 31%|\u2588\u2588\u2588 | 52.6M/170M [02:11\u003c05:02, 390kB/s] 31%|\u2588\u2588\u2588 | 52.7M/170M [02:11\u003c05:01, 390kB/s] 31%|\u2588\u2588\u2588 | 52.8M/170M [02:11\u003c04:58, 395kB/s] 31%|\u2588\u2588\u2588 | 52.8M/170M [02:11\u003c04:57, 395kB/s] 31%|\u2588\u2588\u2588 | 52.9M/170M [02:11\u003c04:56, 397kB/s] 31%|\u2588\u2588\u2588 | 53.0M/170M [02:11\u003c05:13, 375kB/s] 31%|\u2588\u2588\u2588 | 53.0M/170M [02:12\u003c05:06, 383kB/s] 31%|\u2588\u2588\u2588 | 53.1M/170M [02:12\u003c05:00, 390kB/s] 31%|\u2588\u2588\u2588 | 53.1M/170M [02:12\u003c05:00, 391kB/s] 31%|\u2588\u2588\u2588 | 53.2M/170M [02:12\u003c04:58, 393kB/s] 31%|\u2588\u2588\u2588\u258f | 53.3M/170M [02:12\u003c05:06, 383kB/s] 31%|\u2588\u2588\u2588\u258f | 53.3M/170M [02:12\u003c05:04, 385kB/s] 31%|\u2588\u2588\u2588\u258f | 53.4M/170M [02:13\u003c05:15, 372kB/s] 31%|\u2588\u2588\u2588\u258f | 53.5M/170M [02:13\u003c04:50, 402kB/s] 31%|\u2588\u2588\u2588\u258f | 53.5M/170M [02:13\u003c04:49, 404kB/s] 31%|\u2588\u2588\u2588\u258f | 53.6M/170M [02:13\u003c05:05, 383kB/s] 31%|\u2588\u2588\u2588\u258f | 53.7M/170M [02:13\u003c04:59, 390kB/s] 32%|\u2588\u2588\u2588\u258f | 53.7M/170M [02:13\u003c04:59, 389kB/s] 32%|\u2588\u2588\u2588\u258f | 53.8M/170M [02:14\u003c04:56, 394kB/s] 32%|\u2588\u2588\u2588\u258f | 53.9M/170M [02:14\u003c04:56, 394kB/s] 32%|\u2588\u2588\u2588\u258f | 53.9M/170M [02:14\u003c05:05, 382kB/s] 32%|\u2588\u2588\u2588\u258f | 54.0M/170M [02:14\u003c05:03, 384kB/s] 32%|\u2588\u2588\u2588\u258f | 54.1M/170M [02:14\u003c05:00, 387kB/s] 32%|\u2588\u2588\u2588\u258f | 54.1M/170M [02:14\u003c04:59, 389kB/s] 32%|\u2588\u2588\u2588\u258f | 54.2M/170M [02:15\u003c04:55, 393kB/s] 32%|\u2588\u2588\u2588\u258f | 54.3M/170M [02:15\u003c04:56, 392kB/s] 32%|\u2588\u2588\u2588\u258f | 54.3M/170M [02:15\u003c05:05, 380kB/s] 32%|\u2588\u2588\u2588\u258f | 54.4M/170M [02:15\u003c05:02, 384kB/s] 32%|\u2588\u2588\u2588\u258f | 54.5M/170M [02:15\u003c04:58, 389kB/s] 32%|\u2588\u2588\u2588\u258f | 54.5M/170M [02:15\u003c04:58, 389kB/s] 32%|\u2588\u2588\u2588\u258f | 54.6M/170M [02:16\u003c05:01, 385kB/s] 32%|\u2588\u2588\u2588\u258f | 54.7M/170M [02:16\u003c05:07, 377kB/s] 32%|\u2588\u2588\u2588\u258f | 54.7M/170M [02:16\u003c05:05, 379kB/s] 32%|\u2588\u2588\u2588\u258f | 54.8M/170M [02:16\u003c04:59, 386kB/s] 32%|\u2588\u2588\u2588\u258f | 54.9M/170M [02:16\u003c04:57, 388kB/s] 32%|\u2588\u2588\u2588\u258f | 54.9M/170M [02:17\u003c04:56, 390kB/s] 32%|\u2588\u2588\u2588\u258f | 55.0M/170M [02:17\u003c05:10, 372kB/s] 32%|\u2588\u2588\u2588\u258f | 55.1M/170M [02:17\u003c05:23, 357kB/s] 32%|\u2588\u2588\u2588\u258f | 55.1M/170M [02:17\u003c04:57, 387kB/s] 32%|\u2588\u2588\u2588\u258f | 55.2M/170M [02:17\u003c04:57, 387kB/s] 32%|\u2588\u2588\u2588\u258f | 55.2M/170M [02:17\u003c05:03, 379kB/s] 32%|\u2588\u2588\u2588\u258f | 55.3M/170M [02:18\u003c05:09, 372kB/s] 32%|\u2588\u2588\u2588\u258f | 55.4M/170M [02:18\u003c05:00, 383kB/s] 33%|\u2588\u2588\u2588\u258e | 55.4M/170M [02:18\u003c04:57, 387kB/s] 33%|\u2588\u2588\u2588\u258e | 55.5M/170M [02:18\u003c04:53, 392kB/s] 33%|\u2588\u2588\u2588\u258e | 55.6M/170M [02:18\u003c04:54, 391kB/s] 33%|\u2588\u2588\u2588\u258e | 55.6M/170M [02:18\u003c05:04, 378kB/s] 33%|\u2588\u2588\u2588\u258e | 55.7M/170M [02:19\u003c05:03, 379kB/s] 33%|\u2588\u2588\u2588\u258e | 55.8M/170M [02:19\u003c04:58, 384kB/s] 33%|\u2588\u2588\u2588\u258e | 55.8M/170M [02:19\u003c04:54, 389kB/s] 33%|\u2588\u2588\u2588\u258e | 55.9M/170M [02:19\u003c04:51, 393kB/s] 33%|\u2588\u2588\u2588\u258e | 56.0M/170M [02:19\u003c04:50, 394kB/s] 33%|\u2588\u2588\u2588\u258e | 56.0M/170M [02:19\u003c04:59, 382kB/s] 33%|\u2588\u2588\u2588\u258e | 56.1M/170M [02:20\u003c04:54, 388kB/s] 33%|\u2588\u2588\u2588\u258e | 56.2M/170M [02:20\u003c04:57, 384kB/s] 33%|\u2588\u2588\u2588\u258e | 56.2M/170M [02:20\u003c05:03, 377kB/s] 33%|\u2588\u2588\u2588\u258e | 56.3M/170M [02:20\u003c04:49, 395kB/s] 33%|\u2588\u2588\u2588\u258e | 56.4M/170M [02:20\u003c04:59, 381kB/s] 33%|\u2588\u2588\u2588\u258e | 56.4M/170M [02:20\u003c05:07, 371kB/s] 33%|\u2588\u2588\u2588\u258e | 56.5M/170M [02:21\u003c04:54, 387kB/s] 33%|\u2588\u2588\u2588\u258e | 56.6M/170M [02:21\u003c05:07, 371kB/s] 33%|\u2588\u2588\u2588\u258e | 56.6M/170M [02:21\u003c04:42, 404kB/s] 33%|\u2588\u2588\u2588\u258e | 56.7M/170M [02:21\u003c04:52, 389kB/s] 33%|\u2588\u2588\u2588\u258e | 56.8M/170M [02:21\u003c04:57, 382kB/s] 33%|\u2588\u2588\u2588\u258e | 56.8M/170M [02:22\u003c05:04, 374kB/s] 33%|\u2588\u2588\u2588\u258e | 56.9M/170M [02:22\u003c04:45, 398kB/s] 33%|\u2588\u2588\u2588\u258e | 57.0M/170M [02:22\u003c04:44, 400kB/s] 33%|\u2588\u2588\u2588\u258e | 57.0M/170M [02:22\u003c04:54, 385kB/s] 33%|\u2588\u2588\u2588\u258e | 57.1M/170M [02:22\u003c04:54, 386kB/s] 34%|\u2588\u2588\u2588\u258e | 57.1M/170M [02:22\u003c04:52, 388kB/s] 34%|\u2588\u2588\u2588\u258e | 57.2M/170M [02:23\u003c04:55, 383kB/s] 34%|\u2588\u2588\u2588\u258e | 57.3M/170M [02:23\u003c04:49, 391kB/s] 34%|\u2588\u2588\u2588\u258e | 57.3M/170M [02:23\u003c05:01, 375kB/s] 34%|\u2588\u2588\u2588\u258e | 57.4M/170M [02:23\u003c04:57, 380kB/s] 34%|\u2588\u2588\u2588\u258e | 57.5M/170M [02:23\u003c05:00, 376kB/s] 34%|\u2588\u2588\u2588\u258e | 57.5M/170M [02:23\u003c04:47, 393kB/s] 34%|\u2588\u2588\u2588\u258d | 57.6M/170M [02:24\u003c04:53, 385kB/s] 34%|\u2588\u2588\u2588\u258d | 57.7M/170M [02:24\u003c04:49, 390kB/s] 34%|\u2588\u2588\u2588\u258d | 57.7M/170M [02:24\u003c05:00, 375kB/s] 34%|\u2588\u2588\u2588\u258d | 57.8M/170M [02:24\u003c04:53, 384kB/s] 34%|\u2588\u2588\u2588\u258d | 57.9M/170M [02:24\u003c04:53, 384kB/s] 34%|\u2588\u2588\u2588\u258d | 57.9M/170M [02:24\u003c05:00, 374kB/s] 34%|\u2588\u2588\u2588\u258d | 58.0M/170M [02:25\u003c04:46, 393kB/s] 34%|\u2588\u2588\u2588\u258d | 58.1M/170M [02:25\u003c04:55, 380kB/s] 34%|\u2588\u2588\u2588\u258d | 58.1M/170M [02:25\u003c04:53, 383kB/s] 34%|\u2588\u2588\u2588\u258d | 58.2M/170M [02:25\u003c04:47, 391kB/s] 34%|\u2588\u2588\u2588\u258d | 58.3M/170M [02:25\u003c04:47, 391kB/s] 34%|\u2588\u2588\u2588\u258d | 58.3M/170M [02:25\u003c04:50, 385kB/s] 34%|\u2588\u2588\u2588\u258d | 58.4M/170M [02:26\u003c04:54, 381kB/s] 34%|\u2588\u2588\u2588\u258d | 58.5M/170M [02:26\u003c04:48, 389kB/s] 34%|\u2588\u2588\u2588\u258d | 58.5M/170M [02:26\u003c04:46, 391kB/s] 34%|\u2588\u2588\u2588\u258d | 58.6M/170M [02:26\u003c05:00, 372kB/s] 34%|\u2588\u2588\u2588\u258d | 58.7M/170M [02:26\u003c04:38, 402kB/s] 34%|\u2588\u2588\u2588\u258d | 58.7M/170M [02:26\u003c04:51, 383kB/s] 34%|\u2588\u2588\u2588\u258d | 58.8M/170M [02:27\u003c04:47, 389kB/s] 35%|\u2588\u2588\u2588\u258d | 58.9M/170M [02:27\u003c04:44, 392kB/s] 35%|\u2588\u2588\u2588\u258d | 58.9M/170M [02:27\u003c04:44, 393kB/s] 35%|\u2588\u2588\u2588\u258d | 59.0M/170M [02:27\u003c04:41, 396kB/s] 35%|\u2588\u2588\u2588\u258d | 59.0M/170M [02:27\u003c04:52, 381kB/s] 35%|\u2588\u2588\u2588\u258d | 59.1M/170M [02:27\u003c04:49, 384kB/s] 35%|\u2588\u2588\u2588\u258d | 59.2M/170M [02:28\u003c04:45, 389kB/s] 35%|\u2588\u2588\u2588\u258d | 59.2M/170M [02:28\u003c04:44, 391kB/s] 35%|\u2588\u2588\u2588\u258d | 59.3M/170M [02:28\u003c04:48, 385kB/s] 35%|\u2588\u2588\u2588\u258d | 59.4M/170M [02:28\u003c04:44, 391kB/s] 35%|\u2588\u2588\u2588\u258d | 59.4M/170M [02:28\u003c04:56, 374kB/s] 35%|\u2588\u2588\u2588\u258d | 59.5M/170M [02:28\u003c04:51, 381kB/s] 35%|\u2588\u2588\u2588\u258d | 59.6M/170M [02:29\u003c04:46, 387kB/s] 35%|\u2588\u2588\u2588\u258d | 59.6M/170M [02:29\u003c04:47, 385kB/s] 35%|\u2588\u2588\u2588\u258c | 59.7M/170M [02:29\u003c04:42, 393kB/s] 35%|\u2588\u2588\u2588\u258c | 59.8M/170M [02:29\u003c04:54, 376kB/s] 35%|\u2588\u2588\u2588\u258c | 59.8M/170M [02:29\u003c04:48, 384kB/s] 35%|\u2588\u2588\u2588\u258c | 59.9M/170M [02:29\u003c04:46, 387kB/s] 35%|\u2588\u2588\u2588\u258c | 60.0M/170M [02:30\u003c04:44, 389kB/s] 35%|\u2588\u2588\u2588\u258c | 60.0M/170M [02:30\u003c04:41, 393kB/s] 35%|\u2588\u2588\u2588\u258c | 60.1M/170M [02:30\u003c04:51, 378kB/s] 35%|\u2588\u2588\u2588\u258c | 60.2M/170M [02:30\u003c04:47, 384kB/s] 35%|\u2588\u2588\u2588\u258c | 60.2M/170M [02:30\u003c04:44, 387kB/s] 35%|\u2588\u2588\u2588\u258c | 60.3M/170M [02:30\u003c04:43, 389kB/s] 35%|\u2588\u2588\u2588\u258c | 60.4M/170M [02:31\u003c04:39, 393kB/s] 35%|\u2588\u2588\u2588\u258c | 60.4M/170M [02:31\u003c04:52, 376kB/s] 35%|\u2588\u2588\u2588\u258c | 60.5M/170M [02:31\u003c05:03, 362kB/s] 36%|\u2588\u2588\u2588\u258c | 60.6M/170M [02:31\u003c04:39, 394kB/s] 36%|\u2588\u2588\u2588\u258c | 60.6M/170M [02:31\u003c04:39, 393kB/s] 36%|\u2588\u2588\u2588\u258c | 60.7M/170M [02:32\u003c04:45, 385kB/s] 36%|\u2588\u2588\u2588\u258c | 60.8M/170M [02:32\u003c04:35, 398kB/s] 36%|\u2588\u2588\u2588\u258c | 60.8M/170M [02:32\u003c04:54, 373kB/s] 36%|\u2588\u2588\u2588\u258c | 60.9M/170M [02:32\u003c04:49, 379kB/s] 36%|\u2588\u2588\u2588\u258c | 60.9M/170M [02:32\u003c04:44, 385kB/s] 36%|\u2588\u2588\u2588\u258c | 61.0M/170M [02:32\u003c04:42, 387kB/s] 36%|\u2588\u2588\u2588\u258c | 61.1M/170M [02:33\u003c04:39, 391kB/s] 36%|\u2588\u2588\u2588\u258c | 61.1M/170M [02:33\u003c04:49, 377kB/s] 36%|\u2588\u2588\u2588\u258c | 61.2M/170M [02:33\u003c04:45, 383kB/s] 36%|\u2588\u2588\u2588\u258c | 61.3M/170M [02:33\u003c04:44, 383kB/s] 36%|\u2588\u2588\u2588\u258c | 61.3M/170M [02:33\u003c04:45, 383kB/s] 36%|\u2588\u2588\u2588\u258c | 61.4M/170M [02:33\u003c04:43, 385kB/s] 36%|\u2588\u2588\u2588\u258c | 61.5M/170M [02:34\u003c04:52, 372kB/s] 36%|\u2588\u2588\u2588\u258c | 61.5M/170M [02:34\u003c04:45, 382kB/s] 36%|\u2588\u2588\u2588\u258c | 61.6M/170M [02:34\u003c04:46, 380kB/s] 36%|\u2588\u2588\u2588\u258c | 61.7M/170M [02:34\u003c04:42, 385kB/s] 36%|\u2588\u2588\u2588\u258c | 61.7M/170M [02:34\u003c04:38, 390kB/s] 36%|\u2588\u2588\u2588\u258c | 61.8M/170M [02:34\u003c04:49, 375kB/s] 36%|\u2588\u2588\u2588\u258b | 61.9M/170M [02:35\u003c04:44, 382kB/s] 36%|\u2588\u2588\u2588\u258b | 61.9M/170M [02:35\u003c04:42, 384kB/s] 36%|\u2588\u2588\u2588\u258b | 62.0M/170M [02:35\u003c04:42, 384kB/s] 36%|\u2588\u2588\u2588\u258b | 62.1M/170M [02:35\u003c04:38, 389kB/s] 36%|\u2588\u2588\u2588\u258b | 62.1M/170M [02:35\u003c04:48, 376kB/s] 36%|\u2588\u2588\u2588\u258b | 62.2M/170M [02:35\u003c04:43, 382kB/s] 37%|\u2588\u2588\u2588\u258b | 62.3M/170M [02:36\u003c04:39, 387kB/s] 37%|\u2588\u2588\u2588\u258b | 62.3M/170M [02:36\u003c04:37, 389kB/s] 37%|\u2588\u2588\u2588\u258b | 62.4M/170M [02:36\u003c04:35, 392kB/s] 37%|\u2588\u2588\u2588\u258b | 62.5M/170M [02:36\u003c04:33, 395kB/s] 37%|\u2588\u2588\u2588\u258b | 62.5M/170M [02:36\u003c04:45, 379kB/s] 37%|\u2588\u2588\u2588\u258b | 62.6M/170M [02:36\u003c04:41, 383kB/s] 37%|\u2588\u2588\u2588\u258b | 62.7M/170M [02:37\u003c04:38, 388kB/s] 37%|\u2588\u2588\u2588\u258b | 62.7M/170M [02:37\u003c04:36, 389kB/s] 37%|\u2588\u2588\u2588\u258b | 62.8M/170M [02:37\u003c04:34, 393kB/s] 37%|\u2588\u2588\u2588\u258b | 62.8M/170M [02:37\u003c04:45, 377kB/s] 37%|\u2588\u2588\u2588\u258b | 62.9M/170M [02:37\u003c04:38, 387kB/s] 37%|\u2588\u2588\u2588\u258b | 63.0M/170M [02:37\u003c04:35, 391kB/s] 37%|\u2588\u2588\u2588\u258b | 63.0M/170M [02:38\u003c04:35, 390kB/s] 37%|\u2588\u2588\u2588\u258b | 63.1M/170M [02:38\u003c04:45, 377kB/s] 37%|\u2588\u2588\u2588\u258b | 63.2M/170M [02:38\u003c04:47, 373kB/s] 37%|\u2588\u2588\u2588\u258b | 63.2M/170M [02:38\u003c04:34, 391kB/s] 37%|\u2588\u2588\u2588\u258b | 63.3M/170M [02:38\u003c04:48, 371kB/s] 37%|\u2588\u2588\u2588\u258b | 63.4M/170M [02:38\u003c04:27, 400kB/s] 37%|\u2588\u2588\u2588\u258b | 63.4M/170M [02:39\u003c04:27, 400kB/s] 37%|\u2588\u2588\u2588\u258b | 63.5M/170M [02:39\u003c04:41, 380kB/s] 37%|\u2588\u2588\u2588\u258b | 63.6M/170M [02:39\u003c04:47, 372kB/s] 37%|\u2588\u2588\u2588\u258b | 63.6M/170M [02:39\u003c04:32, 393kB/s] 37%|\u2588\u2588\u2588\u258b | 63.7M/170M [02:39\u003c04:46, 373kB/s] 37%|\u2588\u2588\u2588\u258b | 63.8M/170M [02:40\u003c04:25, 402kB/s] 37%|\u2588\u2588\u2588\u258b | 63.8M/170M [02:40\u003c04:36, 386kB/s] 37%|\u2588\u2588\u2588\u258b | 63.9M/170M [02:40\u003c04:49, 368kB/s] 38%|\u2588\u2588\u2588\u258a | 64.0M/170M [02:40\u003c04:29, 396kB/s] 38%|\u2588\u2588\u2588\u258a | 64.0M/170M [02:40\u003c04:27, 399kB/s] 38%|\u2588\u2588\u2588\u258a | 64.1M/170M [02:40\u003c04:31, 392kB/s] 38%|\u2588\u2588\u2588\u258a | 64.2M/170M [02:41\u003c04:38, 382kB/s] 38%|\u2588\u2588\u2588\u258a | 64.2M/170M [02:41\u003c04:36, 384kB/s] 38%|\u2588\u2588\u2588\u258a | 64.3M/170M [02:41\u003c04:36, 384kB/s] 38%|\u2588\u2588\u2588\u258a | 64.4M/170M [02:41\u003c04:42, 375kB/s] 38%|\u2588\u2588\u2588\u258a | 64.4M/170M [02:41\u003c04:27, 396kB/s] 38%|\u2588\u2588\u2588\u258a | 64.5M/170M [02:41\u003c04:42, 375kB/s] 38%|\u2588\u2588\u2588\u258a | 64.6M/170M [02:42\u003c04:29, 393kB/s] 38%|\u2588\u2588\u2588\u258a | 64.6M/170M [02:42\u003c04:28, 395kB/s] 38%|\u2588\u2588\u2588\u258a | 64.7M/170M [02:42\u003c04:46, 369kB/s] 38%|\u2588\u2588\u2588\u258a | 64.7M/170M [02:42\u003c04:23, 402kB/s] 38%|\u2588\u2588\u2588\u258a | 64.8M/170M [02:42\u003c04:22, 402kB/s] 38%|\u2588\u2588\u2588\u258a | 64.9M/170M [02:42\u003c04:34, 385kB/s] 38%|\u2588\u2588\u2588\u258a | 64.9M/170M [02:43\u003c04:43, 373kB/s] 38%|\u2588\u2588\u2588\u258a | 65.0M/170M [02:43\u003c04:29, 392kB/s] 38%|\u2588\u2588\u2588\u258a | 65.1M/170M [02:43\u003c04:35, 383kB/s] 38%|\u2588\u2588\u2588\u258a | 65.1M/170M [02:43\u003c04:25, 397kB/s] 38%|\u2588\u2588\u2588\u258a | 65.2M/170M [02:43\u003c04:33, 386kB/s] 38%|\u2588\u2588\u2588\u258a | 65.3M/170M [02:43\u003c04:31, 388kB/s] 38%|\u2588\u2588\u2588\u258a | 65.3M/170M [02:44\u003c04:33, 384kB/s] 38%|\u2588\u2588\u2588\u258a | 65.4M/170M [02:44\u003c04:26, 394kB/s] 38%|\u2588\u2588\u2588\u258a | 65.5M/170M [02:44\u003c04:30, 389kB/s] 38%|\u2588\u2588\u2588\u258a | 65.5M/170M [02:44\u003c04:37, 378kB/s] 38%|\u2588\u2588\u2588\u258a | 65.6M/170M [02:44\u003c04:30, 388kB/s] 39%|\u2588\u2588\u2588\u258a | 65.7M/170M [02:44\u003c04:29, 390kB/s] 39%|\u2588\u2588\u2588\u258a | 65.7M/170M [02:45\u003c04:27, 391kB/s] 39%|\u2588\u2588\u2588\u258a | 65.8M/170M [02:45\u003c04:28, 390kB/s] 39%|\u2588\u2588\u2588\u258a | 65.9M/170M [02:45\u003c04:28, 389kB/s] 39%|\u2588\u2588\u2588\u258a | 65.9M/170M [02:45\u003c04:37, 376kB/s] 39%|\u2588\u2588\u2588\u258a | 66.0M/170M [02:45\u003c04:34, 381kB/s] 39%|\u2588\u2588\u2588\u258a | 66.1M/170M [02:45\u003c04:29, 387kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.1M/170M [02:46\u003c04:30, 386kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.2M/170M [02:46\u003c04:28, 389kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.3M/170M [02:46\u003c04:35, 379kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.3M/170M [02:46\u003c04:31, 383kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.4M/170M [02:46\u003c04:29, 387kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.5M/170M [02:46\u003c04:31, 383kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.5M/170M [02:47\u003c04:21, 398kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.6M/170M [02:47\u003c04:29, 385kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.7M/170M [02:47\u003c04:25, 391kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.7M/170M [02:47\u003c04:24, 392kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.8M/170M [02:47\u003c04:21, 397kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.8M/170M [02:47\u003c04:20, 397kB/s] 39%|\u2588\u2588\u2588\u2589 | 66.9M/170M [02:48\u003c04:30, 384kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.0M/170M [02:48\u003c04:30, 382kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.0M/170M [02:48\u003c04:25, 390kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.1M/170M [02:48\u003c04:22, 395kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.2M/170M [02:48\u003c04:22, 394kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.2M/170M [02:48\u003c04:29, 383kB/s] 39%|\u2588\u2588\u2588\u2589 | 67.3M/170M [02:49\u003c04:26, 387kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.4M/170M [02:49\u003c04:22, 393kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.4M/170M [02:49\u003c04:20, 396kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.5M/170M [02:49\u003c04:23, 390kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.6M/170M [02:49\u003c04:20, 396kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.6M/170M [02:50\u003c04:29, 382kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.7M/170M [02:50\u003c04:25, 387kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.8M/170M [02:50\u003c04:21, 393kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.8M/170M [02:50\u003c04:21, 393kB/s] 40%|\u2588\u2588\u2588\u2589 | 67.9M/170M [02:50\u003c04:19, 395kB/s] 40%|\u2588\u2588\u2588\u2589 | 68.0M/170M [02:50\u003c04:26, 384kB/s] 40%|\u2588\u2588\u2588\u2589 | 68.0M/170M [02:51\u003c04:25, 386kB/s] 40%|\u2588\u2588\u2588\u2589 | 68.1M/170M [02:51\u003c04:23, 388kB/s] 40%|\u2588\u2588\u2588\u2589 | 68.2M/170M [02:51\u003c04:19, 394kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.2M/170M [02:51\u003c04:22, 390kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.3M/170M [02:51\u003c04:29, 379kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.4M/170M [02:51\u003c04:23, 388kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.4M/170M [02:52\u003c04:24, 386kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.5M/170M [02:52\u003c04:18, 394kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.6M/170M [02:52\u003c04:20, 392kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.6M/170M [02:52\u003c04:31, 375kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.7M/170M [02:52\u003c04:28, 380kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.7M/170M [02:52\u003c04:27, 380kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.8M/170M [02:53\u003c04:18, 394kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.9M/170M [02:53\u003c04:19, 391kB/s] 40%|\u2588\u2588\u2588\u2588 | 68.9M/170M [02:53\u003c04:19, 392kB/s] 40%|\u2588\u2588\u2588\u2588 | 69.0M/170M [02:53\u003c04:29, 376kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.1M/170M [02:53\u003c04:26, 380kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.1M/170M [02:53\u003c04:23, 385kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.2M/170M [02:54\u003c04:23, 384kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.3M/170M [02:54\u003c04:21, 387kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.3M/170M [02:54\u003c04:28, 377kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.4M/170M [02:54\u003c04:24, 383kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.5M/170M [02:54\u003c04:24, 382kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.5M/170M [02:54\u003c04:21, 386kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.6M/170M [02:55\u003c04:23, 383kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.7M/170M [02:55\u003c04:34, 368kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.7M/170M [02:55\u003c04:28, 375kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.8M/170M [02:55\u003c04:28, 376kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.9M/170M [02:55\u003c04:23, 381kB/s] 41%|\u2588\u2588\u2588\u2588 | 69.9M/170M [02:55\u003c04:24, 380kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.0M/170M [02:56\u003c04:40, 358kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.1M/170M [02:56\u003c04:26, 377kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.1M/170M [02:56\u003c04:25, 377kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.2M/170M [02:56\u003c04:23, 380kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.3M/170M [02:56\u003c04:24, 379kB/s] 41%|\u2588\u2588\u2588\u2588 | 70.3M/170M [02:57\u003c04:30, 371kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.4M/170M [02:57\u003c04:31, 369kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.5M/170M [02:57\u003c04:26, 375kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.5M/170M [02:57\u003c04:21, 382kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.6M/170M [02:57\u003c04:22, 380kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.6M/170M [02:57\u003c04:24, 378kB/s] 41%|\u2588\u2588\u2588\u2588\u258f | 70.7M/170M [02:58\u003c04:30, 369kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 70.8M/170M [02:58\u003c04:28, 372kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 70.8M/170M [02:58\u003c04:24, 376kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 70.9M/170M [02:58\u003c04:22, 380kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.0M/170M [02:58\u003c04:20, 383kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.0M/170M [02:58\u003c04:28, 370kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.1M/170M [02:59\u003c04:25, 374kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.2M/170M [02:59\u003c04:23, 377kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.2M/170M [02:59\u003c04:23, 377kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.3M/170M [02:59\u003c04:25, 373kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.4M/170M [02:59\u003c04:32, 363kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.4M/170M [03:00\u003c04:22, 377kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.5M/170M [03:00\u003c04:29, 367kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.6M/170M [03:00\u003c04:15, 387kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.6M/170M [03:00\u003c04:17, 384kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.7M/170M [03:00\u003c04:38, 355kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.8M/170M [03:00\u003c04:17, 384kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.8M/170M [03:01\u003c04:19, 381kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 71.9M/170M [03:01\u003c04:28, 368kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.0M/170M [03:01\u003c04:09, 395kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.0M/170M [03:01\u003c04:21, 377kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.1M/170M [03:01\u003c04:24, 372kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.2M/170M [03:01\u003c04:14, 386kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.2M/170M [03:02\u003c04:16, 382kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.3M/170M [03:02\u003c04:16, 383kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.4M/170M [03:02\u003c04:15, 384kB/s] 42%|\u2588\u2588\u2588\u2588\u258f | 72.4M/170M [03:02\u003c04:27, 367kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.5M/170M [03:02\u003c04:21, 375kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.5M/170M [03:02\u003c04:18, 378kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.6M/170M [03:03\u003c04:26, 367kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.7M/170M [03:03\u003c04:14, 384kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.7M/170M [03:03\u003c04:24, 370kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.8M/170M [03:03\u003c04:27, 366kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.9M/170M [03:03\u003c04:13, 385kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 72.9M/170M [03:03\u003c04:13, 384kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.0M/170M [03:04\u003c04:13, 385kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.1M/170M [03:04\u003c04:23, 370kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.1M/170M [03:04\u003c04:17, 377kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.2M/170M [03:04\u003c04:17, 377kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.3M/170M [03:04\u003c04:16, 379kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.3M/170M [03:05\u003c04:13, 383kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.4M/170M [03:05\u003c04:24, 367kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.5M/170M [03:05\u003c04:26, 365kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.5M/170M [03:05\u003c04:14, 381kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.6M/170M [03:05\u003c04:15, 379kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.7M/170M [03:05\u003c04:11, 385kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.7M/170M [03:06\u003c04:22, 369kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.8M/170M [03:06\u003c04:20, 371kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.9M/170M [03:06\u003c04:15, 378kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 73.9M/170M [03:06\u003c04:15, 378kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 74.0M/170M [03:06\u003c04:15, 378kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 74.1M/170M [03:06\u003c04:16, 376kB/s] 43%|\u2588\u2588\u2588\u2588\u258e | 74.1M/170M [03:07\u003c04:23, 365kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.2M/170M [03:07\u003c04:18, 372kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.3M/170M [03:07\u003c04:16, 375kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.3M/170M [03:07\u003c04:13, 379kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.4M/170M [03:07\u003c04:11, 382kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.4M/170M [03:08\u003c04:21, 368kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.5M/170M [03:08\u003c04:16, 375kB/s] 44%|\u2588\u2588\u2588\u2588\u258e | 74.6M/170M [03:08\u003c04:13, 379kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 74.6M/170M [03:08\u003c04:15, 375kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 74.7M/170M [03:08\u003c04:11, 381kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 74.8M/170M [03:08\u003c04:22, 364kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 74.8M/170M [03:09\u003c04:15, 374kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 74.9M/170M [03:09\u003c04:14, 375kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.0M/170M [03:09\u003c04:14, 376kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.0M/170M [03:09\u003c04:29, 355kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.1M/170M [03:09\u003c04:53, 325kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.2M/170M [03:10\u003c04:37, 343kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.2M/170M [03:10\u003c04:31, 351kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.3M/170M [03:10\u003c04:16, 371kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.4M/170M [03:10\u003c04:11, 378kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.4M/170M [03:10\u003c04:25, 359kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.5M/170M [03:10\u003c04:21, 364kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.6M/170M [03:11\u003c04:14, 373kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.6M/170M [03:11\u003c04:10, 378kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.7M/170M [03:11\u003c04:10, 379kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.8M/170M [03:11\u003c04:06, 384kB/s] 44%|\u2588\u2588\u2588\u2588\u258d | 75.8M/170M [03:11\u003c04:15, 370kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 75.9M/170M [03:11\u003c04:09, 379kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.0M/170M [03:12\u003c04:09, 379kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.0M/170M [03:12\u003c04:09, 379kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.1M/170M [03:12\u003c04:05, 384kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.2M/170M [03:12\u003c04:14, 370kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.2M/170M [03:12\u003c04:12, 374kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.3M/170M [03:12\u003c04:11, 374kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.3M/170M [03:13\u003c04:10, 377kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.4M/170M [03:13\u003c04:07, 381kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.5M/170M [03:13\u003c04:15, 368kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.5M/170M [03:13\u003c04:11, 374kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.6M/170M [03:13\u003c04:08, 378kB/s] 45%|\u2588\u2588\u2588\u2588\u258d | 76.7M/170M [03:14\u003c04:07, 378kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 76.7M/170M [03:14\u003c04:05, 381kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 76.8M/170M [03:14\u003c04:20, 359kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 76.9M/170M [03:14\u003c04:07, 379kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 76.9M/170M [03:14\u003c04:02, 386kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.0M/170M [03:14\u003c04:01, 387kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.1M/170M [03:15\u003c04:04, 381kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.1M/170M [03:15\u003c04:02, 385kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.2M/170M [03:15\u003c04:11, 371kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.3M/170M [03:15\u003c04:11, 371kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.3M/170M [03:15\u003c04:08, 375kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.4M/170M [03:15\u003c04:08, 375kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.5M/170M [03:16\u003c04:04, 380kB/s] 45%|\u2588\u2588\u2588\u2588\u258c | 77.5M/170M [03:16\u003c04:13, 366kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.6M/170M [03:16\u003c04:09, 372kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.7M/170M [03:16\u003c04:04, 379kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.7M/170M [03:16\u003c04:03, 381kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.8M/170M [03:16\u003c04:02, 382kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.9M/170M [03:17\u003c04:10, 370kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 77.9M/170M [03:17\u003c04:03, 379kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.0M/170M [03:17\u003c04:04, 379kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.1M/170M [03:17\u003c04:05, 377kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.1M/170M [03:17\u003c04:00, 384kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.2M/170M [03:18\u003c04:11, 368kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.2M/170M [03:18\u003c04:05, 375kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.3M/170M [03:18\u003c04:04, 377kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.4M/170M [03:18\u003c04:01, 382kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.4M/170M [03:18\u003c04:01, 381kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.5M/170M [03:18\u003c04:17, 358kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.6M/170M [03:19\u003c04:04, 376kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.6M/170M [03:19\u003c04:03, 376kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.7M/170M [03:19\u003c04:00, 382kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.8M/170M [03:19\u003c04:00, 381kB/s] 46%|\u2588\u2588\u2588\u2588\u258c | 78.8M/170M [03:19\u003c03:56, 387kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 78.9M/170M [03:19\u003c04:04, 375kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 79.0M/170M [03:20\u003c04:03, 376kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 79.0M/170M [03:20\u003c03:59, 381kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 79.1M/170M [03:20\u003c03:57, 385kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 79.2M/170M [03:20\u003c03:58, 383kB/s] 46%|\u2588\u2588\u2588\u2588\u258b | 79.2M/170M [03:20\u003c04:03, 374kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.3M/170M [03:20\u003c04:03, 374kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.4M/170M [03:21\u003c04:02, 376kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.4M/170M [03:21\u003c03:57, 383kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.5M/170M [03:21\u003c03:55, 386kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.6M/170M [03:21\u003c04:03, 374kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.6M/170M [03:21\u003c04:01, 376kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.7M/170M [03:22\u003c03:57, 382kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.8M/170M [03:22\u003c04:05, 370kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.8M/170M [03:22\u003c03:52, 390kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 79.9M/170M [03:22\u003c04:01, 375kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.0M/170M [03:22\u003c03:59, 378kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.0M/170M [03:22\u003c03:56, 382kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.1M/170M [03:23\u003c03:57, 380kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.2M/170M [03:23\u003c03:57, 380kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.2M/170M [03:23\u003c04:04, 370kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.3M/170M [03:23\u003c04:05, 367kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.3M/170M [03:23\u003c04:05, 368kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.4M/170M [03:23\u003c03:50, 391kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.5M/170M [03:24\u003c03:57, 379kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.5M/170M [03:24\u003c03:49, 392kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.6M/170M [03:24\u003c03:57, 379kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.7M/170M [03:24\u003c04:01, 373kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.7M/170M [03:24\u003c03:51, 387kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.8M/170M [03:24\u003c03:54, 383kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.9M/170M [03:25\u003c03:52, 385kB/s] 47%|\u2588\u2588\u2588\u2588\u258b | 80.9M/170M [03:25\u003c03:59, 374kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.0M/170M [03:25\u003c03:58, 375kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.1M/170M [03:25\u003c03:57, 377kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.1M/170M [03:25\u003c04:01, 369kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.2M/170M [03:25\u003c03:49, 389kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.3M/170M [03:26\u003c03:57, 375kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.3M/170M [03:26\u003c03:57, 375kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.4M/170M [03:26\u003c03:53, 382kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.5M/170M [03:26\u003c03:49, 388kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.5M/170M [03:26\u003c03:50, 387kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.6M/170M [03:27\u003c03:59, 371kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.7M/170M [03:27\u003c03:57, 373kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.7M/170M [03:27\u003c03:54, 378kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.8M/170M [03:27\u003c03:50, 384kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.9M/170M [03:27\u003c03:50, 384kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 81.9M/170M [03:27\u003c04:00, 368kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.0M/170M [03:28\u003c03:55, 375kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.1M/170M [03:28\u003c03:57, 372kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.1M/170M [03:28\u003c03:52, 380kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.2M/170M [03:28\u003c03:49, 385kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.2M/170M [03:28\u003c03:50, 382kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.3M/170M [03:28\u003c03:55, 374kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.4M/170M [03:29\u003c03:55, 374kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.4M/170M [03:29\u003c03:49, 383kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.5M/170M [03:29\u003c03:49, 383kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.6M/170M [03:29\u003c03:51, 380kB/s] 48%|\u2588\u2588\u2588\u2588\u258a | 82.6M/170M [03:29\u003c03:55, 373kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 82.7M/170M [03:29\u003c03:53, 376kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 82.8M/170M [03:30\u003c03:50, 380kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 82.8M/170M [03:30\u003c03:45, 388kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 82.9M/170M [03:30\u003c03:45, 388kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 83.0M/170M [03:30\u003c03:54, 374kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 83.0M/170M [03:30\u003c03:49, 381kB/s] 49%|\u2588\u2588\u2588\u2588\u258a | 83.1M/170M [03:30\u003c03:48, 383kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.2M/170M [03:31\u003c03:45, 387kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.2M/170M [03:31\u003c03:46, 386kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.3M/170M [03:31\u003c03:52, 375kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.4M/170M [03:31\u003c03:51, 377kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.4M/170M [03:31\u003c03:52, 375kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.5M/170M [03:32\u003c03:46, 383kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.6M/170M [03:32\u003c03:47, 382kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.6M/170M [03:32\u003c03:51, 376kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.7M/170M [03:32\u003c03:48, 380kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.8M/170M [03:32\u003c03:46, 383kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.8M/170M [03:32\u003c03:43, 387kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 83.9M/170M [03:33\u003c03:43, 388kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.0M/170M [03:33\u003c03:43, 388kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.0M/170M [03:33\u003c03:50, 375kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.1M/170M [03:33\u003c03:47, 379kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.1M/170M [03:33\u003c03:45, 383kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.2M/170M [03:33\u003c03:43, 387kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.3M/170M [03:34\u003c03:42, 387kB/s] 49%|\u2588\u2588\u2588\u2588\u2589 | 84.3M/170M [03:34\u003c03:52, 371kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.4M/170M [03:34\u003c03:46, 379kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.5M/170M [03:34\u003c03:45, 381kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.5M/170M [03:34\u003c03:44, 384kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.6M/170M [03:34\u003c03:42, 386kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.7M/170M [03:35\u003c03:47, 377kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.7M/170M [03:35\u003c03:46, 379kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.8M/170M [03:35\u003c03:43, 383kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.9M/170M [03:35\u003c03:41, 387kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 84.9M/170M [03:35\u003c03:41, 386kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 85.0M/170M [03:35\u003c03:47, 376kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 85.1M/170M [03:36\u003c03:46, 377kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 85.1M/170M [03:36\u003c03:46, 376kB/s] 50%|\u2588\u2588\u2588\u2588\u2589 | 85.2M/170M [03:36\u003c03:38, 390kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.3M/170M [03:36\u003c03:40, 387kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.3M/170M [03:36\u003c03:39, 388kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.4M/170M [03:37\u003c03:45, 377kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.5M/170M [03:37\u003c03:42, 382kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.5M/170M [03:37\u003c03:39, 386kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.6M/170M [03:37\u003c03:39, 388kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.7M/170M [03:37\u003c03:37, 391kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.7M/170M [03:37\u003c03:44, 378kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.8M/170M [03:38\u003c03:42, 381kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.9M/170M [03:38\u003c03:39, 385kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 85.9M/170M [03:38\u003c03:37, 389kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 86.0M/170M [03:38\u003c03:36, 390kB/s] 50%|\u2588\u2588\u2588\u2588\u2588 | 86.0M/170M [03:38\u003c03:43, 378kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.1M/170M [03:38\u003c03:40, 382kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.2M/170M [03:39\u003c03:44, 375kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.2M/170M [03:39\u003c03:35, 391kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.3M/170M [03:39\u003c03:36, 389kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.4M/170M [03:39\u003c03:43, 377kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.4M/170M [03:39\u003c03:40, 382kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.5M/170M [03:39\u003c03:39, 383kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.6M/170M [03:40\u003c03:37, 385kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.6M/170M [03:40\u003c03:35, 390kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.7M/170M [03:40\u003c03:57, 353kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.8M/170M [03:40\u003c03:39, 382kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.8M/170M [03:40\u003c03:36, 386kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 86.9M/170M [03:40\u003c03:37, 384kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.0M/170M [03:41\u003c03:44, 372kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.0M/170M [03:41\u003c03:29, 399kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.1M/170M [03:41\u003c03:39, 380kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.2M/170M [03:41\u003c03:37, 383kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.2M/170M [03:41\u003c03:38, 381kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.3M/170M [03:41\u003c03:37, 383kB/s] 51%|\u2588\u2588\u2588\u2588\u2588 | 87.4M/170M [03:42\u003c03:36, 385kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.4M/170M [03:42\u003c03:41, 375kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.5M/170M [03:42\u003c03:38, 379kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.6M/170M [03:42\u003c03:42, 373kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.6M/170M [03:42\u003c03:44, 370kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.7M/170M [03:43\u003c03:32, 389kB/s] 51%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.8M/170M [03:43\u003c03:42, 371kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.8M/170M [03:43\u003c03:39, 376kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.9M/170M [03:43\u003c03:37, 380kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 87.9M/170M [03:43\u003c03:36, 381kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.0M/170M [03:43\u003c03:34, 384kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.1M/170M [03:44\u003c03:42, 371kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.1M/170M [03:44\u003c03:53, 352kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.2M/170M [03:44\u003c03:35, 382kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.3M/170M [03:44\u003c03:33, 385kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.3M/170M [03:44\u003c03:39, 374kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.4M/170M [03:44\u003c03:38, 377kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.5M/170M [03:45\u003c03:37, 378kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.5M/170M [03:45\u003c03:34, 382kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.6M/170M [03:45\u003c03:33, 384kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.7M/170M [03:45\u003c03:34, 381kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.7M/170M [03:45\u003c03:39, 372kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.8M/170M [03:45\u003c03:37, 376kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.9M/170M [03:46\u003c03:33, 382kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 88.9M/170M [03:46\u003c03:35, 378kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.0M/170M [03:46\u003c03:34, 380kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.1M/170M [03:46\u003c03:31, 386kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.1M/170M [03:46\u003c03:41, 367kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.2M/170M [03:47\u003c03:36, 376kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.3M/170M [03:47\u003c03:35, 377kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.3M/170M [03:47\u003c03:35, 377kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.4M/170M [03:47\u003c03:37, 372kB/s] 52%|\u2588\u2588\u2588\u2588\u2588\u258f | 89.5M/170M [03:47\u003c03:40, 367kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.5M/170M [03:47\u003c03:31, 382kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.6M/170M [03:48\u003c03:32, 380kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.7M/170M [03:48\u003c03:31, 383kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.7M/170M [03:48\u003c03:27, 389kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.8M/170M [03:48\u003c03:37, 371kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.8M/170M [03:48\u003c03:34, 375kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 89.9M/170M [03:48\u003c03:31, 381kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.0M/170M [03:49\u003c03:31, 380kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.0M/170M [03:49\u003c03:30, 382kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.1M/170M [03:49\u003c03:45, 356kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.2M/170M [03:49\u003c03:33, 376kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.2M/170M [03:49\u003c03:31, 380kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.3M/170M [03:49\u003c03:29, 382kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.4M/170M [03:50\u003c03:29, 383kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.4M/170M [03:50\u003c03:27, 386kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.5M/170M [03:50\u003c03:34, 372kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.6M/170M [03:50\u003c03:29, 381kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.6M/170M [03:50\u003c03:29, 381kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.7M/170M [03:51\u003c03:31, 378kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.8M/170M [03:51\u003c03:27, 385kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.8M/170M [03:51\u003c03:36, 368kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 90.9M/170M [03:51\u003c03:32, 375kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.0M/170M [03:51\u003c03:31, 376kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.0M/170M [03:51\u003c03:29, 380kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.1M/170M [03:52\u003c03:26, 384kB/s] 53%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.2M/170M [03:52\u003c03:32, 373kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.2M/170M [03:52\u003c03:29, 378kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.3M/170M [03:52\u003c03:28, 380kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.4M/170M [03:52\u003c03:28, 379kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.4M/170M [03:52\u003c03:26, 383kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.5M/170M [03:53\u003c03:34, 369kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.6M/170M [03:53\u003c03:31, 373kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258e | 91.6M/170M [03:53\u003c03:29, 377kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 91.7M/170M [03:53\u003c03:28, 379kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 91.8M/170M [03:53\u003c03:27, 379kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 91.8M/170M [03:53\u003c03:33, 369kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 91.9M/170M [03:54\u003c03:30, 373kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 91.9M/170M [03:54\u003c03:32, 369kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.0M/170M [03:54\u003c03:24, 383kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.1M/170M [03:54\u003c03:23, 385kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.1M/170M [03:54\u003c03:23, 385kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.2M/170M [03:55\u003c03:31, 370kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.3M/170M [03:55\u003c03:28, 376kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.3M/170M [03:55\u003c03:25, 381kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.4M/170M [03:55\u003c03:24, 381kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.5M/170M [03:55\u003c03:24, 382kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.5M/170M [03:55\u003c03:31, 369kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.6M/170M [03:56\u003c03:27, 376kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.7M/170M [03:56\u003c03:26, 376kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.7M/170M [03:56\u003c03:26, 377kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.8M/170M [03:56\u003c03:26, 376kB/s] 54%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.9M/170M [03:56\u003c03:29, 370kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 92.9M/170M [03:56\u003c03:25, 378kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.0M/170M [03:57\u003c03:26, 375kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.1M/170M [03:57\u003c03:23, 380kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.1M/170M [03:57\u003c03:19, 387kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.2M/170M [03:57\u003c03:29, 369kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.3M/170M [03:57\u003c03:26, 374kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.3M/170M [03:57\u003c03:31, 366kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.4M/170M [03:58\u003c03:21, 382kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.5M/170M [03:58\u003c03:22, 380kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.5M/170M [03:58\u003c03:21, 383kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.6M/170M [03:58\u003c03:29, 367kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.7M/170M [03:58\u003c03:26, 371kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258d | 93.7M/170M [03:59\u003c03:23, 377kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 93.8M/170M [03:59\u003c03:30, 365kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 93.8M/170M [03:59\u003c03:18, 385kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 93.9M/170M [03:59\u003c03:29, 365kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.0M/170M [03:59\u003c03:25, 371kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.0M/170M [03:59\u003c03:23, 376kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.1M/170M [04:00\u003c03:22, 377kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.2M/170M [04:00\u003c03:21, 378kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.2M/170M [04:00\u003c03:31, 361kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.3M/170M [04:00\u003c03:25, 371kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.4M/170M [04:00\u003c03:25, 371kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.4M/170M [04:00\u003c03:22, 376kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.5M/170M [04:01\u003c03:21, 377kB/s] 55%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.6M/170M [04:01\u003c03:28, 365kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.6M/170M [04:01\u003c03:26, 367kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.7M/170M [04:01\u003c03:23, 373kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.8M/170M [04:01\u003c03:33, 355kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.8M/170M [04:02\u003c03:16, 385kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 94.9M/170M [04:02\u003c03:26, 366kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.0M/170M [04:02\u003c03:28, 363kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.0M/170M [04:02\u003c03:28, 362kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.1M/170M [04:02\u003c03:16, 383kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.2M/170M [04:02\u003c03:27, 363kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.2M/170M [04:03\u003c03:13, 388kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.3M/170M [04:03\u003c03:22, 372kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.4M/170M [04:03\u003c03:21, 373kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.4M/170M [04:03\u003c03:19, 376kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.5M/170M [04:03\u003c03:19, 375kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.6M/170M [04:03\u003c03:18, 377kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.6M/170M [04:04\u003c03:25, 365kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.7M/170M [04:04\u003c03:32, 352kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.7M/170M [04:04\u003c03:18, 377kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.8M/170M [04:04\u003c03:17, 378kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258c | 95.9M/170M [04:04\u003c03:18, 376kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 95.9M/170M [04:05\u003c03:20, 371kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.0M/170M [04:05\u003c03:19, 373kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.1M/170M [04:05\u003c03:18, 374kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.1M/170M [04:05\u003c03:18, 375kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.2M/170M [04:05\u003c03:17, 376kB/s] 56%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.3M/170M [04:05\u003c03:23, 365kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.3M/170M [04:06\u003c03:21, 367kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.4M/170M [04:06\u003c03:26, 358kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.5M/170M [04:06\u003c03:15, 379kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.5M/170M [04:06\u003c03:15, 379kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.6M/170M [04:06\u003c03:21, 366kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.7M/170M [04:06\u003c03:19, 370kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.7M/170M [04:07\u003c03:18, 371kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.8M/170M [04:07\u003c03:14, 378kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.9M/170M [04:07\u003c03:17, 373kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 96.9M/170M [04:07\u003c03:13, 379kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.0M/170M [04:07\u003c03:19, 368kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.1M/170M [04:08\u003c03:19, 369kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.1M/170M [04:08\u003c03:16, 374kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.2M/170M [04:08\u003c03:16, 373kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.3M/170M [04:08\u003c03:15, 375kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.3M/170M [04:08\u003c03:20, 365kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.4M/170M [04:08\u003c03:19, 366kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.5M/170M [04:09\u003c03:18, 368kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.5M/170M [04:09\u003c03:14, 375kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.6M/170M [04:09\u003c03:15, 373kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.6M/170M [04:09\u003c03:37, 335kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.7M/170M [04:09\u003c03:30, 346kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.8M/170M [04:10\u003c03:25, 354kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.8M/170M [04:10\u003c03:28, 349kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 97.9M/170M [04:10\u003c03:19, 363kB/s] 57%|\u2588\u2588\u2588\u2588\u2588\u258b | 98.0M/170M [04:10\u003c03:15, 371kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.0M/170M [04:10\u003c03:15, 371kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.1M/170M [04:10\u003c03:13, 373kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.2M/170M [04:11\u003c03:16, 368kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.2M/170M [04:11\u003c03:09, 382kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.3M/170M [04:11\u003c03:14, 370kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.4M/170M [04:11\u003c03:14, 370kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.4M/170M [04:11\u003c03:11, 376kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.5M/170M [04:11\u003c03:08, 382kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.6M/170M [04:12\u003c03:09, 379kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.6M/170M [04:12\u003c03:09, 379kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.7M/170M [04:12\u003c03:15, 368kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.8M/170M [04:12\u003c03:14, 369kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.8M/170M [04:12\u003c03:11, 375kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 98.9M/170M [04:13\u003c03:21, 356kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.0M/170M [04:13\u003c03:05, 385kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.0M/170M [04:13\u003c03:12, 371kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.1M/170M [04:13\u003c03:11, 372kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.2M/170M [04:13\u003c03:10, 375kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.2M/170M [04:13\u003c03:08, 379kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.3M/170M [04:14\u003c03:08, 377kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.4M/170M [04:14\u003c03:19, 357kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.4M/170M [04:14\u003c03:18, 358kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.5M/170M [04:14\u003c03:07, 380kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.5M/170M [04:14\u003c03:06, 381kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.6M/170M [04:14\u003c03:06, 380kB/s] 58%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.7M/170M [04:15\u003c03:11, 369kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.7M/170M [04:15\u003c03:12, 367kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.8M/170M [04:15\u003c03:10, 371kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.9M/170M [04:15\u003c03:06, 379kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 99.9M/170M [04:15\u003c03:07, 377kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 100M/170M [04:15\u003c03:11, 367kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 100M/170M [04:16\u003c03:19, 352kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u258a | 100M/170M [04:16\u003c03:03, 382kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 100M/170M [04:16\u003c03:05, 379kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 100M/170M [04:16\u003c03:05, 379kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 100M/170M [04:16\u003c03:04, 380kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 100M/170M [04:17\u003c03:09, 370kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 100M/170M [04:17\u003c03:06, 375kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:17\u003c03:07, 373kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:17\u003c03:03, 380kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:17\u003c03:02, 383kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:17\u003c03:11, 364kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:09, 369kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:06, 373kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:04, 378kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:10, 365kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:10, 365kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:18\u003c03:06, 372kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:19\u003c03:04, 375kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:19\u003c03:02, 378kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:19\u003c03:02, 379kB/s] 59%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:19\u003c03:09, 365kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 101M/170M [04:19\u003c03:05, 372kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:04, 374kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:01, 380kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:02, 378kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:10, 362kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:09, 363kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:20\u003c03:02, 376kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:00, 379kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:00, 380kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:00, 380kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:06, 366kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:03, 373kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2589 | 102M/170M [04:21\u003c03:04, 370kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 102M/170M [04:22\u003c02:58, 382kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 102M/170M [04:22\u003c02:58, 382kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 102M/170M [04:22\u003c03:04, 369kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 102M/170M [04:22\u003c03:02, 372kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:22\u003c03:00, 375kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:22\u003c02:58, 379kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:23\u003c03:07, 363kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:23\u003c03:08, 359kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:23\u003c02:59, 378kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:23\u003c03:05, 364kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:23\u003c02:55, 384kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c02:55, 385kB/s] 60%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c03:02, 368kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c03:05, 364kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c02:55, 383kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c02:56, 381kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:24\u003c02:57, 379kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:25\u003c02:57, 378kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 103M/170M [04:25\u003c03:03, 364kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:25\u003c02:59, 373kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:25\u003c03:04, 362kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:25\u003c02:56, 378kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:25\u003c02:55, 381kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:26\u003c03:02, 365kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:26\u003c02:58, 374kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:26\u003c02:57, 374kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:26\u003c02:56, 376kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:26\u003c03:02, 364kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:27\u003c02:58, 371kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:27\u003c02:54, 379kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:27\u003c02:55, 377kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:27\u003c02:55, 378kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588 | 104M/170M [04:27\u003c02:53, 382kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 104M/170M [04:27\u003c03:01, 365kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c02:58, 369kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c02:55, 376kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c02:57, 371kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c03:04, 357kB/s] 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c03:03, 359kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:28\u003c02:55, 375kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:29\u003c02:52, 379kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:29\u003c02:51, 381kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:29\u003c02:52, 380kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:29\u003c02:51, 382kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:29\u003c02:57, 368kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:30\u003c02:53, 375kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:30\u003c02:53, 375kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:30\u003c02:55, 371kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 105M/170M [04:30\u003c02:51, 379kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:30\u003c02:58, 365kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:30\u003c02:54, 372kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:52, 376kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:51, 377kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:50, 380kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:55, 368kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:51, 377kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:31\u003c02:52, 374kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:32\u003c02:50, 378kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:32\u003c02:47, 384kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:32\u003c02:54, 369kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:32\u003c02:54, 369kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:32\u003c02:50, 377kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:33\u003c02:50, 376kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:33\u003c02:54, 367kB/s] 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 106M/170M [04:33\u003c03:02, 350kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:33\u003c02:53, 369kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:33\u003c02:49, 377kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:33\u003c02:47, 381kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:49, 377kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:46, 382kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:51, 370kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:49, 375kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:48, 377kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:34\u003c02:48, 377kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c02:46, 380kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c03:00, 350kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c02:45, 382kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c02:45, 382kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c02:44, 383kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 107M/170M [04:35\u003c02:42, 388kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:36\u003c02:48, 374kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:36\u003c02:46, 378kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:36\u003c02:45, 380kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:36\u003c02:44, 382kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:36\u003c02:42, 385kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:49, 370kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:46, 376kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:46, 376kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:43, 381kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:43, 382kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:37\u003c02:48, 371kB/s] 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:38\u003c02:47, 371kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:38\u003c02:44, 378kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:38\u003c02:44, 377kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 108M/170M [04:38\u003c02:43, 378kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 109M/170M [04:38\u003c02:47, 371kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 109M/170M [04:38\u003c02:47, 370kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 109M/170M [04:39\u003c02:45, 374kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:39\u003c02:43, 379kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:39\u003c02:42, 380kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:39\u003c02:41, 381kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:39\u003c02:46, 369kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:53, 354kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:41, 381kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:41, 379kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:41, 381kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:47, 366kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:40\u003c02:43, 373kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:41\u003c02:44, 371kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 109M/170M [04:41\u003c02:42, 375kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:41\u003c02:40, 381kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:41\u003c02:45, 367kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:41\u003c02:44, 369kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:41\u003c02:42, 373kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:45, 367kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:40, 377kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:39, 381kB/s] 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:44, 369kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:41, 375kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:42\u003c02:39, 379kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:43\u003c02:40, 377kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:43\u003c02:48, 358kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:43\u003c02:49, 355kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:43\u003c02:39, 377kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:43\u003c02:39, 377kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 110M/170M [04:44\u003c02:37, 381kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 111M/170M [04:44\u003c02:34, 387kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 111M/170M [04:44\u003c02:41, 371kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 111M/170M [04:44\u003c02:40, 373kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 111M/170M [04:44\u003c02:45, 361kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 111M/170M [04:44\u003c02:35, 383kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:33, 388kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:39, 374kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:42, 367kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:34, 384kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:38, 374kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:45\u003c02:32, 388kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:46\u003c02:39, 371kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:46\u003c02:38, 374kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:46\u003c02:36, 378kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 111M/170M [04:46\u003c02:34, 383kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:46\u003c02:34, 380kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:46\u003c02:33, 383kB/s] 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:47\u003c02:37, 374kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:47\u003c02:36, 375kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:47\u003c02:33, 381kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:47\u003c02:34, 380kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:47\u003c02:33, 382kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:37, 371kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:37, 372kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:42, 360kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:29, 389kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:30, 386kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:48\u003c02:35, 373kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:49\u003c02:32, 381kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 112M/170M [04:49\u003c02:32, 381kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:49\u003c02:30, 385kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:49\u003c02:29, 387kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:49\u003c02:33, 376kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:49\u003c02:33, 376kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:50\u003c02:31, 382kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:50\u003c02:28, 389kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 113M/170M [04:50\u003c02:29, 385kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:50\u003c02:32, 377kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:50\u003c02:31, 380kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:50\u003c02:31, 379kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:51\u003c02:29, 384kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:51\u003c02:28, 386kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:51\u003c02:28, 386kB/s] 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:51\u003c02:32, 374kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 113M/170M [04:51\u003c02:30, 378kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:51\u003c02:28, 384kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:52\u003c02:27, 385kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:52\u003c02:27, 385kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:52\u003c02:32, 373kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:52\u003c02:31, 375kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:52\u003c02:30, 377kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:27, 383kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:28, 382kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:36, 360kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:29, 378kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:29, 377kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:53\u003c02:27, 381kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:54\u003c02:28, 378kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:54\u003c02:30, 374kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:54\u003c02:30, 372kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 114M/170M [04:54\u003c02:28, 377kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:54\u003c02:26, 382kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:54\u003c02:26, 382kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:30, 371kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:28, 374kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:27, 378kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:25, 382kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:25, 382kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:55\u003c02:25, 380kB/s] 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 115M/170M [04:56\u003c02:29, 370kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:56\u003c02:28, 374kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:56\u003c02:29, 371kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:56\u003c02:24, 383kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:56\u003c02:22, 386kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:57\u003c02:31, 364kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 115M/170M [04:57\u003c02:28, 371kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:57\u003c02:25, 377kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:57\u003c02:23, 382kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:57\u003c02:23, 382kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:57\u003c02:28, 370kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:24, 377kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:23, 379kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:22, 384kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:20, 387kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:24, 376kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:58\u003c02:24, 376kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:59\u003c02:22, 381kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:59\u003c02:21, 384kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:59\u003c02:21, 383kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:59\u003c02:27, 368kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 116M/170M [04:59\u003c02:24, 374kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [04:59\u003c02:23, 377kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:00\u003c02:20, 383kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:00\u003c02:20, 384kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:00\u003c02:19, 385kB/s] 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:00\u003c02:25, 368kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:00\u003c02:21, 378kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:01\u003c02:22, 377kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:01\u003c02:19, 383kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:01\u003c02:18, 387kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:01\u003c02:23, 371kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 117M/170M [05:01\u003c02:22, 375kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 117M/170M [05:01\u003c02:20, 380kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 117M/170M [05:02\u003c02:18, 384kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 117M/170M [05:02\u003c02:17, 385kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 117M/170M [05:02\u003c02:22, 372kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:02\u003c02:20, 376kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:02\u003c02:26, 362kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:02\u003c02:16, 388kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:17, 384kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:26, 359kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:19, 377kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:18, 380kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:17, 381kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:03\u003c02:20, 372kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:16, 384kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:20, 372kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:24, 362kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:15, 386kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:22, 365kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:04\u003c02:12, 393kB/s] 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 118M/170M [05:05\u003c02:18, 376kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:05\u003c02:18, 376kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:05\u003c02:20, 368kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:05\u003c02:12, 390kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:05\u003c02:17, 378kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:19, 370kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:15, 381kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:15, 381kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:19, 370kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:12, 387kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:06\u003c02:17, 373kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:07\u003c02:18, 370kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:07\u003c02:15, 378kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 119M/170M [05:07\u003c02:14, 379kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 119M/170M [05:07\u003c02:16, 375kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 119M/170M [05:07\u003c02:16, 372kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:07\u003c02:15, 377kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:08\u003c02:15, 377kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:08\u003c02:12, 383kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:08\u003c02:12, 382kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:08\u003c02:11, 387kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:08\u003c02:16, 372kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:13, 380kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:13, 378kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:13, 377kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:11, 384kB/s] 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:19, 362kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:09\u003c02:15, 370kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:10\u003c02:09, 389kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:10\u003c02:08, 390kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 120M/170M [05:10\u003c02:10, 384kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:10\u003c02:15, 369kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:10\u003c02:12, 378kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:10\u003c02:10, 382kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:22, 349kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:16, 365kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:19, 356kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:16, 364kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:12, 374kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:11\u003c02:11, 376kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:12\u003c02:09, 382kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:12\u003c02:13, 368kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:12\u003c02:12, 372kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:12\u003c02:10, 376kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:12\u003c02:09, 379kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 121M/170M [05:13\u003c02:09, 380kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:13\u003c02:07, 384kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:13\u003c02:12, 370kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:13\u003c02:09, 376kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:13\u003c02:09, 376kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:13\u003c02:08, 378kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:12, 367kB/s] 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:13, 365kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:07, 381kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:07, 380kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:06, 383kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:14\u003c02:04, 389kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:15\u003c02:09, 374kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:15\u003c02:07, 379kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:15\u003c02:06, 379kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:15\u003c02:07, 378kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 122M/170M [05:15\u003c02:06, 381kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:10, 367kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:08, 371kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:07, 376kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:06, 377kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:06, 378kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:16\u003c02:08, 370kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:12, 359kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:04, 380kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:04, 380kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:04, 380kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:02, 385kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:17\u003c02:07, 370kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:18\u003c02:06, 372kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:18\u003c02:06, 373kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 123M/170M [05:18\u003c02:05, 375kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 124M/170M [05:18\u003c02:05, 375kB/s] 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 124M/170M [05:18\u003c02:11, 357kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:18\u003c02:05, 374kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:19\u003c02:04, 375kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:19\u003c02:04, 376kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:19\u003c02:02, 382kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:19\u003c02:07, 366kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:19\u003c02:04, 372kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:04, 373kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:04, 374kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:02, 377kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:07, 363kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:05, 369kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:20\u003c02:05, 368kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 124M/170M [05:21\u003c02:08, 358kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:21\u003c02:07, 360kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:21\u003c02:04, 369kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:21\u003c02:02, 374kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:21\u003c02:01, 377kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:21\u003c02:00, 378kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:22\u003c02:00, 379kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:22\u003c02:01, 374kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:22\u003c02:04, 367kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:22\u003c02:01, 374kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:22\u003c02:02, 371kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:23\u003c02:00, 375kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:23\u003c01:59, 380kB/s] 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:23\u003c02:03, 366kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:23\u003c02:03, 367kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 125M/170M [05:23\u003c02:03, 365kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 126M/170M [05:23\u003c02:03, 364kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 126M/170M [05:24\u003c01:59, 375kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 126M/170M [05:24\u003c02:04, 362kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 126M/170M [05:24\u003c02:08, 347kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:24\u003c01:58, 376kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:24\u003c01:59, 373kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c02:03, 361kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c02:04, 357kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c02:00, 371kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c02:01, 367kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c01:56, 381kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:25\u003c01:57, 378kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:26\u003c01:59, 369kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:26\u003c02:01, 363kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:26\u003c01:57, 376kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 126M/170M [05:26\u003c01:57, 374kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:26\u003c01:58, 370kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:26\u003c01:56, 377kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:27\u003c01:59, 366kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:27\u003c01:59, 365kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:27\u003c01:58, 370kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:27\u003c01:56, 374kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:27\u003c01:55, 378kB/s] 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:58, 368kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:57, 370kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:56, 373kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:54, 378kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:54, 376kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:28\u003c01:57, 366kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:29\u003c01:56, 370kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 127M/170M [05:29\u003c01:56, 370kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:29\u003c01:54, 375kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:29\u003c01:54, 375kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:29\u003c01:57, 365kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:29\u003c01:56, 369kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:30\u003c01:55, 370kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 128M/170M [05:30\u003c01:53, 376kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:30\u003c01:53, 376kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:30\u003c01:53, 375kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:30\u003c01:56, 365kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:56, 364kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:53, 371kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:53, 371kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:53, 371kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:58, 355kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 128M/170M [05:31\u003c01:58, 353kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:52, 373kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:51, 377kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:50, 379kB/s] 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:53, 369kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:52, 370kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:32\u003c01:52, 370kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:33\u003c01:50, 377kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:33\u003c01:50, 374kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:33\u003c01:53, 364kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:33\u003c01:53, 364kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:33\u003c01:52, 369kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:34\u003c01:49, 376kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:34\u003c01:50, 374kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:34\u003c01:53, 363kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:34\u003c01:52, 366kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 129M/170M [05:34\u003c01:51, 368kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:34\u003c01:49, 374kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:51, 367kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:51, 366kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:50, 368kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:49, 373kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:49, 372kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 130M/170M [05:35\u003c01:47, 377kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:36\u003c01:47, 375kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:36\u003c01:51, 364kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:36\u003c01:49, 368kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:36\u003c01:47, 373kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:36\u003c01:46, 376kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:37\u003c01:46, 376kB/s] 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:37\u003c01:50, 364kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 130M/170M [05:37\u003c01:48, 368kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:37\u003c01:54, 350kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:37\u003c01:44, 380kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:37\u003c01:45, 379kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:48, 366kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:47, 369kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:46, 372kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:45, 376kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:44, 378kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:38\u003c01:47, 368kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:39\u003c01:46, 369kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:39\u003c01:45, 373kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:39\u003c01:43, 379kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:39\u003c01:43, 377kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:39\u003c01:44, 376kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 131M/170M [05:40\u003c01:46, 367kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:40\u003c01:44, 371kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:40\u003c01:44, 372kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:40\u003c01:42, 379kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:40\u003c01:42, 380kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:40\u003c01:45, 366kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:41\u003c01:47, 358kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:41\u003c01:46, 361kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:41\u003c01:40, 384kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:41\u003c01:40, 384kB/s] 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 132M/170M [05:41\u003c01:44, 368kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 132M/170M [05:41\u003c01:43, 370kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 132M/170M [05:42\u003c01:42, 373kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 132M/170M [05:42\u003c01:42, 372kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 132M/170M [05:42\u003c01:41, 376kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 132M/170M [05:42\u003c01:44, 364kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:42\u003c01:42, 369kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:47, 352kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:39, 382kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:39, 378kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:47, 349kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:40, 374kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:43\u003c01:39, 378kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:44, 360kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:37, 386kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:37, 383kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:41, 366kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:40, 370kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:44\u003c01:40, 371kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:45\u003c01:40, 369kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:45\u003c01:44, 355kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 133M/170M [05:45\u003c01:44, 353kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:45\u003c01:39, 372kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:45\u003c01:40, 366kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:36, 380kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:36, 380kB/s] 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:40, 366kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:39, 367kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:37, 373kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:46\u003c01:37, 373kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:47\u003c01:39, 366kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:47\u003c01:41, 359kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 134M/170M [05:47\u003c01:38, 370kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 134M/170M [05:47\u003c01:36, 377kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 134M/170M [05:47\u003c01:35, 377kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 134M/170M [05:47\u003c01:36, 376kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 134M/170M [05:48\u003c01:35, 377kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:48\u003c01:38, 364kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:48\u003c01:37, 370kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:48\u003c01:37, 367kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:48\u003c01:37, 369kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:35, 372kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:44, 339kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:34, 376kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:34, 375kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:34, 375kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:49\u003c01:35, 372kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:50\u003c01:37, 364kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:50\u003c01:35, 371kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:50\u003c01:34, 372kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:50\u003c01:34, 373kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 135M/170M [05:50\u003c01:32, 377kB/s] 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:36, 361kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:35, 364kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:33, 372kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:33, 371kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:33, 371kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:51\u003c01:39, 347kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:33, 370kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:31, 376kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:31, 375kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:31, 375kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:30, 378kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:52\u003c01:35, 360kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:53\u003c01:33, 365kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 136M/170M [05:53\u003c01:32, 368kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 136M/170M [05:53\u003c01:32, 368kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:53\u003c01:30, 375kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:53\u003c01:34, 360kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:31, 370kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:30, 372kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:30, 374kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:29, 375kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:33, 361kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:54\u003c01:31, 368kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:55\u003c01:30, 369kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:55\u003c01:32, 363kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:55\u003c01:32, 361kB/s] 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:55\u003c01:31, 363kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:55\u003c01:30, 368kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:56\u003c01:29, 371kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:56\u003c01:29, 370kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 137M/170M [05:56\u003c01:29, 370kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:56\u003c01:31, 359kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:56\u003c01:30, 362kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:56\u003c01:28, 369kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:28, 369kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:28, 369kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:28, 368kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:31, 358kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:28, 365kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:57\u003c01:28, 364kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:58\u003c01:31, 352kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:58\u003c01:26, 375kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:58\u003c01:29, 360kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:58\u003c01:29, 361kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:58\u003c01:28, 365kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 138M/170M [05:59\u003c01:26, 368kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [05:59\u003c01:25, 372kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [05:59\u003c01:29, 358kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [05:59\u003c01:27, 365kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [05:59\u003c01:26, 365kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [05:59\u003c01:30, 350kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:00\u003c01:24, 375kB/s] 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:00\u003c01:27, 359kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:00\u003c01:26, 365kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:00\u003c01:25, 369kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:00\u003c01:25, 369kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:01\u003c01:24, 371kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:01\u003c01:26, 359kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:01\u003c01:26, 362kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:01\u003c01:24, 368kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 139M/170M [06:01\u003c01:23, 370kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:01\u003c01:26, 359kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:02\u003c01:26, 356kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:02\u003c01:25, 361kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:02\u003c01:24, 364kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:02\u003c01:25, 361kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:02\u003c01:23, 365kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:23, 368kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:27, 347kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:24, 359kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:24, 361kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:23, 364kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:03\u003c01:22, 365kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:04\u003c01:25, 352kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:04\u003c01:24, 355kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 140M/170M [06:04\u003c01:23, 360kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 141M/170M [06:04\u003c01:22, 364kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 141M/170M [06:04\u003c01:20, 369kB/s] 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 141M/170M [06:05\u003c01:23, 356kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:05\u003c01:23, 357kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:05\u003c01:22, 360kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:05\u003c01:21, 364kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:05\u003c01:21, 364kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:05\u003c01:22, 356kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:06\u003c01:22, 356kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:06\u003c01:20, 363kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:06\u003c01:20, 366kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:06\u003c01:20, 366kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:06\u003c01:20, 365kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:07\u003c01:22, 351kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:07\u003c01:21, 358kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 141M/170M [06:07\u003c01:20, 359kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:07\u003c01:19, 363kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:07\u003c01:18, 368kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:07\u003c01:22, 347kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:08\u003c01:19, 361kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:08\u003c01:19, 362kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:08\u003c01:18, 366kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:08\u003c01:17, 368kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:08\u003c01:19, 358kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:18, 361kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:18, 363kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:19, 357kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:16, 369kB/s] 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:19, 354kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:09\u003c01:18, 359kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 142M/170M [06:10\u003c01:17, 363kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 143M/170M [06:10\u003c01:15, 370kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 143M/170M [06:10\u003c01:16, 366kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 143M/170M [06:10\u003c01:15, 367kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 143M/170M [06:10\u003c01:18, 355kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:17, 359kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:15, 367kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:15, 366kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:14, 367kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:16, 357kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:11\u003c01:16, 356kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:12\u003c01:15, 360kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:12\u003c01:14, 366kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:12\u003c01:14, 365kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:12\u003c01:16, 357kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 143M/170M [06:12\u003c01:15, 360kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:18, 344kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:11, 374kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:12, 371kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:14, 360kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:14, 360kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:13\u003c01:13, 363kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:12, 367kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:11, 369kB/s] 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:13, 360kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:13, 361kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:12, 362kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:14\u003c01:11, 368kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:15\u003c01:11, 369kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:15\u003c01:10, 369kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 144M/170M [06:15\u003c01:12, 357kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:15\u003c01:11, 362kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:15\u003c01:12, 359kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:16\u003c01:10, 366kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:16\u003c01:11, 363kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:16\u003c01:12, 355kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:16\u003c01:11, 358kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 145M/170M [06:16\u003c01:10, 362kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:16\u003c01:09, 368kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:17\u003c01:09, 366kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:17\u003c01:09, 363kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:17\u003c01:08, 368kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:17\u003c01:08, 369kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:17\u003c01:07, 372kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:18\u003c01:07, 371kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:18\u003c01:09, 359kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 145M/170M [06:18\u003c01:09, 361kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:18\u003c01:08, 366kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:18\u003c01:06, 372kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:18\u003c01:07, 369kB/s] 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:19\u003c01:08, 362kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:19\u003c01:11, 344kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:19\u003c01:06, 372kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:19\u003c01:05, 374kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:19\u003c01:06, 369kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:06, 370kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:08, 358kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:07, 362kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:07, 360kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:05, 366kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:20\u003c01:05, 365kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 146M/170M [06:21\u003c01:08, 353kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:21\u003c01:08, 347kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:21\u003c01:08, 349kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:21\u003c01:05, 366kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:21\u003c01:04, 368kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:22\u003c01:06, 356kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:22\u003c01:05, 359kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:22\u003c01:05, 362kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 147M/170M [06:22\u003c01:04, 365kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:22\u003c01:04, 365kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:22\u003c01:05, 355kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:23\u003c01:05, 355kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:23\u003c01:05, 357kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:23\u003c01:05, 355kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:23\u003c01:03, 366kB/s] 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 147M/170M [06:23\u003c01:05, 352kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:04, 355kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:03, 359kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:03, 362kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:02, 365kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:02, 364kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:24\u003c01:04, 353kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:25\u003c01:03, 355kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:25\u003c01:02, 360kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:25\u003c01:01, 363kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:25\u003c01:01, 363kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:25\u003c01:03, 352kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:26\u003c01:02, 357kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:26\u003c01:01, 360kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:26\u003c01:00, 364kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 148M/170M [06:26\u003c01:00, 363kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:26\u003c01:02, 351kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:26\u003c01:01, 354kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:27\u003c01:00, 359kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:27\u003c00:59, 365kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:27\u003c00:59, 366kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:27\u003c01:01, 350kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:27\u003c01:03, 339kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:28\u003c00:59, 361kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:28\u003c00:58, 368kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:28\u003c01:00, 354kB/s] 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 149M/170M [06:28\u003c01:01, 349kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 149M/170M [06:28\u003c00:58, 361kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 149M/170M [06:28\u003c00:58, 361kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 149M/170M [06:29\u003c00:59, 353kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 149M/170M [06:29\u003c00:57, 367kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 149M/170M [06:29\u003c00:56, 371kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:29\u003c00:59, 350kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:29\u003c00:58, 360kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:57, 360kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:57, 360kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:58, 356kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:58, 354kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:56, 362kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:30\u003c00:56, 362kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:31\u003c00:56, 363kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:31\u003c00:55, 368kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:31\u003c00:57, 353kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:31\u003c00:56, 356kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:31\u003c00:55, 363kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:32\u003c00:55, 363kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 150M/170M [06:32\u003c00:54, 364kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:32\u003c00:56, 356kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:32\u003c00:55, 358kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:32\u003c00:54, 364kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:32\u003c00:54, 364kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:33\u003c00:55, 355kB/s] 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:33\u003c00:54, 362kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:33\u003c00:56, 348kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:33\u003c00:54, 356kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:33\u003c00:53, 361kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:34\u003c00:54, 359kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:34\u003c00:52, 364kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 151M/170M [06:34\u003c00:55, 349kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 151M/170M [06:34\u003c00:53, 358kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 151M/170M [06:34\u003c00:54, 352kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 151M/170M [06:35\u003c00:54, 349kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:35\u003c00:51, 369kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:35\u003c00:53, 351kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:35\u003c00:52, 359kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:35\u003c00:52, 359kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:35\u003c00:52, 360kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:36\u003c00:51, 366kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:36\u003c00:53, 349kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:36\u003c00:52, 350kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:36\u003c00:50, 364kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:36\u003c00:50, 367kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:37\u003c00:50, 362kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:37\u003c00:52, 351kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:37\u003c00:51, 354kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:37\u003c00:50, 361kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 152M/170M [06:37\u003c00:50, 361kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:37\u003c00:49, 360kB/s] 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:38\u003c00:49, 366kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:38\u003c00:51, 349kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:38\u003c00:49, 356kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:38\u003c00:49, 358kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:38\u003c00:49, 357kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:48, 363kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:50, 350kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:49, 355kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:49, 355kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:48, 355kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:39\u003c00:47, 360kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:40\u003c00:52, 329kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:40\u003c00:47, 359kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 153M/170M [06:40\u003c00:47, 358kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 153M/170M [06:40\u003c00:47, 361kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:40\u003c00:46, 362kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:41\u003c00:48, 346kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:41\u003c00:48, 348kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:41\u003c00:47, 352kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:41\u003c00:49, 338kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:41\u003c00:45, 362kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:47, 350kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:46, 353kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:46, 356kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:45, 356kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:45, 355kB/s] 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:42\u003c00:45, 357kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:43\u003c00:47, 339kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:43\u003c00:45, 355kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 154M/170M [06:43\u003c00:45, 355kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:43\u003c00:44, 358kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:43\u003c00:44, 358kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:44\u003c00:46, 344kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:44\u003c00:45, 349kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:44\u003c00:44, 353kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:44\u003c00:44, 354kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:44\u003c00:43, 354kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:45, 344kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:44, 347kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:44, 349kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:43, 353kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:42, 358kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:45\u003c00:43, 345kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:46\u003c00:43, 348kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 155M/170M [06:46\u003c00:42, 353kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 156M/170M [06:46\u003c00:42, 354kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:46\u003c00:41, 357kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:46\u003c00:43, 345kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:44, 334kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:40, 361kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:40, 362kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:40, 361kB/s] 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:40, 363kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:47\u003c00:41, 347kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:48\u003c00:40, 352kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:48\u003c00:40, 351kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:48\u003c00:41, 341kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:48\u003c00:38, 368kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:48\u003c00:39, 354kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:49\u003c00:39, 356kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 156M/170M [06:49\u003c00:38, 359kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:49\u003c00:38, 361kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:49\u003c00:38, 363kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:49\u003c00:39, 353kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:40, 341kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:37, 364kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:36, 368kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:37, 366kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:38, 353kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:50\u003c00:37, 356kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:51\u003c00:36, 361kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:51\u003c00:36, 360kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:51\u003c00:36, 364kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:51\u003c00:37, 350kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:51\u003c00:36, 359kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 157M/170M [06:52\u003c00:36, 361kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 158M/170M [06:52\u003c00:35, 366kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 158M/170M [06:52\u003c00:35, 366kB/s] 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 158M/170M [06:52\u003c00:35, 366kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:52\u003c00:35, 356kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:52\u003c00:35, 359kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:35, 360kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:34, 366kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:34, 366kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:34, 355kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:34, 358kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:53\u003c00:34, 360kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:54\u003c00:34, 359kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:54\u003c00:34, 350kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:54\u003c00:33, 359kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 158M/170M [06:54\u003c00:33, 362kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:54\u003c00:34, 347kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:31, 373kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:31, 372kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:32, 360kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:32, 360kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:32, 361kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:55\u003c00:31, 368kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:56\u003c00:31, 366kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:56\u003c00:31, 365kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:56\u003c00:32, 355kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:56\u003c00:31, 358kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:56\u003c00:31, 360kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:57\u003c00:30, 365kB/s] 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:57\u003c00:30, 367kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 159M/170M [06:57\u003c00:31, 355kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 160M/170M [06:57\u003c00:30, 357kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 160M/170M [06:57\u003c00:30, 359kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 160M/170M [06:57\u003c00:29, 365kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 160M/170M [06:58\u003c00:29, 365kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 160M/170M [06:58\u003c00:30, 355kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:58\u003c00:29, 358kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:58\u003c00:29, 362kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:58\u003c00:28, 365kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:28, 364kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:29, 354kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:28, 356kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:28, 359kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:27, 364kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [06:59\u003c00:27, 365kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [07:00\u003c00:28, 353kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 160M/170M [07:00\u003c00:28, 354kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:00\u003c00:27, 361kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:00\u003c00:27, 365kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:00\u003c00:26, 367kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:26, 367kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:27, 356kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:26, 359kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:26, 358kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:26, 364kB/s] 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:01\u003c00:25, 363kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:02\u003c00:27, 334kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:02\u003c00:25, 362kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:02\u003c00:25, 363kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:02\u003c00:25, 366kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:02\u003c00:24, 367kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 161M/170M [07:03\u003c00:25, 352kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:03\u003c00:25, 351kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:03\u003c00:24, 359kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:03\u003c00:25, 342kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:03\u003c00:23, 369kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:04\u003c00:24, 357kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:04\u003c00:24, 356kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 162M/170M [07:04\u003c00:23, 360kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:04\u003c00:23, 365kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:04\u003c00:23, 361kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:04\u003c00:23, 354kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:05\u003c00:23, 354kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:05\u003c00:23, 353kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:05\u003c00:22, 365kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:05\u003c00:22, 361kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 162M/170M [07:05\u003c00:22, 363kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:22, 352kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:22, 357kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:22, 356kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:21, 359kB/s] 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:21, 359kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:06\u003c00:21, 353kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:07\u003c00:21, 357kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:07\u003c00:21, 356kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:07\u003c00:20, 363kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:07\u003c00:20, 362kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:07\u003c00:20, 349kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:08\u003c00:20, 353kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:08\u003c00:20, 357kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:08\u003c00:19, 362kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 163M/170M [07:08\u003c00:19, 359kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:08\u003c00:19, 350kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:08\u003c00:20, 340kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:09\u003c00:18, 366kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:09\u003c00:18, 367kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:09\u003c00:18, 363kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:09\u003c00:20, 327kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:09\u003c00:18, 352kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:10\u003c00:17, 363kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:10\u003c00:17, 366kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 164M/170M [07:10\u003c00:17, 365kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:10\u003c00:17, 367kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:10\u003c00:18, 330kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:11\u003c00:18, 328kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:11\u003c00:17, 354kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:11\u003c00:16, 361kB/s] 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 164M/170M [07:11\u003c00:17, 351kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:11\u003c00:17, 348kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:11\u003c00:16, 362kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:12\u003c00:15, 365kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:12\u003c00:15, 367kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:12\u003c00:15, 367kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:12\u003c00:15, 355kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:12\u003c00:15, 358kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:15, 360kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:14, 362kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:14, 371kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:14, 356kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:14, 358kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:13\u003c00:14, 364kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:14\u003c00:14, 363kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 165M/170M [07:14\u003c00:13, 362kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:14\u003c00:14, 350kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:14\u003c00:13, 356kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:14\u003c00:13, 363kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:13, 362kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:12, 362kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:12, 367kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:12, 351kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:12, 356kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:15\u003c00:12, 355kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:16\u003c00:12, 361kB/s] 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 166M/170M [07:16\u003c00:11, 366kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 166M/170M [07:16\u003c00:12, 351kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 166M/170M [07:16\u003c00:11, 353kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 166M/170M [07:16\u003c00:11, 348kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 166M/170M [07:17\u003c00:11, 358kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:17\u003c00:10, 361kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:17\u003c00:11, 350kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:17\u003c00:10, 353kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:17\u003c00:10, 360kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:17\u003c00:10, 359kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:18\u003c00:10, 349kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:18\u003c00:10, 350kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:18\u003c00:09, 358kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:18\u003c00:09, 364kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:18\u003c00:09, 362kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:19\u003c00:09, 363kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:19\u003c00:08, 367kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:19\u003c00:09, 352kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:19\u003c00:08, 353kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 167M/170M [07:19\u003c00:08, 353kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:19\u003c00:08, 361kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:20\u003c00:08, 364kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:20\u003c00:08, 353kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:20\u003c00:07, 361kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:20\u003c00:07, 362kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:20\u003c00:07, 362kB/s] 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:07, 368kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:07, 352kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:06, 353kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:06, 359kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:06, 359kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:21\u003c00:06, 365kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:22\u003c00:06, 350kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 168M/170M [07:22\u003c00:06, 346kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 168M/170M [07:22\u003c00:05, 363kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 168M/170M [07:22\u003c00:05, 361kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:22\u003c00:05, 361kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:23\u003c00:05, 353kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:23\u003c00:05, 350kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:23\u003c00:04, 356kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:23\u003c00:04, 358kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:23\u003c00:04, 357kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:04, 363kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:04, 347kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:04, 341kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:03, 362kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:03, 363kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:24\u003c00:03, 366kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:25\u003c00:03, 353kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:25\u003c00:03, 359kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 169M/170M [07:25\u003c00:02, 358kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:25\u003c00:02, 364kB/s] 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:25\u003c00:02, 349kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:02, 349kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:02, 357kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:01, 359kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:01, 362kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:01, 366kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:26\u003c00:01, 349kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:27\u003c00:01, 353kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:27\u003c00:01, 355kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:27\u003c00:00, 354kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:27\u003c00:00, 359kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:27\u003c00:00, 350kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:28\u003c00:00, 350kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 170M/170M [07:28\u003c00:00, 359kB/s] 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 170M/170M [07:28\u003c00:00, 380kB/s] Note This section is for CPU users only who are interested in quick results. Use this option only if you\u2019re interested in a small scale experiment. Keep in mind the code should run fairly quickly using any GPU. Select only the first num_images_to_keep images from the train/test dataset #from torch.utils.data import Subset #num_images_to_keep = 2000 #train_dataset = Subset(train_dataset, range(min(num_images_to_keep, 50_000))) #test_dataset = Subset(test_dataset, range(min(num_images_to_keep, 10_000))) #Dataloaders train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2) test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2) Defining model classes and utility functions# Next, we need to define our model classes. Several user-defined parameters need to be set here. We use two different architectures, keeping the number of filters fixed across our experiments to ensure fair comparisons. Both architectures are Convolutional Neural Networks (CNNs) with a different number of convolutional layers that serve as feature extractors, followed by a classifier with 10 classes. The number of filters and neurons is smaller for the students. # Deeper neural network class to be used as teacher: class DeepNN(nn.Module): def __init__(self, num_classes=10): super(DeepNN, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 128, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(64, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.1), nn.Linear(512, num_classes) ) def forward(self, x): x = self.features(x) x = torch.flatten(x, 1) x = self.classifier(x) return x # Lightweight neural network class to be used as student: class LightNN(nn.Module): def __init__(self, num_classes=10): super(LightNN, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(16, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.1), nn.Linear(256, num_classes) ) def forward(self, x): x = self.features(x) x = torch.flatten(x, 1) x = self.classifier(x) return x We employ 2 functions to help us produce and evaluate the results on our original classification task. One function is called train and takes the following arguments: model: A model instance to train (update its weights) via this function. train_loader: We defined our train_loader above, and its job is to feed the data into the model. epochs: How many times we loop over the dataset. learning_rate: The learning rate determines how large our steps towards convergence should be. Too large or too small steps can be detrimental. device: Determines the device to run the workload on. Can be either CPU or GPU depending on availability. Our test function is similar, but it will be invoked with test_loader to load images from the test set. Train both networks with Cross-Entropy. The student will be used as a baseline:# def train(model, train_loader, epochs, learning_rate, device): criterion = nn.CrossEntropyLoss() optimizer = optim.Adam(model.parameters(), lr=learning_rate) model.train() for epoch in range(epochs): running_loss = 0.0 for inputs, labels in train_loader: # inputs: A collection of batch_size images # labels: A vector of dimensionality batch_size with integers denoting class of each image inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() outputs = model(inputs) # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes # labels: The actual labels of the images. Vector of dimensionality batch_size loss = criterion(outputs, labels) loss.backward() optimizer.step() running_loss += loss.item() print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\") def test(model, test_loader, device): model.to(device) model.eval() correct = 0 total = 0 with torch.no_grad(): for inputs, labels in test_loader: inputs, labels = inputs.to(device), labels.to(device) outputs = model(inputs) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() accuracy = 100 * correct / total print(f\"Test Accuracy: {accuracy:.2f}%\") return accuracy Cross-entropy runs# For reproducibility, we need to set the torch manual seed. We train networks using different methods, so to compare them fairly, it makes sense to initialize the networks with the same weights. Start by training the teacher network using cross-entropy: torch.manual_seed(42) nn_deep = DeepNN(num_classes=10).to(device) train(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device) test_accuracy_deep = test(nn_deep, test_loader, device) # Instantiate the lightweight network: torch.manual_seed(42) nn_light = LightNN(num_classes=10).to(device) Epoch 1/10, Loss: 1.3271830167306964 Epoch 2/10, Loss: 0.8552837539511873 Epoch 3/10, Loss: 0.6703156300670351 Epoch 4/10, Loss: 0.5238153989357717 Epoch 5/10, Loss: 0.4080631322872913 Epoch 6/10, Loss: 0.30342950422288206 Epoch 7/10, Loss: 0.21514463859141025 Epoch 8/10, Loss: 0.16292207244107182 Epoch 9/10, Loss: 0.13193816674487366 Epoch 10/10, Loss: 0.12099153160229516 Test Accuracy: 75.70% We instantiate one more lightweight network model to compare their performances. Back propagation is sensitive to weight initialization, so we need to make sure these two networks have the exact same initialization. torch.manual_seed(42) new_nn_light = LightNN(num_classes=10).to(device) To ensure we have created a copy of the first network, we inspect the norm of its first layer. If it matches, then we are safe to conclude that the networks are indeed the same. # Print the norm of the first layer of the initial lightweight model print(\"Norm of 1st layer of nn_light:\", torch.norm(nn_light.features[0].weight).item()) # Print the norm of the first layer of the new lightweight model print(\"Norm of 1st layer of new_nn_light:\", torch.norm(new_nn_light.features[0].weight).item()) Norm of 1st layer of nn_light: 2.327361822128296 Norm of 1st layer of new_nn_light: 2.327361822128296 Print the total number of parameters in each model: total_params_deep = \"{:,}\".format(sum(p.numel() for p in nn_deep.parameters())) print(f\"DeepNN parameters: {total_params_deep}\") total_params_light = \"{:,}\".format(sum(p.numel() for p in nn_light.parameters())) print(f\"LightNN parameters: {total_params_light}\") DeepNN parameters: 1,186,986 LightNN parameters: 267,738 Train and test the lightweight network with cross entropy loss: train(nn_light, train_loader, epochs=10, learning_rate=0.001, device=device) test_accuracy_light_ce = test(nn_light, test_loader, device) Epoch 1/10, Loss: 1.4671805133600064 Epoch 2/10, Loss: 1.1543215095539532 Epoch 3/10, Loss: 1.0236207388551033 Epoch 4/10, Loss: 0.9234162407457981 Epoch 5/10, Loss: 0.8482010568804144 Epoch 6/10, Loss: 0.7826402989189948 Epoch 7/10, Loss: 0.716707373519078 Epoch 8/10, Loss: 0.6562516083345389 Epoch 9/10, Loss: 0.6045231478445975 Epoch 10/10, Loss: 0.5522129790252431 Test Accuracy: 70.20% As we can see, based on test accuracy, we can now compare the deeper network that is to be used as a teacher with the lightweight network that is our supposed student. So far, our student has not intervened with the teacher, therefore this performance is achieved by the student itself. The metrics so far can be seen with the following lines: print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\") print(f\"Student accuracy: {test_accuracy_light_ce:.2f}%\") Teacher accuracy: 75.70% Student accuracy: 70.20% Knowledge distillation run# Now let\u2019s try to improve the test accuracy of the student network by incorporating the teacher. Knowledge distillation is a straightforward technique to achieve this, based on the fact that both networks output a probability distribution over our classes. Therefore, the two networks share the same number of output neurons. The method works by incorporating an additional loss into the traditional cross entropy loss, which is based on the softmax output of the teacher network. The assumption is that the output activations of a properly trained teacher network carry additional information that can be leveraged by a student network during training. The original work suggests that utilizing ratios of smaller probabilities in the soft targets can help achieve the underlying objective of deep neural networks, which is to create a similarity structure over the data where similar objects are mapped closer together. For example, in CIFAR-10, a truck could be mistaken for an automobile or airplane, if its wheels are present, but it is less likely to be mistaken for a dog. Therefore, it makes sense to assume that valuable information resides not only in the top prediction of a properly trained model but in the entire output distribution. However, cross entropy alone does not sufficiently exploit this information as the activations for non-predicted classes tend to be so small that propagated gradients do not meaningfully change the weights to construct this desirable vector space. As we continue defining our first helper function that introduces a teacher-student dynamic, we need to include a few extra parameters: T: Temperature controls the smoothness of the output distributions. Larger T leads to smoother distributions, thus smaller probabilities get a larger boost. soft_target_loss_weight: A weight assigned to the extra objective we\u2019re about to include. ce_loss_weight: A weight assigned to cross-entropy. Tuning these weights pushes the network towards optimizing for either objective. Distillation loss is calculated from the logits of the networks. It only returns gradients to the student:# def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device): ce_loss = nn.CrossEntropyLoss() optimizer = optim.Adam(student.parameters(), lr=learning_rate) teacher.eval() # Teacher set to evaluation mode student.train() # Student to train mode for epoch in range(epochs): running_loss = 0.0 for inputs, labels in train_loader: inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() # Forward pass with the teacher model - do not save gradients here as we do not change the teacher\u0027s weights with torch.no_grad(): teacher_logits = teacher(inputs) # Forward pass with the student model student_logits = student(inputs) #Soften the student logits by applying softmax first and log() second soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1) soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1) # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\" soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2) # Calculate the true label loss label_loss = ce_loss(student_logits, labels) # Weighted sum of the two losses loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss loss.backward() optimizer.step() running_loss += loss.item() print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\") # Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss. train_knowledge_distillation(teacher=nn_deep, student=new_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device) test_accuracy_light_ce_and_kd = test(new_nn_light, test_loader, device) # Compare the student test accuracy with and without the teacher, after distillation print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\") print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\") print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\") Epoch 1/10, Loss: 2.382784129103736 Epoch 2/10, Loss: 1.8663179859176011 Epoch 3/10, Loss: 1.6426248407119985 Epoch 4/10, Loss: 1.4837263118275597 Epoch 5/10, Loss: 1.357022206344263 Epoch 6/10, Loss: 1.2425179967794882 Epoch 7/10, Loss: 1.1478852298863405 Epoch 8/10, Loss: 1.0633694465507937 Epoch 9/10, Loss: 0.9885236020283321 Epoch 10/10, Loss: 0.9223598107657469 Test Accuracy: 70.79% Teacher accuracy: 75.70% Student accuracy without teacher: 70.20% Student accuracy with CE + KD: 70.79% Cosine loss minimization run# Feel free to play around with the temperature parameter that controls the softness of the softmax function and the loss coefficients. In neural networks, it is easy to include additional loss functions to the main objectives to achieve goals like better generalization. Let\u2019s try including an objective for the student, but now let\u2019s focus on their hidden states rather than their output layers. Our goal is to convey information from the teacher\u2019s representation to the student by including a naive loss function, whose minimization implies that the flattened vectors that are subsequently passed to the classifiers have become more similar as the loss decreases. Of course, the teacher does not update its weights, so the minimization depends only on the student\u2019s weights. The rationale behind this method is that we are operating under the assumption that the teacher model has a better internal representation that is unlikely to be achieved by the student without external intervention, therefore we artificially push the student to mimic the internal representation of the teacher. Whether or not this will end up helping the student is not straightforward, though, because pushing the lightweight network to reach this point could be a good thing, assuming that we have found an internal representation that leads to better test accuracy, but it could also be harmful because the networks have different architectures and the student does not have the same learning capacity as the teacher. In other words, there is no reason for these two vectors, the student\u2019s and the teacher\u2019s to match per component. The student could reach an internal representation that is a permutation of the teacher\u2019s and it would be just as efficient. Nonetheless, we can still run a quick experiment to figure out the impact of this method. We will be using the CosineEmbeddingLoss which is given by the following formula: Formula for CosineEmbeddingLoss# Obviously, there is one thing that we need to resolve first. When we applied distillation to the output layer we mentioned that both networks have the same number of neurons, equal to the number of classes. However, this is not the case for the layer following our convolutional layers. Here, the teacher has more neurons than the student after the flattening of the final convolutional layer. Our loss function accepts two vectors of equal dimensionality as inputs, therefore we need to somehow match them. We will solve this by including an average pooling layer after the teacher\u2019s convolutional layer to reduce its dimensionality to match that of the student. To proceed, we will modify our model classes, or create new ones. Now, the forward function returns not only the logits of the network but also the flattened hidden representation after the convolutional layer. We include the aforementioned pooling for the modified teacher. class ModifiedDeepNNCosine(nn.Module): def __init__(self, num_classes=10): super(ModifiedDeepNNCosine, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 128, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(64, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.1), nn.Linear(512, num_classes) ) def forward(self, x): x = self.features(x) flattened_conv_output = torch.flatten(x, 1) x = self.classifier(flattened_conv_output) flattened_conv_output_after_pooling = torch.nn.functional.avg_pool1d(flattened_conv_output, 2) return x, flattened_conv_output_after_pooling # Create a similar student class where we return a tuple. We do not apply pooling after flattening. class ModifiedLightNNCosine(nn.Module): def __init__(self, num_classes=10): super(ModifiedLightNNCosine, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(16, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.1), nn.Linear(256, num_classes) ) def forward(self, x): x = self.features(x) flattened_conv_output = torch.flatten(x, 1) x = self.classifier(flattened_conv_output) return x, flattened_conv_output # We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance modified_nn_deep = ModifiedDeepNNCosine(num_classes=10).to(device) modified_nn_deep.load_state_dict(nn_deep.state_dict()) # Once again ensure the norm of the first layer is the same for both networks print(\"Norm of 1st layer for deep_nn:\", torch.norm(nn_deep.features[0].weight).item()) print(\"Norm of 1st layer for modified_deep_nn:\", torch.norm(modified_nn_deep.features[0].weight).item()) # Initialize a modified lightweight network with the same seed as our other lightweight instances. This will be trained from scratch to examine the effectiveness of cosine loss minimization. torch.manual_seed(42) modified_nn_light = ModifiedLightNNCosine(num_classes=10).to(device) print(\"Norm of 1st layer:\", torch.norm(modified_nn_light.features[0].weight).item()) Norm of 1st layer for deep_nn: 7.484958648681641 Norm of 1st layer for modified_deep_nn: 7.484958648681641 Norm of 1st layer: 2.327361822128296 Naturally, we need to change the train loop because now the model returns a tuple (logits, hidden_representation). Using a sample input tensor we can print their shapes. # Create a sample input tensor sample_input = torch.randn(128, 3, 32, 32).to(device) # Batch size: 128, Filters: 3, Image size: 32x32 # Pass the input through the student logits, hidden_representation = modified_nn_light(sample_input) # Print the shapes of the tensors print(\"Student logits shape:\", logits.shape) # batch_size x total_classes print(\"Student hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size # Pass the input through the teacher logits, hidden_representation = modified_nn_deep(sample_input) # Print the shapes of the tensors print(\"Teacher logits shape:\", logits.shape) # batch_size x total_classes print(\"Teacher hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size Student logits shape: torch.Size([128, 10]) Student hidden representation shape: torch.Size([128, 1024]) Teacher logits shape: torch.Size([128, 10]) Teacher hidden representation shape: torch.Size([128, 1024]) In our case, hidden_representation_size is 1024. This is the flattened feature map of the final convolutional layer of the student and as you can see, it is the input for its classifier. It is 1024 for the teacher too, because we made it so with avg_pool1d from 2048. The loss applied here only affects the weights of the student prior to the loss calculation. In other words, it does not affect the classifier of the student. The modified training loop is the following: In Cosine Loss minimization, we want to maximize the cosine similarity of the two representations by returning gradients to the student:# def train_cosine_loss(teacher, student, train_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight, device): ce_loss = nn.CrossEntropyLoss() cosine_loss = nn.CosineEmbeddingLoss() optimizer = optim.Adam(student.parameters(), lr=learning_rate) teacher.to(device) student.to(device) teacher.eval() # Teacher set to evaluation mode student.train() # Student to train mode for epoch in range(epochs): running_loss = 0.0 for inputs, labels in train_loader: inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() # Forward pass with the teacher model and keep only the hidden representation with torch.no_grad(): _, teacher_hidden_representation = teacher(inputs) # Forward pass with the student model student_logits, student_hidden_representation = student(inputs) # Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase. hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(inputs.size(0)).to(device)) # Calculate the true label loss label_loss = ce_loss(student_logits, labels) # Weighted sum of the two losses loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss loss.backward() optimizer.step() running_loss += loss.item() print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\") We need to modify our test function for the same reason. Here we ignore the hidden representation returned by the model. def test_multiple_outputs(model, test_loader, device): model.to(device) model.eval() correct = 0 total = 0 with torch.no_grad(): for inputs, labels in test_loader: inputs, labels = inputs.to(device), labels.to(device) outputs, _ = model(inputs) # Disregard the second tensor of the tuple _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() accuracy = 100 * correct / total print(f\"Test Accuracy: {accuracy:.2f}%\") return accuracy In this case, we could easily include both knowledge distillation and cosine loss minimization in the same function. It is common to combine methods to achieve better performance in teacher-student paradigms. For now, we can run a simple train-test session. # Train and test the lightweight network with cross entropy loss train_cosine_loss(teacher=modified_nn_deep, student=modified_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device) test_accuracy_light_ce_and_cosine_loss = test_multiple_outputs(modified_nn_light, test_loader, device) Epoch 1/10, Loss: 1.3022451111117896 Epoch 2/10, Loss: 1.069513086315311 Epoch 3/10, Loss: 0.9664173464640937 Epoch 4/10, Loss: 0.8912734627113927 Epoch 5/10, Loss: 0.8368349814658884 Epoch 6/10, Loss: 0.7920724071200241 Epoch 7/10, Loss: 0.7531237022956009 Epoch 8/10, Loss: 0.7154772927998887 Epoch 9/10, Loss: 0.6751815193449445 Epoch 10/10, Loss: 0.6528371971891359 Test Accuracy: 70.17% Intermediate regressor run# Our naive minimization does not guarantee better results for several reasons, one being the dimensionality of the vectors. Cosine similarity generally works better than Euclidean distance for vectors of higher dimensionality, but we were dealing with vectors with 1024 components each, so it is much harder to extract meaningful similarities. Furthermore, as we mentioned, pushing towards a match of the hidden representation of the teacher and the student is not supported by theory. There are no good reasons why we should be aiming for a 1:1 match of these vectors. We will provide a final example of training intervention by including an extra network called regressor. The objective is to first extract the feature map of the teacher after a convolutional layer, then extract a feature map of the student after a convolutional layer, and finally try to match these maps. However, this time, we will introduce a regressor between the networks to facilitate the matching process. The regressor will be trainable and ideally will do a better job than our naive cosine loss minimization scheme. Its main job is to match the dimensionality of these feature maps so that we can properly define a loss function between the teacher and the student. Defining such a loss function provides a teaching \u201cpath,\u201d which is basically a flow to back-propagate gradients that will change the student\u2019s weights. Focusing on the output of the convolutional layers right before each classifier for our original networks, we have the following shapes: # Pass the sample input only from the convolutional feature extractor convolutional_fe_output_student = nn_light.features(sample_input) convolutional_fe_output_teacher = nn_deep.features(sample_input) # Print their shapes print(\"Student\u0027s feature extractor output shape: \", convolutional_fe_output_student.shape) print(\"Teacher\u0027s feature extractor output shape: \", convolutional_fe_output_teacher.shape) Student\u0027s feature extractor output shape: torch.Size([128, 16, 8, 8]) Teacher\u0027s feature extractor output shape: torch.Size([128, 32, 8, 8]) We have 32 filters for the teacher and 16 filters for the student. We will include a trainable layer that converts the feature map of the student to the shape of the feature map of the teacher. In practice, we modify the lightweight class to return the hidden state after an intermediate regressor that matches the sizes of the convolutional feature maps and the teacher class to return the output of the final convolutional layer without pooling or flattening. The trainable layer matches the shapes of the intermediate tensors and Mean Squared Error (MSE) is properly defined:# class ModifiedDeepNNRegressor(nn.Module): def __init__(self, num_classes=10): super(ModifiedDeepNNRegressor, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 128, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(), nn.Conv2d(64, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) self.classifier = nn.Sequential( nn.Linear(2048, 512), nn.ReLU(), nn.Dropout(0.1), nn.Linear(512, num_classes) ) def forward(self, x): x = self.features(x) conv_feature_map = x x = torch.flatten(x, 1) x = self.classifier(x) return x, conv_feature_map class ModifiedLightNNRegressor(nn.Module): def __init__(self, num_classes=10): super(ModifiedLightNNRegressor, self).__init__() self.features = nn.Sequential( nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), nn.Conv2d(16, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), ) # Include an extra regressor (in our case linear) self.regressor = nn.Sequential( nn.Conv2d(16, 32, kernel_size=3, padding=1) ) self.classifier = nn.Sequential( nn.Linear(1024, 256), nn.ReLU(), nn.Dropout(0.1), nn.Linear(256, num_classes) ) def forward(self, x): x = self.features(x) regressor_output = self.regressor(x) x = torch.flatten(x, 1) x = self.classifier(x) return x, regressor_output After that, we have to update our train loop again. This time, we extract the regressor output of the student, the feature map of the teacher, we calculate the MSE on these tensors (they have the exact same shape so it\u2019s properly defined) and we back propagate gradients based on that loss, in addition to the regular cross entropy loss of the classification task. def train_mse_loss(teacher, student, train_loader, epochs, learning_rate, feature_map_weight, ce_loss_weight, device): ce_loss = nn.CrossEntropyLoss() mse_loss = nn.MSELoss() optimizer = optim.Adam(student.parameters(), lr=learning_rate) teacher.to(device) student.to(device) teacher.eval() # Teacher set to evaluation mode student.train() # Student to train mode for epoch in range(epochs): running_loss = 0.0 for inputs, labels in train_loader: inputs, labels = inputs.to(device), labels.to(device) optimizer.zero_grad() # Again ignore teacher logits with torch.no_grad(): _, teacher_feature_map = teacher(inputs) # Forward pass with the student model student_logits, regressor_feature_map = student(inputs) # Calculate the loss hidden_rep_loss = mse_loss(regressor_feature_map, teacher_feature_map) # Calculate the true label loss label_loss = ce_loss(student_logits, labels) # Weighted sum of the two losses loss = feature_map_weight * hidden_rep_loss + ce_loss_weight * label_loss loss.backward() optimizer.step() running_loss += loss.item() print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\") # Notice how our test function remains the same here with the one we used in our previous case. We only care about the actual outputs because we measure accuracy. # Initialize a ModifiedLightNNRegressor torch.manual_seed(42) modified_nn_light_reg = ModifiedLightNNRegressor(num_classes=10).to(device) # We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance modified_nn_deep_reg = ModifiedDeepNNRegressor(num_classes=10).to(device) modified_nn_deep_reg.load_state_dict(nn_deep.state_dict()) # Train and test once again train_mse_loss(teacher=modified_nn_deep_reg, student=modified_nn_light_reg, train_loader=train_loader, epochs=10, learning_rate=0.001, feature_map_weight=0.25, ce_loss_weight=0.75, device=device) test_accuracy_light_ce_and_mse_loss = test_multiple_outputs(modified_nn_light_reg, test_loader, device) Epoch 1/10, Loss: 1.6838112078664247 Epoch 2/10, Loss: 1.3166023142197554 Epoch 3/10, Loss: 1.1786157706814349 Epoch 4/10, Loss: 1.0872286506321118 Epoch 5/10, Loss: 1.011615929396256 Epoch 6/10, Loss: 0.9495215641568079 Epoch 7/10, Loss: 0.8970692712632592 Epoch 8/10, Loss: 0.8469349098632403 Epoch 9/10, Loss: 0.807100487639532 Epoch 10/10, Loss: 0.7707832170569379 Test Accuracy: 70.94% It is expected that the final method will work better than CosineLoss because now we have allowed a trainable layer between the teacher and the student, which gives the student some wiggle room when it comes to learning, rather than pushing the student to copy the teacher\u2019s representation. Including the extra network is the idea behind hint-based distillation. print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\") print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\") print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\") print(f\"Student accuracy with CE + CosineLoss: {test_accuracy_light_ce_and_cosine_loss:.2f}%\") print(f\"Student accuracy with CE + RegressorMSE: {test_accuracy_light_ce_and_mse_loss:.2f}%\") Teacher accuracy: 75.70% Student accuracy without teacher: 70.20% Student accuracy with CE + KD: 70.79% Student accuracy with CE + CosineLoss: 70.17% Student accuracy with CE + RegressorMSE: 70.94% Conclusion# None of the methods above increases the number of parameters for the network or inference time, so the performance increase comes at the little cost of calculating gradients during training. In ML applications, we mostly care about inference time because training happens before the model deployment. If our lightweight model is still too heavy for deployment, we can apply different ideas, such as post-training quantization. Additional losses can be applied in many tasks, not just classification, and you can experiment with quantities like coefficients, temperature, or number of neurons. Feel free to tune any numbers in the tutorial above, but keep in mind, if you change the number of neurons / filters chances are a shape mismatch might occur. For more information, see: Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural network. In: Neural Information Processing System Deep Learning Workshop (2015) Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C., Bengio, Y.: Fitnets: Hints for thin deep nets. In: Proceedings of the International Conference on Learning Representations (2015) Total running time of the script: (11 minutes 41.284 seconds) Download Jupyter notebook: knowledge_distillation_tutorial.ipynb Download Python source code: knowledge_distillation_tutorial.py Download zipped: knowledge_distillation_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/beginner/knowledge_distillation_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>