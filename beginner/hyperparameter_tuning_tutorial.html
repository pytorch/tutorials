
<!DOCTYPE html>

<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"> <!--<![endif]-->
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Hyperparameter tuning with Ray Tune — PyTorch Tutorials 1.6.0 documentation</title>
<link href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
<link href="../_static/gallery.css" rel="stylesheet" type="text/css"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial"/>
<link href="../advanced/dispatcher.html" rel="prev" title="Dispatcher in C++"/>
<script src="../_static/js/modernizr.min.js"></script>
<!-- Preload the theme fonts -->
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-book.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" rel="preload" type="font/woff2"/>
<!-- Preload the katex fonts -->
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" rel="preload" type="font/woff2"/>
</head>
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="container">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<div class="ecosystem-dropdown">
<a data-toggle="ecosystem-dropdown" id="dropdownMenuButton">
                Ecosystem
              </a>
<div class="ecosystem-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/hub">
<span class="dropdown-title">Models (Beta)</span>
<p>Discover, publish, and reuse pre-trained models</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
<span class="dropdown-title">Tools &amp; Libraries</span>
<p>Explore the ecosystem of tools and libraries</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<div class="resources-dropdown">
<a data-toggle="resources-dropdown" id="resourcesDropdownButton">
                Resources
              </a>
<div class="resources-dropdown-menu">
<a "="" class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
<p>Find resources and get questions answered</p>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/features">
<span class="dropdown-title">About</span>
<p>Learn about PyTorch’s features and capabilities</p>
</a>
</div>
</div>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#"></a>
</div>
</div>
</div>
<body class="pytorch-body">
<div class="table-of-contents-link-wrapper">
<span>Table of Contents</span>
<a class="toggle-table-of-contents" data-behavior="toggle-table-of-contents" href="#"></a>
</div>
<nav class="pytorch-left-menu" data-toggle="wy-nav-shift" id="pytorch-left-menu">
<div class="pytorch-side-scroll">
<div aria-label="main navigation" class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation">
<div class="pytorch-left-menu-search">
<div class="version">
                  1.6.0
                </div>
<div role="search">
<form action="../search.html" class="wy-form" id="rtd-search-form" method="get">
<input name="q" placeholder="Search Tutorials" type="text"/>
<input name="check_keywords" type="hidden" value="yes"/>
<input name="area" type="hidden" value="default"/>
</form>
</div>
</div>
<p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image/Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="audio_preprocessing_tutorial.html">torchaudio Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="text_sentiment_ngrams_tutorial.html">Text Classification with TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchtext_translation_tutorial.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/named_tensor_tutorial.html">(prototype) Introduction to Named Tensors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Dispatcher in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="aws_distributed_training_tutorial.html">(advanced) PyTorch 1.0 Distributed Trainer with Amazon AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
</ul>
</div>
</div>
</nav>
<div class="pytorch-container">
<div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
<div class="pytorch-breadcrumbs-wrapper">
<div aria-label="breadcrumbs navigation" role="navigation">
<ul class="pytorch-breadcrumbs">
<li>
<a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>
<li>Hyperparameter tuning with Ray Tune</li>
<li class="pytorch-breadcrumbs-aside">
<a href="../_sources/beginner/hyperparameter_tuning_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"/></a>
</li>
</ul>
</div>
</div>
<div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
</div>
<section class="pytorch-content-wrap" data-toggle="wy-nav-shift" id="pytorch-content-wrap">
<div class="pytorch-content-left">
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/hyperparameter_tuning_tutorial</div>
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</div>
<div class="rst-content">
<div class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<article class="pytorch-article" id="pytorch-article" itemprop="articleBody">
<div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="hyperparameter-tuning-with-ray-tune">
<span id="sphx-glr-beginner-hyperparameter-tuning-tutorial-py"></span><h1>Hyperparameter tuning with Ray Tune<a class="headerlink" href="#hyperparameter-tuning-with-ray-tune" title="Permalink to this headline">¶</a></h1>
<p>Hyperparameter tuning can make the difference between an average model and a highly
accurate one. Often simple things like choosing a different learning rate or changing
a network layer size can have a dramatic impact on your model performance.</p>
<p>Fortunately, there are tools that help with finding the best combination of parameters.
<a class="reference external" href="https://docs.ray.io/en/latest/tune.html">Ray Tune</a> is an industry standard tool for
distributed hyperparameter tuning. Ray Tune includes the latest hyperparameter search
algorithms, integrates with TensorBoard and other analysis libraries, and natively
supports distributed training through <a class="reference external" href="https://ray.io/">Ray’s distributed machine learning engine</a>.</p>
<p>In this tutorial, we will show you how to integrate Ray Tune into your PyTorch
training workflow. We will extend <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">this tutorial from the PyTorch documentation</a> for training
a CIFAR10 image classifier.</p>
<p>As you will see, we only need to add some slight modifications. In particular, we
need to</p>
<ol class="arabic simple">
<li>wrap data loading and training in functions,</li>
<li>make some network parameters configurable,</li>
<li>add checkpointing (optional),</li>
<li>and define the search space for the model tuning</li>
</ol>
<div class="line-block">
<div class="line"><br/></div>
</div>
<p>To run this tutorial, please make sure the following packages are
installed:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">ray[tune]</span></code>: Distributed hyperparameter tuning library</li>
<li><code class="docutils literal notranslate"><span class="pre">torchvision</span></code>: For the data transformers</li>
</ul>
<div class="section" id="setup-imports">
<h2>Setup / Imports<a class="headerlink" href="#setup-imports" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with the imports:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>
<span class="kn">from</span> <span class="nn">ray.tune</span> <span class="kn">import</span> <span class="n">CLIReporter</span>
<span class="kn">from</span> <span class="nn">ray.tune.schedulers</span> <span class="kn">import</span> <span class="n">ASHAScheduler</span>
</pre></div>
</div>
<p>Most of the imports are needed for building the PyTorch model. Only the last three
imports are for Ray Tune.</p>
</div>
<div class="section" id="data-loaders">
<h2>Data loaders<a class="headerlink" href="#data-loaders" title="Permalink to this headline">¶</a></h2>
<p>We wrap the data loaders in their own function and pass a global data directory.
This way we can share a data directory between different trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">):</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="p">])</span>

    <span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
        <span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span>
</pre></div>
</div>
</div>
<div class="section" id="configurable-neural-network">
<h2>Configurable neural network<a class="headerlink" href="#configurable-neural-network" title="Permalink to this headline">¶</a></h2>
<p>We can only tune those parameters that are configurable. In this example, we can specify
the layer sizes of the fully connected layers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l1</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mi">84</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="n">l1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l1</span><span class="p">,</span> <span class="n">l2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">l2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
<div class="section" id="the-train-function">
<h2>The train function<a class="headerlink" href="#the-train-function" title="Permalink to this headline">¶</a></h2>
<p>Now it gets interesting, because we introduce some changes to the example <a class="reference external" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html">from the PyTorch
documentation</a>.</p>
<p>We wrap the training script in a function <code class="docutils literal notranslate"><span class="pre">train_cifar(config,</span> <span class="pre">checkpoint_dir=None,</span> <span class="pre">data_dir=None)</span></code>.
As you can guess, the <code class="docutils literal notranslate"><span class="pre">config</span></code> parameter will receive the hyperparameters we would like to
train with. The <code class="docutils literal notranslate"><span class="pre">checkpoint_dir</span></code> parameter is used to restore checkpoints. The <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> specifies
the directory where we load and store the data, so multiple runs can share the same data source.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

<span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>
</pre></div>
</div>
<p>The learning rate of the optimizer is made configurable, too:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
<p>We also split the training data into a training and validation subset. We thus train on
80% of the data and calculate the validation loss on the remaining 20%. The batch sizes
with which we iterate through the training and test sets are configurable as well.</p>
<div class="section" id="adding-multi-gpu-support-with-dataparallel">
<h3>Adding (multi) GPU support with DataParallel<a class="headerlink" href="#adding-multi-gpu-support-with-dataparallel" title="Permalink to this headline">¶</a></h3>
<p>Image classification benefits largely from GPUs. Luckily, we can continue to use
PyTorch’s abstractions in Ray Tune. Thus, we can wrap our model in <code class="docutils literal notranslate"><span class="pre">nn.DataParallel</span></code>
to support data parallel training on multiple GPUs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>By using a <code class="docutils literal notranslate"><span class="pre">device</span></code> variable we make sure that training also works when we have
no GPUs available. PyTorch requires us to send our data to the GPU memory explicitly,
like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>The code now supports training on CPUs, on a single GPU, and on multiple GPUs. Notably, Ray
also supports <a class="reference external" href="https://docs.ray.io/en/master/using-ray-with-gpus.html#fractional-gpus">fractional GPUs</a>
so we can share GPUs among trials, as long as the model still fits on the GPU memory. We’ll come back
to that later.</p>
</div>
<div class="section" id="communicating-with-ray-tune">
<h3>Communicating with Ray Tune<a class="headerlink" href="#communicating-with-ray-tune" title="Permalink to this headline">¶</a></h3>
<p>The most interesting part is the communication with Ray Tune:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

<span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we first save a checkpoint and then report some metrics back to Ray Tune. Specifically,
we send the validation loss and accuracy back to Ray Tune. Ray Tune can then use these metrics
to decide which hyperparameter configuration lead to the best results. These metrics
can also be used to stop bad performing trials early in order to avoid wasting
resources on those trials.</p>
<p>The checkpoint saving is optional, however, it is necessary if we wanted to use advanced
schedulers like
<a class="reference external" href="https://docs.ray.io/en/master/tune/tutorials/tune-advanced-tutorial.html">Population Based Training</a>.
Also, by saving the checkpoint we can later load the trained models and validate them
on a test set.</p>
</div>
<div class="section" id="full-training-function">
<h3>Full training function<a class="headerlink" href="#full-training-function" title="Permalink to this headline">¶</a></h3>
<p>The full code example looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_cifar</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>

    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
    <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">],</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
        <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
        <span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_state</span><span class="p">)</span>

    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>

    <span class="n">test_abs</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
    <span class="n">train_subset</span><span class="p">,</span> <span class="n">val_subset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
        <span class="n">trainset</span><span class="p">,</span> <span class="p">[</span><span class="n">test_abs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_abs</span><span class="p">])</span>

    <span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">valloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">val_subset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]),</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">epoch_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># zero the parameter gradients</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="c1"># forward + backward + optimize</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="c1"># print statistics</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">epoch_steps</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">1999</span><span class="p">:</span>  <span class="c1"># print every 2000 mini-batches</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">"[</span><span class="si">%d</span><span class="s2">, </span><span class="si">%5d</span><span class="s2">] loss: </span><span class="si">%.3f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                                                <span class="n">running_loss</span> <span class="o">/</span> <span class="n">epoch_steps</span><span class="p">))</span>
                <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="c1"># Validation loss</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">val_steps</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">val_steps</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">with</span> <span class="n">tune</span><span class="o">.</span><span class="n">checkpoint_dir</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">as</span> <span class="n">checkpoint_dir</span><span class="p">:</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">((</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()),</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="p">(</span><span class="n">val_loss</span> <span class="o">/</span> <span class="n">val_steps</span><span class="p">),</span> <span class="n">accuracy</span><span class="o">=</span><span class="n">correct</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Finished Training"</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, most of the code is adapted directly from the original example.</p>
</div>
</div>
<div class="section" id="test-set-accuracy">
<h2>Test set accuracy<a class="headerlink" href="#test-set-accuracy" title="Permalink to this headline">¶</a></h2>
<p>Commonly the performance of a machine learning model is tested on a hold-out test
set with data that has not been used for training the model. We also wrap this in a
function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_accuracy</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">):</span>
    <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

    <span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">testloader</span><span class="p">:</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
            <span class="n">images</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
</pre></div>
</div>
<p>The function also expects a <code class="docutils literal notranslate"><span class="pre">device</span></code> parameter, so we can do the
test set validation on a GPU.</p>
</div>
<div class="section" id="configuring-the-search-space">
<h2>Configuring the search space<a class="headerlink" href="#configuring-the-search-space" title="Permalink to this headline">¶</a></h2>
<p>Lastly, we need to define Ray Tune’s search space. Here is an example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span><span class="o">**</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
    <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tune.sample_from()</span></code> function makes it possible to define your own sample
methods to obtain hyperparameters. In this example, the <code class="docutils literal notranslate"><span class="pre">l1</span></code> and <code class="docutils literal notranslate"><span class="pre">l2</span></code> parameters
should be powers of 2 between 4 and 256, so either 4, 8, 16, 32, 64, 128, or 256.
The <code class="docutils literal notranslate"><span class="pre">lr</span></code> (learning rate) should be uniformly sampled between 0.0001 and 0.1. Lastly,
the batch size is a choice between 2, 4, 8, and 16.</p>
<p>At each trial, Ray Tune will now randomly sample a combination of parameters from these
search spaces. It will then train a number of models in parallel and find the best
performing one among these. We also use the <code class="docutils literal notranslate"><span class="pre">ASHAScheduler</span></code> which will terminate bad
performing trials early.</p>
<p>We wrap the <code class="docutils literal notranslate"><span class="pre">train_cifar</span></code> function with <code class="docutils literal notranslate"><span class="pre">functools.partial</span></code> to set the constant
<code class="docutils literal notranslate"><span class="pre">data_dir</span></code> parameter. We can also tell Ray Tune what resources should be
available for each trial:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gpus_per_trial</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># ...</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
    <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">,</span>
    <span class="n">checkpoint_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>You can specify the number of CPUs, which are then available e.g.
to increase the <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> of the PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> instances. The selected
number of GPUs are made visible to PyTorch in each trial. Trials do not have access to
GPUs that haven’t been requested for them - so you don’t have to care about two trials
using the same set of resources.</p>
<p>Here we can also specify fractional GPUs, so something like <code class="docutils literal notranslate"><span class="pre">gpus_per_trial=0.5</span></code> is
completely valid. The trials will then share GPUs among each other.
You just have to make sure that the models still fit in the GPU memory.</p>
<p>After training the models, we will find the best performing one and load the trained
network from the checkpoint file. We then obtain the test set accuracy and report
everything by printing.</p>
<p>The full main function looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">"./data"</span><span class="p">)</span>
    <span class="n">load_data</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"l1"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"l2"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">sample_from</span><span class="p">(</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)),</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">),</span>
        <span class="s2">"batch_size"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
    <span class="p">}</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">ASHAScheduler</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">"loss"</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">,</span>
        <span class="n">max_t</span><span class="o">=</span><span class="n">max_num_epochs</span><span class="p">,</span>
        <span class="n">grace_period</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">reduction_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">reporter</span> <span class="o">=</span> <span class="n">CLIReporter</span><span class="p">(</span>
        <span class="c1"># parameter_columns=["l1", "l2", "lr", "batch_size"],</span>
        <span class="n">metric_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">,</span> <span class="s2">"training_iteration"</span><span class="p">])</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">train_cifar</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="n">data_dir</span><span class="p">),</span>
        <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s2">"cpu"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">"gpu"</span><span class="p">:</span> <span class="n">gpus_per_trial</span><span class="p">},</span>
        <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">progress_reporter</span><span class="o">=</span><span class="n">reporter</span><span class="p">)</span>

    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">get_best_trial</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">,</span> <span class="s2">"min"</span><span class="p">,</span> <span class="s2">"last"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial config: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation loss: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"loss"</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial final validation accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">best_trial</span><span class="o">.</span><span class="n">last_result</span><span class="p">[</span><span class="s2">"accuracy"</span><span class="p">]))</span>

    <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l1"</span><span class="p">],</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">"l2"</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">"cpu"</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda:0"</span>
        <span class="k">if</span> <span class="n">gpus_per_trial</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">best_trained_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">)</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">best_checkpoint_dir</span> <span class="o">=</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">value</span>
    <span class="n">model_state</span><span class="p">,</span> <span class="n">optimizer_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">best_checkpoint_dir</span><span class="p">,</span> <span class="s2">"checkpoint"</span><span class="p">))</span>
    <span class="n">best_trained_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_state</span><span class="p">)</span>

    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_accuracy</span><span class="p">(</span><span class="n">best_trained_model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Best trial test set accuracy: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="c1"># You can change the number of GPUs per trial here:</span>
    <span class="n">main</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_num_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gpus_per_trial</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz
Extracting /var/lib/jenkins/workspace/beginner_source/data/cifar-10-python.tar.gz to /var/lib/jenkins/workspace/beginner_source/data
Files already downloaded and verified
== Status ==
Memory usage on this node: 4.0/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None
Resources requested: 2/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (9 PENDING, 1 RUNNING)
+---------------------+----------+-------+--------------+------+------+-------------+
| Trial name          | status   | loc   |   batch_size |   l1 |   l2 |          lr |
|---------------------+----------+-------+--------------+------+------+-------------|
| DEFAULT_79ae1_00000 | RUNNING  |       |           16 |  256 |    8 | 0.000100905 |
| DEFAULT_79ae1_00001 | PENDING  |       |            4 |    4 |   64 | 0.00502624  |
| DEFAULT_79ae1_00002 | PENDING  |       |            8 |    8 |    8 | 0.000388007 |
| DEFAULT_79ae1_00003 | PENDING  |       |           16 |    4 |   32 | 0.0243759   |
| DEFAULT_79ae1_00004 | PENDING  |       |            2 |   32 |  128 | 0.00376088  |
| DEFAULT_79ae1_00005 | PENDING  |       |           16 |    8 |   32 | 0.0600091   |
| DEFAULT_79ae1_00006 | PENDING  |       |            2 |  128 |   64 | 0.0318437   |
| DEFAULT_79ae1_00007 | PENDING  |       |            8 |    8 |    8 | 0.00975354  |
| DEFAULT_79ae1_00008 | PENDING  |       |            2 |   64 |  128 | 0.00594678  |
| DEFAULT_79ae1_00009 | PENDING  |       |            8 |    8 |    4 | 0.000398399 |
+---------------------+----------+-------+--------------+------+------+-------------+


[2m[36m(pid=1092)[0m Files already downloaded and verified
[2m[36m(pid=1136)[0m Files already downloaded and verified
[2m[36m(pid=1088)[0m Files already downloaded and verified
[2m[36m(pid=1101)[0m Files already downloaded and verified
[2m[36m(pid=1168)[0m Files already downloaded and verified
[2m[36m(pid=1081)[0m Files already downloaded and verified
[2m[36m(pid=1098)[0m Files already downloaded and verified
[2m[36m(pid=1082)[0m Files already downloaded and verified
[2m[36m(pid=1090)[0m Files already downloaded and verified
[2m[36m(pid=1093)[0m Files already downloaded and verified
[2m[36m(pid=1092)[0m Files already downloaded and verified
[2m[36m(pid=1136)[0m Files already downloaded and verified
[2m[36m(pid=1088)[0m Files already downloaded and verified
[2m[36m(pid=1101)[0m Files already downloaded and verified
[2m[36m(pid=1168)[0m Files already downloaded and verified
[2m[36m(pid=1098)[0m Files already downloaded and verified
[2m[36m(pid=1081)[0m Files already downloaded and verified
[2m[36m(pid=1082)[0m Files already downloaded and verified
[2m[36m(pid=1090)[0m Files already downloaded and verified
[2m[36m(pid=1093)[0m Files already downloaded and verified
[2m[36m(pid=1081)[0m [1,  2000] loss: 2.198
[2m[36m(pid=1093)[0m [1,  2000] loss: 2.108
[2m[36m(pid=1136)[0m [1,  2000] loss: 2.093
[2m[36m(pid=1090)[0m [1,  2000] loss: 2.341
[2m[36m(pid=1082)[0m [1,  2000] loss: 2.051
[2m[36m(pid=1101)[0m [1,  2000] loss: 2.295
[2m[36m(pid=1098)[0m [1,  2000] loss: 2.313
[2m[36m(pid=1088)[0m [1,  2000] loss: 1.993
[2m[36m(pid=1168)[0m [1,  2000] loss: 2.236
[2m[36m(pid=1092)[0m [1,  2000] loss: 2.326
[2m[36m(pid=1081)[0m [1,  4000] loss: 1.029
[2m[36m(pid=1093)[0m [1,  4000] loss: 0.970
[2m[36m(pid=1136)[0m [1,  4000] loss: 0.964
Result for DEFAULT_79ae1_00003:
  accuracy: 0.2766
  date: 2020-09-21_20-39-29
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 1.8650087287902832
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 30.090057611465454
  time_this_iter_s: 30.090057611465454
  time_total_s: 30.090057611465454
  timestamp: 1600720769
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 8.7/240.1 GiB
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.8650087287902832
Resources requested: 20/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 RUNNING)
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | RUNNING  |                 |           16 |  256 |    8 | 0.000100905 |         |            |                      |
| DEFAULT_79ae1_00001 | RUNNING  |                 |            4 |    4 |   64 | 0.00502624  |         |            |                      |
| DEFAULT_79ae1_00002 | RUNNING  |                 |            8 |    8 |    8 | 0.000388007 |         |            |                      |
| DEFAULT_79ae1_00003 | RUNNING  | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 1.86501 |     0.2766 |                    1 |
| DEFAULT_79ae1_00004 | RUNNING  |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | RUNNING  |                 |           16 |    8 |   32 | 0.0600091   |         |            |                      |
| DEFAULT_79ae1_00006 | RUNNING  |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING  |                 |            8 |    8 |    8 | 0.00975354  |         |            |                      |
| DEFAULT_79ae1_00008 | RUNNING  |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | RUNNING  |                 |            8 |    8 |    4 | 0.000398399 |         |            |                      |
+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00005:
  accuracy: 0.0997
  date: 2020-09-21_20-39-30
  done: true
  experiment_id: 358210cbe29c447b8922d5ac70be5baf
  experiment_tag: 5_batch_size=16,l1=8,l2=32,lr=0.060009
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.304117810821533
  node_ip: 172.17.0.2
  pid: 1168
  should_checkpoint: true
  time_since_restore: 30.121013402938843
  time_this_iter_s: 30.121013402938843
  time_total_s: 30.121013402938843
  timestamp: 1600720770
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00005

[2m[36m(pid=1090)[0m [1,  4000] loss: 1.171
Result for DEFAULT_79ae1_00000:
  accuracy: 0.1017
  date: 2020-09-21_20-39-31
  done: true
  experiment_id: 1232104623c74c169299d915ce855211
  experiment_tag: 0_batch_size=16,l1=256,l2=8,lr=0.0001009
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.322201280593872
  node_ip: 172.17.0.2
  pid: 1092
  should_checkpoint: true
  time_since_restore: 31.363142013549805
  time_this_iter_s: 31.363142013549805
  time_total_s: 31.363142013549805
  timestamp: 1600720771
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00000

[2m[36m(pid=1082)[0m [1,  4000] loss: 0.942
[2m[36m(pid=1101)[0m [1,  4000] loss: 1.101
[2m[36m(pid=1098)[0m [1,  4000] loss: 1.153
[2m[36m(pid=1081)[0m [1,  6000] loss: 0.676
[2m[36m(pid=1093)[0m [1,  6000] loss: 0.625
[2m[36m(pid=1136)[0m [1,  6000] loss: 0.623
[2m[36m(pid=1090)[0m [1,  6000] loss: 0.779
Result for DEFAULT_79ae1_00007:
  accuracy: 0.3078
  date: 2020-09-21_20-39-42
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 1.7980498471736908
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 42.05501317977905
  time_this_iter_s: 42.05501317977905
  time_total_s: 42.05501317977905
  timestamp: 1600720782
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 7.7/240.1 GiB
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -2.0845632698059084
Resources requested: 16/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (8 RUNNING, 2 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    |                 |            4 |    4 |   64 | 0.00502624  |         |            |                      |
| DEFAULT_79ae1_00002 | RUNNING    |                 |            8 |    8 |    8 | 0.000388007 |         |            |                      |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 1.86501 |     0.2766 |                    1 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79805 |     0.3078 |                    1 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | RUNNING    |                 |            8 |    8 |    4 | 0.000398399 |         |            |                      |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00002:
  accuracy: 0.1955
  date: 2020-09-21_20-39-42
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.076271940612793
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 42.41563439369202
  time_this_iter_s: 42.41563439369202
  time_total_s: 42.41563439369202
  timestamp: 1600720782
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00002

Result for DEFAULT_79ae1_00009:
  accuracy: 0.097
  date: 2020-09-21_20-39-42
  done: true
  experiment_id: 1089e175a9f04f77a14e5004f79b4f3d
  experiment_tag: 9_batch_size=8,l1=8,l2=4,lr=0.0003984
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.302834967803955
  node_ip: 172.17.0.2
  pid: 1098
  should_checkpoint: true
  time_since_restore: 42.55151081085205
  time_this_iter_s: 42.55151081085205
  time_total_s: 42.55151081085205
  timestamp: 1600720782
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00009

[2m[36m(pid=1088)[0m [2,  2000] loss: 1.913
[2m[36m(pid=1081)[0m [1,  8000] loss: 0.502
[2m[36m(pid=1093)[0m [1,  8000] loss: 0.477
[2m[36m(pid=1136)[0m [1,  8000] loss: 0.460
Result for DEFAULT_79ae1_00003:
  accuracy: 0.223
  date: 2020-09-21_20-39-50
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 2
  loss: 1.9946562120437623
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 50.51594424247742
  time_this_iter_s: 20.425886631011963
  time_total_s: 50.51594424247742
  timestamp: 1600720790
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9946562120437623 | Iter 1.000: -2.189553454208374
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    |                 |            4 |    4 |   64 | 0.00502624  |         |            |                      |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 2.07627 |     0.1955 |                    1 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 1.99466 |     0.223  |                    2 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79805 |     0.3078 |                    1 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1090)[0m [1,  8000] loss: 0.585
[2m[36m(pid=1082)[0m [2,  2000] loss: 1.863
[2m[36m(pid=1101)[0m [2,  2000] loss: 2.013
[2m[36m(pid=1081)[0m [1, 10000] loss: 0.405
[2m[36m(pid=1093)[0m [1, 10000] loss: 0.375
[2m[36m(pid=1136)[0m [1, 10000] loss: 0.363
[2m[36m(pid=1090)[0m [1, 10000] loss: 0.467
[2m[36m(pid=1081)[0m [1, 12000] loss: 0.333
[2m[36m(pid=1093)[0m [1, 12000] loss: 0.311
[2m[36m(pid=1082)[0m [2,  4000] loss: 0.904
Result for DEFAULT_79ae1_00001:
  accuracy: 0.3275
  date: 2020-09-21_20-40-03
  done: false
  experiment_id: 1bbc7a7895e54fbcb940a03305b600d0
  experiment_tag: 1_batch_size=4,l1=4,l2=64,lr=0.0050262
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 1.7699519322037698
  node_ip: 172.17.0.2
  pid: 1136
  should_checkpoint: true
  time_since_restore: 63.868627309799194
  time_this_iter_s: 63.868627309799194
  time_total_s: 63.868627309799194
  timestamp: 1600720803
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00001

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9946562120437623 | Iter 1.000: -2.076271940612793
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76995 |     0.3275 |                    1 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 2.07627 |     0.1955 |                    1 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 1.99466 |     0.223  |                    2 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79805 |     0.3078 |                    1 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1088)[0m [3,  2000] loss: 2.061
[2m[36m(pid=1101)[0m [2,  4000] loss: 0.957
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1002
  date: 2020-09-21_20-40-10
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 3
  loss: 2.3069201332092284
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 70.4439582824707
  time_this_iter_s: 19.928014039993286
  time_total_s: 70.4439582824707
  timestamp: 1600720810
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: -1.9946562120437623 | Iter 1.000: -2.076271940612793
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76995 |     0.3275 |                    1 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 2.07627 |     0.1955 |                    1 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.30692 |     0.1002 |                    3 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79805 |     0.3078 |                    1 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1090)[0m [1, 12000] loss: 0.390
[2m[36m(pid=1081)[0m [1, 14000] loss: 0.289
[2m[36m(pid=1093)[0m [1, 14000] loss: 0.266
Result for DEFAULT_79ae1_00007:
  accuracy: 0.3027
  date: 2020-09-21_20-40-12
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 2
  loss: 1.8049614634513855
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 72.9041838645935
  time_this_iter_s: 30.849170684814453
  time_total_s: 72.9041838645935
  timestamp: 1600720812
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 79ae1_00007

[2m[36m(pid=1136)[0m [2,  2000] loss: 1.805
Result for DEFAULT_79ae1_00002:
  accuracy: 0.2801
  date: 2020-09-21_20-40-13
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 2
  loss: 1.8522035459518433
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 73.93428492546082
  time_this_iter_s: 31.5186505317688
  time_total_s: 73.93428492546082
  timestamp: 1600720813
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 79ae1_00002

[2m[36m(pid=1093)[0m [1, 16000] loss: 0.231
[2m[36m(pid=1081)[0m [1, 16000] loss: 0.254
[2m[36m(pid=1136)[0m [2,  4000] loss: 0.907
[2m[36m(pid=1090)[0m [1, 14000] loss: 0.334
[2m[36m(pid=1082)[0m [3,  2000] loss: 1.767
[2m[36m(pid=1088)[0m [4,  2000] loss: 2.257
[2m[36m(pid=1101)[0m [3,  2000] loss: 1.827
[2m[36m(pid=1093)[0m [1, 18000] loss: 0.207
[2m[36m(pid=1081)[0m [1, 18000] loss: 0.225
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1007
  date: 2020-09-21_20-40-30
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 4
  loss: 2.304528719711304
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 90.63147377967834
  time_this_iter_s: 20.18751549720764
  time_total_s: 90.63147377967834
  timestamp: 1600720830
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.304528719711304 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.076271940612793
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76995 |     0.3275 |                    1 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.8522  |     0.2801 |                    2 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.30453 |     0.1007 |                    4 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.80496 |     0.3027 |                    2 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [2,  6000] loss: 0.600
[2m[36m(pid=1090)[0m [1, 16000] loss: 0.293
[2m[36m(pid=1082)[0m [3,  4000] loss: 0.903
[2m[36m(pid=1101)[0m [3,  4000] loss: 0.887
[2m[36m(pid=1093)[0m [1, 20000] loss: 0.187
[2m[36m(pid=1081)[0m [1, 20000] loss: 0.202
[2m[36m(pid=1136)[0m [2,  8000] loss: 0.454
[2m[36m(pid=1090)[0m [1, 18000] loss: 0.260
Result for DEFAULT_79ae1_00007:
  accuracy: 0.3178
  date: 2020-09-21_20-40-43
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 3
  loss: 1.7704263922214507
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 103.74907493591309
  time_this_iter_s: 30.84489107131958
  time_total_s: 103.74907493591309
  timestamp: 1600720843
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.304528719711304 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.076271940612793
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76995 |     0.3275 |                    1 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.8522  |     0.2801 |                    2 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.30453 |     0.1007 |                    4 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.77043 |     0.3178 |                    3 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1088)[0m [5,  2000] loss: 2.303
Result for DEFAULT_79ae1_00002:
  accuracy: 0.3288
  date: 2020-09-21_20-40-45
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 3
  loss: 1.7250523057937621
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 105.13578486442566
  time_this_iter_s: 31.201499938964844
  time_total_s: 105.13578486442566
  timestamp: 1600720845
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 79ae1_00002

[2m[36m(pid=1136)[0m [2, 10000] loss: 0.364
Result for DEFAULT_79ae1_00003:
  accuracy: 0.109
  date: 2020-09-21_20-40-50
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 5
  loss: 2.2939017021179198
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 111.0763897895813
  time_this_iter_s: 20.444916009902954
  time_total_s: 111.0763897895813
  timestamp: 1600720850
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 7.2/240.1 GiB
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 8.000: None | Iter 4.000: -2.304528719711304 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.076271940612793
Resources requested: 14/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (7 RUNNING, 3 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76995 |     0.3275 |                    1 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.72505 |     0.3288 |                    3 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.2939  |     0.109  |                    5 |
| DEFAULT_79ae1_00004 | RUNNING    |                 |            2 |   32 |  128 | 0.00376088  |         |            |                      |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.77043 |     0.3178 |                    3 |
| DEFAULT_79ae1_00008 | RUNNING    |                 |            2 |   64 |  128 | 0.00594678  |         |            |                      |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00004:
  accuracy: 0.288
  date: 2020-09-21_20-40-51
  done: false
  experiment_id: e9f3bc460b5047efab2187cd37b38e02
  experiment_tag: 4_batch_size=2,l1=32,l2=128,lr=0.0037609
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 1.8948279816046356
  node_ip: 172.17.0.2
  pid: 1093
  should_checkpoint: true
  time_since_restore: 110.88702154159546
  time_this_iter_s: 110.88702154159546
  time_total_s: 110.88702154159546
  timestamp: 1600720851
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00004

Result for DEFAULT_79ae1_00008:
  accuracy: 0.239
  date: 2020-09-21_20-40-52
  done: true
  experiment_id: 0530fda6dd354dd2b8c8d0f6db1c1aac
  experiment_tag: 8_batch_size=2,l1=64,l2=128,lr=0.0059468
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.018311379826069
  node_ip: 172.17.0.2
  pid: 1081
  should_checkpoint: true
  time_since_restore: 112.22666525840759
  time_this_iter_s: 112.22666525840759
  time_total_s: 112.22666525840759
  timestamp: 1600720852
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00008

[2m[36m(pid=1090)[0m [1, 20000] loss: 0.234
[2m[36m(pid=1082)[0m [4,  2000] loss: 1.760
[2m[36m(pid=1101)[0m [4,  2000] loss: 1.702
Result for DEFAULT_79ae1_00001:
  accuracy: 0.3383
  date: 2020-09-21_20-40-56
  done: false
  experiment_id: 1bbc7a7895e54fbcb940a03305b600d0
  experiment_tag: 1_batch_size=4,l1=4,l2=64,lr=0.0050262
  hostname: 18e16d8a13a6
  iterations_since_restore: 2
  loss: 1.7636220365047455
  node_ip: 172.17.0.2
  pid: 1136
  should_checkpoint: true
  time_since_restore: 117.04371237754822
  time_this_iter_s: 53.17508506774902
  time_total_s: 117.04371237754822
  timestamp: 1600720856
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 79ae1_00001

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 8.000: None | Iter 4.000: -2.304528719711304 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.018311379826069
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76362 |     0.3383 |                    2 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.72505 |     0.3288 |                    3 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.2939  |     0.109  |                    5 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    |                 |            2 |  128 |   64 | 0.0318437   |         |            |                      |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.77043 |     0.3178 |                    3 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1093)[0m [2,  2000] loss: 1.887
[2m[36m(pid=1088)[0m [6,  2000] loss: 2.294
[2m[36m(pid=1082)[0m [4,  4000] loss: 0.883
Result for DEFAULT_79ae1_00006:
  accuracy: 0.1007
  date: 2020-09-21_20-41-05
  done: true
  experiment_id: 2663f80c02b64a159a00262d7f61fc4e
  experiment_tag: 6_batch_size=2,l1=128,l2=64,lr=0.031844
  hostname: 18e16d8a13a6
  iterations_since_restore: 1
  loss: 2.332287749695778
  node_ip: 172.17.0.2
  pid: 1090
  should_checkpoint: true
  time_since_restore: 125.71267557144165
  time_this_iter_s: 125.71267557144165
  time_total_s: 125.71267557144165
  timestamp: 1600720865
  timesteps_since_restore: 0
  training_iteration: 1
  trial_id: 79ae1_00006

== Status ==
Memory usage on this node: 6.7/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -2.304528719711304 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 12/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (6 RUNNING, 4 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76362 |     0.3383 |                    2 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.72505 |     0.3288 |                    3 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.2939  |     0.109  |                    5 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | RUNNING    | 172.17.0.2:1090 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.77043 |     0.3178 |                    3 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [3,  2000] loss: 1.805
[2m[36m(pid=1101)[0m [4,  4000] loss: 0.836
[2m[36m(pid=1093)[0m [2,  4000] loss: 0.931
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1068
  date: 2020-09-21_20-41-10
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 6
  loss: 2.2975869762420653
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 130.60929155349731
  time_this_iter_s: 19.532901763916016
  time_total_s: 130.60929155349731
  timestamp: 1600720870
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 79ae1_00003

Result for DEFAULT_79ae1_00007:
  accuracy: 0.2908
  date: 2020-09-21_20-41-13
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 4
  loss: 1.9331315527915955
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 133.94267892837524
  time_this_iter_s: 30.193603992462158
  time_total_s: 133.94267892837524
  timestamp: 1600720873
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -2.1188301362514497 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76362 |     0.3383 |                    2 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.72505 |     0.3288 |                    3 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.29759 |     0.1068 |                    6 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.93313 |     0.2908 |                    4 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [3,  4000] loss: 0.908
Result for DEFAULT_79ae1_00002:
  accuracy: 0.3629
  date: 2020-09-21_20-41-15
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 4
  loss: 1.634586717891693
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 135.4520401954651
  time_this_iter_s: 30.31625533103943
  time_total_s: 135.4520401954651
  timestamp: 1600720875
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 79ae1_00002

[2m[36m(pid=1093)[0m [2,  6000] loss: 0.623
[2m[36m(pid=1136)[0m [3,  6000] loss: 0.614
[2m[36m(pid=1088)[0m [7,  2000] loss: 2.295
[2m[36m(pid=1082)[0m [5,  2000] loss: 1.774
[2m[36m(pid=1093)[0m [2,  8000] loss: 0.466
[2m[36m(pid=1101)[0m [5,  2000] loss: 1.616
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1024
  date: 2020-09-21_20-41-29
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 7
  loss: 2.3021462203979493
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 149.9416379928589
  time_this_iter_s: 19.332346439361572
  time_total_s: 149.9416379928589
  timestamp: 1600720889
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 6.1/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76362 |     0.3383 |                    2 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.63459 |     0.3629 |                    4 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.30215 |     0.1024 |                    7 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.93313 |     0.2908 |                    4 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [3,  8000] loss: 0.459
[2m[36m(pid=1093)[0m [2, 10000] loss: 0.374
[2m[36m(pid=1082)[0m [5,  4000] loss: 0.894
[2m[36m(pid=1101)[0m [5,  4000] loss: 0.800
[2m[36m(pid=1136)[0m [3, 10000] loss: 0.393
[2m[36m(pid=1093)[0m [2, 12000] loss: 0.314
Result for DEFAULT_79ae1_00007:
  accuracy: 0.3437
  date: 2020-09-21_20-41-43
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 5
  loss: 1.7956827806949616
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 163.26087045669556
  time_this_iter_s: 29.318191528320312
  time_total_s: 163.26087045669556
  timestamp: 1600720903
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 6.1/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: None | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.76362 |     0.3383 |                    2 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.63459 |     0.3629 |                    4 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.30215 |     0.1024 |                    7 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79568 |     0.3437 |                    5 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1088)[0m [8,  2000] loss: 2.301
Result for DEFAULT_79ae1_00002:
  accuracy: 0.396
  date: 2020-09-21_20-41-45
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 5
  loss: 1.5581882798194886
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 165.59167218208313
  time_this_iter_s: 30.139631986618042
  time_total_s: 165.59167218208313
  timestamp: 1600720905
  timesteps_since_restore: 0
  training_iteration: 5
  trial_id: 79ae1_00002

Result for DEFAULT_79ae1_00001:
  accuracy: 0.2787
  date: 2020-09-21_20-41-46
  done: false
  experiment_id: 1bbc7a7895e54fbcb940a03305b600d0
  experiment_tag: 1_batch_size=4,l1=4,l2=64,lr=0.0050262
  hostname: 18e16d8a13a6
  iterations_since_restore: 3
  loss: 1.9169371470928191
  node_ip: 172.17.0.2
  pid: 1136
  should_checkpoint: true
  time_since_restore: 166.80613708496094
  time_this_iter_s: 49.76242470741272
  time_total_s: 166.80613708496094
  timestamp: 1600720906
  timesteps_since_restore: 0
  training_iteration: 3
  trial_id: 79ae1_00001

[2m[36m(pid=1093)[0m [2, 14000] loss: 0.266
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1048
  date: 2020-09-21_20-41-49
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 8
  loss: 2.299399206161499
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 169.2664031982422
  time_this_iter_s: 19.3247652053833
  time_total_s: 169.2664031982422
  timestamp: 1600720909
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 6.1/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.91694 |     0.2787 |                    3 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55819 |     0.396  |                    5 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.2994  |     0.1048 |                    8 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79568 |     0.3437 |                    5 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1082)[0m [6,  2000] loss: 1.807
[2m[36m(pid=1136)[0m [4,  2000] loss: 1.946
[2m[36m(pid=1101)[0m [6,  2000] loss: 1.555
[2m[36m(pid=1093)[0m [2, 16000] loss: 0.238
[2m[36m(pid=1088)[0m [9,  2000] loss: 2.300
[2m[36m(pid=1136)[0m [4,  4000] loss: 0.982
[2m[36m(pid=1082)[0m [6,  4000] loss: 0.914
[2m[36m(pid=1093)[0m [2, 18000] loss: 0.209
[2m[36m(pid=1101)[0m [6,  4000] loss: 0.771
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1
  date: 2020-09-21_20-42-08
  done: false
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 9
  loss: 2.29986978225708
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 188.21875143051147
  time_this_iter_s: 18.952348232269287
  time_total_s: 188.21875143051147
  timestamp: 1600720928
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 79ae1_00003

== Status ==
Memory usage on this node: 6.1/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.91694 |     0.2787 |                    3 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55819 |     0.396  |                    5 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.29987 |     0.1    |                    9 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.79568 |     0.3437 |                    5 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [4,  6000] loss: 0.702
[2m[36m(pid=1093)[0m [2, 20000] loss: 0.191
Result for DEFAULT_79ae1_00007:
  accuracy: 0.3048
  date: 2020-09-21_20-42-12
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 6
  loss: 1.8979502903938295
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 192.96437525749207
  time_this_iter_s: 29.70350480079651
  time_total_s: 192.96437525749207
  timestamp: 1600720932
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 79ae1_00007

Result for DEFAULT_79ae1_00002:
  accuracy: 0.4114
  date: 2020-09-21_20-42-15
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 6
  loss: 1.5554904752731322
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 195.11810111999512
  time_this_iter_s: 29.526428937911987
  time_total_s: 195.11810111999512
  timestamp: 1600720935
  timesteps_since_restore: 0
  training_iteration: 6
  trial_id: 79ae1_00002

== Status ==
Memory usage on this node: 6.1/240.1 GiB
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8285825047016144 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.91694 |     0.2787 |                    3 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55549 |     0.4114 |                    6 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.29987 |     0.1    |                    9 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.89483 |     0.288  |                    1 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.89795 |     0.3048 |                    6 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1136)[0m [4,  8000] loss: 0.563
[2m[36m(pid=1088)[0m [10,  2000] loss: 2.300
[2m[36m(pid=1082)[0m [7,  2000] loss: 1.806
Result for DEFAULT_79ae1_00004:
  accuracy: 0.2907
  date: 2020-09-21_20-42-24
  done: true
  experiment_id: e9f3bc460b5047efab2187cd37b38e02
  experiment_tag: 4_batch_size=2,l1=32,l2=128,lr=0.0037609
  hostname: 18e16d8a13a6
  iterations_since_restore: 2
  loss: 1.8536756362900138
  node_ip: 172.17.0.2
  pid: 1093
  should_checkpoint: true
  time_since_restore: 204.36427283287048
  time_this_iter_s: 93.47725129127502
  time_total_s: 204.36427283287048
  timestamp: 1600720944
  timesteps_since_restore: 0
  training_iteration: 2
  trial_id: 79ae1_00004

== Status ==
Memory usage on this node: 6.2/240.1 GiB
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -1.9331315527915955 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 10/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (5 RUNNING, 5 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 1.91694 |     0.2787 |                    3 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55549 |     0.4114 |                    6 |
| DEFAULT_79ae1_00003 | RUNNING    | 172.17.0.2:1088 |           16 |    4 |   32 | 0.0243759   | 2.29987 |     0.1    |                    9 |
| DEFAULT_79ae1_00004 | RUNNING    | 172.17.0.2:1093 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.89795 |     0.3048 |                    6 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


[2m[36m(pid=1101)[0m [7,  2000] loss: 1.489
Result for DEFAULT_79ae1_00003:
  accuracy: 0.1039
  date: 2020-09-21_20-42-27
  done: true
  experiment_id: 9946778a87714a4894cfc1180226834e
  experiment_tag: 3_batch_size=16,l1=4,l2=32,lr=0.024376
  hostname: 18e16d8a13a6
  iterations_since_restore: 10
  loss: 2.301052016067505
  node_ip: 172.17.0.2
  pid: 1088
  should_checkpoint: true
  time_since_restore: 207.60384130477905
  time_this_iter_s: 19.385089874267578
  time_total_s: 207.60384130477905
  timestamp: 1600720947
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 79ae1_00003

[2m[36m(pid=1136)[0m [4, 10000] loss: 0.456
[2m[36m(pid=1082)[0m [7,  4000] loss: 0.946
[2m[36m(pid=1101)[0m [7,  4000] loss: 0.751
Result for DEFAULT_79ae1_00001:
  accuracy: 0.1038
  date: 2020-09-21_20-42-36
  done: true
  experiment_id: 1bbc7a7895e54fbcb940a03305b600d0
  experiment_tag: 1_batch_size=4,l1=4,l2=64,lr=0.0050262
  hostname: 18e16d8a13a6
  iterations_since_restore: 4
  loss: 2.301591167116165
  node_ip: 172.17.0.2
  pid: 1136
  should_checkpoint: true
  time_since_restore: 216.5272274017334
  time_this_iter_s: 49.72109031677246
  time_total_s: 216.5272274017334
  timestamp: 1600720956
  timesteps_since_restore: 0
  training_iteration: 4
  trial_id: 79ae1_00001

== Status ==
Memory usage on this node: 5.2/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 6/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (3 RUNNING, 7 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | RUNNING    | 172.17.0.2:1136 |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55549 |     0.4114 |                    6 |
| DEFAULT_79ae1_00003 | TERMINATED |                 |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |                 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.89795 |     0.3048 |                    6 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00007:
  accuracy: 0.2869
  date: 2020-09-21_20-42-41
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 7
  loss: 1.957276029586792
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 221.83797359466553
  time_this_iter_s: 28.873598337173462
  time_total_s: 221.83797359466553
  timestamp: 1600720961
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -2.299399206161499 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | TERMINATED |                 |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.55549 |     0.4114 |                    6 |
| DEFAULT_79ae1_00003 | TERMINATED |                 |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |                 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 1.95728 |     0.2869 |                    7 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00002:
  accuracy: 0.4388
  date: 2020-09-21_20-42-43
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 7
  loss: 1.4743298194885255
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 223.82499742507935
  time_this_iter_s: 28.70689630508423
  time_total_s: 223.82499742507935
  timestamp: 1600720963
  timesteps_since_restore: 0
  training_iteration: 7
  trial_id: 79ae1_00002

[2m[36m(pid=1082)[0m [8,  2000] loss: 1.935
[2m[36m(pid=1101)[0m [8,  2000] loss: 1.467
[2m[36m(pid=1082)[0m [8,  4000] loss: 0.976
[2m[36m(pid=1101)[0m [8,  4000] loss: 0.726
Result for DEFAULT_79ae1_00007:
  accuracy: 0.2025
  date: 2020-09-21_20-43-09
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 8
  loss: 2.103267540740967
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 249.8705985546112
  time_this_iter_s: 28.03262495994568
  time_total_s: 249.8705985546112
  timestamp: 1600720989
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -2.201333373451233 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | TERMINATED |                 |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.47433 |     0.4388 |                    7 |
| DEFAULT_79ae1_00003 | TERMINATED |                 |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |                 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 2.10327 |     0.2025 |                    8 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00002:
  accuracy: 0.4609
  date: 2020-09-21_20-43-11
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 8
  loss: 1.4512013450145722
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 251.70548582077026
  time_this_iter_s: 27.880488395690918
  time_total_s: 251.70548582077026
  timestamp: 1600720991
  timesteps_since_restore: 0
  training_iteration: 8
  trial_id: 79ae1_00002

[2m[36m(pid=1082)[0m [9,  2000] loss: 1.915
[2m[36m(pid=1101)[0m [9,  2000] loss: 1.425
[2m[36m(pid=1082)[0m [9,  4000] loss: 1.055
[2m[36m(pid=1101)[0m [9,  4000] loss: 0.699
Result for DEFAULT_79ae1_00007:
  accuracy: 0.1089
  date: 2020-09-21_20-43-37
  done: false
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 9
  loss: 2.2825397274017334
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 277.9951310157776
  time_this_iter_s: 28.124532461166382
  time_total_s: 277.9951310157776
  timestamp: 1600721017
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 8.000: -2.103267540740967 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | TERMINATED |                 |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.4512  |     0.4609 |                    8 |
| DEFAULT_79ae1_00003 | TERMINATED |                 |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |                 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 2.28254 |     0.1089 |                    9 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00002:
  accuracy: 0.4827
  date: 2020-09-21_20-43-39
  done: false
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 9
  loss: 1.3903643867492677
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 279.9267737865448
  time_this_iter_s: 28.221287965774536
  time_total_s: 279.9267737865448
  timestamp: 1600721019
  timesteps_since_restore: 0
  training_iteration: 9
  trial_id: 79ae1_00002

[2m[36m(pid=1082)[0m [10,  2000] loss: 2.280
[2m[36m(pid=1101)[0m [10,  2000] loss: 1.379
[2m[36m(pid=1082)[0m [10,  4000] loss: 1.147
[2m[36m(pid=1101)[0m [10,  4000] loss: 0.684
Result for DEFAULT_79ae1_00007:
  accuracy: 0.1009
  date: 2020-09-21_20-44-05
  done: true
  experiment_id: b968c158f8f04acfa889e6269e06743b
  experiment_tag: 7_batch_size=8,l1=8,l2=8,lr=0.0097535
  hostname: 18e16d8a13a6
  iterations_since_restore: 10
  loss: 2.302148694419861
  node_ip: 172.17.0.2
  pid: 1082
  should_checkpoint: true
  time_since_restore: 305.90295219421387
  time_this_iter_s: 27.90782117843628
  time_total_s: 305.90295219421387
  timestamp: 1600721045
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 79ae1_00007

== Status ==
Memory usage on this node: 4.6/240.1 GiB
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 8.000: -2.103267540740967 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 4/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (2 RUNNING, 8 TERMINATED)
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |                 |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | TERMINATED |                 |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | RUNNING    | 172.17.0.2:1101 |            8 |    8 |    8 | 0.000388007 | 1.39036 |     0.4827 |                    9 |
| DEFAULT_79ae1_00003 | TERMINATED |                 |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |                 |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |                 |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |                 |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | RUNNING    | 172.17.0.2:1082 |            8 |    8 |    8 | 0.00975354  | 2.30215 |     0.1009 |                   10 |
| DEFAULT_79ae1_00008 | TERMINATED |                 |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |                 |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+


Result for DEFAULT_79ae1_00002:
  accuracy: 0.502
  date: 2020-09-21_20-44-07
  done: true
  experiment_id: cfab037e3fcd473a92d773d729f383ed
  experiment_tag: 2_batch_size=8,l1=8,l2=8,lr=0.00038801
  hostname: 18e16d8a13a6
  iterations_since_restore: 10
  loss: 1.3655993687152863
  node_ip: 172.17.0.2
  pid: 1101
  should_checkpoint: true
  time_since_restore: 307.5741539001465
  time_this_iter_s: 27.647380113601685
  time_total_s: 307.5741539001465
  timestamp: 1600721047
  timesteps_since_restore: 0
  training_iteration: 10
  trial_id: 79ae1_00002

== Status ==
Memory usage on this node: 4.1/240.1 GiB
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 8.000: -2.103267540740967 | Iter 4.000: -2.1173613599538803 | Iter 2.000: -1.8522035459518433 | Iter 1.000: -2.047291660219431
Resources requested: 0/32 CPUs, 0/2 GPUs, 0.0/157.81 GiB heap, 0.0/49.41 GiB objects
Result logdir: /var/lib/jenkins/ray_results/DEFAULT
Number of trials: 10 (10 TERMINATED)
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+
| Trial name          | status     | loc   |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |
|---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------|
| DEFAULT_79ae1_00000 | TERMINATED |       |           16 |  256 |    8 | 0.000100905 | 2.3222  |     0.1017 |                    1 |
| DEFAULT_79ae1_00001 | TERMINATED |       |            4 |    4 |   64 | 0.00502624  | 2.30159 |     0.1038 |                    4 |
| DEFAULT_79ae1_00002 | TERMINATED |       |            8 |    8 |    8 | 0.000388007 | 1.3656  |     0.502  |                   10 |
| DEFAULT_79ae1_00003 | TERMINATED |       |           16 |    4 |   32 | 0.0243759   | 2.30105 |     0.1039 |                   10 |
| DEFAULT_79ae1_00004 | TERMINATED |       |            2 |   32 |  128 | 0.00376088  | 1.85368 |     0.2907 |                    2 |
| DEFAULT_79ae1_00005 | TERMINATED |       |           16 |    8 |   32 | 0.0600091   | 2.30412 |     0.0997 |                    1 |
| DEFAULT_79ae1_00006 | TERMINATED |       |            2 |  128 |   64 | 0.0318437   | 2.33229 |     0.1007 |                    1 |
| DEFAULT_79ae1_00007 | TERMINATED |       |            8 |    8 |    8 | 0.00975354  | 2.30215 |     0.1009 |                   10 |
| DEFAULT_79ae1_00008 | TERMINATED |       |            2 |   64 |  128 | 0.00594678  | 2.01831 |     0.239  |                    1 |
| DEFAULT_79ae1_00009 | TERMINATED |       |            8 |    8 |    4 | 0.000398399 | 2.30283 |     0.097  |                    1 |
+---------------------+------------+-------+--------------+------+------+-------------+---------+------------+----------------------+


Best trial config: {'l1': 8, 'l2': 8, 'lr': 0.00038800718018527913, 'batch_size': 8}
Best trial final validation loss: 1.3655993687152863
Best trial final validation accuracy: 0.502
Files already downloaded and verified
Files already downloaded and verified
Best trial test set accuracy: 0.5049
</pre></div>
</div>
<p>If you run the code, an example output could look like this:</p>
<p>Most trials have been stopped early in order to avoid wasting resources.
The best performing trial achieved a validation accuracy of about 58%, which could
be confirmed on the test set.</p>
<p>So that’s it! You can now tune the parameters of your PyTorch models.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 5 minutes  27.108 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-beginner-hyperparameter-tuning-tutorial-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/95074cd7ce8c3e57a92e7a9c49182e6a/hyperparameter_tuning_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">hyperparameter_tuning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/c24b93738bc036c1b66d0387555bf69a/hyperparameter_tuning_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">hyperparameter_tuning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</article>
</div>
<footer>
<div aria-label="footer navigation" class="rst-footer-buttons" role="navigation">
<a accesskey="n" class="btn btn-neutral float-right" href="../intermediate/pruning_tutorial.html" rel="next" title="Pruning Tutorial">Next <img class="next-page" src="../_static/images/chevron-right-orange.svg"/></a>
<a accesskey="p" class="btn btn-neutral" href="../advanced/dispatcher.html" rel="prev" title="Dispatcher in C++"><img class="previous-page" src="../_static/images/chevron-right-orange.svg"/> Previous</a>
</div>
<hr class="helpful-hr hr-top"/>
<div class="helpful-container">
<div class="helpful-question">Was this helpful?</div>
<div class="helpful-question yes-link" data-behavior="was-this-helpful-event" data-response="yes">Yes</div>
<div class="helpful-question no-link" data-behavior="was-this-helpful-event" data-response="no">No</div>
<div class="was-helpful-thank-you">Thank you</div>
</div>
<hr class="helpful-hr hr-bottom"/>
<div role="contentinfo">
<p>
        © Copyright 2017, PyTorch.

    </p>
</div>
<div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
</footer>
</div>
</div>
<div class="pytorch-content-right" id="pytorch-content-right">
<div class="pytorch-right-menu" id="pytorch-right-menu">
<div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
<ul>
<li><a class="reference internal" href="#">Hyperparameter tuning with Ray Tune</a><ul>
<li><a class="reference internal" href="#setup-imports">Setup / Imports</a></li>
<li><a class="reference internal" href="#data-loaders">Data loaders</a></li>
<li><a class="reference internal" href="#configurable-neural-network">Configurable neural network</a></li>
<li><a class="reference internal" href="#the-train-function">The train function</a><ul>
<li><a class="reference internal" href="#adding-multi-gpu-support-with-dataparallel">Adding (multi) GPU support with DataParallel</a></li>
<li><a class="reference internal" href="#communicating-with-ray-tune">Communicating with Ray Tune</a></li>
<li><a class="reference internal" href="#full-training-function">Full training function</a></li>
</ul>
</li>
<li><a class="reference internal" href="#test-set-accuracy">Test set accuracy</a></li>
<li><a class="reference internal" href="#configuring-the-search-space">Configuring the search space</a></li>
</ul>
</li>
</ul>
</div>
</div>
</div>
</section>
</div>
<script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js" type="text/javascript"></script>
<script src="../_static/jquery.js" type="text/javascript"></script>
<script src="../_static/underscore.js" type="text/javascript"></script>
<script src="../_static/doctools.js" type="text/javascript"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script src="../_static/js/vendor/popper.min.js" type="text/javascript"></script>
<script src="../_static/js/vendor/bootstrap.min.js" type="text/javascript"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>
<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Download',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
   });

   $("[data-behavior='was-this-helpful-event']").on('click', function(){
    $(".helpful-question").hide();
    $(".was-helpful-thank-you").show();
    fbq('trackCustom', "Was this Helpful?", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      helpful: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: 'Was this Helpful?',
      eventAction: 'click',
      eventLabel: $(this).attr("data-response")
    });
    gtag('event', $(this).attr("data-response"), {
      'event_category': 'Was this Helpful?',
      'event_label': $("h1").first().text()
    });
   });

   if (location.pathname == "/") {
     $(".helpful-container").hide();
     $(".hr-bottom").hide();
   }
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView
  &amp;noscript=1" width="1"/>
</noscript>
<img alt="" height="1" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0" style="border-style:none;" width="1"/>
<!-- Begin Footer -->
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4 text-center">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4 text-center">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4 text-center">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="footer-logo-wrapper">
<a class="footer-logo" href="https://pytorch.org/"></a>
</div>
<div class="footer-links-wrapper">
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
<li><a href="https://pytorch.org/get-started">Get Started</a></li>
<li><a href="https://pytorch.org/features">Features</a></li>
<li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
<li><a href="https://pytorch.org/blog/">Blog</a></li>
<li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
</ul>
</div>
<div class="footer-links-col">
<ul>
<li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
<li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
<li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
<li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
<li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
</ul>
</div>
<div class="footer-links-col follow-us-col">
<ul>
<li class="list-title">Stay Connected</li>
<li>
<div id="mc_embed_signup">
<form action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&amp;id=91d0dccd39" class="email-subscribe-form validate" id="mc-embedded-subscribe-form" method="post" name="mc-embedded-subscribe-form" novalidate="" target="_blank">
<div class="email-subscribe-form-fields-wrapper" id="mc_embed_signup_scroll">
<div class="mc-field-group">
<label for="mce-EMAIL" style="display:none;">Email Address</label>
<input class="required email" id="mce-EMAIL" name="EMAIL" placeholder="Email Address" type="email" value=""/>
</div>
<div class="clear" id="mce-responses">
<div class="response" id="mce-error-response" style="display:none"></div>
<div class="response" id="mce-success-response" style="display:none"></div>
</div> <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
<div aria-hidden="true" style="position: absolute; left: -5000px;"><input name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" type="text" value=""/></div>
<div class="clear">
<input class="button email-subscribe-button" id="mc-embedded-subscribe" name="subscribe" type="submit" value=""/>
</div>
</div>
</form>
</div>
</li>
</ul>
<div class="footer-social-icons">
<a class="facebook" href="https://www.facebook.com/pytorch" target="_blank"></a>
<a class="twitter" href="https://twitter.com/pytorch" target="_blank"></a>
<a class="youtube" href="https://www.youtube.com/pytorch" target="_blank"></a>
</div>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/images/pytorch-x.svg">
</img></div>
</div>
<!-- End Footer -->
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="container">
<div class="mobile-main-menu-header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#"></a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/features">Features</a>
</li>
<li>
<a href="https://pytorch.org/ecosystem">Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/mobile">Mobile</a>
</li>
<li>
<a href="https://pytorch.org/hub">PyTorch Hub</a>
</li>
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li class="active">
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/docs/stable/index.html">Docs</a>
</li>
<li>
<a href="https://pytorch.org/resources">Resources</a>
</li>
<li>
<a href="https://github.com/pytorch/pytorch">Github</a>
</li>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<script src="../_static/js/vendor/anchor.min.js" type="text/javascript"></script>
<script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body></html>
