

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Data Loading and Processing Tutorial &mdash; PyTorch Tutorials 0.1.12_2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  
    <link rel="stylesheet" href="../_static/css/pytorch_theme.css" type="text/css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PyTorch Tutorials 0.1.12_2 documentation" href="../index.html"/>
        <link rel="next" title="Deep Learning for NLP with Pytorch" href="deep_learning_nlp_tutorial.html"/>
        <link rel="prev" title="Transfer Learning tutorial" href="transfer_learning_tutorial.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyTorch Tutorials
          

          
            
            <img src="../_static/pytorch-logo-dark.svg" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.1.12_2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Beginner Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a><ul>
<li class="toctree-l2"><a class="reference internal" href="blitz/tensor_tutorial.html">What is PyTorch?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#tensors">Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#operations">Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/autograd_tutorial.html">Autograd: automatic differentiation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/neural_networks_tutorial.html">Neural Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#define-the-network">Define the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#loss-function">Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#backprop">Backprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/neural_networks_tutorial.html#update-the-weights">Update the weights</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="blitz/cifar10_tutorial.html">Training a classifier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#what-about-data">What about data?</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#training-an-image-classifier">Training an image classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#loading-and-normalizing-cifar10">1. Loading and normalizing CIFAR10</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#define-a-convolution-neural-network">2. Define a Convolution Neural Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer">3. Define a Loss function and optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#train-the-network">4. Train the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="blitz/cifar10_tutorial.html#test-the-network-on-the-test-data">5. Test the network on the test data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#training-on-gpu">Training on GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="blitz/cifar10_tutorial.html#where-do-i-go-next">Where do I go next?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="former_torchies_tutorial.html">PyTorch for former Torch users</a><ul>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/tensor_tutorial.html">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#inplace-out-of-place">Inplace / Out-of-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#zero-indexing">Zero Indexing</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#no-camel-casing">No camel casing</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="former_torchies/tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="former_torchies/tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/autograd_tutorial.html">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/nn_tutorial.html">nn package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#example-1-convnet">Example 1: ConvNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#forward-and-backward-function-hooks">Forward and Backward Function Hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/nn_tutorial.html#example-2-recurrent-net">Example 2: Recurrent Net</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="former_torchies/parallelism_tutorial.html">Multi-GPU examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/parallelism_tutorial.html#dataparallel">DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="former_torchies/parallelism_tutorial.html#part-of-the-model-on-cpu-and-part-on-the-gpu">Part of the model on CPU and part on the GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_with_examples.html">Learning PyTorch with Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#warm-up-numpy">Warm-up: numpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-tensors">PyTorch: Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#autograd">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-variables-and-autograd">PyTorch: Variables and autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-defining-new-autograd-functions">PyTorch: Defining new autograd functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#tensorflow-static-graphs">TensorFlow: Static Graphs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#nn-module"><cite>nn</cite> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-nn">PyTorch: nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-optim">PyTorch: optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-custom-nn-modules">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#pytorch-control-flow-weight-sharing">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pytorch_with_examples.html#examples">Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#id1">Tensors</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_tensor/two_layer_net_numpy.html">Warm-up: numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_tensor/two_layer_net_tensor.html">PyTorch: Tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#id2">Autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/two_layer_net_autograd.html">PyTorch: Variables and autograd</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/two_layer_net_custom_function.html">PyTorch: Defining new autograd functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_autograd/tf_two_layer_net.html">TensorFlow: Static Graphs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pytorch_with_examples.html#id3"><cite>nn</cite> module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_nn.html">PyTorch: nn</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_optim.html">PyTorch: optim</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/two_layer_net_module.html">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l4"><a class="reference internal" href="examples_nn/dynamic_net.html">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transfer_learning_tutorial.html">Transfer Learning tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning_tutorial.html#load-data">Load Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transfer_learning_tutorial.html#visualize-a-few-images">Visualize a few images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning_tutorial.html#training-the-model">Training the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transfer_learning_tutorial.html#learning-rate-scheduler">Learning rate scheduler</a></li>
<li class="toctree-l3"><a class="reference internal" href="transfer_learning_tutorial.html#visualizing-the-model-predictions">Visualizing the model predictions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning_tutorial.html#finetuning-the-convnet">Finetuning the convnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transfer_learning_tutorial.html#train-and-evaluate">Train and evaluate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="transfer_learning_tutorial.html#convnet-as-fixed-feature-extractor">ConvNet as fixed feature extractor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="transfer_learning_tutorial.html#id1">Train and evaluate</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Data Loading and Processing Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#dataset-class">Dataset class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#transforms">Transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#compose-transforms">Compose transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#iterating-through-the-dataset">Iterating through the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#afterword-torchvision">Afterword: torchvision</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deep_learning_nlp_tutorial.html">Deep Learning for NLP with Pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nlp/pytorch_tutorial.html">Introduction to PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/pytorch_tutorial.html#introduction-to-torch-s-tensor-library">Introduction to Torch&#8217;s tensor library</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#creating-tensors">Creating Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#operations-with-tensors">Operations with Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/pytorch_tutorial.html#reshaping-tensors">Reshaping Tensors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nlp/pytorch_tutorial.html#computation-graphs-and-automatic-differentiation">Computation Graphs and Automatic Differentiation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/deep_learning_tutorial.html">Deep Learning with PyTorch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#deep-learning-building-blocks-affine-maps-non-linearities-and-objectives">Deep Learning Building Blocks: Affine maps, non-linearities and objectives</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#affine-maps">Affine Maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#non-linearities">Non-Linearities</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#softmax-and-probabilities">Softmax and Probabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#objective-functions">Objective Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#optimization-and-training">Optimization and Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/deep_learning_tutorial.html#creating-network-components-in-pytorch">Creating Network Components in Pytorch</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nlp/deep_learning_tutorial.html#example-logistic-regression-bag-of-words-classifier">Example: Logistic Regression Bag-of-Words classifier</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/word_embeddings_tutorial.html">Word Embeddings: Encoding Lexical Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#getting-dense-word-embeddings">Getting Dense Word Embeddings</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#word-embeddings-in-pytorch">Word Embeddings in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#an-example-n-gram-language-modeling">An Example: N-Gram Language Modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/word_embeddings_tutorial.html#exercise-computing-word-embeddings-continuous-bag-of-words">Exercise: Computing Word Embeddings: Continuous Bag-of-Words</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/sequence_models_tutorial.html">Sequence Models and Long-Short Term Memory Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#lstm-s-in-pytorch">LSTM&#8217;s in Pytorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging">Example: An LSTM for Part-of-Speech Tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/sequence_models_tutorial.html#exercise-augmenting-the-lstm-part-of-speech-tagger-with-character-level-features">Exercise: Augmenting the LSTM part-of-speech tagger with character-level features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nlp/advanced_tutorial.html">Advanced: Making Dynamic Decisions and the Bi-LSTM CRF</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#dynamic-versus-static-deep-learning-toolkits">Dynamic versus Static Deep Learning Toolkits</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#bi-lstm-conditional-random-field-discussion">Bi-LSTM Conditional Random Field Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#implementation-notes">Implementation Notes</a></li>
<li class="toctree-l3"><a class="reference internal" href="nlp/advanced_tutorial.html#exercise-a-new-loss-function-for-discriminative-tagging">Exercise: A new loss function for discriminative tagging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Intermediate Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">Classifying Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-the-data">Preparing the Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#turning-names-into-tensors">Turning Names into Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#plotting-the-results">Plotting the Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#evaluating-the-results">Evaluating the Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#running-on-user-input">Running on User Input</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">Generating Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-the-data">Preparing the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#plotting-the-losses">Plotting the Losses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#sampling-the-network">Sampling the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">Translation with a Sequence to Sequence Network and Attention</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#loading-data-files">Loading data files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model">The Seq2Seq Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-encoder">The Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#the-decoder">The Decoder</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#simple-decoder">Simple Decoder</a></li>
<li class="toctree-l4"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#attention-decoder">Attention Decoder</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#preparing-training-data">Preparing Training Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-the-model">Training the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#plotting-results">Plotting results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#evaluation">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#training-and-evaluating">Training and Evaluating</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#visualizing-attention">Visualizing Attention</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#replay-memory">Replay Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#dqn-algorithm">DQN algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#q-network">Q-network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#input-extraction">Input extraction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#hyperparameters-and-utilities">Hyperparameters and utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html#training-loop">Training loop</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Advanced Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/neural_style_tutorial.html">Neural Transfer with PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/neural_style_tutorial.html#introduction">Introduction</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#neural-what">Neural what?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#how-does-it-work">How does it work?</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../advanced/neural_style_tutorial.html#ok-how-does-it-work">OK. How does it work?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/neural_style_tutorial.html#pytorch-implementation">PyTorch implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#packages">Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#cuda">Cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#load-images">Load images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#display-images">Display images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#content-loss">Content loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#style-loss">Style loss</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#load-the-neural-network">Load the neural network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#input-image">Input image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../advanced/neural_style_tutorial.html#gradient-descent">Gradient descent</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html#parameter-less-example">Parameter-less example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/numpy_extensions_tutorial.html#parametrized-example">Parametrized example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/c_extension.html">Custom C extensions for pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../advanced/c_extension.html#step-1-prepare-your-c-code">Step 1. prepare your C code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced/c_extension.html#step-2-include-it-in-your-python-code">Step 2: Include it in your Python code</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyTorch Tutorials</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Data Loading and Processing Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/beginner/data_loading_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="data-loading-and-processing-tutorial">
<span id="sphx-glr-beginner-data-loading-tutorial-py"></span><h1>Data Loading and Processing Tutorial<a class="headerlink" href="#data-loading-and-processing-tutorial" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://chsasank.github.io">Sasank Chilamkurthy</a></p>
<p>A lot of effort in solving any machine learning problem goes in to
preparing the data. PyTorch provides many tools to make data loading
easy and hopefully, to make your code more readable. In this tutorial,
we will see how to load and preprocess/augment data from a non trivial
dataset.</p>
<p>To run this tutorial, please make sure the following packages are
installed:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">scikit-image</span></code>: For image io and transforms</li>
<li><code class="docutils literal"><span class="pre">pandas</span></code>: For easier csv parsing</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span><span class="p">,</span> <span class="n">transform</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">utils</span>

<span class="c1"># Ignore warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>   <span class="c1"># interactive mode</span>
</pre></div>
</div>
<p>The dataset we are going to deal with is that of facial pose.
This means that a face is annotated like this:</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/landmarked_face2.png"><img alt="../_images/landmarked_face2.png" src="../_images/landmarked_face2.png" style="width: 400px;" /></a>
</div>
<p>Over all, 68 different landmark points are annotated for each face.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Download the dataset from <a class="reference external" href="https://download.pytorch.org/tutorial/faces.zip">here</a>
so that the images are in a directory named &#8216;faces/&#8217;.
This dataset was actually
generated by applying excellent <a class="reference external" href="http://blog.dlib.net/2014/08/real-time-face-pose-estimation.html">dlib&#8217;s pose
estimation</a>
on a few images from imagenet tagged as &#8216;face&#8217;.</p>
</div>
<p>Dataset comes with a csv file with annotations which looks like this:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">image_name</span><span class="p">,</span><span class="n">part_0_x</span><span class="p">,</span><span class="n">part_0_y</span><span class="p">,</span><span class="n">part_1_x</span><span class="p">,</span><span class="n">part_1_y</span><span class="p">,</span><span class="n">part_2_x</span><span class="p">,</span> <span class="o">...</span> <span class="p">,</span><span class="n">part_67_x</span><span class="p">,</span><span class="n">part_67_y</span>
<span class="mi">0805</span><span class="n">personali01</span><span class="o">.</span><span class="n">jpg</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">83</span><span class="p">,</span><span class="mi">27</span><span class="p">,</span><span class="mi">98</span><span class="p">,</span> <span class="o">...</span> <span class="mi">84</span><span class="p">,</span><span class="mi">134</span>
<span class="mi">1084239450</span><span class="n">_e76e00b7e7</span><span class="o">.</span><span class="n">jpg</span><span class="p">,</span><span class="mi">70</span><span class="p">,</span><span class="mi">236</span><span class="p">,</span><span class="mi">71</span><span class="p">,</span><span class="mi">257</span><span class="p">,</span> <span class="o">...</span> <span class="p">,</span><span class="mi">128</span><span class="p">,</span><span class="mi">312</span>
</pre></div>
</div>
<p>Let&#8217;s quickly read the CSV and get the annotations in an (N, 2) array where N
is the number of landmarks.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">landmarks_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;faces/face_landmarks.csv&#39;</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">65</span>
<span class="n">img_name</span> <span class="o">=</span> <span class="n">landmarks_frame</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">landmarks</span> <span class="o">=</span> <span class="n">landmarks_frame</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="n">landmarks</span> <span class="o">=</span> <span class="n">landmarks</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Image name: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">img_name</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Landmarks shape: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">landmarks</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;First 4 Landmarks: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">landmarks</span><span class="p">[:</span><span class="mi">4</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Image</span> <span class="n">name</span><span class="p">:</span> <span class="n">person</span><span class="o">-</span><span class="mf">7.</span><span class="n">jpg</span>
<span class="n">Landmarks</span> <span class="n">shape</span><span class="p">:</span> <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">First</span> <span class="mi">4</span> <span class="n">Landmarks</span><span class="p">:</span> <span class="p">[[</span> <span class="mf">32.</span>  <span class="mf">65.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">33.</span>  <span class="mf">76.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">34.</span>  <span class="mf">86.</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">34.</span>  <span class="mf">97.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Let&#8217;s write a simple helper function to show an image and its landmarks
and use it to show a sample.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">show_landmarks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">landmarks</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Show image with landmarks&quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">landmarks</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">landmarks</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># pause a bit so that plots are updated</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">show_landmarks</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;faces/&#39;</span><span class="p">,</span> <span class="n">img_name</span><span class="p">)),</span>
               <span class="n">landmarks</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_data_loading_tutorial_001.png" class="align-center" src="../_images/sphx_glr_data_loading_tutorial_001.png" />
<div class="section" id="dataset-class">
<h2>Dataset class<a class="headerlink" href="#dataset-class" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal"><span class="pre">torch.utils.data.Dataset</span></code> is an abstract class representing a
dataset.
Your custom dataset should inherit <code class="docutils literal"><span class="pre">Dataset</span></code> and override the following
methods:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">__len__</span></code> so that <code class="docutils literal"><span class="pre">len(dataset)</span></code> returns the size of the dataset.</li>
<li><code class="docutils literal"><span class="pre">__getitem__</span></code> to support the indexing such that <code class="docutils literal"><span class="pre">dataset[i]</span></code> can
be used to get <span class="math">\(i\)</span>th sample</li>
</ul>
<p>Let&#8217;s create a dataset class for our face landmarks dataset. We will
read the csv in <code class="docutils literal"><span class="pre">__init__</span></code> but leave the reading of images to
<code class="docutils literal"><span class="pre">__getitem__</span></code>. This is memory efficient because all the images are not
stored in the memory at once but read as required.</p>
<p>Sample of our dataset will be a dict
<code class="docutils literal"><span class="pre">{'image':</span> <span class="pre">image,</span> <span class="pre">'landmarks':</span> <span class="pre">landmarks}</span></code>. Our datset will take an
optional argument <code class="docutils literal"><span class="pre">transform</span></code> so that any required processing can be
applied on the sample. We will see the usefulness of <code class="docutils literal"><span class="pre">transform</span></code> in the
next section.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FaceLandmarksDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Face Landmarks dataset.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">csv_file</span><span class="p">,</span> <span class="n">root_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            csv_file (string): Path to the csv file with annotations.</span>
<span class="sd">            root_dir (string): Directory with all the images.</span>
<span class="sd">            transform (callable, optional): Optional transform to be applied</span>
<span class="sd">                on a sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">landmarks_frame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root_dir</span> <span class="o">=</span> <span class="n">root_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">landmarks_frame</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">landmarks_frame</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">img_name</span><span class="p">)</span>
        <span class="n">landmarks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">landmarks_frame</span><span class="o">.</span><span class="n">ix</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
        <span class="n">landmarks</span> <span class="o">=</span> <span class="n">landmarks</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s1">&#39;landmarks&#39;</span><span class="p">:</span> <span class="n">landmarks</span><span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sample</span>
</pre></div>
</div>
<p>Let&#8217;s instantiate this class and iterate through the data samples. We
will print the sizes of first 4 samples and show their landmarks.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">face_dataset</span> <span class="o">=</span> <span class="n">FaceLandmarksDataset</span><span class="p">(</span><span class="n">csv_file</span><span class="o">=</span><span class="s1">&#39;faces/face_landmarks.csv&#39;</span><span class="p">,</span>
                                    <span class="n">root_dir</span><span class="o">=</span><span class="s1">&#39;faces/&#39;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">face_dataset</span><span class="p">)):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">face_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Sample #{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
    <span class="n">show_landmarks</span><span class="p">(</span><span class="o">**</span><span class="n">sample</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">break</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_data_loading_tutorial_002.png" class="align-center" src="../_images/sphx_glr_data_loading_tutorial_002.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="p">(</span><span class="mi">324</span><span class="p">,</span> <span class="mi">215</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="mi">1</span> <span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">333</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="mi">2</span> <span class="p">(</span><span class="mi">250</span><span class="p">,</span> <span class="mi">258</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="mi">3</span> <span class="p">(</span><span class="mi">434</span><span class="p">,</span> <span class="mi">290</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="p">(</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="transforms">
<h2>Transforms<a class="headerlink" href="#transforms" title="Permalink to this headline">¶</a></h2>
<p>One issue we can see from the above is that the samples are not of the
same size. Most neural networks expect the images of a fixed size.
Therefore, we will need to write some prepocessing code.
Let&#8217;s create three transforms:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">Rescale</span></code>: to scale the image</li>
<li><code class="docutils literal"><span class="pre">RandomCrop</span></code>: to crop from image randomly. This is data
augmentation.</li>
<li><code class="docutils literal"><span class="pre">ToTensor</span></code>: to convert the numpy images to torch images (we need to
swap axes).</li>
</ul>
<p>We will write them as callable classes instead of simple functions so
that parameters of the transform need not be passed everytime it&#8217;s
called. For this, we just need to implement <code class="docutils literal"><span class="pre">__call__</span></code> method and
if required, <code class="docutils literal"><span class="pre">__init__</span></code> method. We can then use a transform like this:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">tsfm</span> <span class="o">=</span> <span class="n">Transform</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">transformed_sample</span> <span class="o">=</span> <span class="n">tsfm</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
<p>Observe below how these transforms had to be applied both on the image and
landmarks.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Rescale</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Rescale the image in a sample to a given size.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_size (tuple or tuple): Desired output size. If tuple, output is</span>
<span class="sd">            matched to output_size. If int, smaller of image edges is matched</span>
<span class="sd">            to output_size keeping aspect ratio the same.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">landmarks</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span>

        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">*</span> <span class="n">h</span> <span class="o">/</span> <span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">*</span> <span class="n">w</span> <span class="o">/</span> <span class="n">h</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span>

        <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">new_h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">new_w</span><span class="p">)</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span><span class="p">))</span>

        <span class="c1"># h and w are swapped for landmarks because for images,</span>
        <span class="c1"># x and y axes are axis 1 and 0 respectively</span>
        <span class="n">landmarks</span> <span class="o">=</span> <span class="n">landmarks</span> <span class="o">*</span> <span class="p">[</span><span class="n">new_w</span> <span class="o">/</span> <span class="n">w</span><span class="p">,</span> <span class="n">new_h</span> <span class="o">/</span> <span class="n">h</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">img</span><span class="p">,</span> <span class="s1">&#39;landmarks&#39;</span><span class="p">:</span> <span class="n">landmarks</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">RandomCrop</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Crop randomly the image in a sample.</span>

<span class="sd">    Args:</span>
<span class="sd">        output_size (tuple or int): Desired output size. If int, square crop</span>
<span class="sd">            is made.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">landmarks</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span>

        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">new_h</span><span class="p">,</span> <span class="n">new_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span>

        <span class="n">top</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">h</span> <span class="o">-</span> <span class="n">new_h</span><span class="p">)</span>
        <span class="n">left</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">w</span> <span class="o">-</span> <span class="n">new_w</span><span class="p">)</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="n">top</span><span class="p">:</span> <span class="n">top</span> <span class="o">+</span> <span class="n">new_h</span><span class="p">,</span>
                      <span class="n">left</span><span class="p">:</span> <span class="n">left</span> <span class="o">+</span> <span class="n">new_w</span><span class="p">]</span>

        <span class="n">landmarks</span> <span class="o">=</span> <span class="n">landmarks</span> <span class="o">-</span> <span class="p">[</span><span class="n">left</span><span class="p">,</span> <span class="n">top</span><span class="p">]</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s1">&#39;landmarks&#39;</span><span class="p">:</span> <span class="n">landmarks</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">ToTensor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sample</span><span class="p">):</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">landmarks</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span>

        <span class="c1"># swap color axis because</span>
        <span class="c1"># numpy image: H x W x C</span>
        <span class="c1"># torch image: C X H X W</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">image</span><span class="p">),</span>
                <span class="s1">&#39;landmarks&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">landmarks</span><span class="p">)}</span>
</pre></div>
</div>
<div class="section" id="compose-transforms">
<h3>Compose transforms<a class="headerlink" href="#compose-transforms" title="Permalink to this headline">¶</a></h3>
<p>Now, we apply the transforms on an sample.</p>
<p>Let&#8217;s say we want to rescale the shorter side of the image to 256 and
then randomly crop a square of size 224 from it. i.e, we want to compose
<code class="docutils literal"><span class="pre">Rescale</span></code> and <code class="docutils literal"><span class="pre">RandomCrop</span></code> transforms.
<code class="docutils literal"><span class="pre">torchvision.transforms.Compose</span></code> is a simple callable class which allows us
to do this.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">scale</span> <span class="o">=</span> <span class="n">Rescale</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
<span class="n">crop</span> <span class="o">=</span> <span class="n">RandomCrop</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="n">composed</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">Rescale</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                               <span class="n">RandomCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">)])</span>

<span class="c1"># Apply each of the above transforms on sample.</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">face_dataset</span><span class="p">[</span><span class="mi">65</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tsfrm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">scale</span><span class="p">,</span> <span class="n">crop</span><span class="p">,</span> <span class="n">composed</span><span class="p">]):</span>
    <span class="n">transformed_sample</span> <span class="o">=</span> <span class="n">tsfrm</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">tsfrm</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">show_landmarks</span><span class="p">(</span><span class="o">**</span><span class="n">transformed_sample</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_data_loading_tutorial_003.png" class="align-center" src="../_images/sphx_glr_data_loading_tutorial_003.png" />
</div>
</div>
<div class="section" id="iterating-through-the-dataset">
<h2>Iterating through the dataset<a class="headerlink" href="#iterating-through-the-dataset" title="Permalink to this headline">¶</a></h2>
<p>Let&#8217;s put this all together to create a dataset with composed
transforms.
To summarize, every time this dataset is sampled:</p>
<ul class="simple">
<li>An image is read from the file on the fly</li>
<li>Transforms are applied on the read image</li>
<li>Since one of the transforms is random, data is augmentated on
sampling</li>
</ul>
<p>We can iterate over the created dataset with a <code class="docutils literal"><span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">range</span></code>
loop as before.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">transformed_dataset</span> <span class="o">=</span> <span class="n">FaceLandmarksDataset</span><span class="p">(</span><span class="n">csv_file</span><span class="o">=</span><span class="s1">&#39;faces/face_landmarks.csv&#39;</span><span class="p">,</span>
                                           <span class="n">root_dir</span><span class="o">=</span><span class="s1">&#39;faces/&#39;</span><span class="p">,</span>
                                           <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                                               <span class="n">Rescale</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
                                               <span class="n">RandomCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
                                               <span class="n">ToTensor</span><span class="p">()</span>
                                           <span class="p">]))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">transformed_dataset</span><span class="p">)):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">transformed_dataset</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">sample</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">break</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">1</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">2</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">3</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
<p>However, we are losing a lot of features by using a simple <code class="docutils literal"><span class="pre">for</span></code> loop to
iterate over the data. In particular, we are missing out on:</p>
<ul class="simple">
<li>Batching the data</li>
<li>Shuffling the data</li>
<li>Load the data in parallel using <code class="docutils literal"><span class="pre">multiprocessing</span></code> workers.</li>
</ul>
<p><code class="docutils literal"><span class="pre">torch.utils.data.DataLoader</span></code> is an iterator which provides all these
features. Parameters used below should be clear. One parameter of
interest is <code class="docutils literal"><span class="pre">collate_fn</span></code>. You can specify how exactly the samples need
to be batched using <code class="docutils literal"><span class="pre">collate_fn</span></code>. However, default collate should work
fine for most use cases.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">transformed_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="c1"># Helper function to show a batch</span>
<span class="k">def</span> <span class="nf">show_landmarks_batch</span><span class="p">(</span><span class="n">sample_batched</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Show image with landmarks for a batch of samples.&quot;&quot;&quot;</span>
    <span class="n">images_batch</span><span class="p">,</span> <span class="n">landmarks_batch</span> <span class="o">=</span> \
            <span class="n">sample_batched</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">],</span> <span class="n">sample_batched</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">images_batch</span><span class="p">)</span>
    <span class="n">im_size</span> <span class="o">=</span> <span class="n">images_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">grid</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">images_batch</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">landmarks_batch</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">im_size</span><span class="p">,</span>
                    <span class="n">landmarks_batch</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                    <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Batch from dataloader&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i_batch</span><span class="p">,</span> <span class="n">sample_batched</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">i_batch</span><span class="p">,</span> <span class="n">sample_batched</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="n">sample_batched</span><span class="p">[</span><span class="s1">&#39;landmarks&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

    <span class="c1"># observe 4th batch and stop.</span>
    <span class="k">if</span> <span class="n">i_batch</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">show_landmarks_batch</span><span class="p">(</span><span class="n">sample_batched</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">break</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_data_loading_tutorial_004.png" class="align-center" src="../_images/sphx_glr_data_loading_tutorial_004.png" />
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">1</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">2</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="mi">3</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">])</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">68</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="afterword-torchvision">
<h2>Afterword: torchvision<a class="headerlink" href="#afterword-torchvision" title="Permalink to this headline">¶</a></h2>
<p>In this tutorial, we have seen how to write and use datasets, transforms
and dataloader. <code class="docutils literal"><span class="pre">torchvision</span></code> package provides some common datasets and
transforms. You might not even have to write custom classes. One of the
more generic datasets available in torchvision is <code class="docutils literal"><span class="pre">ImageFolder</span></code>.
It assumes that images are organized in the following way:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">/</span><span class="n">ants</span><span class="o">/</span><span class="n">xxx</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">ants</span><span class="o">/</span><span class="n">xxy</span><span class="o">.</span><span class="n">jpeg</span>
<span class="n">root</span><span class="o">/</span><span class="n">ants</span><span class="o">/</span><span class="n">xxz</span><span class="o">.</span><span class="n">png</span>
<span class="o">.</span>
<span class="o">.</span>
<span class="o">.</span>
<span class="n">root</span><span class="o">/</span><span class="n">bees</span><span class="o">/</span><span class="mf">123.</span><span class="n">jpg</span>
<span class="n">root</span><span class="o">/</span><span class="n">bees</span><span class="o">/</span><span class="n">nsdf3</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">bees</span><span class="o">/</span><span class="n">asd932_</span><span class="o">.</span><span class="n">png</span>
</pre></div>
</div>
<p>where &#8216;ants&#8217;, &#8216;bees&#8217; etc. are class labels. Similarly generic transforms
which operate on <code class="docutils literal"><span class="pre">PIL.Image</span></code> like  <code class="docutils literal"><span class="pre">RandomHorizontalFlip</span></code>, <code class="docutils literal"><span class="pre">Scale</span></code>,
are also avaiable. You can use these to write a dataloader like this:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="k">import</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">data_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomSizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                             <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">])</span>
<span class="n">hymenoptera_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;hymenoptera_data/train&#39;</span><span class="p">,</span>
                                           <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">)</span>
<span class="n">dataset_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">hymenoptera_dataset</span><span class="p">,</span>
                                             <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                             <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>For an example with training code, please see
<a class="reference internal" href="transfer_learning_tutorial.html"><span class="doc">Transfer Learning tutorial</span></a>.</p>
<p><strong>Total running time of the script:</strong> ( 0 minutes  13.087 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/data_loading_tutorial.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">data_loading_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/data_loading_tutorial.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">data_loading_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="http://sphinx-gallery.readthedocs.io">Generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="deep_learning_nlp_tutorial.html" class="btn btn-neutral float-right" title="Deep Learning for NLP with Pytorch" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="transfer_learning_tutorial.html" class="btn btn-neutral" title="Transfer Learning tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.1.12_2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-2', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>