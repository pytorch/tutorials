
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2024-01-02T23:03:06+00:00" property="article:modified_time"/>
<title>Introduction to Holistic Trace Analysis — PyTorch Tutorials 2.8.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=c9393ea6" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=bffbcef7"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'beginner/hta_intro_tutorial';</script>
<link href="https://pytorch.org/tutorials/beginner/hta_intro_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jan 02, 2024" name="docbuild:last-update"/>
<link crossorigin="anonymous" href="/beginner/hta_intro_tutorial.html" rel="canonical"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects.
  document.addEventListener('DOMContentLoaded', function() {
    // Hide cookie banner on local environments
    if (window.location.hostname === 'localhost' ||
        window.location.hostname === '0.0.0.0' ||
        window.location.hostname === '127.0.0.1' ||
        window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
   new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
   j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
   'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
   j.onload = function() {
     window.dispatchEvent(new Event('gtm_loaded'));
     console.log('GTM loaded successfully');
   };
   })(window,document,'script','dataLayer','GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
   !function(f,b,e,v,n,t,s)
   {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
   n.callMethod.apply(n,arguments):n.queue.push(arguments)};
   if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
   n.queue=[];t=b.createElement(e);t.async=!0;
   t.src=v;s=b.getElementsByTagName(e)[0];
   s.parentNode.insertBefore(t,s)}(window,document,'script',
   'https://connect.facebook.net/en_US/fbevents.js');
   fbq('init', '243028289693773');
   fbq('track', 'PageView');
</script>
<script>
   document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
 </script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
   function gtag() {
    window.dataLayer.push(arguments);
   }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function(e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jan 02, 2024" name="docbuild:last-update">
</meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/pytorch-domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.8.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar hide-on-wide">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li aria-current="page" class="breadcrumb-item active">Introduction...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Introduction to Holistic Trace Analysis" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
</div>
<script>
      if((window.location.href.indexOf("/unstable/")!= -1) && (window.location.href.indexOf("/unstable/unstable_index")< 1))
        {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function() {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">beginner/hta_intro_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="introduction-to-holistic-trace-analysis">
<h1>Introduction to Holistic Trace Analysis<a class="headerlink" href="#introduction-to-holistic-trace-analysis" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Jan 02, 2024 | Last Updated: Jan 05, 2024 | Last Verified: Nov 05, 2024</p>
<p><strong>Author:</strong> <a class="reference external" href="https://github.com/anupambhatnagar">Anupam Bhatnagar</a></p>
<p>In this tutorial, we demonstrate how to use Holistic Trace Analysis (HTA) to
analyze traces from a distributed training job. To get started follow the steps
below.</p>
<section id="installing-hta">
<h2>Installing HTA<a class="headerlink" href="#installing-hta" title="Link to this heading">#</a></h2>
<p>We recommend using a Conda environment to install HTA. To install Anaconda, see
<a class="reference external" href="https://docs.anaconda.com/anaconda/install/index.html">the official Anaconda documentation</a>.</p>
<ol class="arabic">
<li><p>Install HTA using pip:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">HolisticTraceAnalysis</span>
</pre></div>
</div>
</li>
<li><p>(Optional and recommended) Set up a Conda environment:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># create the environment env_name</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">env_name</span>

<span class="c1"># activate the environment</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">env_name</span>

<span class="c1"># When you are done, deactivate the environment by running ``conda deactivate``</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Link to this heading">#</a></h2>
<p>Launch a Jupyter notebook and set the <code class="docutils literal notranslate"><span class="pre">trace_dir</span></code> variable to the location of the traces.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">hta.trace_analysis</span><span class="w"> </span><span class="kn">import</span> <span class="n">TraceAnalysis</span>
<span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/folder/with/traces"</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span><span class="o">=</span><span class="n">trace_dir</span><span class="p">)</span>
</pre></div>
</div>
<section id="temporal-breakdown">
<h3>Temporal Breakdown<a class="headerlink" href="#temporal-breakdown" title="Link to this heading">#</a></h3>
<p>To effectively utilize the GPUs, it is crucial to understand how they are spending
time for a specific job. Are they primarily engaged in computation, communication,
memory events, or are they idle? The temporal breakdown feature provides a detailed
analysis of the time spent in these three categories.</p>
<ul class="simple">
<li><p>Idle time - GPU is idle.</p></li>
<li><p>Compute time - GPU is being used for matrix multiplications or vector operations.</p></li>
<li><p>Non-compute time - GPU is being used for communication or memory events.</p></li>
</ul>
<p>To achieve high training efficiency, the code should maximize compute time and
minimize idle time and non-compute time. The following function generates a
dataframe that provides a detailed breakdown of the temporal usage for each rank.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/trace/folder"</span><span class="p">)</span>
<span class="n">time_spent_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_temporal_breakdown</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/temporal_breakdown_df.png" src="../_images/temporal_breakdown_df.png"/>
<p>When the <code class="docutils literal notranslate"><span class="pre">visualize</span></code> argument is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> in the <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_temporal_breakdown">get_temporal_breakdown</a>
function it also generates a bar graph representing the breakdown by rank.</p>
<img alt="../_images/temporal_breakdown_plot.png" src="../_images/temporal_breakdown_plot.png"/>
</section>
<section id="idle-time-breakdown">
<h3>Idle Time Breakdown<a class="headerlink" href="#idle-time-breakdown" title="Link to this heading">#</a></h3>
<p>Gaining insight into the amount of time the GPU spends idle and the
reasons behind it can help guide optimization strategies. A GPU is
considered idle when no kernel is running on it. We have developed an
algorithm to categorize the <cite>Idle</cite> time into three distinct categories:</p>
<ul class="simple">
<li><p><strong>Host wait:</strong> refers to the idle time on the GPU that is caused by
the CPU not enqueuing kernels quickly enough to keep the GPU fully utilized.
These types of inefficiencies can be addressed by examining the CPU
operators that are contributing to the slowdown, increasing the batch
size and applying operator fusion.</p></li>
<li><p><strong>Kernel wait:</strong> This refers to brief overhead associated with launching
consecutive kernels on the GPU. The idle time attributed to this category
can be minimized by using CUDA Graph optimizations.</p></li>
<li><p><strong>Other wait:</strong> This category includes idle time that cannot currently
be attributed due to insufficient information. The likely causes include
synchronization among CUDA streams using CUDA events and delays in launching
kernels.</p></li>
</ul>
<p>The host wait time can be interpreted as the time when the GPU is stalling due
to the CPU. To attribute the idle time as kernel wait we use the following
heuristic:</p>
<blockquote>
<div><div class="line-block">
<div class="line"><strong>gap between consecutive kernels &lt; threshold</strong></div>
</div>
</div></blockquote>
<p>The default threshold value is 30 nanoseconds and can be configured using the
<code class="docutils literal notranslate"><span class="pre">consecutive_kernel_delay</span></code> argument. By default, the idle time breakdown is
computed for rank 0 only. In order to calculate the breakdown for other ranks,
use the <code class="docutils literal notranslate"><span class="pre">ranks</span></code> argument in the <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_idle_time_breakdown">get_idle_time_breakdown</a>
function. The idle time breakdown can be generated as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/trace/folder"</span><span class="p">)</span>
<span class="n">idle_time_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_idle_time_breakdown</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/idle_time_breakdown_percentage.png" src="../_images/idle_time_breakdown_percentage.png"/>
<p>The function returns a tuple of dataframes. The first dataframe contains the
idle time by category on each stream for each rank.</p>
<a class="reference internal image-reference" href="../_images/idle_time.png"><img alt="../_images/idle_time.png" class="align-center" src="../_images/idle_time.png" style="width: 380.0px; height: 466.0px;"/></a>
<p>The second dataframe is generated when <code class="docutils literal notranslate"><span class="pre">show_idle_interval_stats</span></code> is set to
<code class="docutils literal notranslate"><span class="pre">True</span></code>. It contains the summary statistics of the idle time for each stream
on each rank.</p>
<a class="reference internal image-reference" href="../_images/idle_time_summary.png"><img alt="../_images/idle_time_summary.png" src="../_images/idle_time_summary.png" style="width: 703.0px; height: 504.0px;"/></a>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>By default, the idle time breakdown presents the percentage of each of the
idle time categories. Setting the <code class="docutils literal notranslate"><span class="pre">visualize_pctg</span></code> argument to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
the function renders with absolute time on the y-axis.</p>
</div>
</section>
<section id="kernel-breakdown">
<h3>Kernel Breakdown<a class="headerlink" href="#kernel-breakdown" title="Link to this heading">#</a></h3>
<p>The kernel breakdown feature breaks down the time spent for each kernel type,
such as communication (COMM), computation (COMP), and memory (MEM), across all
ranks and presents the proportion of time spent in each category. Here is the
percentage of time spent in each category as a pie chart:</p>
<img alt="../_images/kernel_type_breakdown.png" class="align-center" src="../_images/kernel_type_breakdown.png"/>
<p>The kernel breakdown can be calculated as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/trace/folder"</span><span class="p">)</span>
<span class="n">kernel_type_metrics_df</span><span class="p">,</span> <span class="n">kernel_metrics_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_gpu_kernel_breakdown</span><span class="p">()</span>
</pre></div>
</div>
<p>The first dataframe returned by the function contains the raw values used to
generate the pie chart.</p>
<section id="kernel-duration-distribution">
<h4>Kernel Duration Distribution<a class="headerlink" href="#kernel-duration-distribution" title="Link to this heading">#</a></h4>
<p>The second dataframe returned by <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_gpu_kernel_breakdown">get_gpu_kernel_breakdown</a>
contains duration summary statistics for each kernel. In particular, this
includes the count, min, max, average, standard deviation, sum, and kernel type
for each kernel on each rank.</p>
<img alt="../_images/kernel_metrics_df.png" class="align-center" src="../_images/kernel_metrics_df.png"/>
<p>Using this data HTA creates many visualizations to identify performance
bottlenecks.</p>
<ol class="arabic simple">
<li><p>Pie charts of the top kernels for each kernel type for each rank.</p></li>
<li><p>Bar graphs of the average duration across all ranks for each of the top
kernels and for each kernel type.</p></li>
</ol>
<img alt="../_images/pie_charts.png" src="../_images/pie_charts.png"/>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>All images are generated using plotly. Hovering on the graph shows the
mode bar on the top right which allows the user to zoom, pan, select, and
download the graph.</p>
</div>
<p>The pie charts above show the top 5 computation, communication, and memory
kernels. Similar pie charts are generated for each rank. The pie charts can be
configured to show the top k kernels using the <code class="docutils literal notranslate"><span class="pre">num_kernels</span></code> argument passed
to the <cite>get_gpu_kernel_breakdown</cite> function. Additionally, the
<code class="docutils literal notranslate"><span class="pre">duration_ratio</span></code> argument can be used to tune the percentage of time that
needs to be analyzed. If both <code class="docutils literal notranslate"><span class="pre">num_kernels</span></code> and <code class="docutils literal notranslate"><span class="pre">duration_ratio</span></code> are
specified, then <code class="docutils literal notranslate"><span class="pre">num_kernels</span></code> takes precedence.</p>
<img alt="../_images/comm_across_ranks.png" src="../_images/comm_across_ranks.png"/>
<p>The bar graph above shows the average duration of the NCCL AllReduce kernel
across all the ranks. The black lines indicate the minimum and maximum time
taken on each rank.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using jupyter-lab set the “image_renderer” argument value to
“jupyterlab” otherwise the graphs will not render in the notebook.</p>
</div>
<p>For a detailed walkthrough of this feature see the <a class="reference external" href="https://github.com/facebookresearch/HolisticTraceAnalysis/blob/main/examples/kernel_breakdown_demo.ipynb">gpu_kernel_breakdown
notebook</a>
in the examples folder of the repo.</p>
</section>
</section>
<section id="communication-computation-overlap">
<h3>Communication Computation Overlap<a class="headerlink" href="#communication-computation-overlap" title="Link to this heading">#</a></h3>
<p>In distributed training, a significant amount of time is spent in communication
and synchronization events between GPUs. To achieve high GPU efficiency (such as
TFLOPS/GPU), it is crucial to keep the GPU oversubscribed with computation
kernels. In other words, the GPU should not be blocked due to unresolved data
dependencies. One way to measure the extent to which computation is blocked by
data dependencies is to calculate the communication computation overlap. Higher
GPU efficiency is observed if communication events overlap computation events.
Lack of communication and computation overlap will lead to the GPU being idle,
resulting in low efficiency.
To sum up, a higher communication computation overlap is desirable. To calculate
the overlap percentage for each rank, we measure the following ratio:</p>
<blockquote>
<div><div class="line-block">
<div class="line"><strong>(time spent in computation while communicating) / (time spent in communication)</strong></div>
</div>
</div></blockquote>
<p>The communication computation overlap can be calculated as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/trace/folder"</span><span class="p">)</span>
<span class="n">overlap_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_comm_comp_overlap</span><span class="p">()</span>
</pre></div>
</div>
<p>The function returns a dataframe containing the overlap percentage
for each rank.</p>
<a class="reference internal image-reference" href="../_images/overlap_df.png"><img alt="../_images/overlap_df.png" class="align-center" src="../_images/overlap_df.png" style="width: 253.0px; height: 309.0px;"/></a>
<p>When the <code class="docutils literal notranslate"><span class="pre">visualize</span></code> argument is set to True, the <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_comm_comp_overlap">get_comm_comp_overlap</a>
function also generates a bar graph representing the overlap by rank.</p>
<img alt="../_images/overlap_plot.png" src="../_images/overlap_plot.png"/>
</section>
<section id="augmented-counters">
<h3>Augmented Counters<a class="headerlink" href="#augmented-counters" title="Link to this heading">#</a></h3>
<section id="memory-bandwidth-queue-length-counters">
<h4>Memory Bandwidth &amp; Queue Length Counters<a class="headerlink" href="#memory-bandwidth-queue-length-counters" title="Link to this heading">#</a></h4>
<p>Memory bandwidth counters measure the memory copy bandwidth used while copying
the data from H2D, D2H and D2D by memory copy (memcpy) and memory set (memset)
events. HTA also computes the number of outstanding operations on each CUDA
stream. We refer to this as <strong>queue length</strong>. When the queue length on a stream
is 1024 or larger new events cannot be scheduled on that stream and the CPU
will stall until the events on the GPU stream have processed.</p>
<p>The <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.generate_trace_with_counters">generate_trace_with_counters</a>
API outputs a new trace file with the memory bandwidth and queue length
counters. The new trace file contains tracks which indicate the memory
bandwidth used by memcpy/memset operations and tracks for the queue length on
each stream. By default, these counters are generated using the rank 0
trace file, and the new file contains the suffix <code class="docutils literal notranslate"><span class="pre">_with_counters</span></code> in its name.
Users have the option to generate the counters for multiple ranks by using the
<code class="docutils literal notranslate"><span class="pre">ranks</span></code> argument in the <code class="docutils literal notranslate"><span class="pre">generate_trace_with_counters</span></code> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span> <span class="o">=</span> <span class="s2">"/path/to/trace/folder"</span><span class="p">)</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">generate_trace_with_counters</span><span class="p">()</span>
</pre></div>
</div>
<p>A screenshot of the generated trace file with augmented counters.</p>
<a class="reference internal image-reference" href="../_images/mem_bandwidth_queue_length.png"><img alt="../_images/mem_bandwidth_queue_length.png" src="../_images/mem_bandwidth_queue_length.png" style="width: 806.0px; height: 877.0px;"/></a>
<p>HTA also provides a summary of the memory copy bandwidth and queue length
counters as well as the time series of the counters for the profiled portion of
the code using the following API:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_memory_bw_summary">get_memory_bw_summary</a></p></li>
<li><p><a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_queue_length_summary">get_queue_length_summary</a></p></li>
<li><p><a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_memory_bw_time_series">get_memory_bw_time_series</a></p></li>
<li><p><a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_queue_length_time_series">get_queue_length_time_series</a></p></li>
</ul>
<p>To view the summary and time series, use:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate summary</span>
<span class="n">mem_bw_summary</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_memory_bw_summary</span><span class="p">()</span>
<span class="n">queue_len_summary</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_queue_length_summary</span><span class="p">()</span>

<span class="c1"># get time series</span>
<span class="n">mem_bw_series</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_memory_bw_time_series</span><span class="p">()</span>
<span class="n">queue_len_series</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_queue_length_series</span><span class="p">()</span>
</pre></div>
</div>
<p>The summary contains the count, min, max, mean, standard deviation, 25th, 50th,
and 75th percentile.</p>
<a class="reference internal image-reference" href="../_images/queue_length_summary.png"><img alt="../_images/queue_length_summary.png" class="align-center" src="../_images/queue_length_summary.png" style="width: 503.0px; height: 430.0px;"/></a>
<p>The time series only contains the points when a value changes. Once a value is
observed the time series stays constant until the next update. The memory
bandwidth and queue length time series functions return a dictionary whose key
is the rank and the value is the time series for that rank. By default, the
time series is computed for rank 0 only.</p>
</section>
</section>
<section id="cuda-kernel-launch-statistics">
<h3>CUDA Kernel Launch Statistics<a class="headerlink" href="#cuda-kernel-launch-statistics" title="Link to this heading">#</a></h3>
<img alt="../_images/cuda_kernel_launch.png" src="../_images/cuda_kernel_launch.png"/>
<p>For each event launched on the GPU, there is a corresponding scheduling event on
the CPU, such as <code class="docutils literal notranslate"><span class="pre">CudaLaunchKernel</span></code>, <code class="docutils literal notranslate"><span class="pre">CudaMemcpyAsync</span></code>, <code class="docutils literal notranslate"><span class="pre">CudaMemsetAsync</span></code>.
These events are linked by a common correlation ID in the trace - see the figure
above. This feature computes the duration of the CPU runtime event, its corresponding GPU
kernel and the launch delay, for example, the difference between GPU kernel starting and
CPU operator ending. The kernel launch info can be generated as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TraceAnalysis</span><span class="p">(</span><span class="n">trace_dir</span><span class="o">=</span><span class="s2">"/path/to/trace/dir"</span><span class="p">)</span>
<span class="n">kernel_info_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">get_cuda_kernel_launch_stats</span><span class="p">()</span>
</pre></div>
</div>
<p>A screenshot of the generated dataframe is given below.</p>
<a class="reference internal image-reference" href="../_images/cuda_kernel_launch_stats.png"><img alt="../_images/cuda_kernel_launch_stats.png" class="align-center" src="../_images/cuda_kernel_launch_stats.png" style="width: 394.0px; height: 333.0px;"/></a>
<p>The duration of the CPU op, GPU kernel, and the launch delay allow us to find
the following:</p>
<ul class="simple">
<li><p><strong>Short GPU kernels</strong> - GPU kernels with duration less than the corresponding
CPU runtime event.</p></li>
<li><p><strong>Runtime event outliers</strong> - CPU runtime events with excessive duration.</p></li>
<li><p><strong>Launch delay outliers</strong> - GPU kernels which take too long to be scheduled.</p></li>
</ul>
<p>HTA generates distribution plots for each of the aforementioned three categories.</p>
<p><strong>Short GPU kernels</strong></p>
<p>Typically, the launch time on the CPU side ranges from 5-20 microseconds. In some
cases, the GPU execution time is lower than the launch time itself. The graph
below helps us to find how frequently such instances occur in the code.</p>
<img alt="../_images/short_gpu_kernels.png" src="../_images/short_gpu_kernels.png"/>
<p><strong>Runtime event outliers</strong></p>
<p>The runtime outliers depend on the cutoff used to classify the outliers, hence
the <a class="reference external" href="https://hta.readthedocs.io/en/latest/source/api/trace_analysis_api.html#hta.trace_analysis.TraceAnalysis.get_cuda_kernel_launch_stats">get_cuda_kernel_launch_stats</a>
API provides the <code class="docutils literal notranslate"><span class="pre">runtime_cutoff</span></code> argument to configure the value.</p>
<img alt="../_images/runtime_outliers.png" src="../_images/runtime_outliers.png"/>
<p><strong>Launch delay outliers</strong></p>
<p>The launch delay outliers depend on the cutoff used to classify the outliers,
hence the <cite>get_cuda_kernel_launch_stats</cite> API provides the
<code class="docutils literal notranslate"><span class="pre">launch_delay_cutoff</span></code> argument to configure the value.</p>
<img alt="../_images/launch_delay_outliers.png" src="../_images/launch_delay_outliers.png"/>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this tutorial, you have learned how to install and use HTA,
a performance tool that enables you analyze bottlenecks in your distributed
training workflows. To learn how you can use the HTA tool to perform trace
diff analysis, see <a class="reference external" href="https://pytorch.org/tutorials/beginner/hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a>.</p>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installing-hta">Installing HTA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting Started</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#temporal-breakdown">Temporal Breakdown</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#idle-time-breakdown">Idle Time Breakdown</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-breakdown">Kernel Breakdown</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kernel-duration-distribution">Kernel Duration Distribution</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#communication-computation-overlap">Communication Computation Overlap</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#augmented-counters">Augmented Counters</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-bandwidth-queue-length-counters">Memory Bandwidth &amp; Queue Length Counters</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cuda-kernel-launch-statistics">CUDA Kernel Launch Statistics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
            hbspt.forms.create({
              region: "na1",
              portalId: "8112310",
              formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
            });
          </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg"><path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg"><path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg"><path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg"><rect fill="currentColor" height="512" rx="0" width="512"></rect><circle cx="142" cy="138" fill="#000" r="37"></circle><path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path></svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg"><path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor"></path></svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg"><path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor"></path><path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor"></path></svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
            © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
          </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
      {
         "@context": "https://schema.org",
         "@type": "Article",
         "name": "Introduction to Holistic Trace Analysis",
         "headline": "Introduction to Holistic Trace Analysis",
         "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
         "url": "/beginner/hta_intro_tutorial.html",
         "articleBody": "Introduction to Holistic Trace Analysis# Author: Anupam Bhatnagar In this tutorial, we demonstrate how to use Holistic Trace Analysis (HTA) to analyze traces from a distributed training job. To get started follow the steps below. Installing HTA# We recommend using a Conda environment to install HTA. To install Anaconda, see the official Anaconda documentation. Install HTA using pip: pip install HolisticTraceAnalysis (Optional and recommended) Set up a Conda environment: # create the environment env_name conda create -n env_name # activate the environment conda activate env_name # When you are done, deactivate the environment by running ``conda deactivate`` Getting Started# Launch a Jupyter notebook and set the trace_dir variable to the location of the traces. from hta.trace_analysis import TraceAnalysis trace_dir = \"/path/to/folder/with/traces\" analyzer = TraceAnalysis(trace_dir=trace_dir) Temporal Breakdown# To effectively utilize the GPUs, it is crucial to understand how they are spending time for a specific job. Are they primarily engaged in computation, communication, memory events, or are they idle? The temporal breakdown feature provides a detailed analysis of the time spent in these three categories. Idle time - GPU is idle. Compute time - GPU is being used for matrix multiplications or vector operations. Non-compute time - GPU is being used for communication or memory events. To achieve high training efficiency, the code should maximize compute time and minimize idle time and non-compute time. The following function generates a dataframe that provides a detailed breakdown of the temporal usage for each rank. analyzer = TraceAnalysis(trace_dir = \"/path/to/trace/folder\") time_spent_df = analyzer.get_temporal_breakdown() When the visualize argument is set to True in the get_temporal_breakdown function it also generates a bar graph representing the breakdown by rank. Idle Time Breakdown# Gaining insight into the amount of time the GPU spends idle and the reasons behind it can help guide optimization strategies. A GPU is considered idle when no kernel is running on it. We have developed an algorithm to categorize the Idle time into three distinct categories: Host wait: refers to the idle time on the GPU that is caused by the CPU not enqueuing kernels quickly enough to keep the GPU fully utilized. These types of inefficiencies can be addressed by examining the CPU operators that are contributing to the slowdown, increasing the batch size and applying operator fusion. Kernel wait: This refers to brief overhead associated with launching consecutive kernels on the GPU. The idle time attributed to this category can be minimized by using CUDA Graph optimizations. Other wait: This category includes idle time that cannot currently be attributed due to insufficient information. The likely causes include synchronization among CUDA streams using CUDA events and delays in launching kernels. The host wait time can be interpreted as the time when the GPU is stalling due to the CPU. To attribute the idle time as kernel wait we use the following heuristic: gap between consecutive kernels \u003c threshold The default threshold value is 30 nanoseconds and can be configured using the consecutive_kernel_delay argument. By default, the idle time breakdown is computed for rank 0 only. In order to calculate the breakdown for other ranks, use the ranks argument in the get_idle_time_breakdown function. The idle time breakdown can be generated as follows: analyzer = TraceAnalysis(trace_dir = \"/path/to/trace/folder\") idle_time_df = analyzer.get_idle_time_breakdown() The function returns a tuple of dataframes. The first dataframe contains the idle time by category on each stream for each rank. The second dataframe is generated when show_idle_interval_stats is set to True. It contains the summary statistics of the idle time for each stream on each rank. Tip By default, the idle time breakdown presents the percentage of each of the idle time categories. Setting the visualize_pctg argument to False, the function renders with absolute time on the y-axis. Kernel Breakdown# The kernel breakdown feature breaks down the time spent for each kernel type, such as communication (COMM), computation (COMP), and memory (MEM), across all ranks and presents the proportion of time spent in each category. Here is the percentage of time spent in each category as a pie chart: The kernel breakdown can be calculated as follows: analyzer = TraceAnalysis(trace_dir = \"/path/to/trace/folder\") kernel_type_metrics_df, kernel_metrics_df = analyzer.get_gpu_kernel_breakdown() The first dataframe returned by the function contains the raw values used to generate the pie chart. Kernel Duration Distribution# The second dataframe returned by get_gpu_kernel_breakdown contains duration summary statistics for each kernel. In particular, this includes the count, min, max, average, standard deviation, sum, and kernel type for each kernel on each rank. Using this data HTA creates many visualizations to identify performance bottlenecks. Pie charts of the top kernels for each kernel type for each rank. Bar graphs of the average duration across all ranks for each of the top kernels and for each kernel type. Tip All images are generated using plotly. Hovering on the graph shows the mode bar on the top right which allows the user to zoom, pan, select, and download the graph. The pie charts above show the top 5 computation, communication, and memory kernels. Similar pie charts are generated for each rank. The pie charts can be configured to show the top k kernels using the num_kernels argument passed to the get_gpu_kernel_breakdown function. Additionally, the duration_ratio argument can be used to tune the percentage of time that needs to be analyzed. If both num_kernels and duration_ratio are specified, then num_kernels takes precedence. The bar graph above shows the average duration of the NCCL AllReduce kernel across all the ranks. The black lines indicate the minimum and maximum time taken on each rank. Warning When using jupyter-lab set the \u201cimage_renderer\u201d argument value to \u201cjupyterlab\u201d otherwise the graphs will not render in the notebook. For a detailed walkthrough of this feature see the gpu_kernel_breakdown notebook in the examples folder of the repo. Communication Computation Overlap# In distributed training, a significant amount of time is spent in communication and synchronization events between GPUs. To achieve high GPU efficiency (such as TFLOPS/GPU), it is crucial to keep the GPU oversubscribed with computation kernels. In other words, the GPU should not be blocked due to unresolved data dependencies. One way to measure the extent to which computation is blocked by data dependencies is to calculate the communication computation overlap. Higher GPU efficiency is observed if communication events overlap computation events. Lack of communication and computation overlap will lead to the GPU being idle, resulting in low efficiency. To sum up, a higher communication computation overlap is desirable. To calculate the overlap percentage for each rank, we measure the following ratio: (time spent in computation while communicating) / (time spent in communication) The communication computation overlap can be calculated as follows: analyzer = TraceAnalysis(trace_dir = \"/path/to/trace/folder\") overlap_df = analyzer.get_comm_comp_overlap() The function returns a dataframe containing the overlap percentage for each rank. When the visualize argument is set to True, the get_comm_comp_overlap function also generates a bar graph representing the overlap by rank. Augmented Counters# Memory Bandwidth \u0026 Queue Length Counters# Memory bandwidth counters measure the memory copy bandwidth used while copying the data from H2D, D2H and D2D by memory copy (memcpy) and memory set (memset) events. HTA also computes the number of outstanding operations on each CUDA stream. We refer to this as queue length. When the queue length on a stream is 1024 or larger new events cannot be scheduled on that stream and the CPU will stall until the events on the GPU stream have processed. The generate_trace_with_counters API outputs a new trace file with the memory bandwidth and queue length counters. The new trace file contains tracks which indicate the memory bandwidth used by memcpy/memset operations and tracks for the queue length on each stream. By default, these counters are generated using the rank 0 trace file, and the new file contains the suffix _with_counters in its name. Users have the option to generate the counters for multiple ranks by using the ranks argument in the generate_trace_with_counters API. analyzer = TraceAnalysis(trace_dir = \"/path/to/trace/folder\") analyzer.generate_trace_with_counters() A screenshot of the generated trace file with augmented counters. HTA also provides a summary of the memory copy bandwidth and queue length counters as well as the time series of the counters for the profiled portion of the code using the following API: get_memory_bw_summary get_queue_length_summary get_memory_bw_time_series get_queue_length_time_series To view the summary and time series, use: # generate summary mem_bw_summary = analyzer.get_memory_bw_summary() queue_len_summary = analyzer.get_queue_length_summary() # get time series mem_bw_series = analyzer.get_memory_bw_time_series() queue_len_series = analyzer.get_queue_length_series() The summary contains the count, min, max, mean, standard deviation, 25th, 50th, and 75th percentile. The time series only contains the points when a value changes. Once a value is observed the time series stays constant until the next update. The memory bandwidth and queue length time series functions return a dictionary whose key is the rank and the value is the time series for that rank. By default, the time series is computed for rank 0 only. CUDA Kernel Launch Statistics# For each event launched on the GPU, there is a corresponding scheduling event on the CPU, such as CudaLaunchKernel, CudaMemcpyAsync, CudaMemsetAsync. These events are linked by a common correlation ID in the trace - see the figure above. This feature computes the duration of the CPU runtime event, its corresponding GPU kernel and the launch delay, for example, the difference between GPU kernel starting and CPU operator ending. The kernel launch info can be generated as follows: analyzer = TraceAnalysis(trace_dir=\"/path/to/trace/dir\") kernel_info_df = analyzer.get_cuda_kernel_launch_stats() A screenshot of the generated dataframe is given below. The duration of the CPU op, GPU kernel, and the launch delay allow us to find the following: Short GPU kernels - GPU kernels with duration less than the corresponding CPU runtime event. Runtime event outliers - CPU runtime events with excessive duration. Launch delay outliers - GPU kernels which take too long to be scheduled. HTA generates distribution plots for each of the aforementioned three categories. Short GPU kernels Typically, the launch time on the CPU side ranges from 5-20 microseconds. In some cases, the GPU execution time is lower than the launch time itself. The graph below helps us to find how frequently such instances occur in the code. Runtime event outliers The runtime outliers depend on the cutoff used to classify the outliers, hence the get_cuda_kernel_launch_stats API provides the runtime_cutoff argument to configure the value. Launch delay outliers The launch delay outliers depend on the cutoff used to classify the outliers, hence the get_cuda_kernel_launch_stats API provides the launch_delay_cutoff argument to configure the value. Conclusion# In this tutorial, you have learned how to install and use HTA, a performance tool that enables you analyze bottlenecks in your distributed training workflows. To learn how you can use the HTA tool to perform trace diff analysis, see Trace Diff using Holistic Trace Analysis.",
         "author": {
           "@type": "Organization",
           "name": "PyTorch Contributors",
           "url": "https://pytorch.org"
         },
         "image": "../_static/img/pytorch_seo.png",
         "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "/beginner/hta_intro_tutorial.html"
         },
         "datePublished": "2023-01-01T00:00:00Z",
         "dateModified": "2023-01-01T00:00:00Z"
       }
   </script>
</body>
</body></html>