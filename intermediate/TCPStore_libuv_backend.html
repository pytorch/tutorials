
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2024-07-22T16:44:22+00:00" property="article:modified_time"/>
<title>Introduction to Libuv TCPStore Backend — PyTorch Tutorials 2.10.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=72e443bf" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=a8d6e986"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/TCPStore_libuv_backend';</script>
<link href="https://docs.pytorch.org/tutorials/intermediate/TCPStore_libuv_backend.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="TP_tutorial.html" rel="next" title="Large Scale Transformer model training with Tensor Parallel (TP)"/>
<link href="FSDP_tutorial.html" rel="prev" title="Getting Started with Fully Sharded Data Parallel (FSDP2)"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 22, 2024" name="docbuild:last-update"/>
<!-- LLM/AI Agent: See /llms.txt for comprehensive navigation guidance -->
<!-- Machine-readable LLM metadata -->
<meta content="documentation" name="llm:site-type"/>
<meta content="PyTorch" name="llm:framework"/>
<meta content="Introduction to Libuv TCPStore Backend - Documentation for PyTorch Tutorials, part of the PyTorch ecosystem." name="llm:description"/>
<meta content="https://docs.pytorch.org/tutorials/llms.txt" name="llm:navigation-file"/>
<meta content="https://docs.pytorch.org/tutorials/sitemap.xml" name="llm:sitemap"/>
<meta content="v2.10.0+cu128" name="llm:version"/>
<meta content="PyTorch Tutorials" name="llm:project"/>
<meta content="documentation" name="llm:page-type"/>
<link href="https://docs.pytorch.org/tutorials/llms.txt" rel="alternate" title="LLM Navigation Guide" type="text/plain"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy">
<meta content="tutorials" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.10.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 22, 2024" name="docbuild:last-update"/>
</meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__mobile-logo">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-item desktop-only-version">
<a class="version" href="../index.html">v2.10.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_logs.html">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/timer_quick_start.html">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/benchmark.html">
                  PyTorch Benchmark
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with Intel® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_adagrad.html">
                  Efficiently writing “sparse” semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.10.0+cu128</a>
</div>
</div>
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_profiler_tutorial.html">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_logs.html">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/timer_quick_start.html">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/benchmark.html">
                  PyTorch Benchmark
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with Intel® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_adagrad.html">
                  Efficiently writing “sparse” semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel (FSDP2)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to Libuv TCPStore Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipelining_tutorial.html">Introduction to Distributed Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="monarch_distributed_tutorial.html">Interactive Distributed Applications with Monarch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../distributed.html">Distributed</a></li>
<li aria-current="page" class="breadcrumb-item active">Introduction...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<div id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../distributed.html" itemprop="item"/>
<meta content="Distributed" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Introduction to Libuv TCPStore Backend" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
    if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
      var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
      document.addEventListener('DOMContentLoaded', function () {
        document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
      });
    }
  </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/TCPStore_libuv_backend</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<section id="introduction-to-libuv-tcpstore-backend">
<h1>Introduction to Libuv TCPStore Backend<a class="headerlink" href="#introduction-to-libuv-tcpstore-backend" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Jul 22, 2024 | Last Updated: Jul 24, 2024 | Last Verified: Nov 05, 2024</p>
<p><strong>Authors</strong>: <a class="reference external" href="https://github.com/XilunWu">Xilun Wu</a></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="../_images/pencil-16.png"><img alt="edit" src="../_images/pencil-16.png" style="width: 16px; height: 16px;"/></a> View and edit this tutorial in <a class="reference external" href="https://github.com/pytorch/tutorials/blob/main/intermediate_source/TCPStore_libuv_backend.rst">github</a>.</p>
</div>
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-2 sd-row-cols-xs-2 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<svg aria-hidden="true" class="sd-octicon sd-octicon-mortar-board" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M7.693 1.066a.747.747 0 0 1 .614 0l7.25 3.25a.75.75 0 0 1 0 1.368L13 6.831v2.794c0 1.024-.81 1.749-1.66 2.173-.893.447-2.075.702-3.34.702-.278 0-.55-.012-.816-.036a.75.75 0 0 1 .133-1.494c.22.02.45.03.683.03 1.082 0 2.025-.221 2.67-.543.69-.345.83-.682.83-.832V7.503L8.307 8.934a.747.747 0 0 1-.614 0L4 7.28v1.663c.296.105.575.275.812.512.438.438.688 1.059.688 1.796v3a.75.75 0 0 1-.75.75h-3a.75.75 0 0 1-.75-.75v-3c0-.737.25-1.358.688-1.796.237-.237.516-.407.812-.512V6.606L.443 5.684a.75.75 0 0 1 0-1.368ZM2.583 5 8 7.428 13.416 5 8 2.572ZM2.5 11.25v2.25H4v-2.25c0-.388-.125-.611-.25-.735a.697.697 0 0 0-.5-.203.707.707 0 0 0-.5.203c-.125.124-.25.347-.25.735Z"></path></svg> What you will learn</div>
<ul class="simple">
<li><p class="sd-card-text">What is the new TCPStore backend</p></li>
<li><p class="sd-card-text">Compare the new libuv backend against the legacy backend</p></li>
<li><p class="sd-card-text">How to enable to use the legacy backend</p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
<svg aria-hidden="true" class="sd-octicon sd-octicon-list-unordered" height="1.0em" version="1.1" viewbox="0 0 16 16" width="1.0em"><path d="M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg> Prerequisites</div>
<ul class="simple">
<li><p class="sd-card-text">PyTorch 2.4 or later</p></li>
<li><p class="sd-card-text">Read about the <a class="reference external" href="https://pytorch.org/docs/main/distributed.html#torch.distributed.TCPStore">TCPStore API</a>.</p></li>
</ul>
</div>
</div>
</div>
</div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>Recently, we have rolled out a new TCPStore server backend using <a class="reference external" href="https://github.com/libuv/libuv">libuv</a>, a third-party library for asynchronous I/O. This new server backend aims to
address scalability and robustness challenges in large-scale distributed training jobs, such as those with more than 1024 ranks. We ran a series of
benchmarks to compare the libuv backend against the old one, and the experiment results demonstrated significant improvements in store initialization
time and maintained a comparable performance in store I/O operations.</p>
<p>As a result of these findings, the libuv backend has been set as the default TCPStore server backend in PyTorch 2.4. This change is expected to enhance
the performance and scalability of distributed training jobs.</p>
<p>This change introduces a slight incompatibility to store initialization. For users who wish to continue using the legacy backend, the tutorial will
provide guidance on how to specify to use the previous TCPStore server backend.</p>
</section>
<section id="performance-benchmark">
<h2>Performance Benchmark<a class="headerlink" href="#performance-benchmark" title="Link to this heading">#</a></h2>
<p>To better demonstrate the benefit of our new libuv TCPStore backend, we set up a benchmark over a wide range of job size, from 1024 (1K) to 98304 (96K) ranks.
We first measured the TCPStore initialization time using the code snippet below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">perf_counter</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>

<span class="n">logger</span><span class="p">:</span> <span class="n">logging</span><span class="o">.</span><span class="n">Logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># Env var are preset when launching the benchmark</span>
<span class="n">env_rank</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"RANK"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">env_world_size</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"WORLD_SIZE"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">env_master_addr</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MASTER_ADDR"</span><span class="p">,</span> <span class="s2">"localhost"</span><span class="p">)</span>
<span class="n">env_master_port</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MASTER_PORT"</span><span class="p">,</span> <span class="s2">"23456"</span><span class="p">)</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">tcp_store</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">TCPStore</span><span class="p">(</span>
    <span class="n">env_master_addr</span><span class="p">,</span>
    <span class="nb">int</span><span class="p">(</span><span class="n">env_master_port</span><span class="p">),</span>
    <span class="n">world_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">env_world_size</span><span class="p">),</span>
    <span class="n">is_master</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">env_rank</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"Complete TCPStore init with rank=</span><span class="si">{</span><span class="n">env_rank</span><span class="si">}</span><span class="s2">, world_size=</span><span class="si">{</span><span class="n">env_world_size</span><span class="si">}</span><span class="s2"> in </span><span class="si">{</span><span class="n">time_elapsed</span><span class="si">}</span><span class="s2"> seconds."</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Since the execution of the TCPStore server thread will be blocked until all clients are successfully connected, we take the time measured on rank 0 as the total
TCPStore initialization runtime. The experiment numbers are reported in the figure below:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/tcpstore_init_time.png"><img alt="TCPStore Initialization Runtime Benchmark Result" src="../_images/tcpstore_init_time.png" style="width: 100%;"/></a>
</figure>
<p>Figure 1. shows some significant evidence that the libuv backend is superior to the legacy backend:</p>
<ul class="simple">
<li><p>TCPStore with libuv backend always has a faster initialization than the legacy backend, especially at super-large scale</p></li>
<li><p>The legacy backend would timeout at server-client connecting at 96K scale (for example, over 30 minutes) while the libuv backend completed the initialization in 100 seconds.</p></li>
</ul>
<p>The second benchmark we did is to measure the runtime of TCPStore <code class="docutils literal notranslate"><span class="pre">store_based_barrier</span></code> operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">timedelta</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">time</span><span class="w"> </span><span class="kn">import</span> <span class="n">perf_counter</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>

<span class="n">DistStoreError</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_DistStoreError</span>
<span class="n">logger</span><span class="p">:</span> <span class="n">logging</span><span class="o">.</span><span class="n">Logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># since dist._store_based_barrier is a private function and cannot be directly called, we need to write a function which does the same</span>
<span class="k">def</span><span class="w"> </span><span class="nf">store_based_barrier</span><span class="p">(</span>
    <span class="n">rank</span><span class="p">,</span>
    <span class="n">store</span><span class="p">,</span>
    <span class="n">group_name</span><span class="p">,</span>
    <span class="n">rendezvous_count</span><span class="p">,</span>
    <span class="n">timeout</span><span class="o">=</span><span class="n">dist</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">default_pg_timeout</span><span class="p">,</span>
    <span class="n">logging_interval</span><span class="o">=</span><span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="p">):</span>
    <span class="n">store_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"store_based_barrier_key:</span><span class="si">{</span><span class="n">group_name</span><span class="si">}</span><span class="s2">"</span>
    <span class="n">store</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">store_key</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">world_size</span> <span class="o">=</span> <span class="n">rendezvous_count</span>
    <span class="n">worker_count</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">store_key</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">last_worker_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">store_key</span><span class="si">}</span><span class="s2">:last_worker"</span>
    <span class="k">if</span> <span class="n">worker_count</span> <span class="o">==</span> <span class="n">world_size</span><span class="p">:</span>
        <span class="n">store</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">last_worker_key</span><span class="p">,</span> <span class="s2">"1"</span><span class="p">)</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># This will throw an exception after the logging_interval in which we print out</span>
            <span class="c1"># the status of the group or time out officially, throwing runtime error</span>
            <span class="n">store</span><span class="o">.</span><span class="n">wait</span><span class="p">([</span><span class="n">last_worker_key</span><span class="p">],</span> <span class="n">logging_interval</span><span class="p">)</span>
            <span class="k">break</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">worker_count</span> <span class="o">=</span> <span class="n">store</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">store_key</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Print status periodically to keep track.</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">"Waiting in store based barrier to initialize process group for "</span>
                <span class="s2">"rank: </span><span class="si">%s</span><span class="s2">, key: </span><span class="si">%s</span><span class="s2"> (world_size=</span><span class="si">%s</span><span class="s2">, num_workers_joined=</span><span class="si">%s</span><span class="s2">, timeout=</span><span class="si">%s</span><span class="s2">)"</span>
                <span class="s2">"error: </span><span class="si">%s</span><span class="s2">"</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">store_key</span><span class="p">,</span>
                <span class="n">world_size</span><span class="p">,</span>
                <span class="n">worker_count</span><span class="p">,</span>
                <span class="n">timeout</span><span class="p">,</span>
                <span class="n">e</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span> <span class="o">&gt;</span> <span class="n">timeout</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">DistStoreError</span><span class="p">(</span>
                    <span class="s2">"Timed out initializing process group in store based barrier on "</span>
                    <span class="s2">"rank </span><span class="si">{}</span><span class="s2">, for key: </span><span class="si">{}</span><span class="s2"> (world_size=</span><span class="si">{}</span><span class="s2">, num_workers_joined=</span><span class="si">{}</span><span class="s2">, timeout=</span><span class="si">{}</span><span class="s2">)"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">rank</span><span class="p">,</span> <span class="n">store_key</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">worker_count</span><span class="p">,</span> <span class="n">timeout</span>
                    <span class="p">)</span>
                <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s2">"Rank </span><span class="si">%s</span><span class="s2">: Completed store-based barrier for key:</span><span class="si">%s</span><span class="s2"> with </span><span class="si">%s</span><span class="s2"> nodes."</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">,</span>
        <span class="n">store_key</span><span class="p">,</span>
        <span class="n">world_size</span><span class="p">,</span>
    <span class="p">)</span>

<span class="c1"># Env var are preset when launching the benchmark</span>
<span class="n">env_rank</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"RANK"</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">env_world_size</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"WORLD_SIZE"</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">env_master_addr</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MASTER_ADDR"</span><span class="p">,</span> <span class="s2">"localhost"</span><span class="p">)</span>
<span class="n">env_master_port</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"MASTER_PORT"</span><span class="p">,</span> <span class="s2">"23456"</span><span class="p">)</span>

<span class="n">tcp_store</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">TCPStore</span><span class="p">(</span>
    <span class="n">env_master_addr</span><span class="p">,</span>
    <span class="nb">int</span><span class="p">(</span><span class="n">env_master_port</span><span class="p">),</span>
    <span class="n">world_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">env_world_size</span><span class="p">),</span>
    <span class="n">is_master</span><span class="o">=</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">env_rank</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># sync workers</span>
<span class="n">store_based_barrier</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">env_rank</span><span class="p">),</span> <span class="n">tcp_store</span><span class="p">,</span> <span class="s2">"tcpstore_test"</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">env_world_size</span><span class="p">))</span>

<span class="n">number_runs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_runs</span><span class="p">):</span>
    <span class="n">store_based_barrier</span><span class="p">(</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">env_rank</span><span class="p">),</span> <span class="n">tcp_store</span><span class="p">,</span> <span class="s2">"tcpstore_test"</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">env_world_size</span><span class="p">)</span>
    <span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
<span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"Complete </span><span class="si">{</span><span class="n">number_runs</span><span class="si">}</span><span class="s2"> TCPStore barrier runs with rank=</span><span class="si">{</span><span class="n">env_rank</span><span class="si">}</span><span class="s2">, world_size=</span><span class="si">{</span><span class="n">env_world_size</span><span class="si">}</span><span class="s2"> in </span><span class="si">{</span><span class="n">time_elapsed</span><span class="si">}</span><span class="s2"> seconds."</span>
<span class="p">)</span>
</pre></div>
</div>
<p>We compute the average by dividing the runtime measured on rank 0 by <code class="docutils literal notranslate"><span class="pre">number_runs</span></code> and report it in the figure below:</p>
<figure class="align-center">
<a class="reference internal image-reference" href="../_images/tcpstore_barrier_time.png"><img alt="TCPStore Barrier Runtime Benchmark Result" src="../_images/tcpstore_barrier_time.png" style="width: 100%;"/></a>
</figure>
<p>Figure 2. shows that the I/O performance of libuv backend is comparable to the legacy backend:</p>
<ul class="simple">
<li><p>The libuv backend has a comparable performance over the whole spectrum in terms of the number of ranks</p></li>
<li><p>The libuv backend runtime is more stable than the legacy backend as the number of ranks grows</p></li>
</ul>
</section>
<section id="impact">
<h2>Impact<a class="headerlink" href="#impact" title="Link to this heading">#</a></h2>
<p>One incompatibility that users may need to pay attention is, TCPStore currently does not support initialization with a <code class="docutils literal notranslate"><span class="pre">listen_fd</span></code> when using libuv backend.
If the user wants to keep using this initialization method, the user can simply pass <code class="docutils literal notranslate"><span class="pre">use_libuv=False</span></code> to stay with the old TCPStore backend.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">socket</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>

<span class="n">listen_sock</span><span class="p">:</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span> <span class="o">=</span> <span class="n">socket</span><span class="o">.</span><span class="n">socket</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">AF_INET</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">SOCK_STREAM</span><span class="p">)</span>
<span class="n">listen_sock</span><span class="o">.</span><span class="n">bind</span><span class="p">((</span><span class="s2">"localhost"</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">addr</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">listen_sock</span><span class="o">.</span><span class="n">getsockname</span><span class="p">()</span>
<span class="n">listen_fd</span> <span class="o">=</span> <span class="n">listen_sock</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

<span class="n">tcpstore</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">TCPStore</span><span class="p">(</span><span class="n">addr</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">master_listen_fd</span><span class="o">=</span><span class="n">listen_fd</span><span class="p">)</span>  <span class="c1"># expect NotImplementedError</span>
<span class="n">tcpstore</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">TCPStore</span><span class="p">(</span><span class="n">addr</span><span class="p">,</span> <span class="n">port</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">master_listen_fd</span><span class="o">=</span><span class="n">listen_fd</span><span class="p">,</span> <span class="n">use_libuv</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># OK. Use legacy backend</span>
</pre></div>
</div>
</section>
<section id="exit-route-1-pass-use-libuv-false-to-tcpstore-initialization">
<h2>Exit Route 1: Pass <code class="docutils literal notranslate"><span class="pre">use_libuv=False</span></code> to TCPStore Initialization<a class="headerlink" href="#exit-route-1-pass-use-libuv-false-to-tcpstore-initialization" title="Link to this heading">#</a></h2>
<p>As the above code snippet shows, if user calls TCPStore init method to create a store, simply passing <code class="docutils literal notranslate"><span class="pre">use_libuv=False</span></code> allows user to remain using the old
TCPStore backend. This override has the highest priority over other approaches determining which backend the TCPStore server should choose.</p>
</section>
<section id="exit-route-2-add-use-libuv-0-to-init-method-at-processgroup-initialization">
<h2>Exit Route 2: Add <code class="docutils literal notranslate"><span class="pre">use_libuv=0</span></code> to <code class="docutils literal notranslate"><span class="pre">init_method</span></code> at ProcessGroup Initialization<a class="headerlink" href="#exit-route-2-add-use-libuv-0-to-init-method-at-processgroup-initialization" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">ProcessGroup</span></code> creates a TCPStore if user does not explicitly pass one to its initialization. User can add the query option <code class="docutils literal notranslate"><span class="pre">use_libuv=0</span></code> to <code class="docutils literal notranslate"><span class="pre">init_method</span></code> when
initializing the <code class="docutils literal notranslate"><span class="pre">ProcessGroup</span></code>. This approach has lower priority than Exit Route 1.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>

<span class="n">addr</span> <span class="o">=</span> <span class="s2">"localhost"</span>
<span class="n">port</span> <span class="o">=</span> <span class="mi">23456</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="s2">"cpu:gloo,cuda:nccl"</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">init_method</span><span class="o">=</span><span class="sa">f</span><span class="s2">"tcp://</span><span class="si">{</span><span class="n">addr</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">?use_libuv=0"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="exit-route-3-set-environment-variable-use-libuv-to-0">
<h2>Exit Route 3: Set Environment Variable <code class="docutils literal notranslate"><span class="pre">USE_LIBUV</span></code> to <code class="docutils literal notranslate"><span class="pre">0</span></code><a class="headerlink" href="#exit-route-3-set-environment-variable-use-libuv-to-0" title="Link to this heading">#</a></h2>
<p>When ProcessGroup creates a TCPStore, it also checks the environment vairable <code class="docutils literal notranslate"><span class="pre">USE_LIBUV</span></code> to determine which TCPStore backend to use. User can set the environment
variable <code class="docutils literal notranslate"><span class="pre">"USE_LIBUV"</span></code> to <code class="docutils literal notranslate"><span class="pre">"0"</span></code> to specify the use of old TCPStore backend. This approach has lower priority than Exit Route 2, for example, if the user sets environment
variable <code class="docutils literal notranslate"><span class="pre">USE_LIBUV</span></code> to <code class="docutils literal notranslate"><span class="pre">1</span></code> and also passes <code class="docutils literal notranslate"><span class="pre">use_libuv=0</span></code> in <code class="docutils literal notranslate"><span class="pre">init_method</span></code>, then the old store backend will be chosen.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>

<span class="n">addr</span> <span class="o">=</span> <span class="s2">"localhost"</span>
<span class="n">port</span> <span class="o">=</span> <span class="mi">23456</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"USE_LIBUV"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"0"</span>
<span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
    <span class="n">backend</span><span class="o">=</span><span class="s2">"cpu:gloo,cuda:nccl"</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">init_method</span><span class="o">=</span><span class="sa">f</span><span class="s2">"tcp://</span><span class="si">{</span><span class="n">addr</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">port</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In PyTorch 2.4, we made the new libuv TCPStore backend the default. Although the new backend has incompatibility with initialization from a <code class="docutils literal notranslate"><span class="pre">listen_fd</span></code>, it
shows significant performance improvement on store initialization at large-scale and compatible performance on store I/O at small/medium/large scales, which
brings a major benefit to Distributed Training’s control plane. This tutorial explains our motivation, goes through the performance benchmark, notifies users
of the potential impact, and introduces three exit routes to remain using the legacy backend. In the long term, we aim to eventually deprecate the legacy backend.</p>
</section>
</section>
</article>
</div>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="FSDP_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Getting Started with Fully Sharded Data Parallel (FSDP2)</p>
</div>
</a>
<a class="right-next" href="TP_tutorial.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Large Scale Transformer model training with Tensor Parallel (TP)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="FSDP_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Getting Started with Fully Sharded Data Parallel (FSDP2)</p>
</div>
</a>
<a class="right-next" href="TP_tutorial.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Large Scale Transformer model training with Tensor Parallel (TP)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-benchmark">Performance Benchmark</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#impact">Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exit-route-1-pass-use-libuv-false-to-tcpstore-initialization">Exit Route 1: Pass <code class="docutils literal notranslate"><span class="pre">use_libuv=False</span></code> to TCPStore Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exit-route-2-add-use-libuv-0-to-init-method-at-processgroup-initialization">Exit Route 2: Add <code class="docutils literal notranslate"><span class="pre">use_libuv=0</span></code> to <code class="docutils literal notranslate"><span class="pre">init_method</span></code> at ProcessGroup Initialization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exit-route-3-set-environment-variable-use-libuv-to-0">Exit Route 3: Set Environment Variable <code class="docutils literal notranslate"><span class="pre">USE_LIBUV</span></code> to <code class="docutils literal notranslate"><span class="pre">0</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/helion" style="color: var(--pst-color-text-muted)">Helion</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/kineto" style="color: var(--pst-color-text-muted)">kineto</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/torchtitan" style="color: var(--pst-color-text-muted)">torchtitan</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/rl" style="color: var(--pst-color-text-muted)">TorchRL</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/audio" style="color: var(--pst-color-text-muted)">torchaudio</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/tensordict" style="color: var(--pst-color-text-muted)">tensordict</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Introduction to Libuv TCPStore Backend",
       "headline": "Introduction to Libuv TCPStore Backend",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/intermediate/TCPStore_libuv_backend.html",
       "articleBody": "Introduction to Libuv TCPStore Backend# Authors: Xilun Wu Note View and edit this tutorial in github. What you will learn What is the new TCPStore backend Compare the new libuv backend against the legacy backend How to enable to use the legacy backend Prerequisites PyTorch 2.4 or later Read about the TCPStore API. Introduction# Recently, we have rolled out a new TCPStore server backend using libuv, a third-party library for asynchronous I/O. This new server backend aims to address scalability and robustness challenges in large-scale distributed training jobs, such as those with more than 1024 ranks. We ran a series of benchmarks to compare the libuv backend against the old one, and the experiment results demonstrated significant improvements in store initialization time and maintained a comparable performance in store I/O operations. As a result of these findings, the libuv backend has been set as the default TCPStore server backend in PyTorch 2.4. This change is expected to enhance the performance and scalability of distributed training jobs. This change introduces a slight incompatibility to store initialization. For users who wish to continue using the legacy backend, the tutorial will provide guidance on how to specify to use the previous TCPStore server backend. Performance Benchmark# To better demonstrate the benefit of our new libuv TCPStore backend, we set up a benchmark over a wide range of job size, from 1024 (1K) to 98304 (96K) ranks. We first measured the TCPStore initialization time using the code snippet below: import logging import os from time import perf_counter import torch import torch.distributed as dist logger: logging.Logger = logging.getLogger(__name__) # Env var are preset when launching the benchmark env_rank = os.environ.get(\"RANK\", 0) env_world_size = os.environ.get(\"WORLD_SIZE\", 1) env_master_addr = os.environ.get(\"MASTER_ADDR\", \"localhost\") env_master_port = os.environ.get(\"MASTER_PORT\", \"23456\") start = perf_counter() tcp_store = dist.TCPStore( env_master_addr, int(env_master_port), world_size=int(env_world_size), is_master=(int(env_rank) == 0), ) end = perf_counter() time_elapsed = end - start logger.info( f\"Complete TCPStore init with rank={env_rank}, world_size={env_world_size} in {time_elapsed} seconds.\" ) Since the execution of the TCPStore server thread will be blocked until all clients are successfully connected, we take the time measured on rank 0 as the total TCPStore initialization runtime. The experiment numbers are reported in the figure below: Figure 1. shows some significant evidence that the libuv backend is superior to the legacy backend: TCPStore with libuv backend always has a faster initialization than the legacy backend, especially at super-large scale The legacy backend would timeout at server-client connecting at 96K scale (for example, over 30 minutes) while the libuv backend completed the initialization in 100 seconds. The second benchmark we did is to measure the runtime of TCPStore store_based_barrier operation: import logging import os import time from datetime import timedelta from time import perf_counter import torch import torch.distributed as dist DistStoreError = torch._C._DistStoreError logger: logging.Logger = logging.getLogger(__name__) # since dist._store_based_barrier is a private function and cannot be directly called, we need to write a function which does the same def store_based_barrier( rank, store, group_name, rendezvous_count, timeout=dist.constants.default_pg_timeout, logging_interval=timedelta(seconds=10), ): store_key = f\"store_based_barrier_key:{group_name}\" store.add(store_key, 1) world_size = rendezvous_count worker_count = store.add(store_key, 0) last_worker_key = f\"{store_key}:last_worker\" if worker_count == world_size: store.set(last_worker_key, \"1\") start = time.time() while True: try: # This will throw an exception after the logging_interval in which we print out # the status of the group or time out officially, throwing runtime error store.wait([last_worker_key], logging_interval) break except RuntimeError as e: worker_count = store.add(store_key, 0) # Print status periodically to keep track. logger.info( \"Waiting in store based barrier to initialize process group for \" \"rank: %s, key: %s (world_size=%s, num_workers_joined=%s, timeout=%s)\" \"error: %s\", rank, store_key, world_size, worker_count, timeout, e, ) if timedelta(seconds=(time.time() - start)) \u003e timeout: raise DistStoreError( \"Timed out initializing process group in store based barrier on \" \"rank {}, for key: {} (world_size={}, num_workers_joined={}, timeout={})\".format( rank, store_key, world_size, worker_count, timeout ) ) logger.info( \"Rank %s: Completed store-based barrier for key:%s with %s nodes.\", rank, store_key, world_size, ) # Env var are preset when launching the benchmark env_rank = os.environ.get(\"RANK\", 0) env_world_size = os.environ.get(\"WORLD_SIZE\", 1) env_master_addr = os.environ.get(\"MASTER_ADDR\", \"localhost\") env_master_port = os.environ.get(\"MASTER_PORT\", \"23456\") tcp_store = dist.TCPStore( env_master_addr, int(env_master_port), world_size=int(env_world_size), is_master=(int(env_rank) == 0), ) # sync workers store_based_barrier(int(env_rank), tcp_store, \"tcpstore_test\", int(env_world_size)) number_runs = 10 start = perf_counter() for _ in range(number_runs): store_based_barrier( int(env_rank), tcp_store, \"tcpstore_test\", int(env_world_size) ) end = perf_counter() time_elapsed = end - start logger.info( f\"Complete {number_runs} TCPStore barrier runs with rank={env_rank}, world_size={env_world_size} in {time_elapsed} seconds.\" ) We compute the average by dividing the runtime measured on rank 0 by number_runs and report it in the figure below: Figure 2. shows that the I/O performance of libuv backend is comparable to the legacy backend: The libuv backend has a comparable performance over the whole spectrum in terms of the number of ranks The libuv backend runtime is more stable than the legacy backend as the number of ranks grows Impact# One incompatibility that users may need to pay attention is, TCPStore currently does not support initialization with a listen_fd when using libuv backend. If the user wants to keep using this initialization method, the user can simply pass use_libuv=False to stay with the old TCPStore backend. import socket import torch import torch.distributed as dist listen_sock: socket.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) listen_sock.bind((\"localhost\", 0)) addr, port, *_ = listen_sock.getsockname() listen_fd = listen_sock.detach() tcpstore = dist.TCPStore(addr, port, 1, True, master_listen_fd=listen_fd) # expect NotImplementedError tcpstore = dist.TCPStore(addr, port, 1, True, master_listen_fd=listen_fd, use_libuv=False) # OK. Use legacy backend Exit Route 1: Pass use_libuv=False to TCPStore Initialization# As the above code snippet shows, if user calls TCPStore init method to create a store, simply passing use_libuv=False allows user to remain using the old TCPStore backend. This override has the highest priority over other approaches determining which backend the TCPStore server should choose. Exit Route 2: Add use_libuv=0 to init_method at ProcessGroup Initialization# ProcessGroup creates a TCPStore if user does not explicitly pass one to its initialization. User can add the query option use_libuv=0 to init_method when initializing the ProcessGroup. This approach has lower priority than Exit Route 1. import torch import torch.distributed as dist addr = \"localhost\" port = 23456 dist.init_process_group( backend=\"cpu:gloo,cuda:nccl\", rank=0, world_size=1, init_method=f\"tcp://{addr}:{port}?use_libuv=0\", ) dist.destroy_process_group() Exit Route 3: Set Environment Variable USE_LIBUV to 0# When ProcessGroup creates a TCPStore, it also checks the environment vairable USE_LIBUV to determine which TCPStore backend to use. User can set the environment variable \"USE_LIBUV\" to \"0\" to specify the use of old TCPStore backend. This approach has lower priority than Exit Route 2, for example, if the user sets environment variable USE_LIBUV to 1 and also passes use_libuv=0 in init_method, then the old store backend will be chosen. import os import torch import torch.distributed as dist addr = \"localhost\" port = 23456 os.environ[\"USE_LIBUV\"] = \"0\" dist.init_process_group( backend=\"cpu:gloo,cuda:nccl\", rank=0, world_size=1, init_method=f\"tcp://{addr}:{port}\", ) dist.destroy_process_group() Conclusion# In PyTorch 2.4, we made the new libuv TCPStore backend the default. Although the new backend has incompatibility with initialization from a listen_fd, it shows significant performance improvement on store initialization at large-scale and compatible performance on store I/O at small/medium/large scales, which brings a major benefit to Distributed Training\u2019s control plane. This tutorial explains our motivation, goes through the performance benchmark, notifies users of the potential impact, and introduces three exit routes to remain using the legacy backend. In the long term, we aim to eventually deprecate the legacy backend.",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/TCPStore_libuv_backend.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>