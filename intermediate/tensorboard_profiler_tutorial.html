
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>PyTorch Profiler With TensorBoard — PyTorch Tutorials 2.9.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=047068a3" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=c2809cec"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/tensorboard_profiler_tutorial';</script>
<link href="https://docs.pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="realtime_rpi.html" rel="next" title="Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)"/>
<link href="ax_multiobjective_nas_tutorial.html" rel="prev" title="Multi-Objective NAS with Ax"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="tutorials" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.9.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started/locally">Get Started</a>
</li>
<li>
<a href="https://docs.pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.9.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="realtime_rpi.html">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../ecosystem.html">Ecosystem</a></li>
<li aria-current="page" class="breadcrumb-item active">PyTorch...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../ecosystem.html" itemprop="item"/>
<meta content="Ecosystem" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="PyTorch Profiler With TensorBoard" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/tensorboard_profiler_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-tensorboard-profiler-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="pytorch-profiler-with-tensorboard">
<span id="sphx-glr-intermediate-tensorboard-profiler-tutorial-py"></span><h1>PyTorch Profiler With TensorBoard<a class="headerlink" href="#pytorch-profiler-with-tensorboard" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Apr 20, 2021 | Last Updated: Oct 31, 2024 | Last Verified: Nov 05, 2024</p>
<p>This tutorial demonstrates how to use TensorBoard plugin with PyTorch Profiler
to detect performance bottlenecks of the model.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The TensorBoard integration with the PyTorch profiler is now
deprecated. Instead, use Perfetto or the Chrome trace to
view <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> files. After
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html#using-tracing-functionality">generating a trace</a>,
simply drag the <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> into <a class="reference external" href="https://ui.perfetto.dev/">Perfetto UI</a>
or <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> to visualize your profile.</p>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>PyTorch 1.8 includes an updated profiler API capable of
recording the CPU side operations as well as the CUDA kernel launches on the GPU side.
The profiler can visualize this information
in TensorBoard Plugin and provide analysis of the performance bottlenecks.</p>
<p>In this tutorial, we will use a simple Resnet model to demonstrate how to
use TensorBoard plugin to analyze model performance.</p>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>To install <code class="docutils literal notranslate"><span class="pre">torch</span></code> and <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> use the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
</pre></div>
</div>
</section>
<section id="steps">
<h2>Steps<a class="headerlink" href="#steps" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Prepare the data and model</p></li>
<li><p>Use profiler to record execution events</p></li>
<li><p>Run the profiler</p></li>
<li><p>Use TensorBoard to view results and analyze model performance</p></li>
<li><p>Improve performance with the help of profiler</p></li>
<li><p>Analyze performance with other advanced features</p></li>
<li><p>Additional Practices: Profiling PyTorch on AMD GPUs</p></li>
</ol>
<section id="prepare-the-data-and-model">
<h3>1. Prepare the data and model<a class="headerlink" href="#prepare-the-data-and-model" title="Link to this heading">#</a></h3>
<p>First, import all necessary libraries:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.profiler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.datasets</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">T</span>
</pre></div>
</div>
<p>Then prepare the input data. For this tutorial, we use the CIFAR10 dataset.
Transform it to the desired format and use <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to load each batch.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">T</span><span class="o">.</span><span class="n">Compose</span></a><span class="p">(</span>
    <span class="p">[</span><a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize" title="torchvision.transforms.Resize"><span class="n">T</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
     <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor" title="torchvision.transforms.ToTensor"><span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span></a><span class="p">(),</span>
     <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize" title="torchvision.transforms.Normalize"><span class="n">T</span><span class="o">.</span><span class="n">Normalize</span></a><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>
<span class="n">train_set</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span></a><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, create Resnet model, loss function, and optimizer objects.
To run on GPU, move model and loss to GPU device.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cuda:0"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-models sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18" title="torchvision.models.resnet18"><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span></a><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'IMAGENET1K_V1'</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD" title="torch.optim.SGD"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span></a><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>Define the training step for each batch of input data.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="use-profiler-to-record-execution-events">
<h3>2. Use profiler to record execution events<a class="headerlink" href="#use-profiler-to-record-execution-events" title="Link to this heading">#</a></h3>
<p>The profiler is enabled through the context manager and accepts several parameters,
some of the most useful are:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">schedule</span></code> - callable that takes step (int) as a single parameter
and returns the profiler action to perform at each step.</p>
<p>In this example with <code class="docutils literal notranslate"><span class="pre">wait=1,</span> <span class="pre">warmup=1,</span> <span class="pre">active=3,</span> <span class="pre">repeat=1</span></code>,
profiler will skip the first step/iteration,
start warming up on the second,
record the following three iterations,
after which the trace will become available and on_trace_ready (when set) is called.
In total, the cycle repeats once. Each cycle is called a “span” in TensorBoard plugin.</p>
<p>During <code class="docutils literal notranslate"><span class="pre">wait</span></code> steps, the profiler is disabled.
During <code class="docutils literal notranslate"><span class="pre">warmup</span></code> steps, the profiler starts tracing but the results are discarded.
This is for reducing the profiling overhead.
The overhead at the beginning of profiling is high and easy to bring skew to the profiling result.
During <code class="docutils literal notranslate"><span class="pre">active</span></code> steps, the profiler works and records events.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">on_trace_ready</span></code> - callable that is called at the end of each cycle;
In this example we use <code class="docutils literal notranslate"><span class="pre">torch.profiler.tensorboard_trace_handler</span></code> to generate result files for TensorBoard.
After profiling, result files will be saved into the <code class="docutils literal notranslate"><span class="pre">./log/resnet18</span></code> directory.
Specify this directory as a <code class="docutils literal notranslate"><span class="pre">logdir</span></code> parameter to analyze profile in TensorBoard.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">record_shapes</span></code> - whether to record shapes of the operator inputs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">profile_memory</span></code> - Track tensor memory allocation/deallocation. Note, for old version of pytorch with version
before 1.10, if you suffer long profiling time, please disable it or upgrade to new version.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">with_stack</span></code> - Record source information (file and line number) for the ops.
If the TensorBoard is launched in VS Code (<a class="reference external" href="https://code.visualstudio.com/docs/datascience/pytorch-support#_tensorboard-integration">reference</a>),
clicking a stack frame will navigate to the specific code line.</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.profile" title="torch.profiler.profile"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span></a><span class="p">(</span>
        <span class="n">schedule</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.schedule" title="torch.profiler.schedule"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">schedule</span></a><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">active</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">on_trace_ready</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.tensorboard_trace_handler" title="torch.profiler.tensorboard_trace_handler"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tensorboard_trace_handler</span></a><span class="p">(</span><span class="s1">'./log/resnet18'</span><span class="p">),</span>
        <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">profile_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Need to call this at each step to notify profiler of steps' boundary.</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">train</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, the following non-context manager start/stop is supported as well.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prof</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.profile" title="torch.profiler.profile"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span></a><span class="p">(</span>
        <span class="n">schedule</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.schedule" title="torch.profiler.schedule"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">schedule</span></a><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">active</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">on_trace_ready</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.tensorboard_trace_handler" title="torch.profiler.tensorboard_trace_handler"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tensorboard_trace_handler</span></a><span class="p">(</span><span class="s1">'./log/resnet18'</span><span class="p">),</span>
        <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">prof</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">train</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="run-the-profiler">
<h3>3. Run the profiler<a class="headerlink" href="#run-the-profiler" title="Link to this heading">#</a></h3>
<p>Run the above code. The profiling result will be saved under <code class="docutils literal notranslate"><span class="pre">./log/resnet18</span></code> directory.</p>
</section>
<section id="use-tensorboard-to-view-results-and-analyze-model-performance">
<h3>4. Use TensorBoard to view results and analyze model performance<a class="headerlink" href="#use-tensorboard-to-view-results-and-analyze-model-performance" title="Link to this heading">#</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TensorBoard Plugin support has been deprecated, so some of these functions may not
work as previously. Please take a look at the replacement, <a class="reference external" href="https://github.com/pytorch/kineto/tree/main#holistic-trace-analysis">HTA</a>.</p>
</div>
<p>Install PyTorch Profiler TensorBoard Plugin.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch_tb_profiler</span>
</pre></div>
</div>
<p>Launch the TensorBoard.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=./</span><span class="n">log</span>
</pre></div>
</div>
<p>Open the TensorBoard profile URL in Google Chrome browser or Microsoft Edge browser (<strong>Safari is not supported</strong>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="mi">6006</span><span class="o">/</span><span class="c1">#pytorch_profiler</span>
</pre></div>
</div>
<p>You could see Profiler plugin page as shown below.</p>
<ul class="simple">
<li><p>Overview</p></li>
</ul>
<a class="reference internal image-reference" href="../_static/img/profiler_overview1.png"><img alt="../_static/img/profiler_overview1.png" src="../_static/img/profiler_overview1.png"/></a>
<p>The overview shows a high-level summary of model performance.</p>
<p>The “GPU Summary” panel shows the GPU configuration, GPU usage and Tensor Cores usage.
In this example, the GPU Utilization is low.
The details of these metrics are <a class="reference external" href="https://github.com/pytorch/kineto/blob/main/tb_plugin/docs/gpu_utilization.md">here</a>.</p>
<p>The “Step Time Breakdown” shows distribution of time spent in each step over different categories of execution.
In this example, you can see the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> overhead is significant.</p>
<p>The bottom “Performance Recommendation” uses the profiling data
to automatically highlight likely bottlenecks,
and gives you actionable optimization suggestions.</p>
<p>You can change the view page in left “Views” dropdown list.</p>
<img alt="" src="../_static/img/profiler_views_list.png"/>
<ul class="simple">
<li><p>Operator view</p></li>
</ul>
<p>The operator view displays the performance of every PyTorch operator
that is executed either on the host or device.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_operator_view.png"><img alt="../_static/img/profiler_operator_view.png" src="../_static/img/profiler_operator_view.png"/></a>
<p>The “Self” duration does not include its child operators’ time.
The “Total” duration includes its child operators’ time.</p>
<ul class="simple">
<li><p>View call stack</p></li>
</ul>
<p>Click the <code class="docutils literal notranslate"><span class="pre">View</span> <span class="pre">Callstack</span></code> of an operator, the operators with same name but different call stacks will be shown.
Then click a <code class="docutils literal notranslate"><span class="pre">View</span> <span class="pre">Callstack</span></code> in this sub-table, the call stack frames will be shown.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_callstack.png"><img alt="../_static/img/profiler_callstack.png" src="../_static/img/profiler_callstack.png"/></a>
<p>If the TensorBoard is launched inside VS Code
(<a class="reference external" href="https://devblogs.microsoft.com/python/python-in-visual-studio-code-february-2021-release/#tensorboard-integration">Launch Guide</a>),
clicking a call stack frame will navigate to the specific code line.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_vscode.png"><img alt="../_static/img/profiler_vscode.png" src="../_static/img/profiler_vscode.png"/></a>
<ul class="simple">
<li><p>Kernel view</p></li>
</ul>
<p>The GPU kernel view shows all kernels’ time spent on GPU.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_kernel_view.png"><img alt="../_static/img/profiler_kernel_view.png" src="../_static/img/profiler_kernel_view.png"/></a>
<p>Tensor Cores Used:
Whether this kernel uses Tensor Cores.</p>
<p>Mean Blocks per SM:
Blocks per SM = Blocks of this kernel / SM number of this GPU.
If this number is less than 1, it indicates the GPU multiprocessors are not fully utilized.
“Mean Blocks per SM” is weighted average of all runs of this kernel name, using each run’s duration as weight.</p>
<p>Mean Est. Achieved Occupancy:
Est. Achieved Occupancy is defined in this column’s tooltip.
For most cases such as memory bandwidth bounded kernels, the higher the better.
“Mean Est. Achieved Occupancy” is weighted average of all runs of this kernel name,
using each run’s duration as weight.</p>
<ul class="simple">
<li><p>Trace view</p></li>
</ul>
<p>The trace view shows timeline of profiled operators and GPU kernels.
You can select it to see details as below.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view1.png"><img alt="../_static/img/profiler_trace_view1.png" src="../_static/img/profiler_trace_view1.png"/></a>
<p>You can move the graph and zoom in/out with the help of right side toolbar.
And keyboard can also be used to zoom and move around inside the timeline.
The ‘w’ and ‘s’ keys zoom in centered around the mouse,
and the ‘a’ and ‘d’ keys move the timeline left and right.
You can hit these keys multiple times until you see a readable representation.</p>
<p>If a backward operator’s “Incoming Flow” field is with value “forward correspond to backward”,
you can click the text to get its launching forward operator.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view_fwd_bwd.png"><img alt="../_static/img/profiler_trace_view_fwd_bwd.png" src="../_static/img/profiler_trace_view_fwd_bwd.png"/></a>
<p>In this example, we can see the event prefixed with <code class="docutils literal notranslate"><span class="pre">enumerate(DataLoader)</span></code> costs a lot of time.
And during most of this period, the GPU is idle.
Because this function is loading data and transforming data on host side,
during which the GPU resource is wasted.</p>
</section>
<section id="improve-performance-with-the-help-of-profiler">
<h3>5. Improve performance with the help of profiler<a class="headerlink" href="#improve-performance-with-the-help-of-profiler" title="Link to this heading">#</a></h3>
<p>At the bottom of “Overview” page, the suggestion in “Performance Recommendation” hints the bottleneck is <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.
The PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> uses single process by default.
User could enable multi-process data loading by setting the parameter <code class="docutils literal notranslate"><span class="pre">num_workers</span></code>.
<a class="reference external" href="https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading">Here</a> is more details.</p>
<p>In this example, we follow the “Performance Recommendation” and set <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> as below,
pass a different name such as <code class="docutils literal notranslate"><span class="pre">./log/resnet18_4workers</span></code> to <code class="docutils literal notranslate"><span class="pre">tensorboard_trace_handler</span></code>, and run it again.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Then let’s choose the recently profiled run in left “Runs” dropdown list.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_overview2.png"><img alt="../_static/img/profiler_overview2.png" src="../_static/img/profiler_overview2.png"/></a>
<p>From the above view, we can find the step time is reduced to about 76ms comparing with previous run’s 132ms,
and the time reduction of <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> mainly contributes.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view2.png"><img alt="../_static/img/profiler_trace_view2.png" src="../_static/img/profiler_trace_view2.png"/></a>
<p>From the above view, we can see that the runtime of <code class="docutils literal notranslate"><span class="pre">enumerate(DataLoader)</span></code> is reduced,
and the GPU utilization is increased.</p>
</section>
<section id="analyze-performance-with-other-advanced-features">
<h3>6. Analyze performance with other advanced features<a class="headerlink" href="#analyze-performance-with-other-advanced-features" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Memory view</p></li>
</ul>
<p>To profile memory, <code class="docutils literal notranslate"><span class="pre">profile_memory</span></code> must be set to <code class="docutils literal notranslate"><span class="pre">True</span></code> in arguments of <code class="docutils literal notranslate"><span class="pre">torch.profiler.profile</span></code>.</p>
<p>You can try it by using existing example on Azure</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">storage</span><span class="o">-</span><span class="n">blob</span>
<span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">torchtbprofiler</span><span class="o">.</span><span class="n">blob</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">net</span><span class="o">/</span><span class="n">torchtbprofiler</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">memory_demo_1_10</span>
</pre></div>
</div>
<p>The profiler records all memory allocation/release events and allocator’s internal state during profiling.
The memory view consists of three components as shown in the following.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_view.png"><img alt="../_static/img/profiler_memory_view.png" src="../_static/img/profiler_memory_view.png"/></a>
<p>The components are memory curve graph, memory events table and memory statistics table, from top to bottom, respectively.</p>
<p>The memory type could be selected in “Device” selection box.
For example, “GPU0” means the following table only shows each operator’s memory usage on GPU 0, not including CPU or other GPUs.</p>
<p>The memory curve shows the trends of memory consumption. The “Allocated” curve shows the total memory that is actually
in use, e.g., tensors. In PyTorch, caching mechanism is employed in CUDA allocator and some other allocators. The
“Reserved” curve shows the total memory that is reserved by the allocator. You can left click and drag on the graph
to select events in the desired range:</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_curve_selecting.png"><img alt="../_static/img/profiler_memory_curve_selecting.png" src="../_static/img/profiler_memory_curve_selecting.png"/></a>
<p>After selection, the three components will be updated for the restricted time range, so that you can gain more
information about it. By repeating this process, you can zoom into a very fine-grained detail. Right click on the graph
will reset the graph to the initial state.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_curve_single.png"><img alt="../_static/img/profiler_memory_curve_single.png" src="../_static/img/profiler_memory_curve_single.png"/></a>
<p>In the memory events table, the allocation and release events are paired into one entry. The “operator” column shows
the immediate ATen operator that is causing the allocation. Notice that in PyTorch, ATen operators commonly use
<code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> to allocate memory. For example, <code class="docutils literal notranslate"><span class="pre">aten::ones</span></code> is implemented as <code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> followed by an
<code class="docutils literal notranslate"><span class="pre">aten::fill_</span></code>. Solely display the operator name as <code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> is of little help. It will be shown as
<code class="docutils literal notranslate"><span class="pre">aten::ones</span> <span class="pre">(aten::empty)</span></code> in this special case. The “Allocation Time”, “Release Time” and “Duration”
columns’ data might be missing if the event occurs outside of the time range.</p>
<p>In the memory statistics table, the “Size Increase” column sums up all allocation size and minus all the memory
release size, that is, the net increase of memory usage after this operator. The “Self Size Increase” column is
similar to “Size Increase”, but it does not count children operators’ allocation. With regards to ATen operators’
implementation detail, some operators might call other operators, so memory allocations can happen at any level of the
call stack. That says, “Self Size Increase” only count the memory usage increase at current level of call stack.
Finally, the “Allocation Size” column sums up all allocation without considering the memory release.</p>
<ul class="simple">
<li><p>Distributed view</p></li>
</ul>
<p>The plugin now supports distributed view on profiling DDP with NCCL/GLOO as backend.</p>
<p>You can try it by using existing example on Azure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">storage</span><span class="o">-</span><span class="n">blob</span>
<span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">torchtbprofiler</span><span class="o">.</span><span class="n">blob</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">net</span><span class="o">/</span><span class="n">torchtbprofiler</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">distributed_bert</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_static/img/profiler_distributed_view.png"><img alt="../_static/img/profiler_distributed_view.png" src="../_static/img/profiler_distributed_view.png"/></a>
<p>The “Computation/Communication Overview” shows computation/communication ratio and their overlapping degree.
From this view, User can figure out load balance issue among workers.
For example, if the computation + overlapping time of one worker is much larger than others,
there may be a problem of load balance or this worker may be a straggler.</p>
<p>The “Synchronizing/Communication Overview” shows the efficiency of communication.
“Data Transfer Time” is the time for actual data exchanging.
“Synchronizing Time” is the time for waiting and synchronizing with other workers.</p>
<p>If one worker’s “Synchronizing Time” is much shorter than that of other workers’,
this worker may be a straggler which may have more computation workload than other workers’.</p>
<p>The “Communication Operations Stats” summarizes the detailed statistics of all communication ops in each worker.</p>
</section>
<section id="additional-practices-profiling-pytorch-on-amd-gpus">
<h3>7. Additional Practices: Profiling PyTorch on AMD GPUs<a class="headerlink" href="#additional-practices-profiling-pytorch-on-amd-gpus" title="Link to this heading">#</a></h3>
<p>The AMD ROCm Platform is an open-source software stack designed for GPU computation, consisting of drivers, development tools, and APIs.
We can run the above mentioned steps on AMD GPUs. In this section, we will use Docker to install the ROCm base development image
before installing PyTorch.</p>
<p>For the purpose of example, let’s create a directory called <code class="docutils literal notranslate"><span class="pre">profiler_tutorial</span></code>, and save the code in <strong>Step 1</strong> as <code class="docutils literal notranslate"><span class="pre">test_cifar10.py</span></code> in this directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="o">~/</span><span class="n">profiler_tutorial</span>
<span class="n">cd</span> <span class="n">profiler_tutorial</span>
<span class="n">vi</span> <span class="n">test_cifar10</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>At the time of this writing, the Stable(<code class="docutils literal notranslate"><span class="pre">2.1.1</span></code>) Linux version of PyTorch on ROCm Platform is <a class="reference external" href="https://pytorch.org/get-started/locally/">ROCm 5.6</a>.</p>
<ul class="simple">
<li><p>Obtain a base Docker image with the correct user-space ROCm version installed from <a class="reference external" href="https://hub.docker.com/repository/docker/rocm/dev-ubuntu-20.04">Docker Hub</a>.</p></li>
</ul>
<p>It is <code class="docutils literal notranslate"><span class="pre">rocm/dev-ubuntu-20.04:5.6</span></code>.</p>
<ul class="simple">
<li><p>Start the ROCm base Docker container:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">-</span><span class="n">it</span> <span class="o">--</span><span class="n">network</span><span class="o">=</span><span class="n">host</span> <span class="o">--</span><span class="n">device</span><span class="o">=/</span><span class="n">dev</span><span class="o">/</span><span class="n">kfd</span> <span class="o">--</span><span class="n">device</span><span class="o">=/</span><span class="n">dev</span><span class="o">/</span><span class="n">dri</span> <span class="o">--</span><span class="n">group</span><span class="o">-</span><span class="n">add</span><span class="o">=</span><span class="n">video</span> <span class="o">--</span><span class="n">ipc</span><span class="o">=</span><span class="n">host</span> <span class="o">--</span><span class="n">cap</span><span class="o">-</span><span class="n">add</span><span class="o">=</span><span class="n">SYS_PTRACE</span> <span class="o">--</span><span class="n">security</span><span class="o">-</span><span class="n">opt</span> <span class="n">seccomp</span><span class="o">=</span><span class="n">unconfined</span> <span class="o">--</span><span class="n">shm</span><span class="o">-</span><span class="n">size</span> <span class="mi">8</span><span class="n">G</span> <span class="o">-</span><span class="n">v</span> <span class="o">~/</span><span class="n">profiler_tutorial</span><span class="p">:</span><span class="o">/</span><span class="n">profiler_tutorial</span> <span class="n">rocm</span><span class="o">/</span><span class="n">dev</span><span class="o">-</span><span class="n">ubuntu</span><span class="o">-</span><span class="mf">20.04</span><span class="p">:</span><span class="mf">5.6</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Inside the container, install any dependencies needed for installing the wheels package.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">libjpeg</span><span class="o">-</span><span class="n">dev</span> <span class="n">python3</span><span class="o">-</span><span class="n">dev</span> <span class="o">-</span><span class="n">y</span>
<span class="n">pip3</span> <span class="n">install</span> <span class="n">wheel</span> <span class="n">setuptools</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="ow">is</span><span class="o">-</span><span class="n">python3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Install the wheels:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip3</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">rocm5</span><span class="mf">.6</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Install the <code class="docutils literal notranslate"><span class="pre">torch_tb_profiler</span></code>, and then, run the Python file <code class="docutils literal notranslate"><span class="pre">test_cifar10.py</span></code>:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch_tb_profiler</span>
<span class="n">cd</span> <span class="o">/</span><span class="n">profiler_tutorial</span>
<span class="n">python</span> <span class="n">test_cifar10</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Now, we have all the data needed to view in TensorBoard:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=./</span><span class="n">log</span>
</pre></div>
</div>
<p>Choose different views as described in <strong>Step 4</strong>. For example, below is the <strong>Operator</strong> View:</p>
<a class="reference internal image-reference" href="../_static/img/profiler_rocm_tensorboard_operartor_view.png"><img alt="../_static/img/profiler_rocm_tensorboard_operartor_view.png" src="../_static/img/profiler_rocm_tensorboard_operartor_view.png"/></a>
<p>At the time this section is written, <strong>Trace</strong> view does not work and it displays nothing. You can work around by typing <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> in your Chrome Browser.</p>
<ul class="simple">
<li><p>Copy the <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> file under <code class="docutils literal notranslate"><span class="pre">~/profiler_tutorial/log/resnet18</span></code> directory to the Windows.</p></li>
</ul>
<p>You may need to copy the file by using <code class="docutils literal notranslate"><span class="pre">scp</span></code> if the file is located in a remote location.</p>
<ul class="simple">
<li><p>Click <strong>Load</strong> button to load the trace JSON file from the <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> page in the browser.</p></li>
</ul>
<a class="reference internal image-reference" href="../_static/img/profiler_rocm_chrome_trace_view.png"><img alt="../_static/img/profiler_rocm_chrome_trace_view.png" src="../_static/img/profiler_rocm_chrome_trace_view.png"/></a>
<p>As mentioned previously, you can move the graph and zoom in and out.
You can also use keyboard to zoom and move around inside the timeline.
The <code class="docutils literal notranslate"><span class="pre">w</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code> keys zoom in centered around the mouse,
and the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> keys move the timeline left and right.
You can hit these keys multiple times until you see a readable representation.</p>
</section>
</section>
<section id="learn-more">
<h2>Learn More<a class="headerlink" href="#learn-more" title="Link to this heading">#</a></h2>
<p>Take a look at the following documents to continue your learning,
and feel free to open an issue <a class="reference external" href="https://github.com/pytorch/kineto/issues">here</a>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/kineto/tree/master/tb_plugin">PyTorch TensorBoard Profiler Github</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/master/profiler.html">torch.profiler API</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/kineto/tree/main#holistic-trace-analysis">HTA</a></p></li>
</ul>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-tensorboard-profiler-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0aec568a42e89122e5ca293c86289287/tensorboard_profiler_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tensorboard_profiler_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/67e47b6d6793c700666471b688068f72/tensorboard_profiler_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tensorboard_profiler_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/180ec9b33649e3199154d56f44f40877/tensorboard_profiler_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">tensorboard_profiler_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="ax_multiobjective_nas_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Multi-Objective NAS with Ax</p>
</div>
</a>
<a class="right-next" href="realtime_rpi.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="ax_multiobjective_nas_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Multi-Objective NAS with Ax</p>
</div>
</a>
<a class="right-next" href="realtime_rpi.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps">Steps</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-data-and-model">1. Prepare the data and model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-profiler-to-record-execution-events">2. Use profiler to record execution events</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-profiler">3. Run the profiler</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-tensorboard-to-view-results-and-analyze-model-performance">4. Use TensorBoard to view results and analyze model performance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improve-performance-with-the-help-of-profiler">5. Improve performance with the help of profiler</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-performance-with-other-advanced-features">6. Analyze performance with other advanced features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-practices-profiling-pytorch-on-amd-gpus">7. Additional Practices: Profiling PyTorch on AMD GPUs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more">Learn More</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "PyTorch Profiler With TensorBoard",
       "headline": "PyTorch Profiler With TensorBoard",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/tensorboard_profiler_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. PyTorch Profiler With TensorBoard# This tutorial demonstrates how to use TensorBoard plugin with PyTorch Profiler to detect performance bottlenecks of the model. Warning The TensorBoard integration with the PyTorch profiler is now deprecated. Instead, use Perfetto or the Chrome trace to view trace.json files. After generating a trace, simply drag the trace.json into Perfetto UI or chrome://tracing to visualize your profile. Introduction# PyTorch 1.8 includes an updated profiler API capable of recording the CPU side operations as well as the CUDA kernel launches on the GPU side. The profiler can visualize this information in TensorBoard Plugin and provide analysis of the performance bottlenecks. In this tutorial, we will use a simple Resnet model to demonstrate how to use TensorBoard plugin to analyze model performance. Setup# To install torch and torchvision use the following command: pip install torch torchvision Steps# Prepare the data and model Use profiler to record execution events Run the profiler Use TensorBoard to view results and analyze model performance Improve performance with the help of profiler Analyze performance with other advanced features Additional Practices: Profiling PyTorch on AMD GPUs 1. Prepare the data and model# First, import all necessary libraries: import torch import torch.nn import torch.optim import torch.profiler import torch.utils.data import torchvision.datasets import torchvision.models import torchvision.transforms as T Then prepare the input data. For this tutorial, we use the CIFAR10 dataset. Transform it to the desired format and use DataLoader to load each batch. transform = T.Compose( [T.Resize(224), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) train_set = torchvision.datasets.CIFAR10(root=\u0027./data\u0027, train=True, download=True, transform=transform) train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True) Next, create Resnet model, loss function, and optimizer objects. To run on GPU, move model and loss to GPU device. device = torch.device(\"cuda:0\") model = torchvision.models.resnet18(weights=\u0027IMAGENET1K_V1\u0027).cuda(device) criterion = torch.nn.CrossEntropyLoss().cuda(device) optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) model.train() Define the training step for each batch of input data. def train(data): inputs, labels = data[0].to(device=device), data[1].to(device=device) outputs = model(inputs) loss = criterion(outputs, labels) optimizer.zero_grad() loss.backward() optimizer.step() 2. Use profiler to record execution events# The profiler is enabled through the context manager and accepts several parameters, some of the most useful are: schedule - callable that takes step (int) as a single parameter and returns the profiler action to perform at each step. In this example with wait=1, warmup=1, active=3, repeat=1, profiler will skip the first step/iteration, start warming up on the second, record the following three iterations, after which the trace will become available and on_trace_ready (when set) is called. In total, the cycle repeats once. Each cycle is called a \u201cspan\u201d in TensorBoard plugin. During wait steps, the profiler is disabled. During warmup steps, the profiler starts tracing but the results are discarded. This is for reducing the profiling overhead. The overhead at the beginning of profiling is high and easy to bring skew to the profiling result. During active steps, the profiler works and records events. on_trace_ready - callable that is called at the end of each cycle; In this example we use torch.profiler.tensorboard_trace_handler to generate result files for TensorBoard. After profiling, result files will be saved into the ./log/resnet18 directory. Specify this directory as a logdir parameter to analyze profile in TensorBoard. record_shapes - whether to record shapes of the operator inputs. profile_memory - Track tensor memory allocation/deallocation. Note, for old version of pytorch with version before 1.10, if you suffer long profiling time, please disable it or upgrade to new version. with_stack - Record source information (file and line number) for the ops. If the TensorBoard is launched in VS Code (reference), clicking a stack frame will navigate to the specific code line. with torch.profiler.profile( schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1), on_trace_ready=torch.profiler.tensorboard_trace_handler(\u0027./log/resnet18\u0027), record_shapes=True, profile_memory=True, with_stack=True ) as prof: for step, batch_data in enumerate(train_loader): prof.step() # Need to call this at each step to notify profiler of steps\u0027 boundary. if step \u003e= 1 + 1 + 3: break train(batch_data) Alternatively, the following non-context manager start/stop is supported as well. prof = torch.profiler.profile( schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1), on_trace_ready=torch.profiler.tensorboard_trace_handler(\u0027./log/resnet18\u0027), record_shapes=True, with_stack=True) prof.start() for step, batch_data in enumerate(train_loader): prof.step() if step \u003e= 1 + 1 + 3: break train(batch_data) prof.stop() 3. Run the profiler# Run the above code. The profiling result will be saved under ./log/resnet18 directory. 4. Use TensorBoard to view results and analyze model performance# Note TensorBoard Plugin support has been deprecated, so some of these functions may not work as previously. Please take a look at the replacement, HTA. Install PyTorch Profiler TensorBoard Plugin. pip install torch_tb_profiler Launch the TensorBoard. tensorboard --logdir=./log Open the TensorBoard profile URL in Google Chrome browser or Microsoft Edge browser (Safari is not supported). http://localhost:6006/#pytorch_profiler You could see Profiler plugin page as shown below. Overview The overview shows a high-level summary of model performance. The \u201cGPU Summary\u201d panel shows the GPU configuration, GPU usage and Tensor Cores usage. In this example, the GPU Utilization is low. The details of these metrics are here. The \u201cStep Time Breakdown\u201d shows distribution of time spent in each step over different categories of execution. In this example, you can see the DataLoader overhead is significant. The bottom \u201cPerformance Recommendation\u201d uses the profiling data to automatically highlight likely bottlenecks, and gives you actionable optimization suggestions. You can change the view page in left \u201cViews\u201d dropdown list. Operator view The operator view displays the performance of every PyTorch operator that is executed either on the host or device. The \u201cSelf\u201d duration does not include its child operators\u2019 time. The \u201cTotal\u201d duration includes its child operators\u2019 time. View call stack Click the View Callstack of an operator, the operators with same name but different call stacks will be shown. Then click a View Callstack in this sub-table, the call stack frames will be shown. If the TensorBoard is launched inside VS Code (Launch Guide), clicking a call stack frame will navigate to the specific code line. Kernel view The GPU kernel view shows all kernels\u2019 time spent on GPU. Tensor Cores Used: Whether this kernel uses Tensor Cores. Mean Blocks per SM: Blocks per SM = Blocks of this kernel / SM number of this GPU. If this number is less than 1, it indicates the GPU multiprocessors are not fully utilized. \u201cMean Blocks per SM\u201d is weighted average of all runs of this kernel name, using each run\u2019s duration as weight. Mean Est. Achieved Occupancy: Est. Achieved Occupancy is defined in this column\u2019s tooltip. For most cases such as memory bandwidth bounded kernels, the higher the better. \u201cMean Est. Achieved Occupancy\u201d is weighted average of all runs of this kernel name, using each run\u2019s duration as weight. Trace view The trace view shows timeline of profiled operators and GPU kernels. You can select it to see details as below. You can move the graph and zoom in/out with the help of right side toolbar. And keyboard can also be used to zoom and move around inside the timeline. The \u2018w\u2019 and \u2018s\u2019 keys zoom in centered around the mouse, and the \u2018a\u2019 and \u2018d\u2019 keys move the timeline left and right. You can hit these keys multiple times until you see a readable representation. If a backward operator\u2019s \u201cIncoming Flow\u201d field is with value \u201cforward correspond to backward\u201d, you can click the text to get its launching forward operator. In this example, we can see the event prefixed with enumerate(DataLoader) costs a lot of time. And during most of this period, the GPU is idle. Because this function is loading data and transforming data on host side, during which the GPU resource is wasted. 5. Improve performance with the help of profiler# At the bottom of \u201cOverview\u201d page, the suggestion in \u201cPerformance Recommendation\u201d hints the bottleneck is DataLoader. The PyTorch DataLoader uses single process by default. User could enable multi-process data loading by setting the parameter num_workers. Here is more details. In this example, we follow the \u201cPerformance Recommendation\u201d and set num_workers as below, pass a different name such as ./log/resnet18_4workers to tensorboard_trace_handler, and run it again. train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4) Then let\u2019s choose the recently profiled run in left \u201cRuns\u201d dropdown list. From the above view, we can find the step time is reduced to about 76ms comparing with previous run\u2019s 132ms, and the time reduction of DataLoader mainly contributes. From the above view, we can see that the runtime of enumerate(DataLoader) is reduced, and the GPU utilization is increased. 6. Analyze performance with other advanced features# Memory view To profile memory, profile_memory must be set to True in arguments of torch.profiler.profile. You can try it by using existing example on Azure pip install azure-storage-blob tensorboard --logdir=https://torchtbprofiler.blob.core.windows.net/torchtbprofiler/demo/memory_demo_1_10 The profiler records all memory allocation/release events and allocator\u2019s internal state during profiling. The memory view consists of three components as shown in the following. The components are memory curve graph, memory events table and memory statistics table, from top to bottom, respectively. The memory type could be selected in \u201cDevice\u201d selection box. For example, \u201cGPU0\u201d means the following table only shows each operator\u2019s memory usage on GPU 0, not including CPU or other GPUs. The memory curve shows the trends of memory consumption. The \u201cAllocated\u201d curve shows the total memory that is actually in use, e.g., tensors. In PyTorch, caching mechanism is employed in CUDA allocator and some other allocators. The \u201cReserved\u201d curve shows the total memory that is reserved by the allocator. You can left click and drag on the graph to select events in the desired range: After selection, the three components will be updated for the restricted time range, so that you can gain more information about it. By repeating this process, you can zoom into a very fine-grained detail. Right click on the graph will reset the graph to the initial state. In the memory events table, the allocation and release events are paired into one entry. The \u201coperator\u201d column shows the immediate ATen operator that is causing the allocation. Notice that in PyTorch, ATen operators commonly use aten::empty to allocate memory. For example, aten::ones is implemented as aten::empty followed by an aten::fill_. Solely display the operator name as aten::empty is of little help. It will be shown as aten::ones (aten::empty) in this special case. The \u201cAllocation Time\u201d, \u201cRelease Time\u201d and \u201cDuration\u201d columns\u2019 data might be missing if the event occurs outside of the time range. In the memory statistics table, the \u201cSize Increase\u201d column sums up all allocation size and minus all the memory release size, that is, the net increase of memory usage after this operator. The \u201cSelf Size Increase\u201d column is similar to \u201cSize Increase\u201d, but it does not count children operators\u2019 allocation. With regards to ATen operators\u2019 implementation detail, some operators might call other operators, so memory allocations can happen at any level of the call stack. That says, \u201cSelf Size Increase\u201d only count the memory usage increase at current level of call stack. Finally, the \u201cAllocation Size\u201d column sums up all allocation without considering the memory release. Distributed view The plugin now supports distributed view on profiling DDP with NCCL/GLOO as backend. You can try it by using existing example on Azure: pip install azure-storage-blob tensorboard --logdir=https://torchtbprofiler.blob.core.windows.net/torchtbprofiler/demo/distributed_bert The \u201cComputation/Communication Overview\u201d shows computation/communication ratio and their overlapping degree. From this view, User can figure out load balance issue among workers. For example, if the computation + overlapping time of one worker is much larger than others, there may be a problem of load balance or this worker may be a straggler. The \u201cSynchronizing/Communication Overview\u201d shows the efficiency of communication. \u201cData Transfer Time\u201d is the time for actual data exchanging. \u201cSynchronizing Time\u201d is the time for waiting and synchronizing with other workers. If one worker\u2019s \u201cSynchronizing Time\u201d is much shorter than that of other workers\u2019, this worker may be a straggler which may have more computation workload than other workers\u2019. The \u201cCommunication Operations Stats\u201d summarizes the detailed statistics of all communication ops in each worker. 7. Additional Practices: Profiling PyTorch on AMD GPUs# The AMD ROCm Platform is an open-source software stack designed for GPU computation, consisting of drivers, development tools, and APIs. We can run the above mentioned steps on AMD GPUs. In this section, we will use Docker to install the ROCm base development image before installing PyTorch. For the purpose of example, let\u2019s create a directory called profiler_tutorial, and save the code in Step 1 as test_cifar10.py in this directory. mkdir ~/profiler_tutorial cd profiler_tutorial vi test_cifar10.py At the time of this writing, the Stable(2.1.1) Linux version of PyTorch on ROCm Platform is ROCm 5.6. Obtain a base Docker image with the correct user-space ROCm version installed from Docker Hub. It is rocm/dev-ubuntu-20.04:5.6. Start the ROCm base Docker container: docker run -it --network=host --device=/dev/kfd --device=/dev/dri --group-add=video --ipc=host --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --shm-size 8G -v ~/profiler_tutorial:/profiler_tutorial rocm/dev-ubuntu-20.04:5.6 Inside the container, install any dependencies needed for installing the wheels package. sudo apt update sudo apt install libjpeg-dev python3-dev -y pip3 install wheel setuptools sudo apt install python-is-python3 Install the wheels: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6 Install the torch_tb_profiler, and then, run the Python file test_cifar10.py: pip install torch_tb_profiler cd /profiler_tutorial python test_cifar10.py Now, we have all the data needed to view in TensorBoard: tensorboard --logdir=./log Choose different views as described in Step 4. For example, below is the Operator View: At the time this section is written, Trace view does not work and it displays nothing. You can work around by typing chrome://tracing in your Chrome Browser. Copy the trace.json file under ~/profiler_tutorial/log/resnet18 directory to the Windows. You may need to copy the file by using scp if the file is located in a remote location. Click Load button to load the trace JSON file from the chrome://tracing page in the browser. As mentioned previously, you can move the graph and zoom in and out. You can also use keyboard to zoom and move around inside the timeline. The w and s keys zoom in centered around the mouse, and the a and d keys move the timeline left and right. You can hit these keys multiple times until you see a readable representation. Learn More# Take a look at the following documents to continue your learning, and feel free to open an issue here. PyTorch TensorBoard Profiler Github torch.profiler API HTA Download Jupyter notebook: tensorboard_profiler_tutorial.ipynb Download Python source code: tensorboard_profiler_tutorial.py Download zipped: tensorboard_profiler_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/tensorboard_profiler_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>