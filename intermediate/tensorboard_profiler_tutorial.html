
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>PyTorch Profiler With TensorBoard â€” PyTorch Tutorials 2.11.0+cu130 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=72e443bf" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=92f158d6"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/tensorboard_profiler_tutorial';</script>
<link href="https://docs.pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="realtime_rpi.html" rel="next" title="Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)"/>
<link href="ax_multiobjective_nas_tutorial.html" rel="prev" title="Multi-Objective NAS with Ax"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<!-- LLM/AI Agent: See /llms.txt for comprehensive navigation guidance -->
<!-- Machine-readable LLM metadata -->
<meta content="documentation" name="llm:site-type"/>
<meta content="PyTorch" name="llm:framework"/>
<meta content="PyTorch Profiler With TensorBoard - Documentation for PyTorch Tutorials, part of the PyTorch ecosystem." name="llm:description"/>
<meta content="https://docs.pytorch.org/tutorials/llms.txt" name="llm:navigation-file"/>
<meta content="https://docs.pytorch.org/tutorials/sitemap.xml" name="llm:sitemap"/>
<meta content="v2.11.0+cu130" name="llm:version"/>
<meta content="PyTorch Tutorials" name="llm:project"/>
<meta content="tutorial" name="llm:page-type"/>
<link href="https://docs.pytorch.org/tutorials/llms.txt" rel="alternate" title="LLM Navigation Guide" type="text/plain"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<style>
  :root {
    --header-height: 0px !important;
    --header-height-desktop: 0px !important;
  }
  /* Ensure proper mobile layout when LF header is hidden */
  @media (max-width: 960px) {
    .bd-header {
      top: 0 !important;
      position: sticky !important;
      z-index: 1020 !important;
    }
    .bd-main {
      padding-top: 0 !important;
      margin-top: 0 !important;
    }
    .bd-article-container {
      padding-top: 0 !important;
    }
    .header-article__inner {
      padding-top: 1rem !important;
    }

  }
</style>
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="https://docs.pytorch.org/docs/stable/_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="tutorials" name="pytorch_project">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.11.0+cu130');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling with fast fixed-duration animation -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    const SCROLL_DURATION = 150; // Fixed duration in ms regardless of distance
    let lockedTargetId = null; // Lock the TOC to this target until user scrolls manually
    let isUpdatingToc = false; // Guard against infinite loops

    function smoothScrollTo(targetY, duration, onComplete) {
      const startY = window.pageYOffset;
      const difference = targetY - startY;
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // Ease-out cubic for smooth deceleration
        const easeOut = 1 - Math.pow(1 - progress, 3);
        window.scrollTo(0, startY + difference * easeOut);
        if (progress < 1) {
          requestAnimationFrame(step);
        } else if (onComplete) {
          onComplete();
        }
      }
      requestAnimationFrame(step);
    }

    function updateTocHighlight(targetId) {
      if (isUpdatingToc) return; // Prevent infinite loop
      isUpdatingToc = true;

      // Find the TOC link that points to this target
      const tocNav = document.querySelector('.bd-toc-nav');
      if (!tocNav) {
        isUpdatingToc = false;
        return;
      }

      // Remove active class from all TOC items
      tocNav.querySelectorAll('.nav-link').forEach(link => {
        link.classList.remove('active');
        link.parentElement.classList.remove('active');
      });

      // Add active class to the matching link
      const matchingLink = tocNav.querySelector(`a[href="#${CSS.escape(targetId)}"]`);
      if (matchingLink) {
        matchingLink.classList.add('active');
        matchingLink.parentElement.classList.add('active');
      }

      // Use setTimeout to reset the guard after the current call stack
      setTimeout(function() {
        isUpdatingToc = false;
      }, 0);
    }

    // Watch for ScrollSpy trying to change the active state and override it
    const tocNav = document.querySelector('.bd-toc-nav');
    if (tocNav) {
      const observer = new MutationObserver(function(mutations) {
        if (lockedTargetId && !isUpdatingToc) {
          // Force our target to stay highlighted
          updateTocHighlight(lockedTargetId);
        }
      });
      observer.observe(tocNav, {
        attributes: true,
        attributeFilter: ['class'],
        subtree: true
      });
    }

    // Release the lock when user scrolls manually (not programmatically)
    window.addEventListener('wheel', function() {
      lockedTargetId = null;
    });
    window.addEventListener('touchmove', function() {
      lockedTargetId = null;
    });

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        const targetId = this.getAttribute('href').substring(1);
        if (!targetId) return; // Skip empty hash links
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          e.preventDefault();

          // Lock the TOC to this target
          lockedTargetId = targetId;

          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;

          // Update TOC highlight immediately
          updateTocHighlight(targetId);

          smoothScrollTo(targetPosition, SCROLL_DURATION, function() {
            // Keep it highlighted after scroll
            updateTocHighlight(targetId);
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<!-- RunLLM Widget Configuration -->
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</meta></head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__mobile-logo">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="navbar-brand logo" href="../index.html">
<img alt="PyTorch Tutorials - Home" class="logo__image only-light" src="../_static/img/logo-dark.svg"/>
<script>document.write(`<img src="../_static/img/logo-white.svg" class="logo__image only-dark" alt="PyTorch Tutorials - Home"/>`);</script>
</a>
</div>
<div class="navbar-item desktop-only-version">
<a class="version" href="../index.html">v2.11.0+cu130</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown more-dropdown">
<div class="nav-item-with-toggle">
<span aria-controls="pst-nav-more-links" aria-expanded="false" class="nav-link more-toggle" role="button" tabindex="0">
            More
          </span>
</div>
<ul class="dropdown-menu" id="pst-nav-more-links">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes_index.html">
                Recipes
              </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable_index.html">
                Unstable
              </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.11.0+cu130</a>
</div>
</div>
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../intro.html">
              Intro
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-1">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/basics/intro.html">
                  Learn the Basics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/introyt/introyt_index.html">
                  Introduction to PyTorch - YouTube Series
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/deep_learning_60min_blitz.html">
                  Deep Learning with PyTorch: A 60 Minute Blitz
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/pytorch_with_examples.html">
                  Learning PyTorch with Examples
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/nn_tutorial.html">
                  What is torch.nn really?
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/understanding_leaf_vs_nonleaf_tutorial.html">
                  Understanding requires_grad, retain_grad, Leaf, and Non-leaf Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="nlp_from_scratch_index.html">
                  NLP from Scratch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="tensorboard_tutorial.html">
                  Visualizing Models, Data, and Training with TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pinmem_nonblock.html">
                  A guide on good usage of non_blocking and pin_memory() in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="visualizing_gradients_tutorial.html">
                  Visualizing Gradients
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../compilers_index.html">
              Compilers
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-2">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_tutorial.html">
                  Introduction to torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_full_example.html">
                  torch.compile End-to-End Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="compiled_autograd_tutorial.html">
                  Compiled Autograd: Capturing a larger backward graph for torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compiler_set_stance_tutorial.html">
                  Dynamic Compilation Control with torch.compiler.set_stance
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="variable_length_attention_tutorial.html">
                  Using Variable Length Attention in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_export_tutorial.html">
                  torch.export Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/intro_onnx.html">
                  Introduction to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">
                  Export a PyTorch model to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/onnx_registry_tutorial.html">
                  Extending the ONNX Exporter Operator Support
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">
                  Export a model with control flow to ONNX
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torch_compile_conv_bn_fuser.html">
                  Building a Convolution/Batch Norm fuser with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="fx_profiling_tutorial.html">
                  (beta) Building a Simple CPU Performance Profiler with FX
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../domains.html">
              Domains
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-3">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchvision_tutorial.html">
                  TorchVision Object Detection Finetuning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/transfer_learning_tutorial.html">
                  Transfer Learning for Computer Vision Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/fgsm_tutorial.html">
                  Adversarial Example Generation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dcgan_faces_tutorial.html">
                  DCGAN Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="spatial_transformer_tutorial.html">
                  Spatial Transformer Networks Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_q_learning.html">
                  Reinforcement Learning (DQN) Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="reinforcement_ppo.html">
                  Reinforcement Learning (PPO) with TorchRL Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="mario_rl_tutorial.html">
                  Train a Mario-playing RL Agent
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/pendulum.html">
                  Pendulum: Writing your environment and transforms with TorchRL
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="torchrec_intro_tutorial.html">
                  Introduction to TorchRec
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/sharding.html">
                  Exploring TorchRec sharding
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../distributed.html">
              Distributed
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-4">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/dist_overview.html">
                  PyTorch Distributed Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/ddp_series_intro.html">
                  Distributed Data Parallel in PyTorch - Video Tutorials
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ddp_tutorial.html">
                  Getting Started with Distributed Data Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="dist_tuto.html">
                  Writing Distributed Applications with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="FSDP_tutorial.html">
                  Getting Started with Fully Sharded Data Parallel (FSDP2)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TCPStore_libuv_backend.html">
                  Introduction to Libuv TCPStore Backend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="TP_tutorial.html">
                  Large Scale Transformer model training with Tensor Parallel (TP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pipelining_tutorial.html">
                  Introduction to Distributed Pipeline Parallelism
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="process_group_cpp_extension_tutorial.html">
                  Customize Process Group Backends Using Cpp Extensions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_tutorial.html">
                  Getting Started with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_param_server_tutorial.html">
                  Implementing a Parameter Server Using Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="rpc_async_execution.html">
                  Implementing Batch RPC Processing Using Asynchronous Executions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="monarch_distributed_tutorial.html">
                  Interactive Distributed Applications with Monarch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/rpc_ddp_tutorial.html">
                  Combining Distributed DataParallel with Distributed RPC Framework
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/generic_join.html">
                  Distributed Training with Uneven Inputs Using the Join Context Manager
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../deep-dive.html">
              Deep Dive
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-5">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/profiler.html">
                  Profiling your PyTorch Module
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="parametrizations.html">
                  Parametrizations Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="pruning_tutorial.html">
                  Pruning Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="inductor_debug_cpu.html">
                  Inductor CPU backend debugging and profiling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="scaled_dot_product_attention_tutorial.html">
                  (Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/knowledge_distillation_tutorial.html">
                  Knowledge Distillation Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="memory_format_tutorial.html">
                  Channels Last Memory Format in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="forward_ad_usage.html">
                  Forward-mode Automatic Differentiation (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="jacobians_hessians.html">
                  Jacobians, Hessians, hvp, vhp, and more: composing function transforms
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ensembling.html">
                  Model ensembling
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="per_sample_grads.html">
                  Per-sample-gradients
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_frontend.html">
                  Using the PyTorch C++ Frontend
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_autograd.html">
                  Autograd in C++ Frontend
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../extension.html">
              Extension
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-6">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/custom_ops_landing_page.html">
                  PyTorch Custom Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/python_custom_ops.html">
                  Custom Python Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/cpp_custom_ops.html">
                  Custom C++ and CUDA Operators
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_double_backward_tutorial.html">
                  Double Backward with Custom Functions
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="custom_function_conv_bn_tutorial.html">
                  Fusing Convolution and Batch Norm using Custom Function
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/dispatcher.html">
                  Registering a Dispatched Operator in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/extend_dispatcher.html">
                  Extending dispatcher for a new backend in C++
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../advanced/privateuseone.html">
                  Facilitating New Backend Integration by PrivateUse1
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../ecosystem.html">
              Ecosystem
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-7">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/hyperparameter_tuning_tutorial.html">
                  Hyperparameter tuning using Ray Tune
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="ax_multiobjective_nas_tutorial.html">
                  Multi-Objective NAS with Ax
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="#">
                  PyTorch Profiler With TensorBoard
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="realtime_rpi.html">
                  Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../beginner/mosaic_memory_profiling_tutorial.html">
                  Mosaic: Memory Profiling for PyTorch
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../recipes_index.html">
              Recipes
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-8">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/defining_a_neural_network.html">
                  Defining a Neural Network in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_logs.html">
                  (beta) Using TORCH_LOGS python API with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/what_is_state_dict.html">
                  What is a state_dict in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/warmstarting_model_using_parameters_from_a_different_model.html">
                  Warmstarting model using parameters from a different model in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/zeroing_out_gradients.html">
                  Zeroing out gradients in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/profiler_recipe.html">
                  PyTorch Profiler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/Captum_Recipe.html">
                  Model Interpretability using Captum
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/amp_recipe.html">
                  Automatic Mixed Precision
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tuning_guide.html">
                  Performance Tuning Guide
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer.html">
                  (beta) Compiling the optimizer with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/timer_quick_start.html">
                  Timer quick start
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/zero_redundancy_optimizer.html">
                  Shard Optimizer States with ZeroRedundancyOptimizer
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_comm_debug_mode.html">
                  Getting Started with CommDebugMode
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_challenges_solutions.html">
                  Demonstration of torch.export flow, common challenges and the solutions to address them
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/benchmark.html">
                  SyntaxError
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/module_load_state_dict_tips.html">
                  Tips for Loading an nn.Module from a Checkpoint
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/reasoning_about_shapes.html">
                  Reasoning about Shapes in PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/swap_tensors.html">
                  Extension points in nn.Module for load_state_dict and tensor subclasses
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_export_aoti_python.html">
                  torch.export AOTInductor Tutorial for Python runtime (Beta)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/recipes/tensorboard_with_pytorch.html">
                  How to use TensorBoard with PyTorch
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_torch_function_modes.html">
                  (beta) Utilizing Torch Function modes with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/compiling_optimizer_lr_scheduler.html">
                  (beta) Running the compiled optimizer with an LR Scheduler
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/foreach_map.html">
                  Explicit horizontal fusion with foreach_map and torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">
                  Using User-Defined Triton Kernels with torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_tutorial.html">
                  Compile Time Caching in torch.compile
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/torch_compile_caching_configuration_tutorial.html">
                  Compile Time Caching Configuration
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_compilation.html">
                  Reducing torch.compile cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/regional_aot.html">
                  Reducing AoT cold start compilation time with regional compilation
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/intel_neural_compressor_for_pytorch.html">
                  Ease-of-use quantization for PyTorch with IntelÂ® Neural Compressor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_device_mesh.html">
                  Getting Started with DeviceMesh
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_checkpoint_recipe.html">
                  Getting Started with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/distributed_async_checkpoint_recipe.html">
                  Asynchronous Saving with Distributed Checkpoint (DCP)
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../recipes/debug_mode_tutorial.html">
                  DebugMode: Recording Dispatched Operations and Numerical Debugging
                </a>
</li>
</ul>
</li>
<li class="nav-item dropdown">
<div class="nav-item-with-toggle">
<a class="nav-link nav-internal" href="../unstable_index.html">
              Unstable
            </a>
</div>
<ul class="dropdown-menu" id="dropdown-9">
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/context_parallel.html">
                  Introduction to Context Parallel
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/flight_recorder_tutorial.html">
                  Flight Recorder for Debugging Stuck Jobs
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_cpp_wrapper_tutorial.html">
                  TorchInductor C++ Wrapper Tutorial
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/inductor_windows.html">
                  How to use torch.compile on Windows CPU/XPU
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/vmap_recipe.html">
                  torch.vmap
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/nestedtensor.html">
                  Getting Started with Nested Tensors
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_overview.html">
                  MaskedTensor Overview
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_sparsity.html">
                  MaskedTensor Sparsity
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_advanced_semantics.html">
                  MaskedTensor Advanced Semantics
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/maskedtensor_adagrad.html">
                  Efficiently writing â€œsparseâ€ semantics for Adagrad with MaskedTensor
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/python_extension_autoload.html">
                  Autoloading Out-of-Tree Extension
                </a>
</li>
<li class="">
<a class="nav-link dropdown-item nav-internal" href="../unstable/max_autotune_on_CPU_tutorial.html">
                  Using Max-Autotune Compilation on CPU for Better Performance
                </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item"><!-- PyTorch.org site link - desktop only, two-line layout -->
<!-- Note: The show_pytorch_org_link check is handled in layout.html's navbar_end block -->
<a class="pytorch-site-link nav-link nav-external" data-bs-placement="bottom" data-bs-title="Go to PyTorch.org" data-bs-toggle="tooltip" href="https://pytorch.org">
<span class="pytorch-site-link-text">
<span>Go to</span>
<span>pytorch.org <i class="fa-solid fa-arrow-up-right-from-square external-icon"></i></span>
</span>
</a></div>
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning using Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="realtime_rpi.html">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/mosaic_memory_profiling_tutorial.html">Mosaic: Memory Profiling for PyTorch</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../ecosystem.html">Ecosystem</a></li>
<li aria-current="page" class="breadcrumb-item active">PyTorch...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">â˜…</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<div id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../ecosystem.html" itemprop="item"/>
<meta content="Ecosystem" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="PyTorch Profiler With TensorBoard" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
    if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
      var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
      document.addEventListener('DOMContentLoaded', function () {
        document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
      });
    }
  </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/tensorboard_profiler_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-tensorboard-profiler-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="pytorch-profiler-with-tensorboard">
<span id="sphx-glr-intermediate-tensorboard-profiler-tutorial-py"></span><h1>PyTorch Profiler With TensorBoard<a class="headerlink" href="#pytorch-profiler-with-tensorboard" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Apr 20, 2021 | Last Updated: Oct 31, 2024 | Last Verified: Nov 05, 2024</p>
<p>This tutorial demonstrates how to use TensorBoard plugin with PyTorch Profiler
to detect performance bottlenecks of the model.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The TensorBoard integration with the PyTorch profiler is now
deprecated. Instead, use Perfetto or the Chrome trace to
view <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> files. After
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html#using-tracing-functionality">generating a trace</a>,
simply drag the <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> into <a class="reference external" href="https://ui.perfetto.dev/">Perfetto UI</a>
or <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> to visualize your profile.</p>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>PyTorch 1.8 includes an updated profiler API capable of
recording the CPU side operations as well as the CUDA kernel launches on the GPU side.
The profiler can visualize this information
in TensorBoard Plugin and provide analysis of the performance bottlenecks.</p>
<p>In this tutorial, we will use a simple Resnet model to demonstrate how to
use TensorBoard plugin to analyze model performance.</p>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<p>To install <code class="docutils literal notranslate"><span class="pre">torch</span></code> and <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> use the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span>
</pre></div>
</div>
</section>
<section id="steps">
<h2>Steps<a class="headerlink" href="#steps" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Prepare the data and model</p></li>
<li><p>Use profiler to record execution events</p></li>
<li><p>Run the profiler</p></li>
<li><p>Use TensorBoard to view results and analyze model performance</p></li>
<li><p>Improve performance with the help of profiler</p></li>
<li><p>Analyze performance with other advanced features</p></li>
<li><p>Additional Practices: Profiling PyTorch on AMD GPUs</p></li>
</ol>
<section id="prepare-the-data-and-model">
<h3>1. Prepare the data and model<a class="headerlink" href="#prepare-the-data-and-model" title="Link to this heading">#</a></h3>
<p>First, import all necessary libraries:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.profiler</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.utils.data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.datasets</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.models</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">T</span>
</pre></div>
</div>
<p>Then prepare the input data. For this tutorial, we use the CIFAR10 dataset.
Transform it to the desired format and use <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> to load each batch.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">transform</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><span class="n">T</span><span class="o">.</span><span class="n">Compose</span></a><span class="p">(</span>
    <span class="p">[</span><a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize" title="torchvision.transforms.Resize"><span class="n">T</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
     <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor" title="torchvision.transforms.ToTensor"><span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span></a><span class="p">(),</span>
     <a class="sphx-glr-backref-module-torchvision-transforms sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize" title="torchvision.transforms.Normalize"><span class="n">T</span><span class="o">.</span><span class="n">Normalize</span></a><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>
<span class="n">train_set</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-datasets sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10" title="torchvision.datasets.CIFAR10"><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span></a><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, create Resnet model, loss function, and optimizer objects.
To run on GPU, move model and loss to GPU device.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="torch.device"><span class="n">torch</span><span class="o">.</span><span class="n">device</span></a><span class="p">(</span><span class="s2">"cuda:0"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torchvision-models sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18" title="torchvision.models.resnet18"><span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span></a><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">'IMAGENET1K_V1'</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss" title="torch.nn.CrossEntropyLoss"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span></a><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-optim sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD" title="torch.optim.SGD"><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span></a><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
<p>Define the training step for each batch of input data.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="use-profiler-to-record-execution-events">
<h3>2. Use profiler to record execution events<a class="headerlink" href="#use-profiler-to-record-execution-events" title="Link to this heading">#</a></h3>
<p>The profiler is enabled through the context manager and accepts several parameters,
some of the most useful are:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">schedule</span></code> - callable that takes step (int) as a single parameter
and returns the profiler action to perform at each step.</p>
<p>In this example with <code class="docutils literal notranslate"><span class="pre">wait=1,</span> <span class="pre">warmup=1,</span> <span class="pre">active=3,</span> <span class="pre">repeat=1</span></code>,
profiler will skip the first step/iteration,
start warming up on the second,
record the following three iterations,
after which the trace will become available and on_trace_ready (when set) is called.
In total, the cycle repeats once. Each cycle is called a â€œspanâ€ in TensorBoard plugin.</p>
<p>During <code class="docutils literal notranslate"><span class="pre">wait</span></code> steps, the profiler is disabled.
During <code class="docutils literal notranslate"><span class="pre">warmup</span></code> steps, the profiler starts tracing but the results are discarded.
This is for reducing the profiling overhead.
The overhead at the beginning of profiling is high and easy to bring skew to the profiling result.
During <code class="docutils literal notranslate"><span class="pre">active</span></code> steps, the profiler works and records events.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">on_trace_ready</span></code> - callable that is called at the end of each cycle;
In this example we use <code class="docutils literal notranslate"><span class="pre">torch.profiler.tensorboard_trace_handler</span></code> to generate result files for TensorBoard.
After profiling, result files will be saved into the <code class="docutils literal notranslate"><span class="pre">./log/resnet18</span></code> directory.
Specify this directory as a <code class="docutils literal notranslate"><span class="pre">logdir</span></code> parameter to analyze profile in TensorBoard.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">record_shapes</span></code> - whether to record shapes of the operator inputs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">profile_memory</span></code> - Track tensor memory allocation/deallocation. Note, for old version of pytorch with version
before 1.10, if you suffer long profiling time, please disable it or upgrade to new version.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">with_stack</span></code> - Record source information (file and line number) for the ops.
If the TensorBoard is launched in VS Code (<a class="reference external" href="https://code.visualstudio.com/docs/datascience/pytorch-support#_tensorboard-integration">reference</a>),
clicking a stack frame will navigate to the specific code line.</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.profile" title="torch.profiler.profile"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span></a><span class="p">(</span>
        <span class="n">schedule</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.schedule" title="torch.profiler.schedule"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">schedule</span></a><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">active</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">on_trace_ready</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.tensorboard_trace_handler" title="torch.profiler.tensorboard_trace_handler"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tensorboard_trace_handler</span></a><span class="p">(</span><span class="s1">'./log/resnet18'</span><span class="p">),</span>
        <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">profile_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Need to call this at each step to notify profiler of steps' boundary.</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">train</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, the following non-context manager start/stop is supported as well.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prof</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.profile" title="torch.profiler.profile"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span></a><span class="p">(</span>
        <span class="n">schedule</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.schedule" title="torch.profiler.schedule"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">schedule</span></a><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">active</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">on_trace_ready</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-profiler sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/profiler.html#torch.profiler.tensorboard_trace_handler" title="torch.profiler.tensorboard_trace_handler"><span class="n">torch</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tensorboard_trace_handler</span></a><span class="p">(</span><span class="s1">'./log/resnet18'</span><span class="p">),</span>
        <span class="n">record_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">with_stack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">prof</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">train</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
<span class="n">prof</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="run-the-profiler">
<h3>3. Run the profiler<a class="headerlink" href="#run-the-profiler" title="Link to this heading">#</a></h3>
<p>Run the above code. The profiling result will be saved under <code class="docutils literal notranslate"><span class="pre">./log/resnet18</span></code> directory.</p>
</section>
<section id="use-tensorboard-to-view-results-and-analyze-model-performance">
<h3>4. Use TensorBoard to view results and analyze model performance<a class="headerlink" href="#use-tensorboard-to-view-results-and-analyze-model-performance" title="Link to this heading">#</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>TensorBoard Plugin support has been deprecated, so some of these functions may not
work as previously. Please take a look at the replacement, <a class="reference external" href="https://github.com/pytorch/kineto/tree/main#holistic-trace-analysis">HTA</a>.</p>
</div>
<p>Install PyTorch Profiler TensorBoard Plugin.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch_tb_profiler</span>
</pre></div>
</div>
<p>Launch the TensorBoard.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=./</span><span class="n">log</span>
</pre></div>
</div>
<p>Open the TensorBoard profile URL in Google Chrome browser or Microsoft Edge browser (<strong>Safari is not supported</strong>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">localhost</span><span class="p">:</span><span class="mi">6006</span><span class="o">/</span><span class="c1">#pytorch_profiler</span>
</pre></div>
</div>
<p>You could see Profiler plugin page as shown below.</p>
<ul class="simple">
<li><p>Overview</p></li>
</ul>
<a class="reference internal image-reference" href="../_static/img/profiler_overview1.png"><img alt="../_static/img/profiler_overview1.png" src="../_static/img/profiler_overview1.png"/></a>
<p>The overview shows a high-level summary of model performance.</p>
<p>The â€œGPU Summaryâ€ panel shows the GPU configuration, GPU usage and Tensor Cores usage.
In this example, the GPU Utilization is low.
The details of these metrics are <a class="reference external" href="https://github.com/pytorch/kineto/blob/main/tb_plugin/docs/gpu_utilization.md">here</a>.</p>
<p>The â€œStep Time Breakdownâ€ shows distribution of time spent in each step over different categories of execution.
In this example, you can see the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> overhead is significant.</p>
<p>The bottom â€œPerformance Recommendationâ€ uses the profiling data
to automatically highlight likely bottlenecks,
and gives you actionable optimization suggestions.</p>
<p>You can change the view page in left â€œViewsâ€ dropdown list.</p>
<img alt="" src="../_static/img/profiler_views_list.png"/>
<ul class="simple">
<li><p>Operator view</p></li>
</ul>
<p>The operator view displays the performance of every PyTorch operator
that is executed either on the host or device.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_operator_view.png"><img alt="../_static/img/profiler_operator_view.png" src="../_static/img/profiler_operator_view.png"/></a>
<p>The â€œSelfâ€ duration does not include its child operatorsâ€™ time.
The â€œTotalâ€ duration includes its child operatorsâ€™ time.</p>
<ul class="simple">
<li><p>View call stack</p></li>
</ul>
<p>Click the <code class="docutils literal notranslate"><span class="pre">View</span> <span class="pre">Callstack</span></code> of an operator, the operators with same name but different call stacks will be shown.
Then click a <code class="docutils literal notranslate"><span class="pre">View</span> <span class="pre">Callstack</span></code> in this sub-table, the call stack frames will be shown.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_callstack.png"><img alt="../_static/img/profiler_callstack.png" src="../_static/img/profiler_callstack.png"/></a>
<p>If the TensorBoard is launched inside VS Code
(<a class="reference external" href="https://devblogs.microsoft.com/python/python-in-visual-studio-code-february-2021-release/#tensorboard-integration">Launch Guide</a>),
clicking a call stack frame will navigate to the specific code line.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_vscode.png"><img alt="../_static/img/profiler_vscode.png" src="../_static/img/profiler_vscode.png"/></a>
<ul class="simple">
<li><p>Kernel view</p></li>
</ul>
<p>The GPU kernel view shows all kernelsâ€™ time spent on GPU.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_kernel_view.png"><img alt="../_static/img/profiler_kernel_view.png" src="../_static/img/profiler_kernel_view.png"/></a>
<p>Tensor Cores Used:
Whether this kernel uses Tensor Cores.</p>
<p>Mean Blocks per SM:
Blocks per SM = Blocks of this kernel / SM number of this GPU.
If this number is less than 1, it indicates the GPU multiprocessors are not fully utilized.
â€œMean Blocks per SMâ€ is weighted average of all runs of this kernel name, using each runâ€™s duration as weight.</p>
<p>Mean Est. Achieved Occupancy:
Est. Achieved Occupancy is defined in this columnâ€™s tooltip.
For most cases such as memory bandwidth bounded kernels, the higher the better.
â€œMean Est. Achieved Occupancyâ€ is weighted average of all runs of this kernel name,
using each runâ€™s duration as weight.</p>
<ul class="simple">
<li><p>Trace view</p></li>
</ul>
<p>The trace view shows timeline of profiled operators and GPU kernels.
You can select it to see details as below.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view1.png"><img alt="../_static/img/profiler_trace_view1.png" src="../_static/img/profiler_trace_view1.png"/></a>
<p>You can move the graph and zoom in/out with the help of right side toolbar.
And keyboard can also be used to zoom and move around inside the timeline.
The â€˜wâ€™ and â€˜sâ€™ keys zoom in centered around the mouse,
and the â€˜aâ€™ and â€˜dâ€™ keys move the timeline left and right.
You can hit these keys multiple times until you see a readable representation.</p>
<p>If a backward operatorâ€™s â€œIncoming Flowâ€ field is with value â€œforward correspond to backwardâ€,
you can click the text to get its launching forward operator.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view_fwd_bwd.png"><img alt="../_static/img/profiler_trace_view_fwd_bwd.png" src="../_static/img/profiler_trace_view_fwd_bwd.png"/></a>
<p>In this example, we can see the event prefixed with <code class="docutils literal notranslate"><span class="pre">enumerate(DataLoader)</span></code> costs a lot of time.
And during most of this period, the GPU is idle.
Because this function is loading data and transforming data on host side,
during which the GPU resource is wasted.</p>
</section>
<section id="improve-performance-with-the-help-of-profiler">
<h3>5. Improve performance with the help of profiler<a class="headerlink" href="#improve-performance-with-the-help-of-profiler" title="Link to this heading">#</a></h3>
<p>At the bottom of â€œOverviewâ€ page, the suggestion in â€œPerformance Recommendationâ€ hints the bottleneck is <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.
The PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> uses single process by default.
User could enable multi-process data loading by setting the parameter <code class="docutils literal notranslate"><span class="pre">num_workers</span></code>.
<a class="reference external" href="https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading">Here</a> is more details.</p>
<p>In this example, we follow the â€œPerformance Recommendationâ€ and set <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> as below,
pass a different name such as <code class="docutils literal notranslate"><span class="pre">./log/resnet18_4workers</span></code> to <code class="docutils literal notranslate"><span class="pre">tensorboard_trace_handler</span></code>, and run it again.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">train_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<p>Then letâ€™s choose the recently profiled run in left â€œRunsâ€ dropdown list.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_overview2.png"><img alt="../_static/img/profiler_overview2.png" src="../_static/img/profiler_overview2.png"/></a>
<p>From the above view, we can find the step time is reduced to about 76ms comparing with previous runâ€™s 132ms,
and the time reduction of <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> mainly contributes.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_trace_view2.png"><img alt="../_static/img/profiler_trace_view2.png" src="../_static/img/profiler_trace_view2.png"/></a>
<p>From the above view, we can see that the runtime of <code class="docutils literal notranslate"><span class="pre">enumerate(DataLoader)</span></code> is reduced,
and the GPU utilization is increased.</p>
</section>
<section id="analyze-performance-with-other-advanced-features">
<h3>6. Analyze performance with other advanced features<a class="headerlink" href="#analyze-performance-with-other-advanced-features" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Memory view</p></li>
</ul>
<p>To profile memory, <code class="docutils literal notranslate"><span class="pre">profile_memory</span></code> must be set to <code class="docutils literal notranslate"><span class="pre">True</span></code> in arguments of <code class="docutils literal notranslate"><span class="pre">torch.profiler.profile</span></code>.</p>
<p>You can try it by using existing example on Azure</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">storage</span><span class="o">-</span><span class="n">blob</span>
<span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">torchtbprofiler</span><span class="o">.</span><span class="n">blob</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">net</span><span class="o">/</span><span class="n">torchtbprofiler</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">memory_demo_1_10</span>
</pre></div>
</div>
<p>The profiler records all memory allocation/release events and allocatorâ€™s internal state during profiling.
The memory view consists of three components as shown in the following.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_view.png"><img alt="../_static/img/profiler_memory_view.png" src="../_static/img/profiler_memory_view.png"/></a>
<p>The components are memory curve graph, memory events table and memory statistics table, from top to bottom, respectively.</p>
<p>The memory type could be selected in â€œDeviceâ€ selection box.
For example, â€œGPU0â€ means the following table only shows each operatorâ€™s memory usage on GPU 0, not including CPU or other GPUs.</p>
<p>The memory curve shows the trends of memory consumption. The â€œAllocatedâ€ curve shows the total memory that is actually
in use, e.g., tensors. In PyTorch, caching mechanism is employed in CUDA allocator and some other allocators. The
â€œReservedâ€ curve shows the total memory that is reserved by the allocator. You can left click and drag on the graph
to select events in the desired range:</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_curve_selecting.png"><img alt="../_static/img/profiler_memory_curve_selecting.png" src="../_static/img/profiler_memory_curve_selecting.png"/></a>
<p>After selection, the three components will be updated for the restricted time range, so that you can gain more
information about it. By repeating this process, you can zoom into a very fine-grained detail. Right click on the graph
will reset the graph to the initial state.</p>
<a class="reference internal image-reference" href="../_static/img/profiler_memory_curve_single.png"><img alt="../_static/img/profiler_memory_curve_single.png" src="../_static/img/profiler_memory_curve_single.png"/></a>
<p>In the memory events table, the allocation and release events are paired into one entry. The â€œoperatorâ€ column shows
the immediate ATen operator that is causing the allocation. Notice that in PyTorch, ATen operators commonly use
<code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> to allocate memory. For example, <code class="docutils literal notranslate"><span class="pre">aten::ones</span></code> is implemented as <code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> followed by an
<code class="docutils literal notranslate"><span class="pre">aten::fill_</span></code>. Solely display the operator name as <code class="docutils literal notranslate"><span class="pre">aten::empty</span></code> is of little help. It will be shown as
<code class="docutils literal notranslate"><span class="pre">aten::ones</span> <span class="pre">(aten::empty)</span></code> in this special case. The â€œAllocation Timeâ€, â€œRelease Timeâ€ and â€œDurationâ€
columnsâ€™ data might be missing if the event occurs outside of the time range.</p>
<p>In the memory statistics table, the â€œSize Increaseâ€ column sums up all allocation size and minus all the memory
release size, that is, the net increase of memory usage after this operator. The â€œSelf Size Increaseâ€ column is
similar to â€œSize Increaseâ€, but it does not count children operatorsâ€™ allocation. With regards to ATen operatorsâ€™
implementation detail, some operators might call other operators, so memory allocations can happen at any level of the
call stack. That says, â€œSelf Size Increaseâ€ only count the memory usage increase at current level of call stack.
Finally, the â€œAllocation Sizeâ€ column sums up all allocation without considering the memory release.</p>
<ul class="simple">
<li><p>Distributed view</p></li>
</ul>
<p>The plugin now supports distributed view on profiling DDP with NCCL/GLOO as backend.</p>
<p>You can try it by using existing example on Azure:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">azure</span><span class="o">-</span><span class="n">storage</span><span class="o">-</span><span class="n">blob</span>
<span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">torchtbprofiler</span><span class="o">.</span><span class="n">blob</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">net</span><span class="o">/</span><span class="n">torchtbprofiler</span><span class="o">/</span><span class="n">demo</span><span class="o">/</span><span class="n">distributed_bert</span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_static/img/profiler_distributed_view.png"><img alt="../_static/img/profiler_distributed_view.png" src="../_static/img/profiler_distributed_view.png"/></a>
<p>The â€œComputation/Communication Overviewâ€ shows computation/communication ratio and their overlapping degree.
From this view, User can figure out load balance issue among workers.
For example, if the computation + overlapping time of one worker is much larger than others,
there may be a problem of load balance or this worker may be a straggler.</p>
<p>The â€œSynchronizing/Communication Overviewâ€ shows the efficiency of communication.
â€œData Transfer Timeâ€ is the time for actual data exchanging.
â€œSynchronizing Timeâ€ is the time for waiting and synchronizing with other workers.</p>
<p>If one workerâ€™s â€œSynchronizing Timeâ€ is much shorter than that of other workersâ€™,
this worker may be a straggler which may have more computation workload than other workersâ€™.</p>
<p>The â€œCommunication Operations Statsâ€ summarizes the detailed statistics of all communication ops in each worker.</p>
</section>
<section id="additional-practices-profiling-pytorch-on-amd-gpus">
<h3>7. Additional Practices: Profiling PyTorch on AMD GPUs<a class="headerlink" href="#additional-practices-profiling-pytorch-on-amd-gpus" title="Link to this heading">#</a></h3>
<p>The AMD ROCm Platform is an open-source software stack designed for GPU computation, consisting of drivers, development tools, and APIs.
We can run the above mentioned steps on AMD GPUs. In this section, we will use Docker to install the ROCm base development image
before installing PyTorch.</p>
<p>For the purpose of example, letâ€™s create a directory called <code class="docutils literal notranslate"><span class="pre">profiler_tutorial</span></code>, and save the code in <strong>Step 1</strong> as <code class="docutils literal notranslate"><span class="pre">test_cifar10.py</span></code> in this directory.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span> <span class="o">~/</span><span class="n">profiler_tutorial</span>
<span class="n">cd</span> <span class="n">profiler_tutorial</span>
<span class="n">vi</span> <span class="n">test_cifar10</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>At the time of this writing, the Stable(<code class="docutils literal notranslate"><span class="pre">2.1.1</span></code>) Linux version of PyTorch on ROCm Platform is <a class="reference external" href="https://pytorch.org/get-started/locally/">ROCm 5.6</a>.</p>
<ul class="simple">
<li><p>Obtain a base Docker image with the correct user-space ROCm version installed from <a class="reference external" href="https://hub.docker.com/repository/docker/rocm/dev-ubuntu-20.04">Docker Hub</a>.</p></li>
</ul>
<p>It is <code class="docutils literal notranslate"><span class="pre">rocm/dev-ubuntu-20.04:5.6</span></code>.</p>
<ul class="simple">
<li><p>Start the ROCm base Docker container:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">docker</span> <span class="n">run</span> <span class="o">-</span><span class="n">it</span> <span class="o">--</span><span class="n">network</span><span class="o">=</span><span class="n">host</span> <span class="o">--</span><span class="n">device</span><span class="o">=/</span><span class="n">dev</span><span class="o">/</span><span class="n">kfd</span> <span class="o">--</span><span class="n">device</span><span class="o">=/</span><span class="n">dev</span><span class="o">/</span><span class="n">dri</span> <span class="o">--</span><span class="n">group</span><span class="o">-</span><span class="n">add</span><span class="o">=</span><span class="n">video</span> <span class="o">--</span><span class="n">ipc</span><span class="o">=</span><span class="n">host</span> <span class="o">--</span><span class="n">cap</span><span class="o">-</span><span class="n">add</span><span class="o">=</span><span class="n">SYS_PTRACE</span> <span class="o">--</span><span class="n">security</span><span class="o">-</span><span class="n">opt</span> <span class="n">seccomp</span><span class="o">=</span><span class="n">unconfined</span> <span class="o">--</span><span class="n">shm</span><span class="o">-</span><span class="n">size</span> <span class="mi">8</span><span class="n">G</span> <span class="o">-</span><span class="n">v</span> <span class="o">~/</span><span class="n">profiler_tutorial</span><span class="p">:</span><span class="o">/</span><span class="n">profiler_tutorial</span> <span class="n">rocm</span><span class="o">/</span><span class="n">dev</span><span class="o">-</span><span class="n">ubuntu</span><span class="o">-</span><span class="mf">20.04</span><span class="p">:</span><span class="mf">5.6</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Inside the container, install any dependencies needed for installing the wheels package.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sudo</span> <span class="n">apt</span> <span class="n">update</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">libjpeg</span><span class="o">-</span><span class="n">dev</span> <span class="n">python3</span><span class="o">-</span><span class="n">dev</span> <span class="o">-</span><span class="n">y</span>
<span class="n">pip3</span> <span class="n">install</span> <span class="n">wheel</span> <span class="n">setuptools</span>
<span class="n">sudo</span> <span class="n">apt</span> <span class="n">install</span> <span class="n">python</span><span class="o">-</span><span class="ow">is</span><span class="o">-</span><span class="n">python3</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Install the wheels:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip3</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">rocm5</span><span class="mf">.6</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Install the <code class="docutils literal notranslate"><span class="pre">torch_tb_profiler</span></code>, and then, run the Python file <code class="docutils literal notranslate"><span class="pre">test_cifar10.py</span></code>:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch_tb_profiler</span>
<span class="n">cd</span> <span class="o">/</span><span class="n">profiler_tutorial</span>
<span class="n">python</span> <span class="n">test_cifar10</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Now, we have all the data needed to view in TensorBoard:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=./</span><span class="n">log</span>
</pre></div>
</div>
<p>Choose different views as described in <strong>Step 4</strong>. For example, below is the <strong>Operator</strong> View:</p>
<a class="reference internal image-reference" href="../_static/img/profiler_rocm_tensorboard_operartor_view.png"><img alt="../_static/img/profiler_rocm_tensorboard_operartor_view.png" src="../_static/img/profiler_rocm_tensorboard_operartor_view.png"/></a>
<p>At the time this section is written, <strong>Trace</strong> view does not work and it displays nothing. You can work around by typing <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> in your Chrome Browser.</p>
<ul class="simple">
<li><p>Copy the <code class="docutils literal notranslate"><span class="pre">trace.json</span></code> file under <code class="docutils literal notranslate"><span class="pre">~/profiler_tutorial/log/resnet18</span></code> directory to the Windows.</p></li>
</ul>
<p>You may need to copy the file by using <code class="docutils literal notranslate"><span class="pre">scp</span></code> if the file is located in a remote location.</p>
<ul class="simple">
<li><p>Click <strong>Load</strong> button to load the trace JSON file from the <code class="docutils literal notranslate"><span class="pre">chrome://tracing</span></code> page in the browser.</p></li>
</ul>
<a class="reference internal image-reference" href="../_static/img/profiler_rocm_chrome_trace_view.png"><img alt="../_static/img/profiler_rocm_chrome_trace_view.png" src="../_static/img/profiler_rocm_chrome_trace_view.png"/></a>
<p>As mentioned previously, you can move the graph and zoom in and out.
You can also use keyboard to zoom and move around inside the timeline.
The <code class="docutils literal notranslate"><span class="pre">w</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span></code> keys zoom in centered around the mouse,
and the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> keys move the timeline left and right.
You can hit these keys multiple times until you see a readable representation.</p>
</section>
</section>
<section id="learn-more">
<h2>Learn More<a class="headerlink" href="#learn-more" title="Link to this heading">#</a></h2>
<p>Take a look at the following documents to continue your learning,
and feel free to open an issue <a class="reference external" href="https://github.com/pytorch/kineto/issues">here</a>.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/pytorch/kineto/tree/master/tb_plugin">PyTorch TensorBoard Profiler Github</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/master/profiler.html">torch.profiler API</a></p></li>
<li><p><a class="reference external" href="https://github.com/pytorch/kineto/tree/main#holistic-trace-analysis">HTA</a></p></li>
</ul>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-tensorboard-profiler-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0aec568a42e89122e5ca293c86289287/tensorboard_profiler_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tensorboard_profiler_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/67e47b6d6793c700666471b688068f72/tensorboard_profiler_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tensorboard_profiler_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/180ec9b33649e3199154d56f44f40877/tensorboard_profiler_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">tensorboard_profiler_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</div>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">â˜…</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">â˜…</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="ax_multiobjective_nas_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Multi-Objective NAS with Ax</p>
</div>
</a>
<a class="right-next" href="realtime_rpi.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="ax_multiobjective_nas_tutorial.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Multi-Objective NAS with Ax</p>
</div>
</a>
<a class="right-next" href="realtime_rpi.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title">Real Time Inference on Raspberry Pi 4 and 5 (40 fps!)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps">Steps</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-the-data-and-model">1. Prepare the data and model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-profiler-to-record-execution-events">2. Use profiler to record execution events</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-the-profiler">3. Run the profiler</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#use-tensorboard-to-view-results-and-analyze-model-performance">4. Use TensorBoard to view results and analyze model performance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#improve-performance-with-the-help-of-profiler">5. Improve performance with the help of profiler</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyze-performance-with-other-advanced-features">6. Analyze performance with other advanced features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#additional-practices-profiling-pytorch-on-amd-gpus">7. Additional Practices: Profiling PyTorch on AMD GPUs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#learn-more">Learn More</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/helion" style="color: var(--pst-color-text-muted)">Helion</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/kineto" style="color: var(--pst-color-text-muted)">kineto</a></li>
<li><a class="nav-link nav-external" href="https://github.com/pytorch/torchtitan" style="color: var(--pst-color-text-muted)">torchtitan</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/rl" style="color: var(--pst-color-text-muted)">TorchRL</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/audio" style="color: var(--pst-color-text-muted)">torchaudio</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/tensordict" style="color: var(--pst-color-text-muted)">tensordict</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          Â© PyTorch. Copyright Â© The Linux FoundationÂ®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      Â© Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "PyTorch Profiler With TensorBoard",
       "headline": "PyTorch Profiler With TensorBoard",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment.",
       "url": "/intermediate/tensorboard_profiler_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. PyTorch Profiler With TensorBoard# This tutorial demonstrates how to use TensorBoard plugin with PyTorch Profiler to detect performance bottlenecks of the model. Warning The TensorBoard integration with the PyTorch profiler is now deprecated. Instead, use Perfetto or the Chrome trace to view trace.json files. After generating a trace, simply drag the trace.json into Perfetto UI or chrome://tracing to visualize your profile. Introduction# PyTorch 1.8 includes an updated profiler API capable of recording the CPU side operations as well as the CUDA kernel launches on the GPU side. The profiler can visualize this information in TensorBoard Plugin and provide analysis of the performance bottlenecks. In this tutorial, we will use a simple Resnet model to demonstrate how to use TensorBoard plugin to analyze model performance. Setup# To install torch and torchvision use the following command: pip install torch torchvision Steps# Prepare the data and model Use profiler to record execution events Run the profiler Use TensorBoard to view results and analyze model performance Improve performance with the help of profiler Analyze performance with other advanced features Additional Practices: Profiling PyTorch on AMD GPUs 1. Prepare the data and model# First, import all necessary libraries: import torch import torch.nn import torch.optim import torch.profiler import torch.utils.data import torchvision.datasets import torchvision.models import torchvision.transforms as T Then prepare the input data. For this tutorial, we use the CIFAR10 dataset. Transform it to the desired format and use DataLoader to load each batch. transform = T.Compose( [T.Resize(224), T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) train_set = torchvision.datasets.CIFAR10(root=\u0027./data\u0027, train=True, download=True, transform=transform) train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True) Next, create Resnet model, loss function, and optimizer objects. To run on GPU, move model and loss to GPU device. device = torch.device(\"cuda:0\") model = torchvision.models.resnet18(weights=\u0027IMAGENET1K_V1\u0027).cuda(device) criterion = torch.nn.CrossEntropyLoss().cuda(device) optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) model.train() Define the training step for each batch of input data. def train(data): inputs, labels = data[0].to(device=device), data[1].to(device=device) outputs = model(inputs) loss = criterion(outputs, labels) optimizer.zero_grad() loss.backward() optimizer.step() 2. Use profiler to record execution events# The profiler is enabled through the context manager and accepts several parameters, some of the most useful are: schedule - callable that takes step (int) as a single parameter and returns the profiler action to perform at each step. In this example with wait=1, warmup=1, active=3, repeat=1, profiler will skip the first step/iteration, start warming up on the second, record the following three iterations, after which the trace will become available and on_trace_ready (when set) is called. In total, the cycle repeats once. Each cycle is called a \u201cspan\u201d in TensorBoard plugin. During wait steps, the profiler is disabled. During warmup steps, the profiler starts tracing but the results are discarded. This is for reducing the profiling overhead. The overhead at the beginning of profiling is high and easy to bring skew to the profiling result. During active steps, the profiler works and records events. on_trace_ready - callable that is called at the end of each cycle; In this example we use torch.profiler.tensorboard_trace_handler to generate result files for TensorBoard. After profiling, result files will be saved into the ./log/resnet18 directory. Specify this directory as a logdir parameter to analyze profile in TensorBoard. record_shapes - whether to record shapes of the operator inputs. profile_memory - Track tensor memory allocation/deallocation. Note, for old version of pytorch with version before 1.10, if you suffer long profiling time, please disable it or upgrade to new version. with_stack - Record source information (file and line number) for the ops. If the TensorBoard is launched in VS Code (reference), clicking a stack frame will navigate to the specific code line. with torch.profiler.profile( schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1), on_trace_ready=torch.profiler.tensorboard_trace_handler(\u0027./log/resnet18\u0027), record_shapes=True, profile_memory=True, with_stack=True ) as prof: for step, batch_data in enumerate(train_loader): prof.step() # Need to call this at each step to notify profiler of steps\u0027 boundary. if step \u003e= 1 + 1 + 3: break train(batch_data) Alternatively, the following non-context manager start/stop is supported as well. prof = torch.profiler.profile( schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1), on_trace_ready=torch.profiler.tensorboard_trace_handler(\u0027./log/resnet18\u0027), record_shapes=True, with_stack=True) prof.start() for step, batch_data in enumerate(train_loader): prof.step() if step \u003e= 1 + 1 + 3: break train(batch_data) prof.stop() 3. Run the profiler# Run the above code. The profiling result will be saved under ./log/resnet18 directory. 4. Use TensorBoard to view results and analyze model performance# Note TensorBoard Plugin support has been deprecated, so some of these functions may not work as previously. Please take a look at the replacement, HTA. Install PyTorch Profiler TensorBoard Plugin. pip install torch_tb_profiler Launch the TensorBoard. tensorboard --logdir=./log Open the TensorBoard profile URL in Google Chrome browser or Microsoft Edge browser (Safari is not supported). http://localhost:6006/#pytorch_profiler You could see Profiler plugin page as shown below. Overview The overview shows a high-level summary of model performance. The \u201cGPU Summary\u201d panel shows the GPU configuration, GPU usage and Tensor Cores usage. In this example, the GPU Utilization is low. The details of these metrics are here. The \u201cStep Time Breakdown\u201d shows distribution of time spent in each step over different categories of execution. In this example, you can see the DataLoader overhead is significant. The bottom \u201cPerformance Recommendation\u201d uses the profiling data to automatically highlight likely bottlenecks, and gives you actionable optimization suggestions. You can change the view page in left \u201cViews\u201d dropdown list. Operator view The operator view displays the performance of every PyTorch operator that is executed either on the host or device. The \u201cSelf\u201d duration does not include its child operators\u2019 time. The \u201cTotal\u201d duration includes its child operators\u2019 time. View call stack Click the View Callstack of an operator, the operators with same name but different call stacks will be shown. Then click a View Callstack in this sub-table, the call stack frames will be shown. If the TensorBoard is launched inside VS Code (Launch Guide), clicking a call stack frame will navigate to the specific code line. Kernel view The GPU kernel view shows all kernels\u2019 time spent on GPU. Tensor Cores Used: Whether this kernel uses Tensor Cores. Mean Blocks per SM: Blocks per SM = Blocks of this kernel / SM number of this GPU. If this number is less than 1, it indicates the GPU multiprocessors are not fully utilized. \u201cMean Blocks per SM\u201d is weighted average of all runs of this kernel name, using each run\u2019s duration as weight. Mean Est. Achieved Occupancy: Est. Achieved Occupancy is defined in this column\u2019s tooltip. For most cases such as memory bandwidth bounded kernels, the higher the better. \u201cMean Est. Achieved Occupancy\u201d is weighted average of all runs of this kernel name, using each run\u2019s duration as weight. Trace view The trace view shows timeline of profiled operators and GPU kernels. You can select it to see details as below. You can move the graph and zoom in/out with the help of right side toolbar. And keyboard can also be used to zoom and move around inside the timeline. The \u2018w\u2019 and \u2018s\u2019 keys zoom in centered around the mouse, and the \u2018a\u2019 and \u2018d\u2019 keys move the timeline left and right. You can hit these keys multiple times until you see a readable representation. If a backward operator\u2019s \u201cIncoming Flow\u201d field is with value \u201cforward correspond to backward\u201d, you can click the text to get its launching forward operator. In this example, we can see the event prefixed with enumerate(DataLoader) costs a lot of time. And during most of this period, the GPU is idle. Because this function is loading data and transforming data on host side, during which the GPU resource is wasted. 5. Improve performance with the help of profiler# At the bottom of \u201cOverview\u201d page, the suggestion in \u201cPerformance Recommendation\u201d hints the bottleneck is DataLoader. The PyTorch DataLoader uses single process by default. User could enable multi-process data loading by setting the parameter num_workers. Here is more details. In this example, we follow the \u201cPerformance Recommendation\u201d and set num_workers as below, pass a different name such as ./log/resnet18_4workers to tensorboard_trace_handler, and run it again. train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=4) Then let\u2019s choose the recently profiled run in left \u201cRuns\u201d dropdown list. From the above view, we can find the step time is reduced to about 76ms comparing with previous run\u2019s 132ms, and the time reduction of DataLoader mainly contributes. From the above view, we can see that the runtime of enumerate(DataLoader) is reduced, and the GPU utilization is increased. 6. Analyze performance with other advanced features# Memory view To profile memory, profile_memory must be set to True in arguments of torch.profiler.profile. You can try it by using existing example on Azure pip install azure-storage-blob tensorboard --logdir=https://torchtbprofiler.blob.core.windows.net/torchtbprofiler/demo/memory_demo_1_10 The profiler records all memory allocation/release events and allocator\u2019s internal state during profiling. The memory view consists of three components as shown in the following. The components are memory curve graph, memory events table and memory statistics table, from top to bottom, respectively. The memory type could be selected in \u201cDevice\u201d selection box. For example, \u201cGPU0\u201d means the following table only shows each operator\u2019s memory usage on GPU 0, not including CPU or other GPUs. The memory curve shows the trends of memory consumption. The \u201cAllocated\u201d curve shows the total memory that is actually in use, e.g., tensors. In PyTorch, caching mechanism is employed in CUDA allocator and some other allocators. The \u201cReserved\u201d curve shows the total memory that is reserved by the allocator. You can left click and drag on the graph to select events in the desired range: After selection, the three components will be updated for the restricted time range, so that you can gain more information about it. By repeating this process, you can zoom into a very fine-grained detail. Right click on the graph will reset the graph to the initial state. In the memory events table, the allocation and release events are paired into one entry. The \u201coperator\u201d column shows the immediate ATen operator that is causing the allocation. Notice that in PyTorch, ATen operators commonly use aten::empty to allocate memory. For example, aten::ones is implemented as aten::empty followed by an aten::fill_. Solely display the operator name as aten::empty is of little help. It will be shown as aten::ones (aten::empty) in this special case. The \u201cAllocation Time\u201d, \u201cRelease Time\u201d and \u201cDuration\u201d columns\u2019 data might be missing if the event occurs outside of the time range. In the memory statistics table, the \u201cSize Increase\u201d column sums up all allocation size and minus all the memory release size, that is, the net increase of memory usage after this operator. The \u201cSelf Size Increase\u201d column is similar to \u201cSize Increase\u201d, but it does not count children operators\u2019 allocation. With regards to ATen operators\u2019 implementation detail, some operators might call other operators, so memory allocations can happen at any level of the call stack. That says, \u201cSelf Size Increase\u201d only count the memory usage increase at current level of call stack. Finally, the \u201cAllocation Size\u201d column sums up all allocation without considering the memory release. Distributed view The plugin now supports distributed view on profiling DDP with NCCL/GLOO as backend. You can try it by using existing example on Azure: pip install azure-storage-blob tensorboard --logdir=https://torchtbprofiler.blob.core.windows.net/torchtbprofiler/demo/distributed_bert The \u201cComputation/Communication Overview\u201d shows computation/communication ratio and their overlapping degree. From this view, User can figure out load balance issue among workers. For example, if the computation + overlapping time of one worker is much larger than others, there may be a problem of load balance or this worker may be a straggler. The \u201cSynchronizing/Communication Overview\u201d shows the efficiency of communication. \u201cData Transfer Time\u201d is the time for actual data exchanging. \u201cSynchronizing Time\u201d is the time for waiting and synchronizing with other workers. If one worker\u2019s \u201cSynchronizing Time\u201d is much shorter than that of other workers\u2019, this worker may be a straggler which may have more computation workload than other workers\u2019. The \u201cCommunication Operations Stats\u201d summarizes the detailed statistics of all communication ops in each worker. 7. Additional Practices: Profiling PyTorch on AMD GPUs# The AMD ROCm Platform is an open-source software stack designed for GPU computation, consisting of drivers, development tools, and APIs. We can run the above mentioned steps on AMD GPUs. In this section, we will use Docker to install the ROCm base development image before installing PyTorch. For the purpose of example, let\u2019s create a directory called profiler_tutorial, and save the code in Step 1 as test_cifar10.py in this directory. mkdir ~/profiler_tutorial cd profiler_tutorial vi test_cifar10.py At the time of this writing, the Stable(2.1.1) Linux version of PyTorch on ROCm Platform is ROCm 5.6. Obtain a base Docker image with the correct user-space ROCm version installed from Docker Hub. It is rocm/dev-ubuntu-20.04:5.6. Start the ROCm base Docker container: docker run -it --network=host --device=/dev/kfd --device=/dev/dri --group-add=video --ipc=host --cap-add=SYS_PTRACE --security-opt seccomp=unconfined --shm-size 8G -v ~/profiler_tutorial:/profiler_tutorial rocm/dev-ubuntu-20.04:5.6 Inside the container, install any dependencies needed for installing the wheels package. sudo apt update sudo apt install libjpeg-dev python3-dev -y pip3 install wheel setuptools sudo apt install python-is-python3 Install the wheels: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.6 Install the torch_tb_profiler, and then, run the Python file test_cifar10.py: pip install torch_tb_profiler cd /profiler_tutorial python test_cifar10.py Now, we have all the data needed to view in TensorBoard: tensorboard --logdir=./log Choose different views as described in Step 4. For example, below is the Operator View: At the time this section is written, Trace view does not work and it displays nothing. You can work around by typing chrome://tracing in your Chrome Browser. Copy the trace.json file under ~/profiler_tutorial/log/resnet18 directory to the Windows. You may need to copy the file by using scp if the file is located in a remote location. Click Load button to load the trace JSON file from the chrome://tracing page in the browser. As mentioned previously, you can move the graph and zoom in and out. You can also use keyboard to zoom and move around inside the timeline. The w and s keys zoom in centered around the mouse, and the a and d keys move the timeline left and right. You can hit these keys multiple times until you see a readable representation. Learn More# Take a look at the following documents to continue your learning, and feel free to open an issue here. PyTorch TensorBoard Profiler Github torch.profiler API HTA Download Jupyter notebook: tensorboard_profiler_tutorial.ipynb Download Python source code: tensorboard_profiler_tutorial.py Download zipped: tensorboard_profiler_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "https://pytorch.org/docs/stable/_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/tensorboard_profiler_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>