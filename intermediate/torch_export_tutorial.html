
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>torch.export Tutorial — PyTorch Tutorials 2.8.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=c9393ea6" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=bffbcef7"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/torch_export_tutorial';</script>
<link href="https://docs.pytorch.org/tutorials/intermediate/torch_export_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="../recipes/torch_export_aoti_python.html" rel="next" title="torch.export AOTInductor Tutorial for Python runtime (Beta)"/>
<link href="../recipes/regional_compilation.html" rel="prev" title="Reducing torch.compile cold start compilation time with regional compilation"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<link crossorigin="anonymous" href="/intermediate/torch_export_tutorial.html" rel="canonical"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.8.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started">Get Started</a>
</li>
<li>
<a href="https://pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/pytorch-domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.8.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="compiled_autograd_tutorial.html">Compiled Autograd: Capturing a larger backward graph for <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compiler_set_stance_tutorial.html">Dynamic Compilation Control with <code class="docutils literal notranslate"><span class="pre">torch.compiler.set_stance</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">torch.export</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">torch.export Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ONNX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">Export a PyTorch model to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/onnx_registry_tutorial.html">Extending the ONNX Exporter Operator Support</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">Export a model with control flow to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="torch_compile_conv_bn_fuser.html">Building a Convolution/Batch Norm fuser with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../compilers_index.html">Compilers</a></li>
<li aria-current="page" class="breadcrumb-item active">torch.export...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../compilers_index.html" itemprop="item"/>
<meta content="Compilers" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="torch.export Tutorial" itemprop="name"/>
<meta content="2" itemprop="position"/>
</div>
</div>
<script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/torch_export_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-torch-export-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="torch-export-tutorial">
<span id="sphx-glr-intermediate-torch-export-tutorial-py"></span><h1>torch.export Tutorial<a class="headerlink" href="#torch-export-tutorial" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Oct 02, 2023 | Last Updated: Jan 27, 2025 | Last Verified: Nov 05, 2024</p>
<p><strong>Author:</strong> William Wen, Zhengxu Chen, Angela Yi, Pian Pawakapan</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> and its related features are in prototype status and are subject to backwards compatibility
breaking changes. This tutorial provides a snapshot of <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> usage as of PyTorch 2.5.</p>
</div>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export()</span></code> is the PyTorch 2.X way to export PyTorch models into
standardized model representations, intended
to be run on different (i.e. Python-less) environments. The official
documentation can be found <a class="reference external" href="https://pytorch.org/docs/main/export.html">here</a>.</p>
<p>In this tutorial, you will learn how to use <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.export()</span></code> to extract
<code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code>’s (i.e. single-graph representations) from PyTorch programs.
We also detail some considerations/modifications that you may need
to make in order to make your model compatible with <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.</p>
<p><strong>Contents</strong></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#basic-usage" id="id2">Basic Usage</a></p></li>
<li><p><a class="reference internal" href="#graph-breaks" id="id3">Graph Breaks</a></p></li>
<li><p><a class="reference internal" href="#non-strict-export" id="id4">Non-Strict Export</a></p></li>
<li><p><a class="reference internal" href="#control-flow-ops" id="id5">Control Flow Ops</a></p></li>
<li><p><a class="reference internal" href="#constraints-dynamic-shapes" id="id6">Constraints/Dynamic Shapes</a></p>
<ul>
<li><p><a class="reference internal" href="#basic-concepts-symbols-and-guards" id="id7">Basic concepts: symbols and guards</a></p></li>
<li><p><a class="reference internal" href="#specialization" id="id8">0/1 specialization</a></p></li>
<li><p><a class="reference internal" href="#named-dims" id="id9">Named Dims</a></p></li>
<li><p><a class="reference internal" href="#constraint-violations-suggested-fixes" id="id10">Constraint violations, suggested fixes</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#data-dependent-errors" id="id11">Data-dependent errors</a></p>
<ul>
<li><p><a class="reference internal" href="#guards-torch-check" id="id12">Guards, torch._check()</a></p></li>
<li><p><a class="reference internal" href="#specialized-values" id="id13">Specialized values</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#custom-ops" id="id14">Custom Ops</a></p></li>
<li><p><a class="reference internal" href="#ir-decompositions" id="id15">IR/Decompositions</a></p></li>
<li><p><a class="reference internal" href="#exportdb" id="id16">ExportDB</a></p></li>
<li><p><a class="reference internal" href="#running-the-exported-program" id="id17">Running the Exported Program</a></p></li>
<li><p><a class="reference internal" href="#conclusion" id="id18">Conclusion</a></p></li>
</ul>
</nav>
<section id="basic-usage">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Basic Usage</a><a class="headerlink" href="#basic-usage" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> extracts single-graph representations from PyTorch programs
by tracing the target function, given example inputs.
<code class="docutils literal notranslate"><span class="pre">torch.export.export()</span></code> is the main entry point for <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.</p>
<p>In this tutorial, <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.export.export()</span></code> are practically synonymous,
though <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> generally refers to the PyTorch 2.X export process, and <code class="docutils literal notranslate"><span class="pre">torch.export.export()</span></code>
generally refers to the actual function call.</p>
<p>The signature of <code class="docutils literal notranslate"><span class="pre">torch.export.export()</span></code> is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span>
    <span class="n">mod</span><span class="p">:</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">,</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">dynamic_shapes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ExportedProgram</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.export.export()</span></code> traces the tensor computation graph from calling <code class="docutils literal notranslate"><span class="pre">mod(*args,</span> <span class="pre">**kwargs)</span></code>
and wraps it in an <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code>, which can be serialized or executed later with
different inputs. To execute the <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> we can call <code class="docutils literal notranslate"><span class="pre">.module()</span></code>
on it to return a <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> which is callable, just like the
original program.
We will detail the <code class="docutils literal notranslate"><span class="pre">dynamic_shapes</span></code> argument later in the tutorial.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.export</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a>

<span class="k">class</span><span class="w"> </span><span class="nc">MyModule</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">mod</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">MyModule</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_mod</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_mod</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">exported_mod</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">100</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;class 'torch.export.exported_program.ExportedProgram'&gt;
tensor([[1.2833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6960, 0.0000, 0.0206,
         0.0000],
        [0.0000, 0.0000, 0.5338, 0.4826, 0.0000, 1.1298, 0.8386, 0.0000, 1.8642,
         0.4014],
        [0.0162, 1.2556, 0.8679, 0.5822, 0.8992, 0.2108, 0.8659, 0.0000, 0.5097,
         0.0000],
        [0.0364, 0.3233, 0.5205, 1.5689, 0.0000, 0.1559, 0.5217, 0.0000, 0.0000,
         0.2202],
        [0.0000, 1.4435, 1.2654, 0.0000, 0.0000, 0.0000, 0.0000, 0.9309, 0.6940,
         0.0000],
        [0.2193, 0.4609, 0.0000, 0.2015, 0.5363, 0.0000, 0.8061, 0.0000, 0.3670,
         1.3163],
        [0.5836, 0.0964, 0.6060, 1.9044, 0.8751, 0.0000, 1.1344, 1.9880, 0.0000,
         0.0000],
        [0.0000, 1.6330, 0.6570, 0.0000, 0.0000, 0.0000, 0.0000, 1.8583, 0.0000,
         0.0000]], grad_fn=&lt;ReluBackward0&gt;)
</pre></div>
</div>
<p>Let’s review some attributes of <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> that are of interest.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">graph</span></code> attribute is an <a class="reference external" href="https://pytorch.org/docs/stable/fx.html#torch.fx.Graph">FX graph</a>
traced from the function we exported, that is, the computation graph of all PyTorch operations.
The FX graph is in “ATen IR” meaning that it contains only “ATen-level” operations.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">graph_signature</span></code> attribute gives a more detailed description of the
input and output nodes in the exported graph, describing which ones are
parameters, buffers, user inputs, or user outputs.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">range_constraints</span></code> attributes will be covered later.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_mod</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, p_lin_weight: "f32[10, 100]", p_lin_bias: "f32[10]", x: "f32[8, 100]", y: "f32[8, 100]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:71 in forward, code: return torch.nn.functional.relu(self.lin(x + y), inplace=True)
            add: "f32[8, 100]" = torch.ops.aten.add.Tensor(x, y);  x = y = None

             # File: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear: "f32[8, 10]" = torch.ops.aten.linear.default(add, p_lin_weight, p_lin_bias);  add = p_lin_weight = p_lin_bias = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:71 in forward, code: return torch.nn.functional.relu(self.lin(x + y), inplace=True)
            relu_: "f32[8, 10]" = torch.ops.aten.relu_.default(linear);  linear = None
            return (relu_,)

Graph signature:
    # inputs
    p_lin_weight: PARAMETER target='lin.weight'
    p_lin_bias: PARAMETER target='lin.bias'
    x: USER_INPUT
    y: USER_INPUT

    # outputs
    relu_: USER_OUTPUT

Range constraints: {}
</pre></div>
</div>
<p>See the <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> <a class="reference external" href="https://pytorch.org/docs/main/export.html#torch.export.export">documentation</a>
for more details.</p>
</section>
<section id="graph-breaks">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Graph Breaks</a><a class="headerlink" href="#graph-breaks" title="Link to this heading">#</a></h2>
<p>Although <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> shares components with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>,
the key limitation of <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>, especially when compared to
<code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>, is that it does not support graph breaks. This is because
handling graph breaks involves interpreting the unsupported operation with
default Python evaluation, which is incompatible with the export use case.
Therefore, in order to make your model code compatible with <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>,
you will need to modify your code to remove graph breaks.</p>
<p>A graph break is necessary in cases such as:</p>
<ul class="simple">
<li><p>data-dependent control flow</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Bad1</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <span class="k">if</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tb</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Bad1</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>def forward(self, arg0_1: "f32[3, 3]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:116 in forward, code: if x.sum() &gt; 0:
    sum_1: "f32[]" = torch.ops.aten.sum.default(arg0_1);  arg0_1 = None
    gt: "b8[]" = torch.ops.aten.gt.Scalar(sum_1, 0);  sum_1 = None
    ne: "b8[]" = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
    item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None




def forward(self, arg0_1: "f32[3, 3]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:116 in forward, code: if x.sum() &gt; 0:
    sum_1: "f32[]" = torch.ops.aten.sum.default(arg0_1);  arg0_1 = None
    gt: "b8[]" = torch.ops.aten.gt.Scalar(sum_1, 0);  sum_1 = None
    ne: "b8[]" = torch.ops.aten.ne.Scalar(gt, 0);  gt = None
    item: "Sym(Eq(u0, 1))" = torch.ops.aten.item.default(ne);  ne = item = None

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 122, in &lt;module&gt;
    export(Bad1(), (torch.randn(3, 3),))
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 116, in forward
    if x.sum() &gt; 0:
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 538, in guard_bool
    r = self.evaluate()
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 512, in evaluate
    return self.shape_env.evaluate_sym_node(self, size_oblivious)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7223, in evaluate_sym_node
    return self.evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7323, in evaluate_expr
    return self._inner_evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7346, in _inner_evaluate_expr
    return self._evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7570, in _evaluate_expr
    raise self._make_data_dependent_error(
torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)).  (Size-like symbols: none)

Caused by: (_export/non_strict_utils.py:1051 in __torch_function__)
For more information, run with TORCH_LOGS="dynamic"
For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"
If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing

For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1

The following call raised this error:
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 116, in forward
    if x.sum() &gt; 0:


The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<ul class="simple">
<li><p>accessing tensor data with <code class="docutils literal notranslate"><span class="pre">.data</span></code></p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Bad2</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span><span class="o">.</span><span class="n">data</span></a><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a>

<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Bad2</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>calling unsupported functions (such as many built-in functions)</p></li>
</ul>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Bad3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <span class="nb">id</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Bad3</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="non-strict-export">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Non-Strict Export</a><a class="headerlink" href="#non-strict-export" title="Link to this heading">#</a></h2>
<p>To trace the program, <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> uses TorchDynamo by default, a byte
code analysis engine, to symbolically analyze the Python code and build a
graph based on the results. This analysis allows <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> to provide
stronger guarantees about safety, but not all Python code is supported,
causing these graph breaks.</p>
<p>To address this issue, in PyTorch 2.3, we introduced a new mode of
exporting called non-strict mode, where we trace through the program using the
Python interpreter executing it exactly as it would in eager mode, allowing us
to skip over unsupported Python features. This is done through adding a
<code class="docutils literal notranslate"><span class="pre">strict=False</span></code> flag.</p>
<p>Looking at some of the previous examples which resulted in graph breaks:</p>
<ul class="simple">
<li><p>Calling unsupported functions (such as many built-in functions) traces</p></li>
</ul>
<p>through, but in this case, <code class="docutils literal notranslate"><span class="pre">id(x)</span></code> gets specialized as a constant integer in
the graph. This is because <code class="docutils literal notranslate"><span class="pre">id(x)</span></code> is not a tensor operation, so the
operation is not recorded in the graph.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Bad3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <span class="nb">id</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>

<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">bad3_nonstrict</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Bad3</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),),</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">bad3_nonstrict</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">bad3_nonstrict</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "f32[3, 3]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:179 in forward, code: x = x + 1
            add: "f32[3, 3]" = torch.ops.aten.add.Tensor(x, 1);  x = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:180 in forward, code: return x + id(x)
            add_1: "f32[3, 3]" = torch.ops.aten.add.Tensor(add, 140197977140864);  add = None
            return (add_1,)

Graph signature:
    # inputs
    x: USER_INPUT

    # outputs
    add_1: USER_OUTPUT

Range constraints: {}

tensor([[1.4020e+14, 1.4020e+14, 1.4020e+14],
        [1.4020e+14, 1.4020e+14, 1.4020e+14],
        [1.4020e+14, 1.4020e+14, 1.4020e+14]])
</pre></div>
</div>
<p>However, there are still some features that require rewrites to the original
module:</p>
</section>
<section id="control-flow-ops">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Control Flow Ops</a><a class="headerlink" href="#control-flow-ops" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> actually does support data-dependent control flow.
But these need to be expressed using control flow ops. For example,
we can fix the control flow example above using the <code class="docutils literal notranslate"><span class="pre">cond</span></code> op, like so:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Bad1Fixed</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">true_fn</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">false_fn</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cond.html#torch.cond" title="torch.cond"><span class="n">torch</span><span class="o">.</span><span class="n">cond</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">true_fn</span><span class="p">,</span> <span class="n">false_fn</span><span class="p">,</span> <span class="p">[</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">])</span>

<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_bad1_fixed</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Bad1Fixed</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_bad1_fixed</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">exported_bad1_fixed</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">exported_bad1_fixed</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "f32[3, 3]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:205 in forward, code: return torch.cond(x.sum() &gt; 0, true_fn, false_fn, [x])
            sum_1: "f32[]" = torch.ops.aten.sum.default(x)
            gt: "b8[]" = torch.ops.aten.gt.Scalar(sum_1, 0);  sum_1 = None

             # File: &lt;eval_with_key&gt;.33:9 in forward, code: cond = torch.ops.higher_order.cond(l_args_0_, cond_true_0, cond_false_0, (l_args_3_0_,));  l_args_0_ = cond_true_0 = cond_false_0 = l_args_3_0_ = None
            true_graph_0 = self.true_graph_0
            false_graph_0 = self.false_graph_0
            cond = torch.ops.higher_order.cond(gt, true_graph_0, false_graph_0, (x,));  gt = true_graph_0 = false_graph_0 = x = None
            getitem: "f32[3, 3]" = cond[0];  cond = None
            return (getitem,)

        class true_graph_0(torch.nn.Module):
            def forward(self, x: "f32[3, 3]"):
                 # File: &lt;eval_with_key&gt;.30:6 in forward, code: sin = torch.sin(l_args_3_0__1);  l_args_3_0__1 = None
                sin: "f32[3, 3]" = torch.ops.aten.sin.default(x);  x = None
                return (sin,)

        class false_graph_0(torch.nn.Module):
            def forward(self, x: "f32[3, 3]"):
                 # File: &lt;eval_with_key&gt;.31:6 in forward, code: cos = torch.cos(l_args_3_0__1);  l_args_3_0__1 = None
                cos: "f32[3, 3]" = torch.ops.aten.cos.default(x);  x = None
                return (cos,)

Graph signature:
    # inputs
    x: USER_INPUT

    # outputs
    getitem: USER_OUTPUT

Range constraints: {}

tensor([[0.8415, 0.8415, 0.8415],
        [0.8415, 0.8415, 0.8415],
        [0.8415, 0.8415, 0.8415]])
tensor([[0.5403, 0.5403, 0.5403],
        [0.5403, 0.5403, 0.5403],
        [0.5403, 0.5403, 0.5403]])
</pre></div>
</div>
<p>There are limitations to <code class="docutils literal notranslate"><span class="pre">cond</span></code> that one should be aware of:</p>
<ul class="simple">
<li><p>The predicate (i.e. <code class="docutils literal notranslate"><span class="pre">x.sum()</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>) must result in a boolean or a single-element tensor.</p></li>
<li><p>The operands (i.e. <code class="docutils literal notranslate"><span class="pre">[x]</span></code>) must be tensors.</p></li>
<li><p>The branch function (i.e. <code class="docutils literal notranslate"><span class="pre">true_fn</span></code> and <code class="docutils literal notranslate"><span class="pre">false_fn</span></code>) signature must match with the
operands and they must both return a single tensor with the same metadata (for example, <code class="docutils literal notranslate"><span class="pre">dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">shape</span></code>, etc.).</p></li>
<li><p>Branch functions cannot mutate input or global variables.</p></li>
<li><p>Branch functions cannot access closure variables, except for <code class="docutils literal notranslate"><span class="pre">self</span></code> if the function is
defined in the scope of a method.</p></li>
</ul>
<p>For more details about <code class="docutils literal notranslate"><span class="pre">cond</span></code>, check out the <a class="reference external" href="https://pytorch.org/docs/main/cond.html">cond documentation</a>.</p>
<p>We can also use <code class="docutils literal notranslate"><span class="pre">map</span></code>, which applies a function across the first dimension
of the first tensor argument.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._higher_order_ops.map</span><span class="w"> </span><span class="kn">import</span> <span class="nb">map</span> <span class="k">as</span> <span class="n">torch_map</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MapModule</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">):</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">body</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">):</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a>

        <span class="k">return</span> <span class="n">torch_map</span><span class="p">(</span><span class="n">body</span><span class="p">,</span> <span class="n">xs</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">)</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_map_example</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">MapModule</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_map_example</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">exported_map_example</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><span class="o">*</span><span class="n">inps</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, xs: "f32[6, 4]", y: "i64[]", z: "i64[]"):
             # File: &lt;eval_with_key&gt;.58:9 in forward, code: map_impl = torch.ops.higher_order.map_impl(map_body_0, [l_flat_xs_0_], [l_flat_args_0_, l_flat_args_1_]);  map_body_0 = l_flat_xs_0_ = l_flat_args_0_ = l_flat_args_1_ = None
            body_graph_0 = self.body_graph_0
            map_impl = torch.ops.higher_order.map_impl(body_graph_0, [xs], [y, z]);  body_graph_0 = xs = y = z = None
            getitem: "f32[6, 4]" = map_impl[0];  map_impl = None
            return (getitem,)

        class body_graph_0(torch.nn.Module):
            def forward(self, xs: "f32[4]", y: "i64[]", z: "i64[]"):
                 # File: &lt;eval_with_key&gt;.56:5 in forward, code: add = child.add(l_flat_args_0_);  child = l_flat_args_0_ = None
                add: "f32[4]" = torch.ops.aten.add.Tensor(xs, y);  xs = y = None

                 # File: &lt;eval_with_key&gt;.56:6 in forward, code: add_1 = add.add(l_flat_args_1_);  add = l_flat_args_1_ = None
                add_1: "f32[4]" = torch.ops.aten.add.Tensor(add, z);  add = z = None
                return (add_1,)

Graph signature:
    # inputs
    xs: USER_INPUT
    y: USER_INPUT
    z: USER_INPUT

    # outputs
    getitem: USER_OUTPUT

Range constraints: {}

tensor([[10., 10., 10., 10.],
        [10., 10., 10., 10.],
        [10., 10., 10., 10.],
        [10., 10., 10., 10.],
        [10., 10., 10., 10.],
        [10., 10., 10., 10.]])
</pre></div>
</div>
<p>Other control flow ops include <code class="docutils literal notranslate"><span class="pre">while_loop</span></code>, <code class="docutils literal notranslate"><span class="pre">associative_scan</span></code>, and
<code class="docutils literal notranslate"><span class="pre">scan</span></code>. For more documentation on each operator, please refer to
<a class="reference external" href="https://github.com/pytorch/pytorch/tree/main/torch/_higher_order_ops">this page</a>.</p>
</section>
<section id="constraints-dynamic-shapes">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Constraints/Dynamic Shapes</a><a class="headerlink" href="#constraints-dynamic-shapes" title="Link to this heading">#</a></h2>
<p>This section covers dynamic behavior and representation of exported programs. Dynamic behavior is
subjective to the particular model being exported, so for the most part of this tutorial, we’ll focus
on this particular toy model (with the resulting tensor shapes annotated):</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DynamicModel</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [6, 5]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [4]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [8, 4]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [32]</span>
    <span class="p">):</span>
        <span class="n">x0</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a>  <span class="c1"># [8, 4]</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">)</span>  <span class="c1"># [6, 3]</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># [32]</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a>  <span class="c1"># [32]</span>
        <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x3</span>
</pre></div>
</div>
<p>By default, <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> produces a static program. One consequence of this is that at runtime,
the program won’t work on inputs with different shapes, even if they’re valid in eager mode.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">DynamicModel</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">))</span>
<span class="n">model</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">12</span><span class="p">))</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">ep</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">12</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 286, in &lt;module&gt;
    ep.module()(w, x, torch.randn(3, 4), torch.randn(12))
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 848, in call_wrapped
    return self._wrapped_call(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 424, in __call__
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 411, in __call__
    return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1806, in inner
    args_kwargs_result = hook(self, args, kwargs)  # type: ignore[misc]
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_unlift.py", line 83, in _check_input_constraints_pre_hook
    _check_input_constraints_for_graph(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py", line 426, in _check_input_constraints_for_graph
    _check_symint(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py", line 390, in _check_symint
    raise RuntimeError(
RuntimeError: Expected input at *args[2].shape[0] to be equal to 8, but got 3. If you meant for this dimension to be dynamic, please re-export and specify dynamic_shapes (e.g. with Dim.DYNAMIC)
</pre></div>
</div>
<section id="basic-concepts-symbols-and-guards">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Basic concepts: symbols and guards</a><a class="headerlink" href="#basic-concepts-symbols-and-guards" title="Link to this heading">#</a></h3>
<p>To enable dynamism, <code class="docutils literal notranslate"><span class="pre">export()</span></code> provides a <code class="docutils literal notranslate"><span class="pre">dynamic_shapes</span></code> argument. The easiest way to work with
dynamic shapes is using <code class="docutils literal notranslate"><span class="pre">Dim.AUTO</span></code> and looking at the program that’s returned. Dynamic behavior is specified
at a input dimension-level; for each input we can specify a tuple of values:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.export.dynamic_shapes</span><span class="w"> </span><span class="kn">import</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a>

<span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"w"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">),</span>
    <span class="s2">"x"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,),</span>
    <span class="s2">"y"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">),</span>
    <span class="s2">"z"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,),</span>
<span class="p">}</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">),</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">)</span>
</pre></div>
</div>
<p>Before we look at the program that’s produced, let’s understand what specifying <code class="docutils literal notranslate"><span class="pre">dynamic_shapes</span></code> entails,
and how that interacts with export. For every input dimension where a <code class="docutils literal notranslate"><span class="pre">Dim</span></code> object is specified, a symbol is
<a class="reference external" href="https://pytorch.org/docs/main/export.programming_model.html#basics-of-symbolic-shapes">allocated</a>,
taking on a range of <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">inf]</span></code> (why not <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">inf]</span></code> or <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">inf]</span></code>? we’ll explain later in the
0/1 specialization section).</p>
<p>Export then runs model tracing, looking at each operation that’s performed by the model. Each individual operation can emit
what’s called “guards”; basically boolean condition that are required to be true for the program to be valid.
When guards involve symbols allocated for input dimensions, the program contains restrictions on what input shapes are valid;
i.e. the program’s dynamic behavior. The symbolic shapes subsystem is the part responsible for taking in all the emitted guards
and producing a final program representation that adheres to all of these guards. Before we see this “final representation” in
an <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code>, let’s look at the guards emitted by the toy model we’re tracing.</p>
<p>Here, each forward input tensor is annotated with the symbol allocated at the start of tracing:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DynamicModel</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [s0, s1]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [s2]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [s3, s4]</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">,</span>  <span class="c1"># [s5]</span>
    <span class="p">):</span>
        <span class="n">x0</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a>  <span class="c1"># guard: s2 == s4</span>
        <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">)</span>  <span class="c1"># guard: s1 == 5</span>
        <span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># no guard added here</span>
        <span class="n">x3</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a>  <span class="c1"># guard: s3 * s4 == s5</span>
        <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x3</span>
</pre></div>
</div>
<p>Let’s understand each of the operations and the emitted guards:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x0</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">y</span></code>: This is an element-wise add with broadcasting, since <code class="docutils literal notranslate"><span class="pre">x</span></code> is a 1-d tensor and <code class="docutils literal notranslate"><span class="pre">y</span></code> a 2-d tensor. <code class="docutils literal notranslate"><span class="pre">x</span></code> is broadcasted along the last dimension of <code class="docutils literal notranslate"><span class="pre">y</span></code>, emitting the guard <code class="docutils literal notranslate"><span class="pre">s2</span> <span class="pre">==</span> <span class="pre">s4</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x1</span> <span class="pre">=</span> <span class="pre">self.l(w)</span></code>: Calling <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> performs a matrix multiplication with model parameters. In export, parameters, buffers, and constants are considered program state, which is considered static, and so this is a matmul between a dynamic input (<code class="docutils literal notranslate"><span class="pre">w:</span> <span class="pre">[s0,</span> <span class="pre">s1]</span></code>), and a statically-shaped tensor. This emits the guard <code class="docutils literal notranslate"><span class="pre">s1</span> <span class="pre">==</span> <span class="pre">5</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x2</span> <span class="pre">=</span> <span class="pre">x0.flatten()</span></code>: This call actually doesn’t emit any guards! (at least none relevant to input shapes)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x3</span> <span class="pre">=</span> <span class="pre">x2</span> <span class="pre">+</span> <span class="pre">z</span></code>: <code class="docutils literal notranslate"><span class="pre">x2</span></code> has shape <code class="docutils literal notranslate"><span class="pre">[s3*s4]</span></code> after flattening, and this element-wise add emits <code class="docutils literal notranslate"><span class="pre">s3</span> <span class="pre">*</span> <span class="pre">s4</span> <span class="pre">==</span> <span class="pre">s5</span></code>.</p></li>
</ul>
<p>Writing all of these guards down and summarizing is almost like a mathematical proof, which is what the symbolic shapes
subsystem tries to do! In summary, we can conclude that the program must have the following input shapes to be valid:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">w:</span> <span class="pre">[s0,</span> <span class="pre">5]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x:</span> <span class="pre">[s2]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">y:</span> <span class="pre">[s3,</span> <span class="pre">s2]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">z:</span> <span class="pre">[s2*s3]</span></code></p></li>
</ul>
<p>And when we do finally print out the exported program to see our result, those shapes are what we see annotated on the
corresponding inputs:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, p_l_weight: "f32[3, 5]", p_l_bias: "f32[3]", w: "f32[s15, 5]", x: "f32[s77]", y: "f32[s17, s77]", z: "f32[s17*s77]"):
             #
            sym_size_int_1 = torch.ops.aten.sym_size.int(w, 1)
            sym_size_int_2: "Sym(s77)" = torch.ops.aten.sym_size.int(x, 0)
            sym_size_int_3: "Sym(s17)" = torch.ops.aten.sym_size.int(y, 0)
            sym_size_int_4: "Sym(s77)" = torch.ops.aten.sym_size.int(y, 1)
            sym_size_int_5: "Sym(s17*s77)" = torch.ops.aten.sym_size.int(z, 0)

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:268 in forward, code: x0 = x + y  # [8, 4]
            add: "f32[s17, s77]" = torch.ops.aten.add.Tensor(x, y);  x = y = None

             #
            eq: "Sym(True)" = sym_size_int_2 == sym_size_int_4;  sym_size_int_4 = None
            _assert_scalar_default = torch.ops.aten._assert_scalar.default(eq, "Runtime assertion failed for expression Eq(s77, s94) on node 'eq'");  eq = _assert_scalar_default = None
            eq_1 = sym_size_int_1 == 5;  sym_size_int_1 = None
            _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(eq_1, "Runtime assertion failed for expression Eq(s21, 5) on node 'eq_1'");  eq_1 = _assert_scalar_default_1 = None
            mul: "Sym(s17*s77)" = sym_size_int_3 * sym_size_int_2;  sym_size_int_3 = sym_size_int_2 = None
            eq_2: "Sym(True)" = mul == sym_size_int_5;  mul = sym_size_int_5 = None
            _assert_scalar_default_2 = torch.ops.aten._assert_scalar.default(eq_2, "Runtime assertion failed for expression Eq(s17*s77, s68) on node 'eq_2'");  eq_2 = _assert_scalar_default_2 = None

             # File: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)
            linear: "f32[s15, 3]" = torch.ops.aten.linear.default(w, p_l_weight, p_l_bias);  w = p_l_weight = p_l_bias = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:270 in forward, code: x2 = x0.flatten()  # [32]
            flatten: "f32[s17*s77]" = torch.ops.aten.flatten.using_ints(add);  add = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:271 in forward, code: x3 = x2 + z  # [32]
            add_1: "f32[s17*s77]" = torch.ops.aten.add.Tensor(flatten, z);  flatten = z = None
            return (linear, add_1)

Graph signature:
    # inputs
    p_l_weight: PARAMETER target='l.weight'
    p_l_bias: PARAMETER target='l.bias'
    w: USER_INPUT
    x: USER_INPUT
    y: USER_INPUT
    z: USER_INPUT

    # outputs
    linear: USER_OUTPUT
    add_1: USER_OUTPUT

Range constraints: {s15: VR[2, int_oo], s77: VR[2, int_oo], s17: VR[2, int_oo], s17*s77: VR[4, int_oo]}
</pre></div>
</div>
<p>Another feature to notice is the range_constraints field above, which contains a valid range for each symbol. This isn’t
so interesting currently, since this export call doesn’t emit any guards related to symbol bounds and each base symbol has
a generic bound, but this will come up later.</p>
<p>So far, because we’ve been exporting this toy model, this experience has not been representative of how hard
it typically is to debug dynamic shapes guards &amp; issues. In most cases it isn’t obvious what guards are being emitted,
and which operations and parts of user code are responsible. For this toy model we pinpoint the exact lines, and the guards
are rather intuitive.</p>
<p>In more complicated cases, a helpful first step is always to enable verbose logging. This can be done either with the environment
variable <code class="docutils literal notranslate"><span class="pre">TORCH_LOGS="+dynamic"</span></code>, or interactively with <code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(dynamic=10)</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">dynamic</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">),</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.080000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.081000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L['w'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s15" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.082000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L['w'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s21" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.083000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.085000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L['x'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s77" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.086000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L['y'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s17" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.087000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L['y'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s94" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.089000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L['z'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s68" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.094000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.094000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.095000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.096000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.097000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.098000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.099000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.099000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.100000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.101000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.103000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.104000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s77, s94)"
I0917 20:30:34.105000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[2, int_oo]
V0917 20:30:34.106000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.113000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s21, 5)"
V0917 20:30:34.113000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update)
I0917 20:30:34.114000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5]
V0917 20:30:34.126000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known]
V0917 20:30:34.127000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.130000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s17*s77, s68)"
V0917 20:30:34.130000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[4, int_oo] (update)
I0917 20:30:34.132000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[4, int_oo]
I0917 20:30:34.136000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.137000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[0] s15 None
V0917 20:30:34.137000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[1] 5 None
V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[0] 5 None
V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[1] 1 None
V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].storage_offset() 0 None
V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] s77 None
V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 1 None
V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] s17 None
V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[1] s77 None
V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] s77 None
V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[1] 1 None
V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].size()[0] s17*s77 None
V0917 20:30:34.141000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].stride()[0] 1 None
V0917 20:30:34.141000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].storage_offset() 0 None
V0917 20:30:34.149000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
V0917 20:30:34.155000 31631 torch/fx/experimental/symbolic_shapes.py:7461] eval 5 [trivial]
</pre></div>
</div>
<p>This spits out quite a handful, even with this simple toy model. The log lines here have been cut short at front and end
to ignore unnecessary info, but looking through the logs we can see the lines relevant to what we described above;
e.g. the allocation of symbols:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">create_symbol s0 = 6 for L['w'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">create_symbol s1 = 5 for L['w'].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">runtime_assert True == True [statically known]</span>
<span class="sd">create_symbol s2 = 4 for L['x'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">create_symbol s3 = 8 for L['y'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">create_symbol s4 = 4 for L['y'].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">create_symbol s5 = 32 for L['z'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)</span>
<span class="sd">"""</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>"\ncreate_symbol s0 = 6 for L['w'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\ncreate_symbol s1 = 5 for L['w'].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\nruntime_assert True == True [statically known]\ncreate_symbol s2 = 4 for L['x'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\ncreate_symbol s3 = 8 for L['y'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\ncreate_symbol s4 = 4 for L['y'].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\ncreate_symbol s5 = 32 for L['z'].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in &lt;lambda&gt;)\n"
</pre></div>
</div>
<p>The lines with <cite>create_symbol</cite> show when a new symbol has been allocated, and the logs also identify the tensor variable names
and dimensions they’ve been allocated for. In other lines we can also see the guards emitted:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">runtime_assert Eq(s2, s4) [guard added] x0 = x + y  # output shape: [8, 4]  # dynamic_shapes_tutorial.py:16 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s2, s4)"</span>
<span class="sd">runtime_assert Eq(s1, 5) [guard added] x1 = self.l(w)  # [6, 3]  # dynamic_shapes_tutorial.py:17 in forward (_meta_registrations.py:2127 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s1, 5)"</span>
<span class="sd">runtime_assert Eq(s2*s3, s5) [guard added] x3 = x2 + z  # [32]  # dynamic_shapes_tutorial.py:19 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s2*s3, s5)"</span>
<span class="sd">"""</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>'\nruntime_assert Eq(s2, s4) [guard added] x0 = x + y  # output shape: [8, 4]  # dynamic_shapes_tutorial.py:16 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s2, s4)"\nruntime_assert Eq(s1, 5) [guard added] x1 = self.l(w)  # [6, 3]  # dynamic_shapes_tutorial.py:17 in forward (_meta_registrations.py:2127 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s1, 5)"\nruntime_assert Eq(s2*s3, s5) [guard added] x3 = x2 + z  # [32]  # dynamic_shapes_tutorial.py:19 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s2*s3, s5)"\n'
</pre></div>
</div>
<p>Next to the <code class="docutils literal notranslate"><span class="pre">[guard</span> <span class="pre">added]</span></code> messages, we also see the responsible user lines of code - luckily here the model is simple enough.
In many real-world cases it’s not so straightforward: high-level torch operations can have complicated fake-kernel implementations
or operator decompositions that complicate where and what guards are emitted. In such cases the best way to dig deeper and investigate
is to follow the logs’ suggestion, and re-run with environment variable <code class="docutils literal notranslate"><span class="pre">TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="..."</span></code>, to further
attribute the guard of interest.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dim.AUTO</span></code> is just one of the available options for interacting with <code class="docutils literal notranslate"><span class="pre">dynamic_shapes</span></code>; as of writing this 2 other options are available:
<code class="docutils literal notranslate"><span class="pre">Dim.DYNAMIC</span></code>, and <code class="docutils literal notranslate"><span class="pre">Dim.STATIC</span></code>. <code class="docutils literal notranslate"><span class="pre">Dim.STATIC</span></code> simply marks a dimension static, while <code class="docutils literal notranslate"><span class="pre">Dim.DYNAMIC</span></code> is similar to <code class="docutils literal notranslate"><span class="pre">Dim.AUTO</span></code> in all
ways except one: it raises an error when specializing to a constant; this is designed to maintain dynamism. See for example what happens when a
static guard is emitted on a dynamically-marked dimension:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="s2">"w"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">DYNAMIC</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">),</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.160000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.161000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L['w'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s15" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.162000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L['w'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s21" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.162000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.164000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L['x'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s77" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.165000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L['y'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s17" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.166000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L['y'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s94" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.168000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L['z'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s68" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.173000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.173000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.174000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.175000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.176000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.177000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.177000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.178000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.179000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.180000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.182000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.182000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s77, s94)"
I0917 20:30:34.183000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[2, int_oo]
V0917 20:30:34.185000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.191000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s21, 5)"
V0917 20:30:34.192000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update)
I0917 20:30:34.192000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5]
V0917 20:30:34.205000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known]
V0917 20:30:34.206000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.208000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s17*s77, s68)"
V0917 20:30:34.209000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[4, int_oo] (update)
I0917 20:30:34.210000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[4, int_oo]
I0917 20:30:34.215000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.215000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[0] s15 None
V0917 20:30:34.216000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[1] 5 RelaxedUnspecConstraint(warn_only=False)
V0917 20:30:34.426000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[0] 5 None
V0917 20:30:34.427000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[1] 1 None
V0917 20:30:34.427000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].storage_offset() 0 None
V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] s77 None
V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 1 None
V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] s17 None
V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[1] s77 None
V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] s77 None
V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[1] 1 None
V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].size()[0] s17*s77 None
V0917 20:30:34.431000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].stride()[0] 1 None
V0917 20:30:34.431000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].storage_offset() 0 None
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1798, in _export_to_aten_ir_make_fx
    produce_guards_callback(gm)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1944, in _produce_guards_callback
    return produce_guards_and_solve_constraints(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 549, in produce_guards_and_solve_constraints
    raise constraint_violation_error
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 514, in produce_guards_and_solve_constraints
    shape_env.produce_guards(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5200, in produce_guards
    return self.produce_guards_verbose(*args, **kwargs, langs=("python",))[0].exprs
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5932, in produce_guards_verbose
    raise ConstraintViolationError(
torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (L['w'].size()[1])! For more information, run with TORCH_LOGS="+dynamic".
  - You marked L['w'].size()[1] as dynamic but your code specialized it to be a constant (5). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 418, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 269, in forward
    x1 = self.l(w)  # [6, 3]
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::linear::call(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "RegisterCompositeImplicitAutograd_0.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "??", line 0, in at::native::linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)
  File "??", line 0, in at::_ops::addmm::call(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "", line 0, in c10::impl::BoxedKernelWrapper&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), void&gt;::call(c10::BoxedKernel const&amp;, c10::OperatorHandle const&amp;, c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_0.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_0.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::addmm::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2601, in _dispatch_impl
    decomposition_table[func](*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py", line 309, in _fn
    result = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 90, in inner
    r = f(*tree_map(increase_prec, args), **tree_map(increase_prec, kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 1462, in addmm
    out = alpha * torch.mm(mat1, mat2)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_torch_functions_1.cpp", line 0, in torch::autograd::THPVariable_mm(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::mm::call(at::Tensor const&amp;, at::Tensor const&amp;)
  File "", line 0, in c10::impl::BoxedKernelWrapper&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;), void&gt;::call(c10::BoxedKernel const&amp;, c10::OperatorHandle const&amp;, c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2717, in _dispatch_impl
    r = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py", line 309, in _fn
    result = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 2417, in meta_mm
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 418, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1800, in _export_to_aten_ir_make_fx
    raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e))  # noqa: B904
torch._dynamo.exc.UserError: Constraints violated (L['w'].size()[1])! For more information, run with TORCH_LOGS="+dynamic".
  - You marked L['w'].size()[1] as dynamic but your code specialized it to be a constant (5). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 418, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 269, in forward
    x1 = self.l(w)  # [6, 3]
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_nn_functions.cpp", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::linear::call(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "RegisterCompositeImplicitAutograd_0.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;), &amp;at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear&gt;, at::Tensor, c10::guts::typelist::typelist&lt;at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "??", line 0, in at::native::linear(at::Tensor const&amp;, at::Tensor const&amp;, std::optional&lt;at::Tensor&gt; const&amp;)
  File "??", line 0, in at::_ops::addmm::call(at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "", line 0, in c10::impl::BoxedKernelWrapper&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), void&gt;::call(c10::BoxedKernel const&amp;, c10::OperatorHandle const&amp;, c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_0.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::addmm&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_0.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::addmm::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2601, in _dispatch_impl
    decomposition_table[func](*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py", line 309, in _fn
    result = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 90, in inner
    r = f(*tree_map(increase_prec, args), **tree_map(increase_prec, kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py", line 1462, in addmm
    out = alpha * torch.mm(mat1, mat2)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "python_torch_functions_1.cpp", line 0, in torch::autograd::THPVariable_mm(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::mm::call(at::Tensor const&amp;, at::Tensor const&amp;)
  File "", line 0, in c10::impl::BoxedKernelWrapper&lt;at::Tensor (at::Tensor const&amp;, at::Tensor const&amp;), void&gt;::call(c10::BoxedKernel const&amp;, c10::OperatorHandle const&amp;, c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2717, in _dispatch_impl
    r = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py", line 309, in _fn
    result = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 2417, in meta_mm
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()


The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<p>Static guards also aren’t always inherent to the model; they can also come from user specifications. In fact, a common pitfall leading to shape
specializations is when the user specifies conflicting markers for equivalent dimensions; one dynamic and another static. The same error type is
raised when this is the case for <code class="docutils literal notranslate"><span class="pre">x.shape[0]</span></code> and <code class="docutils literal notranslate"><span class="pre">y.shape[1]</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dynamic_shapes</span><span class="p">[</span><span class="s2">"w"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">)</span>
<span class="n">dynamic_shapes</span><span class="p">[</span><span class="s2">"x"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">STATIC</span><span class="p">,)</span>
<span class="n">dynamic_shapes</span><span class="p">[</span><span class="s2">"y"</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">DYNAMIC</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">),</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.500000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.502000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L['w'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s15" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.503000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L['w'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s21" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.503000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.506000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L['y'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s17" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.507000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L['y'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s94" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.509000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L['z'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s68" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.515000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.516000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.516000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.518000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.519000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.519000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.520000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.521000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.526000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s94, 4) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s94, 4)"
V0917 20:30:34.527000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 4] (update)
I0917 20:30:34.528000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = 4 (range_refined_to_singleton) VR[4, 4]
I0917 20:30:34.537000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s21, 5)"
V0917 20:30:34.537000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update)
I0917 20:30:34.538000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5]
V0917 20:30:34.540000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.557000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(4*s17, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(4*s17, s68)"
V0917 20:30:34.558000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[8, int_oo] (update)
I0917 20:30:34.561000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = 4*s17 (solve) VR[8, int_oo]
I0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[0] s15 None
V0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[1] 5 None
V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[0] 5 None
V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[1] 1 None
V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].storage_offset() 0 None
V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] 4 None
V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 1 None
V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] s17 None
V0917 20:30:34.569000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[1] 4 RelaxedUnspecConstraint(warn_only=False)
V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 4 None
V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[1] 1 None
V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:34.605000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].size()[0] 4*s17 None
V0917 20:30:34.605000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].stride()[0] 1 None
V0917 20:30:34.606000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].storage_offset() 0 None
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1798, in _export_to_aten_ir_make_fx
    produce_guards_callback(gm)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1944, in _produce_guards_callback
    return produce_guards_and_solve_constraints(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 549, in produce_guards_and_solve_constraints
    raise constraint_violation_error
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 514, in produce_guards_and_solve_constraints
    shape_env.produce_guards(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5200, in produce_guards
    return self.produce_guards_verbose(*args, **kwargs, langs=("python",))[0].exprs
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5932, in produce_guards_verbose
    raise ConstraintViolationError(
torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (L['y'].size()[1])! For more information, run with TORCH_LOGS="+dynamic".
  - You marked L['y'].size()[1] as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 431, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 268, in forward
    x0 = x + y  # [8, 4]
  File "??", line 0, in PyNumber_Add
  File "??", line 0, in _Py_c_pow
  File "??", line 0, in PyThread_start_new_thread
  File "??", line 0, in _PyType_LookupId
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add&gt;(_object*, _object*, _object*)
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::add_Tensor::call(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_2.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::add_Tensor&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_2.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2581, in _dispatch_impl
    return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 962, in fast_binary_impl
    final_shape = infer_size(final_shape, shape)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 922, in infer_size
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 431, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1800, in _export_to_aten_ir_make_fx
    raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e))  # noqa: B904
torch._dynamo.exc.UserError: Constraints violated (L['y'].size()[1])! For more information, run with TORCH_LOGS="+dynamic".
  - You marked L['y'].size()[1] as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 431, in &lt;module&gt;
    export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 268, in forward
    x0 = x + y  # [8, 4]
  File "??", line 0, in PyNumber_Add
  File "??", line 0, in _Py_c_pow
  File "??", line 0, in PyThread_start_new_thread
  File "??", line 0, in _PyType_LookupId
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add&gt;(_object*, _object*, _object*)
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::add_Tensor::call(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_2.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::add_Tensor&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_2.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2581, in _dispatch_impl
    return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 962, in fast_binary_impl
    final_shape = infer_size(final_shape, shape)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 922, in infer_size
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()


The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<p>Here you might ask why export “specializes”, i.e. why we resolve this static/dynamic conflict by going with the static route. The answer is because
of the symbolic shapes system described above, of symbols and guards. When <code class="docutils literal notranslate"><span class="pre">x.shape[0]</span></code> is marked static, we don’t allocate a symbol, and compile
treating this shape as a concrete integer 4. A symbol is allocated for <code class="docutils literal notranslate"><span class="pre">y.shape[1]</span></code>, and so we finally emit the guard <code class="docutils literal notranslate"><span class="pre">s3</span> <span class="pre">==</span> <span class="pre">4</span></code>, leading to
specialization.</p>
<p>One feature of export is that during tracing, statements like asserts, <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code>, and <code class="docutils literal notranslate"><span class="pre">if/else</span></code> conditions will also emit guards.
See what happens when we augment the existing model with such statements:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DynamicModel</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">):</span>
        <span class="k">assert</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">w</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">512</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_check</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">x</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">)</span>
        <span class="k">if</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">w</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">x</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">x0</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a>
            <span class="n">x1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">)</span>
            <span class="n">x2</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">x3</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a>
            <span class="k">return</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x3</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a>

<span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"w"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">),</span>
    <span class="s2">"x"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,),</span>
    <span class="s2">"y"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">),</span>
    <span class="s2">"z"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,),</span>
<span class="p">}</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">DynamicModel</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">z</span></a><span class="p">),</span> <span class="n">dynamic_shapes</span><span class="o">=</span><span class="n">dynamic_shapes</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.662000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.664000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L['w'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s15" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.665000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L['w'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s21" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.665000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.667000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L['x'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s77" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.669000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L['y'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s17" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.669000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L['y'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s94" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.671000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L['z'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s68" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.676000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.677000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.677000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.679000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.679000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.680000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.681000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.682000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.683000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.683000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.689000 31631 torch/fx/experimental/symbolic_shapes.py:7197] eval s15 &lt;= 512 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:450 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="s15 &lt;= 512"
V0917 20:30:34.689000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s15 = VR[2, 512] (update)
I0917 20:30:34.693000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert s77 &gt;= 4 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:451 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="s77 &gt;= 4"
V0917 20:30:34.694000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s77 = VR[4, int_oo] (update)
I0917 20:30:34.698000 31631 torch/fx/experimental/symbolic_shapes.py:7197] eval Eq(s15, s77 + 2) [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:452 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s15, s77 + 2)"
V0917 20:30:34.701000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s77 = VR[4, 510] (update)
V0917 20:30:34.702000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s15 = VR[6, 512] (update)
I0917 20:30:34.703000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s15 = s77 + 2 (solve) VR[6, 512]
V0917 20:30:34.705000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.707000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s77, s94)"
V0917 20:30:34.708000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 510] (update)
I0917 20:30:34.708000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[4, 510]
V0917 20:30:34.712000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.718000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s21, 5)"
V0917 20:30:34.719000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update)
I0917 20:30:34.720000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5]
V0917 20:30:34.734000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known]
V0917 20:30:34.736000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.745000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s17*s77, s68)"
V0917 20:30:34.746000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[8, int_oo] (update)
I0917 20:30:34.747000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[8, int_oo]
I0917 20:30:34.752000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[0] s77 + 2 None
V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].size()[1] 5 None
V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[0] 5 None
V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].stride()[1] 1 None
V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['w'].storage_offset() 0 None
V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] s77 None
V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 1 None
V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] s17 None
V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[1] s77 None
V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] s77 None
V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[1] 1 None
V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].size()[0] s17*s77 None
V0917 20:30:34.757000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].stride()[0] 1 None
V0917 20:30:34.757000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['z'].storage_offset() 0 None
V0917 20:30:34.769000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert s77 &gt;= 4 == True [statically known]
V0917 20:30:34.770000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
V0917 20:30:34.777000 31631 torch/fx/experimental/symbolic_shapes.py:7461] eval 5 [trivial]
</pre></div>
</div>
<p>Each of these statements emits an additional guard, and the exported program shows the changes; <code class="docutils literal notranslate"><span class="pre">s0</span></code> is eliminated in favor of <code class="docutils literal notranslate"><span class="pre">s2</span> <span class="pre">+</span> <span class="pre">2</span></code>,
and <code class="docutils literal notranslate"><span class="pre">s2</span></code> now contains lower and upper bounds, reflected in <code class="docutils literal notranslate"><span class="pre">range_constraints</span></code>.</p>
<p>For the if/else condition, you might ask why the True branch was taken, and why it wasn’t the <code class="docutils literal notranslate"><span class="pre">w.shape[0]</span> <span class="pre">!=</span> <span class="pre">x.shape[0]</span> <span class="pre">+</span> <span class="pre">2</span></code> guard that
got emitted from tracing. The answer is that export is guided by the sample inputs provided by tracing, and specializes on the branches taken.
If different sample input shapes were provided that fail the <code class="docutils literal notranslate"><span class="pre">if</span></code> condition, export would trace and emit guards corresponding to the <code class="docutils literal notranslate"><span class="pre">else</span></code> branch.
Additionally, you might ask why we traced only the <code class="docutils literal notranslate"><span class="pre">if</span></code> branch, and if it’s possible to maintain control-flow in your program and keep both branches
alive. For that, refer to rewriting your model code following the <code class="docutils literal notranslate"><span class="pre">Control</span> <span class="pre">Flow</span> <span class="pre">Ops</span></code> section above.</p>
</section>
<section id="specialization">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">0/1 specialization</a><a class="headerlink" href="#specialization" title="Link to this heading">#</a></h3>
<p>Since we’re talking about guards and specializations, it’s a good time to talk about the 0/1 specialization issue we brought up earlier.
The bottom line is that export will specialize on sample input dimensions with value 0 or 1, because these shapes have trace-time properties that
don’t generalize to other shapes. For example, size 1 tensors can broadcast while other sizes fail; and size 0 … . This just means that you should
specify 0/1 sample inputs when you’d like your program to hardcode them, and non-0/1 sample inputs when dynamic behavior is desirable. See what happens
at runtime when we export this linear layer:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span>
    <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),),</span>
    <span class="n">dynamic_shapes</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"input"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">STATIC</span><span class="p">),</span>
    <span class="p">},</span>
<span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">ep</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.782000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.793000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['input'].size()[0] 1 None
V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['input'].size()[1] 4 None
V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['input'].stride()[0] 4 None
V0917 20:30:34.795000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['input'].stride()[1] 1 None
V0917 20:30:34.795000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['input'].storage_offset() 0 None
W0917 20:30:34.797000 31631 torch/_export/non_strict_utils.py:580] dimension inputs['input'].shape[0] 0/1 specialized; Dim.AUTO was specified along with a sample input with hint = 1.
Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 500, in &lt;module&gt;
    ep.module()(torch.randn(2, 4))
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 848, in call_wrapped
    return self._wrapped_call(self, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 424, in __call__
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py", line 411, in __call__
    return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
    return inner()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1806, in inner
    args_kwargs_result = hook(self, args, kwargs)  # type: ignore[misc]
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_unlift.py", line 83, in _check_input_constraints_pre_hook
    _check_input_constraints_for_graph(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py", line 426, in _check_input_constraints_for_graph
    _check_symint(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py", line 390, in _check_symint
    raise RuntimeError(
RuntimeError: Expected input at *args[0].shape[0] to be equal to 1, but got 2. If you meant for this dimension to be dynamic, please re-export and specify dynamic_shapes (e.g. with Dim.DYNAMIC)
</pre></div>
</div>
</section>
<section id="named-dims">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Named Dims</a><a class="headerlink" href="#named-dims" title="Link to this heading">#</a></h3>
<p>So far we’ve only been talking about 3 ways to specify dynamic shapes: <code class="docutils literal notranslate"><span class="pre">Dim.AUTO</span></code>, <code class="docutils literal notranslate"><span class="pre">Dim.DYNAMIC</span></code>, and <code class="docutils literal notranslate"><span class="pre">Dim.STATIC</span></code>. The attraction of these is the
low-friction user experience; all the guards emitted during model tracing are adhered to, and dynamic behavior like min/max ranges, relations, and static/dynamic
dimensions are automatically figured out underneath export. The dynamic shapes subsystem essentially acts as a “discovery” process, summarizing these guards
and presenting what export believes is the overall dynamic behavior of the program. The drawback of this design appears once the user has stronger expectations or
beliefs about the dynamic behavior of these models - maybe there is a strong desire on dynamism and specializations on particular dimensions are to be avoided at
all costs, or maybe we just want to catch changes in dynamic behavior with changes to the original model code, or possibly underlying decompositions or meta-kernels.
These changes won’t be detected and the <code class="docutils literal notranslate"><span class="pre">export()</span></code> call will most likely succeed, unless tests are in place that check the resulting <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> representation.</p>
<p>For such cases, our stance is to recommend the “traditional” way of specifying dynamic shapes, which longer-term users of export might be familiar with: named <code class="docutils literal notranslate"><span class="pre">Dims</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="p">(</span><span class="s2">"dx"</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dh</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="p">(</span><span class="s2">"dh"</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"x"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="s2">"y"</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dh</span></a><span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This style of dynamic shapes allows the user to specify what symbols are allocated for input dimensions, min/max bounds on those symbols, and places restrictions on the
dynamic behavior of the <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code> produced; <code class="docutils literal notranslate"><span class="pre">ConstraintViolation</span></code> errors will be raised if model tracing emits guards that conflict with the relations or static/dynamic
specifications given. For example, in the above specification, the following is asserted:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x.shape[0]</span></code> is to have range <code class="docutils literal notranslate"><span class="pre">[4,</span> <span class="pre">256]</span></code>, and related to <code class="docutils literal notranslate"><span class="pre">y.shape[0]</span></code> by <code class="docutils literal notranslate"><span class="pre">y.shape[0]</span> <span class="pre">==</span> <span class="pre">2</span> <span class="pre">*</span> <span class="pre">x.shape[0]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">x.shape[1]</span></code> is static.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">y.shape[1]</span></code> has range <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">512]</span></code>, and is unrelated to any other dimension.</p></li>
</ul>
<p>In this design, we allow relations between dimensions to be specified with univariate linear expressions: <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">*</span> <span class="pre">dim</span> <span class="pre">+</span> <span class="pre">B</span></code> can be specified for any dimension. This allows users
to specify more complex constraints like integer divisibility for dynamic dimensions:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="p">(</span><span class="s2">"dx"</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>
<span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"x"</span><span class="p">:</span> <span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># x.shape[0] has range [16, 2048], and is divisible by 4.</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="constraint-violations-suggested-fixes">
<h3><a class="toc-backref" href="#id10" role="doc-backlink">Constraint violations, suggested fixes</a><a class="headerlink" href="#constraint-violations-suggested-fixes" title="Link to this heading">#</a></h3>
<p>One common issue with this specification style (before <code class="docutils literal notranslate"><span class="pre">Dim.AUTO</span></code> was introduced), is that the specification would often be mismatched with what was produced by model tracing.
That would lead to <code class="docutils literal notranslate"><span class="pre">ConstraintViolation</span></code> errors and export suggested fixes - see for example with this model &amp; specification, where the model inherently requires equality between
dimensions 0 of <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>, and requires dimension 1 to be static.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">w</span></a> <span class="o">+</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dy</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">d1</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-module" href="https://docs.pytorch.org/docs/stable/export.html#module-torch.export" title="torch.export"><span class="n">torch</span><span class="o">.</span><span class="n">export</span></a><span class="o">.</span><span class="n">dims</span><span class="p">(</span><span class="s2">"dx"</span><span class="p">,</span> <span class="s2">"dy"</span><span class="p">,</span> <span class="s2">"d1"</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span>
        <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span>
        <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">)),</span>
        <span class="n">dynamic_shapes</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">"x"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dx</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">d1</span></a><span class="p">),</span>
            <span class="s2">"y"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">dy</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">d1</span></a><span class="p">),</span>
        <span class="p">},</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.805000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.806000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 6 for L['x'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s77" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.808000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s27 = 4 for L['x'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s27" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.809000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.812000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 6 for L['y'].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s17" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
I0917 20:30:34.812000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L['y'].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="s94" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE="0"
V0917 20:30:34.819000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.820000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.821000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.823000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.823000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.824000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
V0917 20:30:34.826000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:34.828000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s27, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s27, s94)"
I0917 20:30:34.829000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s27 (solve) VR[2, int_oo]
I0917 20:30:34.832000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s17) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s77, s17)"
I0917 20:30:34.833000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s77 = s17 (solve) VR[2, int_oo]
V0917 20:30:34.836000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known]
I0917 20:30:34.845000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s27, 4) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="Eq(s27, 4)"
V0917 20:30:34.846000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s27 = VR[4, 4] (update)
I0917 20:30:34.847000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s27 = 4 (range_refined_to_singleton) VR[4, 4]
I0917 20:30:34.852000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.852000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 4] (update)
I0917 20:30:34.853000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = 4 (find) VR[4, 4]
V0917 20:30:34.853000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] s17 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo])
V0917 20:30:34.854000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[1] 4 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo])
V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 4 None
V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[1] 1 None
V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.873000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] s17 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo])
V0917 20:30:34.873000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[1] 4 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo])
V0917 20:30:34.882000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 4 None
V0917 20:30:34.883000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[1] 1 None
V0917 20:30:34.883000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1798, in _export_to_aten_ir_make_fx
    produce_guards_callback(gm)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1944, in _produce_guards_callback
    return produce_guards_and_solve_constraints(
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 549, in produce_guards_and_solve_constraints
    raise constraint_violation_error
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 514, in produce_guards_and_solve_constraints
    shape_env.produce_guards(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5200, in produce_guards
    return self.produce_guards_verbose(*args, **kwargs, langs=("python",))[0].exprs
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5932, in produce_guards_verbose
    raise ConstraintViolationError(
torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (d1, dy)! For more information, run with TORCH_LOGS="+dynamic".
  - You marked d1 as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 557, in &lt;module&gt;
    ep = export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 553, in forward
    return w + torch.ones(4)
  File "??", line 0, in PyNumber_Add
  File "??", line 0, in _Py_c_pow
  File "??", line 0, in PyThread_start_new_thread
  File "??", line 0, in _PyType_LookupId
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add&gt;(_object*, _object*, _object*)
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::add_Tensor::call(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_2.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::add_Tensor&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_2.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2581, in _dispatch_impl
    return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 962, in fast_binary_impl
    final_shape = infer_size(final_shape, shape)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 922, in infer_size
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()

  - You marked d1 as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 557, in &lt;module&gt;
    ep = export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1798, in _export_to_aten_ir_make_fx
    produce_guards_callback(gm)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1944, in _produce_guards_callback
    return produce_guards_and_solve_constraints(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 514, in produce_guards_and_solve_constraints
    shape_env.produce_guards(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5200, in produce_guards
    return self.produce_guards_verbose(*args, **kwargs, langs=("python",))[0].exprs
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5405, in produce_guards_verbose
    expr1, expr2 = get_expression(src1), get_expression(src2)  # type: ignore[]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5399, in get_expression
    return symint.node.expr
  File "??", line 0, in PyObject_GetAttr
  File "??", line 0, in _PyObject_GenericGetAttrWithDict
  File "??", line 0, in PyObject_IsTrue
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 189, in expr
    return self.shape_env.replace(self._expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 2539, in wrapper
    return fn_cache(self, *args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyErr_FormatFromCause
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6324, in replace
    r = self._find(s)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 2539, in wrapper
    return fn_cache(self, *args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyErr_FormatFromCause
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6809, in _find
    self._set_replacement(a, replaced, "find")
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()

  - The values of dy = L['y'].size()[0] and dx = L['x'].size()[0] must always be equal.
Suggested fixes:
  d1 = 4
  dy = dx

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 557, in &lt;module&gt;
    ep = export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1800, in _export_to_aten_ir_make_fx
    raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e))  # noqa: B904
torch._dynamo.exc.UserError: Constraints violated (d1, dy)! For more information, run with TORCH_LOGS="+dynamic".
  - You marked d1 as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 557, in &lt;module&gt;
    ep = export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 553, in forward
    return w + torch.ones(4)
  File "??", line 0, in PyNumber_Add
  File "??", line 0, in _Py_c_pow
  File "??", line 0, in PyThread_start_new_thread
  File "??", line 0, in _PyType_LookupId
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_&lt;&amp;torch::autograd::THPVariable_add&gt;(_object*, _object*, _object*)
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "", line 0, in torch::handle_torch_function(torch::PythonArgs&amp;, _object*, _object*, _object*, _object*, char const*, char const*)
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "??", line 0, in _PyObject_GetDictPtr
  File "python_variable_methods.cpp", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*)
  File "??", line 0, in at::_ops::add_Tensor::call(at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "init.cpp", line 0, in pybind11::cpp_function::initialize&lt;torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}, pybind11::object, pybind11::args const&amp;, pybind11::kwargs const&amp;&gt;(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}&amp;&amp;, pybind11::object (*)(pybind11::args const&amp;, pybind11::kwargs const&amp;))::{lambda(pybind11::detail::function_call&amp;)#1}::_FUN(pybind11::detail::function_call&amp;)
  File "init.cpp", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;)#2}::operator()(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;) const::{lambda(pybind11::args const&amp;, pybind11::kwargs const&amp;)#1}::operator()(pybind11::args const&amp;, pybind11::kwargs const&amp;) const
  File "??", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, c10::Symbol, pybind11::args const&amp;, pybind11::kwargs const&amp;, bool, std::optional&lt;c10::DispatchKey&gt;)
  File "??", line 0, in torch::jit::invokeOperatorFromPython(std::vector&lt;std::shared_ptr&lt;torch::jit::Operator&gt;, std::allocator&lt;std::shared_ptr&lt;torch::jit::Operator&gt; &gt; &gt; const&amp;, pybind11::args const&amp;, pybind11::kwargs const&amp;, std::optional&lt;c10::DispatchKey&gt;)
  File "register_c10_ops.cpp", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const [clone .isra.0]
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in void c10::BoxedKernel::make_boxed_function&lt;&amp;(anonymous namespace)::pythonTLSSnapshotFallback&gt;(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "VariableType_2.cpp", line 0, in c10::impl::make_boxed_from_unboxed_functor&lt;c10::impl::detail::WrapFunctionIntoFunctor_&lt;c10::CompileTimeFunctionPointer&lt;at::Tensor (c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;), &amp;torch::autograd::VariableType::(anonymous namespace)::add_Tensor&gt;, at::Tensor, c10::guts::typelist::typelist&lt;c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;&gt; &gt;, false&gt;::call(c10::OperatorKernel*, c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "VariableType_2.cpp", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "??", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&amp;, at::Tensor const&amp;, c10::Scalar const&amp;)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;&amp;) const
  File "PythonFallbackKernel.cpp", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const&amp;, c10::DispatchKeySet, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*)
  File "PyInterpreter.cpp", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const&amp;, std::vector&lt;c10::IValue, std::allocator&lt;c10::IValue&gt; &gt;*) const
  File "??", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef&lt;_object*&gt;, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName)
  File "??", line 0, in PyObject_CallMethod
  File "??", line 0, in PyModule_AddObjectRef
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2581, in _dispatch_impl
    return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 962, in fast_binary_impl
    final_shape = infer_size(final_shape, shape)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 922, in infer_size
    torch._check(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1684, in _check
    _check_with(RuntimeError, cond, message)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 1647, in _check_with
    if expect_true(cond):
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 1702, in expect_true
    return a.node.expect_true(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 559, in expect_true
    return self.shape_env.guard_or_defer_runtime_assert(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7730, in guard_or_defer_runtime_assert
    self._maybe_guard_rel(expr)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyCodec_EncodeText
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6868, in _maybe_guard_rel
    self._refine_ranges(expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7819, in _refine_ranges
    self._set_replacement(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()

  - You marked d1 as dynamic but your code specialized it to be a constant (4). If you're using mark_dynamic, either remove it or use maybe_mark_dynamic. If you're using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO.

Framework stack:
  File "??", line 0, in _start
  File "??", line 0, in __libc_start_main
  File "??", line 0, in __libc_init_first
  File "??", line 0, in Py_BytesMain
  File "??", line 0, in Py_RunMain
  File "??", line 0, in _PyRun_AnyFileObject
  File "??", line 0, in _PyRun_SimpleFileObject
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyInit__collections
  File "??", line 0, in PyUnicode_Tailmatch
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
    sys.exit(main())
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
    return make_main(argv)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
    return make_mode.run_make_mode(argv[1:])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
    return make.run_generic_build(args[0])
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
    return build_main(args + opts)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
    app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
    self._init_builder()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
    self.events.emit('builder-inited')
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
    results.append(listener.handler(self.app, *args))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
    ) = generate_dir_rst(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
    results = parallel(
  File "??", line 0, in PyUnicode_Decode
  File "??", line 0, in _PyLong_FromByteArray
  File "??", line 0, in PyObject_SelfIter
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
    p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 85, in wrapper
    p.start()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
    return Popen(process_obj)
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in _PyStack_AsDict
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/conf.py", line 73, in call_fn
    result = func(*args, **kwargs)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
    output_blocks, time_elapsed = execute_script(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
    execute_code_block(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
    is_last_expr, mem_max = _exec_and_get_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
    mem_max, _ = call_memory(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
    return 0.0, func()
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyInit__datetime
  File "??", line 0, in _PyObject_Call_Prepend
  File "??", line 0, in _PyObject_FastCallDictTstate
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
    exec(self.code, self.fake_main.__dict__)
  File "??", line 0, in PyCell_New
  File "??", line 0, in PyFrozenSet_New
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in PyEval_EvalCode
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 557, in &lt;module&gt;
    ep = export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1798, in _export_to_aten_ir_make_fx
    produce_guards_callback(gm)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1944, in _produce_guards_callback
    return produce_guards_and_solve_constraints(
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 514, in produce_guards_and_solve_constraints
    shape_env.produce_guards(
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5200, in produce_guards
    return self.produce_guards_verbose(*args, **kwargs, langs=("python",))[0].exprs
  File "??", line 0, in PyObject_Call
  File "??", line 0, in PyMethod_New
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5405, in produce_guards_verbose
    expr1, expr2 = get_expression(src1), get_expression(src2)  # type: ignore[]
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 5399, in get_expression
    return symint.node.expr
  File "??", line 0, in PyObject_GetAttr
  File "??", line 0, in _PyObject_GenericGetAttrWithDict
  File "??", line 0, in PyObject_IsTrue
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 189, in expr
    return self.shape_env.replace(self._expr)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 2539, in wrapper
    return fn_cache(self, *args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyErr_FormatFromCause
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6324, in replace
    r = self._find(s)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 2539, in wrapper
    return fn_cache(self, *args, **kwargs)
  File "??", line 0, in PyObject_Call
  File "??", line 0, in _PyErr_FormatFromCause
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6809, in _find
    self._set_replacement(a, replaced, "find")
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 6768, in _set_replacement
    CapturedTraceback.extract(cpp=True)
  File "??", line 0, in _PyFunction_Vectorcall
  File "??", line 0, in _PyEval_EvalFrameDefault
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py", line 212, in extract
    torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp),
  File "??", line 0, in _PyObject_MakeTpCall
  File "??", line 0, in PyObject_CallFunctionObjArgs
  File "", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*)
  File "", line 0, in pybind11::cpp_function::initialize&lt;std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt;, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v&gt;(std::shared_ptr&lt;torch::CapturedTraceback&gt; (*&amp;)(bool, bool, bool), std::shared_ptr&lt;torch::CapturedTraceback&gt; (*)(bool, bool, bool), pybind11::name const&amp;, pybind11::scope const&amp;, pybind11::sibling const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;, pybind11::arg_v const&amp;)::{lambda(pybind11::detail::function_call&amp;)#3}::operator()(pybind11::detail::function_call&amp;) const
  File "??", line 0, in torch::CapturedTraceback::gather(bool, bool, bool)
  File "??", line 0, in torch::unwind::unwind()

  - The values of dy = L['y'].size()[0] and dx = L['x'].size()[0] must always be equal.
Suggested fixes:
  d1 = 4
  dy = dx

The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<p>The expectation with suggested fixes is that the user can interactively copy-paste the changes into their dynamic shapes specification, and successfully export afterwards.</p>
<p>Lastly, there’s couple nice-to-knows about the options for specification:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> is a good option for static behavior:
- <code class="docutils literal notranslate"><span class="pre">dynamic_shapes=None</span></code> (default) exports with the entire model being static.
- specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> at an input-level exports with all tensor dimensions static, and is also required for non-tensor inputs.
- specifying <code class="docutils literal notranslate"><span class="pre">None</span></code> at a dimension-level specializes that dimension, though this is deprecated in favor of <code class="docutils literal notranslate"><span class="pre">Dim.STATIC</span></code>.</p></li>
<li><p>specifying per-dimension integer values also produces static behavior, and will additionally check that the provided sample input matches the specification.</p></li>
</ul>
<p>These options are combined in the inputs &amp; dynamic shapes spec below:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="mi">16</span><span class="p">,</span>
    <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dynamic_shapes</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"tensor_0"</span><span class="p">:</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch-export-dynamic_shapes sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.dynamic_shapes.Dim" title="torch.export.dynamic_shapes.Dim"><span class="n">Dim</span></a><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="s2">"tensor_1"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">"int_val"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">"bool_val"</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="data-dependent-errors">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Data-dependent errors</a><a class="headerlink" href="#data-dependent-errors" title="Link to this heading">#</a></h2>
<p>While trying to export models, you have may have encountered errors like “Could not guard on data-dependent expression”, or Could not extract specialized integer from data-dependent expression”.
These errors exist because <code class="docutils literal notranslate"><span class="pre">torch.export()</span></code> compiles programs using FakeTensors, which symbolically represent their real tensor counterparts. While these have equivalent symbolic properties
(e.g. sizes, strides, dtypes), they diverge in that FakeTensors do not contain any data values. While this avoids unnecessary memory usage and expensive computation, it does mean that export may be
unable to out-of-the-box compile parts of user code where compilation relies on data values. In short, if the compiler requires a concrete, data-dependent value in order to proceed, it will error out,
complaining that the value is not available.</p>
<p>Data-dependent values appear in many places, and common sources are calls like <code class="docutils literal notranslate"><span class="pre">item()</span></code>, <code class="docutils literal notranslate"><span class="pre">tolist()</span></code>, or <code class="docutils literal notranslate"><span class="pre">torch.unbind()</span></code> that extract scalar values from tensors.
How are these values represented in the exported program? In the <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_export_tutorial.html#constraints-dynamic-shapes">Constraints/Dynamic Shapes</a>
section, we talked about allocating symbols to represent dynamic input dimensions.
The same happens here: we allocate symbols for every data-dependent value that appears in the program. The important distinction is that these are “unbacked” symbols,
in contrast to the “backed” symbols allocated for input dimensions. The <a class="reference external" href="https://pytorch.org/docs/main/export.programming_model.html#basics-of-symbolic-shapes">“backed/unbacked”</a>
nomenclature refers to the presence/absence of a “hint” for the symbol: a concrete value backing the symbol, that can inform the compiler on how to proceed.</p>
<p>In the input shape symbol case (backed symbols), these hints are simply the sample input shapes provided, which explains why control-flow branching is determined by the sample input properties.
For data-dependent values, the symbols are taken from FakeTensor “data” during tracing, and so the compiler doesn’t know the actual values (hints) that these symbols would take on.</p>
<p>Let’s see how these show up in exported programs:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">b</span> <span class="o">+</span> <span class="p">[</span><span class="n">a</span><span class="p">]</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.965000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.970000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:34.970000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
I0917 20:30:34.974000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u1 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:34.974000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u1]
I0917 20:30:34.976000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u2 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:34.976000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u2]
I0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] 2 None
V0917 20:30:34.979000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 1 None
V0917 20:30:34.979000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "i64[]", y: "i64[2]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:618 in forward, code: a = x.item()
            item: "Sym(u0)" = torch.ops.aten.item.default(x);  x = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:619 in forward, code: b = y.tolist()
            unbind = torch.ops.aten.unbind.int(y);  y = None
            getitem: "i64[]" = unbind[0]
            getitem_1: "i64[]" = unbind[1];  unbind = None
            item_1: "Sym(u1)" = torch.ops.aten.item.default(getitem);  getitem = None
            item_2: "Sym(u2)" = torch.ops.aten.item.default(getitem_1);  getitem_1 = None
            return (item_1, item_2, item)

Graph signature:
    # inputs
    x: USER_INPUT
    y: USER_INPUT

    # outputs
    item_1: USER_OUTPUT
    item_2: USER_OUTPUT
    item: USER_OUTPUT

Range constraints: {u0: VR[-int_oo, int_oo], u1: VR[-int_oo, int_oo], u2: VR[-int_oo, int_oo]}
</pre></div>
</div>
<p>The result is that 3 unbacked symbols (notice they’re prefixed with “u”, instead of the usual “s” for input shape/backed symbols) are allocated and returned:
1 for the <code class="docutils literal notranslate"><span class="pre">item()</span></code> call, and 1 for each of the elements of <code class="docutils literal notranslate"><span class="pre">y</span></code> with the <code class="docutils literal notranslate"><span class="pre">tolist()</span></code> call.
Note from the range constraints field that these take on ranges of <code class="docutils literal notranslate"><span class="pre">[-int_oo,</span> <span class="pre">int_oo]</span></code>, not the default <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">int_oo]</span></code> range allocated to input shape symbols,
since we have no information on what these values are - they don’t represent sizes, so don’t necessarily have positive values.</p>
<section id="guards-torch-check">
<h3><a class="toc-backref" href="#id12" role="doc-backlink">Guards, torch._check()</a><a class="headerlink" href="#guards-torch-check" title="Link to this heading">#</a></h3>
<p>But the case above is easy to export, because the concrete values of these symbols aren’t used in any compiler decision-making; all that’s relevant is that the return values are unbacked symbols.
The data-dependent errors highlighted in this section are cases like the following, where <a class="reference external" href="https://pytorch.org/docs/main/export.programming_model.html#control-flow-static-vs-dynamic">data-dependent guards</a> are encountered:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">*</span> <span class="mi">5</span>
</pre></div>
</div>
<p>Here we actually need the “hint”, or the concrete value of <code class="docutils literal notranslate"><span class="pre">a</span></code> for the compiler to decide whether to trace <code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">2</span></code> or <code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">y</span> <span class="pre">*</span> <span class="pre">5</span></code> as the output.
Because we trace with FakeTensors, we don’t know what <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">//</span> <span class="pre">2</span> <span class="pre">&gt;=</span> <span class="pre">5</span></code> actually evaluates to, and export errors out with “Could not guard on data-dependent expression <code class="docutils literal notranslate"><span class="pre">u0</span> <span class="pre">//</span> <span class="pre">2</span> <span class="pre">&gt;=</span> <span class="pre">5</span> <span class="pre">(unhinted)</span></code>”.</p>
<p>So how do we export this toy model? Unlike <code class="docutils literal notranslate"><span class="pre">torch.compile()</span></code>, export requires full graph compilation, and we can’t just graph break on this. Here are some basic options:</p>
<ol class="arabic simple">
<li><p>Manual specialization: we could intervene by selecting the branch to trace, either by removing the control-flow code to contain only the specialized branch, or using <code class="docutils literal notranslate"><span class="pre">torch.compiler.is_compiling()</span></code> to guard what’s traced at compile-time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch.cond()</span></code>: we could rewrite the control-flow code to use <code class="docutils literal notranslate"><span class="pre">torch.cond()</span></code> so we don’t specialize on a branch.</p></li>
</ol>
<p>While these options are valid, they have their pitfalls. Option 1 sometimes requires drastic, invasive rewrites of the model code to specialize, and <code class="docutils literal notranslate"><span class="pre">torch.cond()</span></code> is not a comprehensive system for handling data-dependent errors.
As we will see, there are data-dependent errors that do not involve control-flow.</p>
<p>The generally recommended approach is to start with <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls. While these give the impression of purely being assert statements, they are in fact a system of informing the compiler on properties of symbols.
While a <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> call does act as an assertion at runtime, when traced at compile-time, the checked expression is sent to the symbolic shapes subsystem for reasoning, and any symbol properties that follow from the expression being true,
are stored as symbol properties (provided it’s smart enough to infer those properties). So even if unbacked symbols don’t have hints, if we’re able to communicate properties that are generally true for these symbols via
<code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls, we can potentially bypass data-dependent guards without rewriting the offending model code.</p>
<p>For example in the model above, inserting <code class="docutils literal notranslate"><span class="pre">torch._check(a</span> <span class="pre">&gt;=</span> <span class="pre">10)</span></code> would tell the compiler that <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">+</span> <span class="pre">2</span></code> can always be returned, and <code class="docutils literal notranslate"><span class="pre">torch._check(a</span> <span class="pre">==</span> <span class="pre">4)</span></code> tells it to return <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">*</span> <span class="pre">5</span></code>.
See what happens when we re-export this model.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_check</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_check</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;=</span> <span class="mi">60</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">+</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="o">*</span> <span class="mi">5</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:34.985000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:34.989000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:34.990000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
I0917 20:30:34.992000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 &gt;= 10 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:673 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="u0 &gt;= 10"
V0917 20:30:34.992000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[10, int_oo] (update)
I0917 20:30:34.997000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 &lt;= 60 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:674 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="u0 &lt;= 60"
V0917 20:30:34.997000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[10, 60] (update)
V0917 20:30:35.002000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known]
I0917 20:30:35.005000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] 4 None
V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 1 None
V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:35.008000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &gt;= 10 == True [statically known]
V0917 20:30:35.009000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &lt;= 60 == True [statically known]
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "i64[]", y: "f32[4]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:672 in forward, code: a = x.item()
            item: "Sym(u0)" = torch.ops.aten.item.default(x);  x = None
            ge_2: "Sym(u0 &gt;= 10)" = item &gt;= 10
            _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_2, "Runtime assertion failed for expression u0 &gt;= 10 on node 'ge_2'");  ge_2 = _assert_scalar_default = None
            le_1: "Sym(u0 &lt;= 60)" = item &lt;= 60;  item = None
            _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le_1, "Runtime assertion failed for expression u0 &lt;= 60 on node 'le_1'");  le_1 = _assert_scalar_default_1 = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:676 in forward, code: return y + 2
            add: "f32[4]" = torch.ops.aten.add.Tensor(y, 2);  y = None
            return (add,)

Graph signature:
    # inputs
    x: USER_INPUT
    y: USER_INPUT

    # outputs
    add: USER_OUTPUT

Range constraints: {u0: VR[10, 60]}
</pre></div>
</div>
<p>Export succeeds, and note from the range constraints field that <code class="docutils literal notranslate"><span class="pre">u0</span></code> takes on a range of <code class="docutils literal notranslate"><span class="pre">[10,</span> <span class="pre">60]</span></code>.</p>
<p>So what information do <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls actually communicate? This varies as the symbolic shapes subsystem gets smarter, but at a fundamental level, these are generally true:</p>
<ol class="arabic simple">
<li><p>Equality with non-data-dependent expressions: <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls that communicate equalities like <code class="docutils literal notranslate"><span class="pre">u0</span> <span class="pre">==</span> <span class="pre">s0</span> <span class="pre">+</span> <span class="pre">4</span></code> or <code class="docutils literal notranslate"><span class="pre">u0</span> <span class="pre">==</span> <span class="pre">5</span></code>.</p></li>
<li><p>Range refinement: calls that provide lower or upper bounds for symbols, like the above.</p></li>
<li><p>Some basic reasoning around more complicated expressions: inserting <code class="docutils literal notranslate"><span class="pre">torch._check(a</span> <span class="pre">&lt;</span> <span class="pre">4)</span></code> will typically tell the compiler that <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;=</span> <span class="pre">4</span></code> is false. Checks on complex expressions like <code class="docutils literal notranslate"><span class="pre">torch._check(a</span> <span class="pre">**</span> <span class="pre">2</span> <span class="pre">-</span> <span class="pre">3</span> <span class="pre">*</span> <span class="pre">a</span> <span class="pre">&lt;=</span> <span class="pre">10)</span></code> will typically get you past identical guards.</p></li>
</ol>
<p>As mentioned previously, <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls have applicability outside of data-dependent control flow. For example, here’s a model where <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> insertion
prevails while manual specialization &amp; <code class="docutils literal notranslate"><span class="pre">torch.cond()</span></code> do not:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">[</span><span class="n">a</span><span class="p">]</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">60</span><span class="p">),</span>
<span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.014000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.020000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:35.020000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] Data dependent variable 'u0' allocated at:
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     sys.exit(main())
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_main(argv)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_mode.run_make_mode(argv[1:])
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make.run_generic_build(args[0])
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return build_main(args + opts)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._init_builder()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self.events.emit('builder-inited')
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     results.append(listener.handler(self.app, *args))
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ) = generate_dir_rst(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     results = parallel(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/conf.py", line 85, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     p.start()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._popen = self._Popen(self)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _default_context.get_context().Process._Popen(process_obj)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Popen(process_obj)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._launch(process_obj)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     code = process_obj._bootstrap(parent_sentinel=child_r)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self.run()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._target(*self._args, **self._kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/conf.py", line 73, in call_fn
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     result = func(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     output_blocks, time_elapsed = execute_script(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     execute_code_block(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     is_last_expr, mem_max = _exec_and_get_memory(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     mem_max, _ = call_memory(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return 0.0, func()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     exec(self.code, self.fake_main.__dict__)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 709, in &lt;module&gt;
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     export(Foo(), inps)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _export(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = _export_for_training(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     export_artifact = export_func(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     aten_export_artifact = _to_aten_func(  # type: ignore[operator]
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm, graph_signature = transform(_make_fx_helper)(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm = make_fx(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_fx_tracer.trace(f, *args)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._trace_inner(f, *args)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     t = dispatch_trace(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return disable_fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     res = super().trace(root, concrete_args)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     (self.create_arg(fn(*args)),),
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = f(*tensors)  # type:ignore[call-arg]
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "&lt;string&gt;", line 1, in &lt;lambda&gt;
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return tuple(flat_fn(*args))
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     tree_out = fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = mod(*args[params_len:], **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.call_module(mod, forward, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Tracer.call_module(self, m, forward, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ret_val = forward(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _orig_module_call(mod, *args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._call_impl(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return forward_call(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     tree_out = mod(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.call_module(mod, forward, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Tracer.call_module(self, m, forward, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ret_val = forward(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _orig_module_call(mod, *args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._call_impl(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return forward_call(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 701, in forward
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     a = x.item()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return torch._library.utils.handle_dispatch_mode(
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return proxy_call(self, func, self.pre_dispatch, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = func(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._op(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.dispatch(func, types, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._cached_dispatch_impl(func, types, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1474, in _cached_dispatch_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._dispatch_impl(func, types, args, kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2687, in _dispatch_impl
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     op_impl_out = op_impl(self, func, *args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 163, in dispatch_to_op_implementations_dict
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return op_implementations_dict[func](fake_mode, func, *args, **kwargs)
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 425, in local_scalar_dense
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     r = fake_mode.shape_env.create_unbacked_symint()
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return retlog(fn(*args, **kwargs))
V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519]
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] failed while attempting to run meta for aten.select.int
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] Traceback (most recent call last):
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2717, in _dispatch_impl
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     r = func(*args, **kwargs)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return self._op(*args, **kwargs)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 5545, in meta_select
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     guard_size_oblivious(-index &gt; size) or guard_size_oblivious(index &gt;= size)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 473, in guard_size_oblivious
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return expr.node.guard_size_oblivious("", 0)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 596, in guard_size_oblivious
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     r = self.evaluate(size_oblivious=True)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 512, in evaluate
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return self.shape_env.evaluate_sym_node(self, size_oblivious)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7223, in evaluate_sym_node
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return self.evaluate_expr(
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7323, in evaluate_expr
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return self._inner_evaluate_expr(
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return retlog(fn(*args, **kwargs))
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7346, in _inner_evaluate_expr
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     return self._evaluate_expr(
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7570, in _evaluate_expr
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]     raise self._make_data_dependent_error(
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression -u0 &gt; 60 (unhinted: -u0 &gt; 60).  (Size-like symbols: none)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] Caused by: (_meta_registrations.py:5545 in meta_select)
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For more information, run with TORCH_LOGS="dynamic"
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721]
E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1



def forward(self, arg0_1: "i64[]", arg1_1: "f32[60]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:701 in forward, code: a = x.item()
    item: "Sym(u0)" = torch.ops.aten.item.default(arg0_1);  arg0_1 = None

     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:702 in forward, code: return y[a]
    select = torch.ops.aten.select.int(arg1_1, 0, item);  arg1_1 = item = select = None




def forward(self, arg0_1: "i64[]", arg1_1: "f32[60]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:701 in forward, code: a = x.item()
    item: "Sym(u0)" = torch.ops.aten.item.default(arg0_1);  arg0_1 = None

     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:702 in forward, code: return y[a]
    select = torch.ops.aten.select.int(arg1_1, 0, item);  arg1_1 = item = select = None

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 709, in &lt;module&gt;
    export(Foo(), inps)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 702, in forward
    return y[a]
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1026, in run
    t = _method(t, *_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
    return torch._library.utils.handle_dispatch_mode(
  File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
    return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
    return proxy_call(self, func, self.pre_dispatch, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
    out = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
    return self.dispatch(func, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
    return self._cached_dispatch_impl(func, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1487, in _cached_dispatch_impl
    output = self._dispatch_impl(func, types, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2717, in _dispatch_impl
    r = func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
    return self._op(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py", line 5545, in meta_select
    guard_size_oblivious(-index &gt; size) or guard_size_oblivious(index &gt;= size)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 473, in guard_size_oblivious
    return expr.node.guard_size_oblivious("", 0)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 596, in guard_size_oblivious
    r = self.evaluate(size_oblivious=True)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 512, in evaluate
    return self.shape_env.evaluate_sym_node(self, size_oblivious)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7223, in evaluate_sym_node
    return self.evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7323, in evaluate_expr
    return self._inner_evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7346, in _inner_evaluate_expr
    return self._evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7570, in _evaluate_expr
    raise self._make_data_dependent_error(
torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression -u0 &gt; 60 (unhinted: -u0 &gt; 60).  (Size-like symbols: none)

Caused by: (_meta_registrations.py:5545 in meta_select)
For more information, run with TORCH_LOGS="dynamic"
For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"
If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing

For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1

The following call raised this error:
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 702, in forward
    return y[a]

To fix the error, insert one of the following checks before this call:
  1. torch._check((-1)*a &gt; 60)
  2. torch._check((-1)*a &lt;= 60)

(These suggested fixes were derived by replacing `u0` with a in -u0 &gt; 60 and its negation.)

The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<p>Here is a scenario where <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> insertion is required simply to prevent an operation from failing. The export call will fail with
“Could not guard on data-dependent expression <code class="docutils literal notranslate"><span class="pre">-u0</span> <span class="pre">&gt;</span> <span class="pre">60</span></code>”, implying that the compiler doesn’t know if this is a valid indexing operation -
if the value of <code class="docutils literal notranslate"><span class="pre">x</span></code> is out-of-bounds for <code class="docutils literal notranslate"><span class="pre">y</span></code> or not. Here, manual specialization is too prohibitive, and <code class="docutils literal notranslate"><span class="pre">torch.cond()</span></code> has no place.
Instead, informing the compiler of <code class="docutils literal notranslate"><span class="pre">u0</span></code>’s range is sufficient:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_check</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_check</span><span class="p">(</span><span class="n">a</span> <span class="o">&lt;</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">y</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">[</span><span class="n">a</span><span class="p">]</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">60</span><span class="p">),</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.046000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.051000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:35.052000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
I0917 20:30:35.053000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 &gt;= 0 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:722 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="u0 &gt;= 0"
V0917 20:30:35.054000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, int_oo] (update)
I0917 20:30:35.057000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 &lt; 60 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:723 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="u0 &lt; 60"
V0917 20:30:35.057000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, 59] (update)
V0917 20:30:35.060000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(-u0 &gt; 60) == False [statically known]
V0917 20:30:35.060000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(u0 &gt;= 60) == False [statically known]
V0917 20:30:35.061000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known]
V0917 20:30:35.062000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known]
I0917 20:30:35.064000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:35.064000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] 60 None
V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 1 None
V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:35.066000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &gt;= 0 == True [statically known]
V0917 20:30:35.068000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &lt;= 59 == True [statically known]
V0917 20:30:35.069000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &lt; 60 == True [statically known]
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "i64[]", y: "f32[60]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:721 in forward, code: a = x.item()
            item: "Sym(u0)" = torch.ops.aten.item.default(x);  x = None
            ge_1: "Sym(u0 &gt;= 0)" = item &gt;= 0
            _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_1, "Runtime assertion failed for expression u0 &gt;= 0 on node 'ge_1'");  ge_1 = _assert_scalar_default = None
            le: "Sym(u0 &lt;= 59)" = item &lt;= 59
            _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le, "Runtime assertion failed for expression u0 &lt;= 59 on node 'le'");  le = _assert_scalar_default_1 = None

             #
            lt_1: "Sym(u0 &lt; 60)" = item &lt; 60
            _assert_scalar_default_2 = torch.ops.aten._assert_scalar.default(lt_1, "Runtime assertion failed for expression u0 &lt; 60 on node 'lt_1'");  lt_1 = _assert_scalar_default_2 = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:724 in forward, code: return y[a]
            select: "f32[]" = torch.ops.aten.select.int(y, 0, item);  y = item = None
            return (select,)

Graph signature:
    # inputs
    x: USER_INPUT
    y: USER_INPUT

    # outputs
    select: USER_OUTPUT

Range constraints: {u0: VR[0, 59]}
</pre></div>
</div>
</section>
<section id="specialized-values">
<h3><a class="toc-backref" href="#id13" role="doc-backlink">Specialized values</a><a class="headerlink" href="#specialized-values" title="Link to this heading">#</a></h3>
<p>Another category of data-dependent error happens when the program attempts to extract a concrete data-dependent integer/float value
while tracing. This looks something like “Could not extract specialized integer from data-dependent expression”, and is analogous to
the previous class of errors - if these occur when attempting to evaluate concrete integer/float values, data-dependent guard errors arise
with evaluating concrete boolean values.</p>
<p>This error typically occurs when there is an explicit or implicit <code class="docutils literal notranslate"><span class="pre">int()</span></code> cast on a data-dependent expression. For example, this list comprehension
has a <cite>range()</cite> call that implicitly does an <code class="docutils literal notranslate"><span class="pre">int()</span></code> cast on the size of the list:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">([</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="k">for</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">b</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">60</span><span class="p">),</span>
<span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.075000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.081000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:35.082000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] Data dependent variable 'u0' allocated at:
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/bin/sphinx-build", line 7, in &lt;module&gt;
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     sys.exit(main())
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 339, in main
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_main(argv)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 213, in make_main
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_mode.run_make_mode(argv[1:])
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 181, in run_make_mode
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make.run_generic_build(args[0])
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py", line 169, in run_generic_build
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return build_main(args + opts)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py", line 293, in build_main
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     app = Sphinx(args.sourcedir, args.confdir, args.outputdir,
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 272, in __init__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._init_builder()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/application.py", line 343, in _init_builder
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self.events.emit('builder-inited')
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx/events.py", line 97, in emit
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     results.append(listener.handler(self.app, *args))
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py", line 757, in generate_gallery_rst
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ) = generate_dir_rst(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 606, in generate_dir_rst
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     results = parallel(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 607, in &lt;genexpr&gt;
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/conf.py", line 85, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     p.start()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 121, in start
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._popen = self._Popen(self)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/context.py", line 224, in _Popen
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _default_context.get_context().Process._Popen(process_obj)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/context.py", line 281, in _Popen
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Popen(process_obj)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 19, in __init__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._launch(process_obj)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/popen_fork.py", line 71, in _launch
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     code = process_obj._bootstrap(parent_sentinel=child_r)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self.run()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     self._target(*self._args, **self._kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/conf.py", line 73, in call_fn
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     result = func(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1374, in generate_file_rst
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     output_blocks, time_elapsed = execute_script(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1192, in execute_script
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     execute_code_block(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1048, in execute_code_block
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     is_last_expr, mem_max = _exec_and_get_memory(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 876, in _exec_and_get_memory
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     mem_max, _ = call_memory(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 1725, in _sg_call_memory_noop
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return 0.0, func()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py", line 794, in __call__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     exec(self.code, self.fake_main.__dict__)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 756, in &lt;module&gt;
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     export(Foo(), inps, strict=False)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _export(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = _export_for_training(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ep = fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     export_artifact = export_func(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     aten_export_artifact = _to_aten_func(  # type: ignore[operator]
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm, graph_signature = transform(_make_fx_helper)(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     gm = make_fx(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return make_fx_tracer.trace(f, *args)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._trace_inner(f, *args)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     t = dispatch_trace(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return disable_fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     res = super().trace(root, concrete_args)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     (self.create_arg(fn(*args)),),
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = f(*tensors)  # type:ignore[call-arg]
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "&lt;string&gt;", line 1, in &lt;lambda&gt;
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return tuple(flat_fn(*args))
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     tree_out = fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = mod(*args[params_len:], **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.call_module(mod, forward, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Tracer.call_module(self, m, forward, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ret_val = forward(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _orig_module_call(mod, *args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._call_impl(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return forward_call(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     tree_out = mod(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.call_module(mod, forward, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return Tracer.call_module(self, m, forward, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     ret_val = forward(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return _orig_module_call(mod, *args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._call_impl(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return forward_call(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 747, in forward
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     a = x.item()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1360, in __torch_function__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1407, in __torch_function__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py", line 1051, in __torch_function__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return func(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 950, in handler
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return torch._library.utils.handle_dispatch_mode(
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py", line 296, in handle_dispatch_mode
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1462, in __torch_dispatch__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return proxy_call(self, func, self.pre_dispatch, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 914, in proxy_call
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     out = func(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_ops.py", line 829, in __call__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._op(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py", line 28, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return fn(*args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1352, in __torch_dispatch__
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self.dispatch(func, types, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2058, in dispatch
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._cached_dispatch_impl(func, types, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 1474, in _cached_dispatch_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return self._dispatch_impl(func, types, args, kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py", line 2687, in _dispatch_impl
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     op_impl_out = op_impl(self, func, *args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 163, in dispatch_to_op_implementations_dict
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return op_implementations_dict[func](fake_mode, func, *args, **kwargs)
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py", line 425, in local_scalar_dense
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     r = fake_mode.shape_env.create_unbacked_symint()
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]   File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]     return retlog(fn(*args, **kwargs))
V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519]



def forward(self, arg0_1: "i64[]", arg1_1: "f32[60]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:747 in forward, code: a = x.item()
    item: "Sym(u0)" = torch.ops.aten.item.default(arg0_1);  arg0_1 = item = None




def forward(self, arg0_1: "i64[]", arg1_1: "f32[60]"):
     # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:747 in forward, code: a = x.item()
    item: "Sym(u0)" = torch.ops.aten.item.default(arg0_1);  arg0_1 = item = None

Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 756, in &lt;module&gt;
    export(Foo(), inps, strict=False)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 319, in export
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py", line 286, in export
    return _export(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2176, in _export
    ep = _export_for_training(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1164, in wrapper
    raise e
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1130, in wrapper
    ep = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py", line 123, in wrapper
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 2037, in _export_for_training
    export_artifact = export_func(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1979, in _non_strict_export
    aten_export_artifact = _to_aten_func(  # type: ignore[operator]
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1770, in _export_to_aten_ir_make_fx
    gm, graph_signature = transform(_make_fx_helper)(
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1900, in _aot_export_non_strict
    gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1685, in _make_fx_helper
    gm = make_fx(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2318, in wrapped
    return make_fx_tracer.trace(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2250, in trace
    return self._trace_inner(f, *args)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 2221, in _trace_inner
    t = dispatch_trace(
  File "/usr/local/lib/python3.10/dist-packages/torch/_compile.py", line 53, in inner
    return disable_fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1254, in dispatch_trace
    graph = tracer.trace(root, concrete_args)  # type: ignore[arg-type]
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1835, in trace
    res = super().trace(root, concrete_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 929, in _fn
    return fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 850, in trace
    (self.create_arg(fn(*args)),),
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1312, in wrapped
    out = f(*tensors)  # type:ignore[call-arg]
  File "&lt;string&gt;", line 1, in &lt;lambda&gt;
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1589, in wrapped_fn
    return tuple(flat_fn(*args))
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 184, in flat_fn
    tree_out = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py", line 906, in functional_call
    out = mod(*args[params_len:], **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py", line 1884, in forward
    tree_out = mod(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 825, in module_call_wrapper
    return self.call_module(mod, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py", line 1905, in call_module
    return Tracer.call_module(self, m, forward, args, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 542, in call_module
    ret_val = forward(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py", line 818, in forward
    return _orig_module_call(mod, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
  File "/var/lib/workspace/intermediate_source/torch_export_tutorial.py", line 748, in forward
    b = torch.cat([y for y in range(a)], dim=0)
  File "/usr/local/lib/python3.10/dist-packages/torch/__init__.py", line 438, in __index__
    return self.node.int_()
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 468, in int_
    return self.guard_int("", 0)  # NB: uses Python backtrace
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 518, in guard_int
    r = self.evaluate()
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py", line 512, in evaluate
    return self.shape_env.evaluate_sym_node(self, size_oblivious)
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7223, in evaluate_sym_node
    return self.evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7323, in evaluate_expr
    return self._inner_evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py", line 272, in wrapper
    return retlog(fn(*args, **kwargs))
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7346, in _inner_evaluate_expr
    return self._evaluate_expr(
  File "/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py", line 7570, in _evaluate_expr
    raise self._make_data_dependent_error(
torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not extract specialized integer from data-dependent expression u0 (unhinted: u0).  (Size-like symbols: none)

Caused by: (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:748 in forward)
For more information, run with TORCH_LOGS="dynamic"
For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL="u0"
If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing

For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1

The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`.
</pre></div>
</div>
<p>For these errors, some basic options you have are:</p>
<ol class="arabic simple">
<li><p>Avoid unnecessary <code class="docutils literal notranslate"><span class="pre">int()</span></code> cast calls, in this case the <code class="docutils literal notranslate"><span class="pre">int(a)</span></code> in the return statement.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">torch._check()</span></code> calls; unfortunately all you may be able to do in this case is specialize (with <code class="docutils literal notranslate"><span class="pre">torch._check(a</span> <span class="pre">==</span> <span class="pre">60)</span></code>).</p></li>
<li><p>Rewrite the offending code at a higher level. For example, the list comprehension is semantically a <code class="docutils literal notranslate"><span class="pre">repeat()</span></code> op, which doesn’t involve an <code class="docutils literal notranslate"><span class="pre">int()</span></code> cast. The following rewrite avoids data-dependent errors:</p></li>
</ol>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Foo</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">b</span> <span class="o">+</span> <span class="n">a</span>

<span class="n">inps</span> <span class="o">=</span> <span class="p">(</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor" title="torch.tensor"><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span></a><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">60</span><span class="p">),</span>
<span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">Foo</span></a><span class="p">(),</span> <span class="n">inps</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.101000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.106000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense)
I0917 20:30:35.106000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0]
I0917 20:30:35.110000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 &gt;= 0 [guard added] (_meta_registrations.py:4247 in meta_repeat), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED="u0 &gt;= 0"
V0917 20:30:35.110000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, int_oo] (update)
V0917 20:30:35.111000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &gt;= 0 == True [statically known]
I0917 20:30:35.114000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate Eq(u0, 0) due to data dependency, it was assumed to be False with no runtime assertions (utils/_stats.py:28 in wrapper)
I0917 20:30:35.114000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
I0917 20:30:35.120000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate 60*u0 &lt; 2 due to data dependency, it was assumed to be False with no runtime assertions (_prims_common/__init__.py:279 in is_contiguous)
I0917 20:30:35.120000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
I0917 20:30:35.121000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate Eq(u0, 1) due to data dependency, it was assumed to be False with no runtime assertions (_prims_common/__init__.py:285 in is_contiguous)
I0917 20:30:35.121000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1
V0917 20:30:35.123000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known]
I0917 20:30:35.128000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:35.128000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].size()[0] 60 None
V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].stride()[0] 1 None
V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['y'].storage_offset() 0 None
V0917 20:30:35.130000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 &gt;= 0 == True [statically known]
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "i64[]", y: "f32[60]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:769 in forward, code: a = x.item()
            item: "Sym(u0)" = torch.ops.aten.item.default(x);  x = None

             #
            sym_constrain_range_for_size_default = torch.ops.aten.sym_constrain_range_for_size.default(item);  sym_constrain_range_for_size_default = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:769 in forward, code: a = x.item()
            ge: "Sym(u0 &gt;= 0)" = item &gt;= 0
            _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge, "Runtime assertion failed for expression u0 &gt;= 0 on node 'ge'");  ge = _assert_scalar_default = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:770 in forward, code: b = y.unsqueeze(0).repeat(a, 1)
            unsqueeze: "f32[1, 60]" = torch.ops.aten.unsqueeze.default(y, 0);  y = None
            repeat: "f32[u0, 60]" = torch.ops.aten.repeat.default(unsqueeze, [item, 1]);  unsqueeze = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:771 in forward, code: return b + a
            add: "f32[u0, 60]" = torch.ops.aten.add.Tensor(repeat, item);  repeat = item = None
            return (add,)

Graph signature:
    # inputs
    x: USER_INPUT
    y: USER_INPUT

    # outputs
    add: USER_OUTPUT

Range constraints: {u0: VR[0, int_oo]}
</pre></div>
</div>
<p>Data-dependent errors can be much more involved, and there are many more options in your toolkit to deal with them: <code class="docutils literal notranslate"><span class="pre">torch._check_is_size()</span></code>, <code class="docutils literal notranslate"><span class="pre">guard_size_oblivious()</span></code>, or real-tensor tracing, as starters.
For more in-depth guides, please refer to the <a class="reference external" href="https://pytorch.org/docs/main/export.programming_model.html">Export Programming Model</a>,
or <a class="reference external" href="https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs">Dealing with GuardOnDataDependentSymNode errors</a>.</p>
</section>
</section>
<section id="custom-ops">
<h2><a class="toc-backref" href="#id14" role="doc-backlink">Custom Ops</a><a class="headerlink" href="#custom-ops" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> can export PyTorch programs with custom operators. Please
refer to <a class="reference external" href="https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html">this page</a>
on how to author a custom operator in either C++ or Python.</p>
<p>The following is an example of registering a custom operator in python to be
used by <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>. The important thing to note is that the custom op
must have a <a class="reference external" href="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit?tab=t.0#heading=h.xvrg7clz290">FakeTensor kernel</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nd">@torch</span><span class="o">.</span><span class="n">library</span><span class="o">.</span><span class="n">custom_op</span><span class="p">(</span><span class="s2">"my_custom_library::custom_op"</span><span class="p">,</span> <span class="n">mutates_args</span><span class="o">=</span><span class="p">{})</span>
<span class="k">def</span><span class="w"> </span><span class="nf">custom_op</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">)</span> <span class="o">-&gt;</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span></a><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"custom_op called!"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>

<span class="nd">@custom_op</span><span class="o">.</span><span class="n">register_fake</span>
<span class="k">def</span><span class="w"> </span><span class="nf">custom_op_meta</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
    <span class="c1"># Returns an empty tensor with the same shape as the expected output</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.empty_like.html#torch.empty_like" title="torch.empty_like"><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
</pre></div>
</div>
<p>Here is an example of exporting a program with the custom op.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CustomOpExample</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">my_custom_library</span><span class="o">.</span><span class="n">custom_op</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a>

<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_custom_op_example</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">export</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">CustomOpExample</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">exported_custom_op_example</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">exported_custom_op_example</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.206000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.216000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:35.216000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] 3 None
V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[1] 3 None
V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 3 None
V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[1] 1 None
V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
ExportedProgram:
    class GraphModule(torch.nn.Module):
        def forward(self, x: "f32[3, 3]"):
             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:812 in forward, code: x = torch.sin(x)
            sin: "f32[3, 3]" = torch.ops.aten.sin.default(x);  x = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:813 in forward, code: x = torch.ops.my_custom_library.custom_op(x)
            custom_op: "f32[3, 3]" = torch.ops.my_custom_library.custom_op.default(sin);  sin = None

             # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:814 in forward, code: x = torch.cos(x)
            cos: "f32[3, 3]" = torch.ops.aten.cos.default(custom_op);  custom_op = None
            return (cos,)

Graph signature:
    # inputs
    x: USER_INPUT

    # outputs
    cos: USER_OUTPUT

Range constraints: {}

custom_op called!
tensor([[1.0000, 0.6898, 1.0000],
        [0.7006, 0.9948, 0.9682],
        [1.0000, 0.9950, 1.0000]])
</pre></div>
</div>
<p>Note that in the <code class="docutils literal notranslate"><span class="pre">ExportedProgram</span></code>, the custom operator is included in the graph.</p>
</section>
<section id="ir-decompositions">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">IR/Decompositions</a><a class="headerlink" href="#ir-decompositions" title="Link to this heading">#</a></h2>
<p>The graph produced by <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> returns a graph containing only
<a class="reference external" href="https://pytorch.org/cppdocs/#aten">ATen operators</a>, which are the
basic unit of computation in PyTorch. As there are over 3000 ATen operators,
export provides a way to narrow down the operator set used in the graph based
on certain characteristics, creating different IRs.</p>
<p>By default, export produces the most generic IR which contains all ATen
operators, including both functional and non-functional operators. A functional
operator is one that does not contain any mutations or aliasing of the inputs.
You can find a list of all ATen operators
<a class="reference external" href="https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml">here</a>
and you can inspect if an operator is functional by checking
<code class="docutils literal notranslate"><span class="pre">op._schema.is_mutable</span></code>, for example:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">add</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">is_mutable</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">add_</span><span class="o">.</span><span class="n">Tensor</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">is_mutable</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>False
True
</pre></div>
</div>
<p>This generic IR can be used to train in eager PyTorch Autograd. This IR can be
more explicitly reached through the API <code class="docutils literal notranslate"><span class="pre">torch.export.export_for_training</span></code>,
which was introduced in PyTorch 2.5, but calling <code class="docutils literal notranslate"><span class="pre">torch.export.export</span></code>
should produce the same graph as of PyTorch 2.6.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">DecompExample</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="torch.nn.Conv2d"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" title="torch.nn.BatchNorm2d"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span></a><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,)</span>

<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep_for_training</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-module" href="https://docs.pytorch.org/docs/stable/export.html#module-torch.export" title="torch.export"><span class="n">torch</span><span class="o">.</span><span class="n">export</span></a><span class="o">.</span><span class="n">export_for_training</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">DecompExample</span></a><span class="p">(),</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),))</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph"><span class="n">ep_for_training</span><span class="o">.</span><span class="n">graph</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:35.227000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:35.257000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] 1 None
V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[1] 1 None
V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[2] 3 None
V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[3] 3 None
V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 9 None
V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[1] 9 None
V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[2] 3 None
V0917 20:30:35.260000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[3] 1 None
V0917 20:30:35.260000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
graph():
    %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight]
    %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias]
    %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight]
    %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias]
    %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean]
    %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var]
    %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked]
    %x : [num_users=1] = placeholder[target=x]
    %conv2d : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%x, %p_conv_weight, %p_conv_bias), kwargs = {})
    %add_ : [num_users=0] = call_function[target=torch.ops.aten.add_.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {})
    %batch_norm : [num_users=1] = call_function[target=torch.ops.aten.batch_norm.default](args = (%conv2d, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05, True), kwargs = {})
    return (batch_norm,)
</pre></div>
</div>
<p>We can then lower this exported program to an operator set which only contains
functional ATen operators through the API <code class="docutils literal notranslate"><span class="pre">run_decompositions</span></code>, which
decomposes the ATen operators into the ones specified in the decomposition
table, and functionalizes the graph. By specifying an empty set, we’re only
performing functionalization, and does not do any additional decompositions.
This results in an IR which contains ~2000 operators (instead of the 3000
operators above), and is ideal for inference cases.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep_for_inference</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.run_decompositions" title="torch.export.ExportedProgram.run_decompositions"><span class="n">ep_for_training</span><span class="o">.</span><span class="n">run_decompositions</span></a><span class="p">(</span><span class="n">decomp_table</span><span class="o">=</span><span class="p">{})</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph"><span class="n">ep_for_inference</span><span class="o">.</span><span class="n">graph</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight]
    %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias]
    %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight]
    %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias]
    %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean]
    %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var]
    %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked]
    %x : [num_users=1] = placeholder[target=x]
    %conv2d : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%x, %p_conv_weight, %p_conv_bias), kwargs = {})
    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {})
    %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%conv2d, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {})
    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {})
    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {})
    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {})
    return (getitem_3, getitem_4, add, getitem)
</pre></div>
</div>
<p>As we can see, the previously mutable operator,
<code class="docutils literal notranslate"><span class="pre">torch.ops.aten.add_.default</span></code> has now been replaced with
<code class="docutils literal notranslate"><span class="pre">torch.ops.aten.add.default</span></code>, a l operator.</p>
<p>We can also further lower this exported program to an operator set which only
contains the
<a class="reference external" href="https://pytorch.org/docs/main/torch.compiler_ir.html#core-aten-ir">Core ATen Operator Set</a>,
which is a collection of only ~180 operators. This IR is optimal for backends
who do not want to reimplement all ATen operators.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch.export</span><span class="w"> </span><span class="kn">import</span> <span class="n">default_decompositions</span>

<a class="sphx-glr-backref-module-torch-export-decomp_utils sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.decomp_utils.CustomDecompTable" title="torch.export.decomp_utils.CustomDecompTable"><span class="n">core_aten_decomp_table</span></a> <span class="o">=</span> <span class="n">default_decompositions</span><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">core_aten_ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.run_decompositions" title="torch.export.ExportedProgram.run_decompositions"><span class="n">ep_for_training</span><span class="o">.</span><span class="n">run_decompositions</span></a><span class="p">(</span><span class="n">decomp_table</span><span class="o">=</span><a class="sphx-glr-backref-module-torch-export-decomp_utils sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.decomp_utils.CustomDecompTable" title="torch.export.decomp_utils.CustomDecompTable"><span class="n">core_aten_decomp_table</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph"><span class="n">core_aten_ep</span><span class="o">.</span><span class="n">graph</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight]
    %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias]
    %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight]
    %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias]
    %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean]
    %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var]
    %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked]
    %x : [num_users=1] = placeholder[target=x]
    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%x, %p_conv_weight, %p_conv_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})
    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {})
    %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%convolution, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {})
    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {})
    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {})
    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {})
    return (getitem_3, getitem_4, add, getitem)
</pre></div>
</div>
<p>We now see that <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.conv2d.default</span></code> has been decomposed
into <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.convolution.default</span></code>. This is because <code class="docutils literal notranslate"><span class="pre">convolution</span></code>
is a more “core” operator, as operations like <code class="docutils literal notranslate"><span class="pre">conv1d</span></code> and <code class="docutils literal notranslate"><span class="pre">conv2d</span></code> can be
implemented using the same op.</p>
<p>We can also specify our own decomposition behaviors:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch-export-decomp_utils sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.decomp_utils.CustomDecompTable" title="torch.export.decomp_utils.CustomDecompTable"><span class="n">my_decomp_table</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-module" href="https://docs.pytorch.org/docs/stable/export.html#module-torch.export" title="torch.export"><span class="n">torch</span><span class="o">.</span><span class="n">export</span></a><span class="o">.</span><span class="n">default_decompositions</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">my_awesome_custom_conv2d_function</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dilation</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">convolution</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">groups</span><span class="p">)</span>

<a class="sphx-glr-backref-module-torch-export-decomp_utils sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.decomp_utils.CustomDecompTable" title="torch.export.decomp_utils.CustomDecompTable"><span class="n">my_decomp_table</span></a><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">aten</span><span class="o">.</span><span class="n">conv2d</span><span class="o">.</span><span class="n">default</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_awesome_custom_conv2d_function</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">my_ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.run_decompositions" title="torch.export.ExportedProgram.run_decompositions"><span class="n">ep_for_training</span><span class="o">.</span><span class="n">run_decompositions</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-export-decomp_utils sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.decomp_utils.CustomDecompTable" title="torch.export.decomp_utils.CustomDecompTable"><span class="n">my_decomp_table</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-attribute" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.graph" title="torch.export.ExportedProgram.graph"><span class="n">my_ep</span><span class="o">.</span><span class="n">graph</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>graph():
    %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight]
    %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias]
    %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight]
    %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias]
    %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean]
    %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var]
    %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked]
    %x : [num_users=1] = placeholder[target=x]
    %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%x, %p_conv_weight, %p_conv_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {})
    %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution, 2), kwargs = {})
    %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {})
    %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%mul, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {})
    %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {})
    %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {})
    %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {})
    return (getitem_3, getitem_4, add, getitem)
</pre></div>
</div>
<p>Notice that instead of <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.conv2d.default</span></code> being decomposed
into <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.convolution.default</span></code>, it is now decomposed into
<code class="docutils literal notranslate"><span class="pre">torch.ops.aten.convolution.default</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.ops.aten.mul.Tensor</span></code>,
which matches our custom decomposition rule.</p>
</section>
<section id="exportdb">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">ExportDB</a><a class="headerlink" href="#exportdb" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> will only ever export a single computation graph from a PyTorch program. Because of this requirement,
there will be Python or PyTorch features that are not compatible with <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>, which will require users to
rewrite parts of their model code. We have seen examples of this earlier in the tutorial – for example, rewriting
if-statements using <code class="docutils literal notranslate"><span class="pre">cond</span></code>.</p>
<p><a class="reference external" href="https://pytorch.org/docs/main/generated/exportdb/index.html">ExportDB</a> is the standard reference that documents
supported and unsupported Python/PyTorch features for <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>. It is essentially a list a program samples, each
of which represents the usage of one particular Python/PyTorch feature and its interaction with <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.
Examples are also tagged by category so that they can be more easily searched.</p>
<p>For example, let’s use ExportDB to get a better understanding of how the predicate works in the <code class="docutils literal notranslate"><span class="pre">cond</span></code> operator.
We can look at the example called <code class="docutils literal notranslate"><span class="pre">cond_predicate</span></code>, which has a <code class="docutils literal notranslate"><span class="pre">torch.cond</span></code> tag. The example code looks like:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">cond_predicate</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    The conditional statement (aka predicate) passed to ``cond()`` must be one of the following:</span>
<span class="sd">    - ``torch.Tensor`` with a single element</span>
<span class="sd">    - boolean expression</span>
<span class="sd">    NOTE: If the `pred` is test on a dim with batch size &lt; 2, it will be specialized.</span>
<span class="sd">    """</span>
    <span class="n">pred</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="ow">and</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/size.html#torch.Size" title="torch.Size"><span class="n">x</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">10</span>
    <span class="k">return</span> <span class="n">cond</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="k">lambda</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="o">.</span><span class="n">cos</span><span class="p">(),</span> <span class="k">lambda</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="p">:</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">y</span></a><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="p">[</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">])</span>
</pre></div>
</div>
<p>More generally, ExportDB can be used as a reference when one of the following occurs:</p>
<ol class="arabic simple">
<li><p>Before attempting <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>, you know ahead of time that your model uses some tricky Python/PyTorch features
and you want to know if <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> covers that feature.</p></li>
<li><p>When attempting <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>, there is a failure and it’s unclear how to work around it.</p></li>
</ol>
<p>ExportDB is not exhaustive, but is intended to cover all use cases found in typical PyTorch code. Feel free to reach
out if there is an important Python/PyTorch feature that should be added to ExportDB or supported by <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.</p>
</section>
<section id="running-the-exported-program">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Running the Exported Program</a><a class="headerlink" href="#running-the-exported-program" title="Link to this heading">#</a></h2>
<p>As <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> is only a graph capturing mechanism, calling the artifact
produced by <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> eagerly will be equivalent to running the eager
module. To optimize the execution of the Exported Program, we can pass this
exported artifact to backends such as Inductor through <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>,
<a class="reference external" href="https://pytorch.org/docs/main/torch.compiler_aot_inductor.html">AOTInductor</a>,
or <a class="reference external" href="https://pytorch.org/TensorRT/dynamo/dynamo_export.html">TensorRT</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">M</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">):</span>
        <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a><span class="p">)</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">x</span></a>

<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">M</span></a><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">"cuda"</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.export" title="torch.export.export"><span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span></a><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">,))</span>

<span class="c1"># Run it eagerly</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">res</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">ep</span><span class="o">.</span><span class="n">module</span></a><span class="p">()(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">res</span></a><span class="p">)</span>

<span class="c1"># Run it with torch.compile</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">res</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram.module" title="torch.export.ExportedProgram.module"><span class="n">ep</span><span class="o">.</span><span class="n">module</span></a><span class="p">(),</span> <span class="n">backend</span><span class="o">=</span><span class="s2">"inductor"</span><span class="p">)(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">res</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>I0917 20:30:36.192000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env
I0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards
V0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[0] 2 None
V0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].size()[1] 3 None
V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[0] 3 None
V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].stride()[1] 1 None
V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L['x'].storage_offset() 0 None
tensor([[-0.0818,  0.3067,  0.4360],
        [-0.0191,  0.2972,  0.4662]], device='cuda:0',
       grad_fn=&lt;AddmmBackward0&gt;)
I0917 20:30:37.613000 31631 torch/fx/experimental/symbolic_shapes.py:3767] [2/0] create_env
/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:282: UserWarning:

TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.

I0917 20:30:38.330000 31631 torch/fx/experimental/symbolic_shapes.py:5238] [2/0] produce_guards
I0917 20:30:38.339000 31631 torch/fx/experimental/symbolic_shapes.py:5238] [2/0] produce_guards
V0917 20:30:38.339000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['x'].size()[0] 2 None
V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['x'].size()[1] 3 None
V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['x'].stride()[0] 3 None
V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['x'].stride()[1] 1 None
V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['x'].storage_offset() 0 None
V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['weight'].size()[0] 3 None
V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['weight'].size()[1] 3 None
V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['weight'].stride()[0] 3 None
V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['weight'].stride()[1] 1 None
V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['weight'].storage_offset() 0 None
V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['bias'].size()[0] 3 None
V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['bias'].stride()[0] 1 None
V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L['self']._modules['linear']._parameters['bias'].storage_offset() 0 None
V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['x'].size()[0] == 2
V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['x'].size()[1] == 3
V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['x'].stride()[0] == 3
V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['x'].stride()[1] == 1
V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['x'].storage_offset() == 0
V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['weight'].size()[0] == 3
V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['weight'].size()[1] == 3
V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['weight'].stride()[0] == 3
V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['weight'].stride()[1] == 1
V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['weight'].storage_offset() == 0
V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['bias'].size()[0] == 3
V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['bias'].stride()[0] == 1
V0917 20:30:38.346000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L['self']._modules['linear']._parameters['bias'].storage_offset() == 0
tensor([[-0.0818,  0.3067,  0.4360],
        [-0.0191,  0.2972,  0.4662]], device='cuda:0',
       grad_fn=&lt;CompiledFunctionBackward&gt;)
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch._inductor</span>

<span class="c1"># Note: these APIs are subject to change</span>
<span class="c1"># Compile the exported program to a PT2 archive using ``AOTInductor``</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">pt2_path</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">aoti_compile_and_package</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-export sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/export.html#torch.export.ExportedProgram" title="torch.export.ExportedProgram"><span class="n">ep</span></a><span class="p">)</span>

<span class="c1"># Load and run the .so file in Python.</span>
<span class="c1"># To load and run it in a C++ environment, see:</span>
<span class="c1"># https://pytorch.org/docs/main/torch.compiler_aot_inductor.html</span>
<span class="n">aoti_compiled</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">aoti_load_package</span><span class="p">(</span><span class="n">pt2_path</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">res</span></a> <span class="o">=</span> <span class="n">aoti_compiled</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="conclusion">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Conclusion</a><a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>We introduced <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>, the new PyTorch 2.X way to export single computation
graphs from PyTorch programs. In particular, we demonstrate several code modifications
and considerations (control flow ops, constraints, etc.) that need to be made in order to export a graph.</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 5.199 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-torch-export-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/fb8083290582c4f473d970913a4186c4/torch_export_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">torch_export_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/b865be3c401c1b4fbdb03f49916ac8e8/torch_export_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">torch_export_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/eb8d1a44ecbb6f9b3f0732396942ffcd/torch_export_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">torch_export_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="../recipes/regional_compilation.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Reducing torch.compile cold start compilation time with regional compilation</p>
</div>
</a>
<a class="right-next" href="../recipes/torch_export_aoti_python.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="../recipes/regional_compilation.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Reducing torch.compile cold start compilation time with regional compilation</p>
</div>
</a>
<a class="right-next" href="../recipes/torch_export_aoti_python.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-usage">Basic Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-breaks">Graph Breaks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-strict-export">Non-Strict Export</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#control-flow-ops">Control Flow Ops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constraints-dynamic-shapes">Constraints/Dynamic Shapes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-concepts-symbols-and-guards">Basic concepts: symbols and guards</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specialization">0/1 specialization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#named-dims">Named Dims</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#constraint-violations-suggested-fixes">Constraint violations, suggested fixes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-dependent-errors">Data-dependent errors</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guards-torch-check">Guards, torch._check()</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specialized-values">Specialized values</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-ops">Custom Ops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ir-decompositions">IR/Decompositions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exportdb">ExportDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-the-exported-program">Running the Exported Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "torch.export Tutorial",
       "headline": "torch.export Tutorial",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/torch_export_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. torch.export Tutorial# Author: William Wen, Zhengxu Chen, Angela Yi, Pian Pawakapan Warning torch.export and its related features are in prototype status and are subject to backwards compatibility breaking changes. This tutorial provides a snapshot of torch.export usage as of PyTorch 2.5. torch.export() is the PyTorch 2.X way to export PyTorch models into standardized model representations, intended to be run on different (i.e. Python-less) environments. The official documentation can be found here. In this tutorial, you will learn how to use torch.export() to extract ExportedProgram\u2019s (i.e. single-graph representations) from PyTorch programs. We also detail some considerations/modifications that you may need to make in order to make your model compatible with torch.export. Contents Basic Usage Graph Breaks Non-Strict Export Control Flow Ops Constraints/Dynamic Shapes Basic concepts: symbols and guards 0/1 specialization Named Dims Constraint violations, suggested fixes Data-dependent errors Guards, torch._check() Specialized values Custom Ops IR/Decompositions ExportDB Running the Exported Program Conclusion Basic Usage# torch.export extracts single-graph representations from PyTorch programs by tracing the target function, given example inputs. torch.export.export() is the main entry point for torch.export. In this tutorial, torch.export and torch.export.export() are practically synonymous, though torch.export generally refers to the PyTorch 2.X export process, and torch.export.export() generally refers to the actual function call. The signature of torch.export.export() is: export( mod: torch.nn.Module, args: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]] = None, *, dynamic_shapes: Optional[Dict[str, Dict[int, Dim]]] = None ) -\u003e ExportedProgram torch.export.export() traces the tensor computation graph from calling mod(*args, **kwargs) and wraps it in an ExportedProgram, which can be serialized or executed later with different inputs. To execute the ExportedProgram we can call .module() on it to return a torch.nn.Module which is callable, just like the original program. We will detail the dynamic_shapes argument later in the tutorial. import torch from torch.export import export class MyModule(torch.nn.Module): def __init__(self): super().__init__() self.lin = torch.nn.Linear(100, 10) def forward(self, x, y): return torch.nn.functional.relu(self.lin(x + y), inplace=True) mod = MyModule() exported_mod = export(mod, (torch.randn(8, 100), torch.randn(8, 100))) print(type(exported_mod)) print(exported_mod.module()(torch.randn(8, 100), torch.randn(8, 100))) \u003cclass \u0027torch.export.exported_program.ExportedProgram\u0027\u003e tensor([[1.2833, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6960, 0.0000, 0.0206, 0.0000], [0.0000, 0.0000, 0.5338, 0.4826, 0.0000, 1.1298, 0.8386, 0.0000, 1.8642, 0.4014], [0.0162, 1.2556, 0.8679, 0.5822, 0.8992, 0.2108, 0.8659, 0.0000, 0.5097, 0.0000], [0.0364, 0.3233, 0.5205, 1.5689, 0.0000, 0.1559, 0.5217, 0.0000, 0.0000, 0.2202], [0.0000, 1.4435, 1.2654, 0.0000, 0.0000, 0.0000, 0.0000, 0.9309, 0.6940, 0.0000], [0.2193, 0.4609, 0.0000, 0.2015, 0.5363, 0.0000, 0.8061, 0.0000, 0.3670, 1.3163], [0.5836, 0.0964, 0.6060, 1.9044, 0.8751, 0.0000, 1.1344, 1.9880, 0.0000, 0.0000], [0.0000, 1.6330, 0.6570, 0.0000, 0.0000, 0.0000, 0.0000, 1.8583, 0.0000, 0.0000]], grad_fn=\u003cReluBackward0\u003e) Let\u2019s review some attributes of ExportedProgram that are of interest. The graph attribute is an FX graph traced from the function we exported, that is, the computation graph of all PyTorch operations. The FX graph is in \u201cATen IR\u201d meaning that it contains only \u201cATen-level\u201d operations. The graph_signature attribute gives a more detailed description of the input and output nodes in the exported graph, describing which ones are parameters, buffers, user inputs, or user outputs. The range_constraints attributes will be covered later. print(exported_mod) ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, p_lin_weight: \"f32[10, 100]\", p_lin_bias: \"f32[10]\", x: \"f32[8, 100]\", y: \"f32[8, 100]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:71 in forward, code: return torch.nn.functional.relu(self.lin(x + y), inplace=True) add: \"f32[8, 100]\" = torch.ops.aten.add.Tensor(x, y); x = y = None # File: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias) linear: \"f32[8, 10]\" = torch.ops.aten.linear.default(add, p_lin_weight, p_lin_bias); add = p_lin_weight = p_lin_bias = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:71 in forward, code: return torch.nn.functional.relu(self.lin(x + y), inplace=True) relu_: \"f32[8, 10]\" = torch.ops.aten.relu_.default(linear); linear = None return (relu_,) Graph signature: # inputs p_lin_weight: PARAMETER target=\u0027lin.weight\u0027 p_lin_bias: PARAMETER target=\u0027lin.bias\u0027 x: USER_INPUT y: USER_INPUT # outputs relu_: USER_OUTPUT Range constraints: {} See the torch.export documentation for more details. Graph Breaks# Although torch.export shares components with torch.compile, the key limitation of torch.export, especially when compared to torch.compile, is that it does not support graph breaks. This is because handling graph breaks involves interpreting the unsupported operation with default Python evaluation, which is incompatible with the export use case. Therefore, in order to make your model code compatible with torch.export, you will need to modify your code to remove graph breaks. A graph break is necessary in cases such as: data-dependent control flow class Bad1(torch.nn.Module): def forward(self, x): if x.sum() \u003e 0: return torch.sin(x) return torch.cos(x) import traceback as tb try: export(Bad1(), (torch.randn(3, 3),)) except Exception: tb.print_exc() def forward(self, arg0_1: \"f32[3, 3]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:116 in forward, code: if x.sum() \u003e 0: sum_1: \"f32[]\" = torch.ops.aten.sum.default(arg0_1); arg0_1 = None gt: \"b8[]\" = torch.ops.aten.gt.Scalar(sum_1, 0); sum_1 = None ne: \"b8[]\" = torch.ops.aten.ne.Scalar(gt, 0); gt = None item: \"Sym(Eq(u0, 1))\" = torch.ops.aten.item.default(ne); ne = item = None def forward(self, arg0_1: \"f32[3, 3]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:116 in forward, code: if x.sum() \u003e 0: sum_1: \"f32[]\" = torch.ops.aten.sum.default(arg0_1); arg0_1 = None gt: \"b8[]\" = torch.ops.aten.gt.Scalar(sum_1, 0); sum_1 = None ne: \"b8[]\" = torch.ops.aten.ne.Scalar(gt, 0); gt = None item: \"Sym(Eq(u0, 1))\" = torch.ops.aten.item.default(ne); ne = item = None Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 122, in \u003cmodule\u003e export(Bad1(), (torch.randn(3, 3),)) File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 116, in forward if x.sum() \u003e 0: File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 538, in guard_bool r = self.evaluate() File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 512, in evaluate return self.shape_env.evaluate_sym_node(self, size_oblivious) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7223, in evaluate_sym_node return self.evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7323, in evaluate_expr return self._inner_evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7346, in _inner_evaluate_expr return self._evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7570, in _evaluate_expr raise self._make_data_dependent_error( torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression Eq(u0, 1) (unhinted: Eq(u0, 1)). (Size-like symbols: none) Caused by: (_export/non_strict_utils.py:1051 in __torch_function__) For more information, run with TORCH_LOGS=\"dynamic\" For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\" If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 The following call raised this error: File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 116, in forward if x.sum() \u003e 0: The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. accessing tensor data with .data class Bad2(torch.nn.Module): def forward(self, x): x.data[0, 0] = 3 return x try: export(Bad2(), (torch.randn(3, 3),)) except Exception: tb.print_exc() calling unsupported functions (such as many built-in functions) class Bad3(torch.nn.Module): def forward(self, x): x = x + 1 return x + id(x) try: export(Bad3(), (torch.randn(3, 3),)) except Exception: tb.print_exc() Non-Strict Export# To trace the program, torch.export uses TorchDynamo by default, a byte code analysis engine, to symbolically analyze the Python code and build a graph based on the results. This analysis allows torch.export to provide stronger guarantees about safety, but not all Python code is supported, causing these graph breaks. To address this issue, in PyTorch 2.3, we introduced a new mode of exporting called non-strict mode, where we trace through the program using the Python interpreter executing it exactly as it would in eager mode, allowing us to skip over unsupported Python features. This is done through adding a strict=False flag. Looking at some of the previous examples which resulted in graph breaks: Calling unsupported functions (such as many built-in functions) traces through, but in this case, id(x) gets specialized as a constant integer in the graph. This is because id(x) is not a tensor operation, so the operation is not recorded in the graph. class Bad3(torch.nn.Module): def forward(self, x): x = x + 1 return x + id(x) bad3_nonstrict = export(Bad3(), (torch.randn(3, 3),), strict=False) print(bad3_nonstrict) print(bad3_nonstrict.module()(torch.ones(3, 3))) ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"f32[3, 3]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:179 in forward, code: x = x + 1 add: \"f32[3, 3]\" = torch.ops.aten.add.Tensor(x, 1); x = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:180 in forward, code: return x + id(x) add_1: \"f32[3, 3]\" = torch.ops.aten.add.Tensor(add, 140197977140864); add = None return (add_1,) Graph signature: # inputs x: USER_INPUT # outputs add_1: USER_OUTPUT Range constraints: {} tensor([[1.4020e+14, 1.4020e+14, 1.4020e+14], [1.4020e+14, 1.4020e+14, 1.4020e+14], [1.4020e+14, 1.4020e+14, 1.4020e+14]]) However, there are still some features that require rewrites to the original module: Control Flow Ops# torch.export actually does support data-dependent control flow. But these need to be expressed using control flow ops. For example, we can fix the control flow example above using the cond op, like so: class Bad1Fixed(torch.nn.Module): def forward(self, x): def true_fn(x): return torch.sin(x) def false_fn(x): return torch.cos(x) return torch.cond(x.sum() \u003e 0, true_fn, false_fn, [x]) exported_bad1_fixed = export(Bad1Fixed(), (torch.randn(3, 3),)) print(exported_bad1_fixed) print(exported_bad1_fixed.module()(torch.ones(3, 3))) print(exported_bad1_fixed.module()(-torch.ones(3, 3))) ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"f32[3, 3]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:205 in forward, code: return torch.cond(x.sum() \u003e 0, true_fn, false_fn, [x]) sum_1: \"f32[]\" = torch.ops.aten.sum.default(x) gt: \"b8[]\" = torch.ops.aten.gt.Scalar(sum_1, 0); sum_1 = None # File: \u003ceval_with_key\u003e.33:9 in forward, code: cond = torch.ops.higher_order.cond(l_args_0_, cond_true_0, cond_false_0, (l_args_3_0_,)); l_args_0_ = cond_true_0 = cond_false_0 = l_args_3_0_ = None true_graph_0 = self.true_graph_0 false_graph_0 = self.false_graph_0 cond = torch.ops.higher_order.cond(gt, true_graph_0, false_graph_0, (x,)); gt = true_graph_0 = false_graph_0 = x = None getitem: \"f32[3, 3]\" = cond[0]; cond = None return (getitem,) class true_graph_0(torch.nn.Module): def forward(self, x: \"f32[3, 3]\"): # File: \u003ceval_with_key\u003e.30:6 in forward, code: sin = torch.sin(l_args_3_0__1); l_args_3_0__1 = None sin: \"f32[3, 3]\" = torch.ops.aten.sin.default(x); x = None return (sin,) class false_graph_0(torch.nn.Module): def forward(self, x: \"f32[3, 3]\"): # File: \u003ceval_with_key\u003e.31:6 in forward, code: cos = torch.cos(l_args_3_0__1); l_args_3_0__1 = None cos: \"f32[3, 3]\" = torch.ops.aten.cos.default(x); x = None return (cos,) Graph signature: # inputs x: USER_INPUT # outputs getitem: USER_OUTPUT Range constraints: {} tensor([[0.8415, 0.8415, 0.8415], [0.8415, 0.8415, 0.8415], [0.8415, 0.8415, 0.8415]]) tensor([[0.5403, 0.5403, 0.5403], [0.5403, 0.5403, 0.5403], [0.5403, 0.5403, 0.5403]]) There are limitations to cond that one should be aware of: The predicate (i.e. x.sum() \u003e 0) must result in a boolean or a single-element tensor. The operands (i.e. [x]) must be tensors. The branch function (i.e. true_fn and false_fn) signature must match with the operands and they must both return a single tensor with the same metadata (for example, dtype, shape, etc.). Branch functions cannot mutate input or global variables. Branch functions cannot access closure variables, except for self if the function is defined in the scope of a method. For more details about cond, check out the cond documentation. We can also use map, which applies a function across the first dimension of the first tensor argument. from torch._higher_order_ops.map import map as torch_map class MapModule(torch.nn.Module): def forward(self, xs, y, z): def body(x, y, z): return x + y + z return torch_map(body, xs, y, z) inps = (torch.ones(6, 4), torch.tensor(5), torch.tensor(4)) exported_map_example = export(MapModule(), inps) print(exported_map_example) print(exported_map_example.module()(*inps)) ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, xs: \"f32[6, 4]\", y: \"i64[]\", z: \"i64[]\"): # File: \u003ceval_with_key\u003e.58:9 in forward, code: map_impl = torch.ops.higher_order.map_impl(map_body_0, [l_flat_xs_0_], [l_flat_args_0_, l_flat_args_1_]); map_body_0 = l_flat_xs_0_ = l_flat_args_0_ = l_flat_args_1_ = None body_graph_0 = self.body_graph_0 map_impl = torch.ops.higher_order.map_impl(body_graph_0, [xs], [y, z]); body_graph_0 = xs = y = z = None getitem: \"f32[6, 4]\" = map_impl[0]; map_impl = None return (getitem,) class body_graph_0(torch.nn.Module): def forward(self, xs: \"f32[4]\", y: \"i64[]\", z: \"i64[]\"): # File: \u003ceval_with_key\u003e.56:5 in forward, code: add = child.add(l_flat_args_0_); child = l_flat_args_0_ = None add: \"f32[4]\" = torch.ops.aten.add.Tensor(xs, y); xs = y = None # File: \u003ceval_with_key\u003e.56:6 in forward, code: add_1 = add.add(l_flat_args_1_); add = l_flat_args_1_ = None add_1: \"f32[4]\" = torch.ops.aten.add.Tensor(add, z); add = z = None return (add_1,) Graph signature: # inputs xs: USER_INPUT y: USER_INPUT z: USER_INPUT # outputs getitem: USER_OUTPUT Range constraints: {} tensor([[10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.]]) Other control flow ops include while_loop, associative_scan, and scan. For more documentation on each operator, please refer to this page. Constraints/Dynamic Shapes# This section covers dynamic behavior and representation of exported programs. Dynamic behavior is subjective to the particular model being exported, so for the most part of this tutorial, we\u2019ll focus on this particular toy model (with the resulting tensor shapes annotated): class DynamicModel(torch.nn.Module): def __init__(self): super().__init__() self.l = torch.nn.Linear(5, 3) def forward( self, w: torch.Tensor, # [6, 5] x: torch.Tensor, # [4] y: torch.Tensor, # [8, 4] z: torch.Tensor, # [32] ): x0 = x + y # [8, 4] x1 = self.l(w) # [6, 3] x2 = x0.flatten() # [32] x3 = x2 + z # [32] return x1, x3 By default, torch.export produces a static program. One consequence of this is that at runtime, the program won\u2019t work on inputs with different shapes, even if they\u2019re valid in eager mode. w = torch.randn(6, 5) x = torch.randn(4) y = torch.randn(8, 4) z = torch.randn(32) model = DynamicModel() ep = export(model, (w, x, y, z)) model(w, x, torch.randn(3, 4), torch.randn(12)) try: ep.module()(w, x, torch.randn(3, 4), torch.randn(12)) except Exception: tb.print_exc() Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 286, in \u003cmodule\u003e ep.module()(w, x, torch.randn(3, 4), torch.randn(12)) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 848, in call_wrapped return self._wrapped_call(self, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 424, in __call__ raise e File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 411, in __call__ return super(self.cls, obj).__call__(*args, **kwargs) # type: ignore[misc] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1879, in _call_impl return inner() File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1806, in inner args_kwargs_result = hook(self, args, kwargs) # type: ignore[misc] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_unlift.py\", line 83, in _check_input_constraints_pre_hook _check_input_constraints_for_graph( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py\", line 426, in _check_input_constraints_for_graph _check_symint( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py\", line 390, in _check_symint raise RuntimeError( RuntimeError: Expected input at *args[2].shape[0] to be equal to 8, but got 3. If you meant for this dimension to be dynamic, please re-export and specify dynamic_shapes (e.g. with Dim.DYNAMIC) Basic concepts: symbols and guards# To enable dynamism, export() provides a dynamic_shapes argument. The easiest way to work with dynamic shapes is using Dim.AUTO and looking at the program that\u2019s returned. Dynamic behavior is specified at a input dimension-level; for each input we can specify a tuple of values: from torch.export.dynamic_shapes import Dim dynamic_shapes = { \"w\": (Dim.AUTO, Dim.AUTO), \"x\": (Dim.AUTO,), \"y\": (Dim.AUTO, Dim.AUTO), \"z\": (Dim.AUTO,), } ep = export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) Before we look at the program that\u2019s produced, let\u2019s understand what specifying dynamic_shapes entails, and how that interacts with export. For every input dimension where a Dim object is specified, a symbol is allocated, taking on a range of [2, inf] (why not [0, inf] or [1, inf]? we\u2019ll explain later in the 0/1 specialization section). Export then runs model tracing, looking at each operation that\u2019s performed by the model. Each individual operation can emit what\u2019s called \u201cguards\u201d; basically boolean condition that are required to be true for the program to be valid. When guards involve symbols allocated for input dimensions, the program contains restrictions on what input shapes are valid; i.e. the program\u2019s dynamic behavior. The symbolic shapes subsystem is the part responsible for taking in all the emitted guards and producing a final program representation that adheres to all of these guards. Before we see this \u201cfinal representation\u201d in an ExportedProgram, let\u2019s look at the guards emitted by the toy model we\u2019re tracing. Here, each forward input tensor is annotated with the symbol allocated at the start of tracing: class DynamicModel(torch.nn.Module): def __init__(self): super().__init__() self.l = torch.nn.Linear(5, 3) def forward( self, w: torch.Tensor, # [s0, s1] x: torch.Tensor, # [s2] y: torch.Tensor, # [s3, s4] z: torch.Tensor, # [s5] ): x0 = x + y # guard: s2 == s4 x1 = self.l(w) # guard: s1 == 5 x2 = x0.flatten() # no guard added here x3 = x2 + z # guard: s3 * s4 == s5 return x1, x3 Let\u2019s understand each of the operations and the emitted guards: x0 = x + y: This is an element-wise add with broadcasting, since x is a 1-d tensor and y a 2-d tensor. x is broadcasted along the last dimension of y, emitting the guard s2 == s4. x1 = self.l(w): Calling nn.Linear() performs a matrix multiplication with model parameters. In export, parameters, buffers, and constants are considered program state, which is considered static, and so this is a matmul between a dynamic input (w: [s0, s1]), and a statically-shaped tensor. This emits the guard s1 == 5. x2 = x0.flatten(): This call actually doesn\u2019t emit any guards! (at least none relevant to input shapes) x3 = x2 + z: x2 has shape [s3*s4] after flattening, and this element-wise add emits s3 * s4 == s5. Writing all of these guards down and summarizing is almost like a mathematical proof, which is what the symbolic shapes subsystem tries to do! In summary, we can conclude that the program must have the following input shapes to be valid: w: [s0, 5] x: [s2] y: [s3, s2] z: [s2*s3] And when we do finally print out the exported program to see our result, those shapes are what we see annotated on the corresponding inputs: print(ep) ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, p_l_weight: \"f32[3, 5]\", p_l_bias: \"f32[3]\", w: \"f32[s15, 5]\", x: \"f32[s77]\", y: \"f32[s17, s77]\", z: \"f32[s17*s77]\"): # sym_size_int_1 = torch.ops.aten.sym_size.int(w, 1) sym_size_int_2: \"Sym(s77)\" = torch.ops.aten.sym_size.int(x, 0) sym_size_int_3: \"Sym(s17)\" = torch.ops.aten.sym_size.int(y, 0) sym_size_int_4: \"Sym(s77)\" = torch.ops.aten.sym_size.int(y, 1) sym_size_int_5: \"Sym(s17*s77)\" = torch.ops.aten.sym_size.int(z, 0) # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:268 in forward, code: x0 = x + y # [8, 4] add: \"f32[s17, s77]\" = torch.ops.aten.add.Tensor(x, y); x = y = None # eq: \"Sym(True)\" = sym_size_int_2 == sym_size_int_4; sym_size_int_4 = None _assert_scalar_default = torch.ops.aten._assert_scalar.default(eq, \"Runtime assertion failed for expression Eq(s77, s94) on node \u0027eq\u0027\"); eq = _assert_scalar_default = None eq_1 = sym_size_int_1 == 5; sym_size_int_1 = None _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(eq_1, \"Runtime assertion failed for expression Eq(s21, 5) on node \u0027eq_1\u0027\"); eq_1 = _assert_scalar_default_1 = None mul: \"Sym(s17*s77)\" = sym_size_int_3 * sym_size_int_2; sym_size_int_3 = sym_size_int_2 = None eq_2: \"Sym(True)\" = mul == sym_size_int_5; mul = sym_size_int_5 = None _assert_scalar_default_2 = torch.ops.aten._assert_scalar.default(eq_2, \"Runtime assertion failed for expression Eq(s17*s77, s68) on node \u0027eq_2\u0027\"); eq_2 = _assert_scalar_default_2 = None # File: /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias) linear: \"f32[s15, 3]\" = torch.ops.aten.linear.default(w, p_l_weight, p_l_bias); w = p_l_weight = p_l_bias = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:270 in forward, code: x2 = x0.flatten() # [32] flatten: \"f32[s17*s77]\" = torch.ops.aten.flatten.using_ints(add); add = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:271 in forward, code: x3 = x2 + z # [32] add_1: \"f32[s17*s77]\" = torch.ops.aten.add.Tensor(flatten, z); flatten = z = None return (linear, add_1) Graph signature: # inputs p_l_weight: PARAMETER target=\u0027l.weight\u0027 p_l_bias: PARAMETER target=\u0027l.bias\u0027 w: USER_INPUT x: USER_INPUT y: USER_INPUT z: USER_INPUT # outputs linear: USER_OUTPUT add_1: USER_OUTPUT Range constraints: {s15: VR[2, int_oo], s77: VR[2, int_oo], s17: VR[2, int_oo], s17*s77: VR[4, int_oo]} Another feature to notice is the range_constraints field above, which contains a valid range for each symbol. This isn\u2019t so interesting currently, since this export call doesn\u2019t emit any guards related to symbol bounds and each base symbol has a generic bound, but this will come up later. So far, because we\u2019ve been exporting this toy model, this experience has not been representative of how hard it typically is to debug dynamic shapes guards \u0026 issues. In most cases it isn\u2019t obvious what guards are being emitted, and which operations and parts of user code are responsible. For this toy model we pinpoint the exact lines, and the guards are rather intuitive. In more complicated cases, a helpful first step is always to enable verbose logging. This can be done either with the environment variable TORCH_LOGS=\"+dynamic\", or interactively with torch._logging.set_logs(dynamic=10): torch._logging.set_logs(dynamic=10) ep = export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) I0917 20:30:34.080000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.081000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s15\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.082000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s21\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.083000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.085000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L[\u0027x\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s77\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.086000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s17\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.087000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s94\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.089000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s68\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.094000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.094000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.095000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.096000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.097000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.098000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.099000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.099000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.100000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.101000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.103000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.104000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s77, s94)\" I0917 20:30:34.105000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[2, int_oo] V0917 20:30:34.106000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.113000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s21, 5)\" V0917 20:30:34.113000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update) I0917 20:30:34.114000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5] V0917 20:30:34.126000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known] V0917 20:30:34.127000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.130000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s17*s77, s68)\" V0917 20:30:34.130000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[4, int_oo] (update) I0917 20:30:34.132000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[4, int_oo] I0917 20:30:34.136000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.137000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[0] s15 None V0917 20:30:34.137000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[1] 5 None V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[0] 5 None V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[1] 1 None V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].storage_offset() 0 None V0917 20:30:34.138000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] s77 None V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 1 None V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] s17 None V0917 20:30:34.139000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[1] s77 None V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] s77 None V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[1] 1 None V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:34.140000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].size()[0] s17*s77 None V0917 20:30:34.141000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].stride()[0] 1 None V0917 20:30:34.141000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].storage_offset() 0 None V0917 20:30:34.149000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] V0917 20:30:34.155000 31631 torch/fx/experimental/symbolic_shapes.py:7461] eval 5 [trivial] This spits out quite a handful, even with this simple toy model. The log lines here have been cut short at front and end to ignore unnecessary info, but looking through the logs we can see the lines relevant to what we described above; e.g. the allocation of symbols: \"\"\" create_symbol s0 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) create_symbol s1 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) runtime_assert True == True [statically known] create_symbol s2 = 4 for L[\u0027x\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) create_symbol s3 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) create_symbol s4 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) create_symbol s5 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e) \"\"\" \"\\ncreate_symbol s0 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\ncreate_symbol s1 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\nruntime_assert True == True [statically known]\\ncreate_symbol s2 = 4 for L[\u0027x\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\ncreate_symbol s3 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\ncreate_symbol s4 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\ncreate_symbol s5 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_dynamo/variables/builder.py:2841 in \u003clambda\u003e)\\n\" The lines with create_symbol show when a new symbol has been allocated, and the logs also identify the tensor variable names and dimensions they\u2019ve been allocated for. In other lines we can also see the guards emitted: \"\"\" runtime_assert Eq(s2, s4) [guard added] x0 = x + y # output shape: [8, 4] # dynamic_shapes_tutorial.py:16 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s2, s4)\" runtime_assert Eq(s1, 5) [guard added] x1 = self.l(w) # [6, 3] # dynamic_shapes_tutorial.py:17 in forward (_meta_registrations.py:2127 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s1, 5)\" runtime_assert Eq(s2*s3, s5) [guard added] x3 = x2 + z # [32] # dynamic_shapes_tutorial.py:19 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s2*s3, s5)\" \"\"\" \u0027\\nruntime_assert Eq(s2, s4) [guard added] x0 = x + y # output shape: [8, 4] # dynamic_shapes_tutorial.py:16 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s2, s4)\"\\nruntime_assert Eq(s1, 5) [guard added] x1 = self.l(w) # [6, 3] # dynamic_shapes_tutorial.py:17 in forward (_meta_registrations.py:2127 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s1, 5)\"\\nruntime_assert Eq(s2*s3, s5) [guard added] x3 = x2 + z # [32] # dynamic_shapes_tutorial.py:19 in forward (_subclasses/fake_impls.py:845 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s2*s3, s5)\"\\n\u0027 Next to the [guard added] messages, we also see the responsible user lines of code - luckily here the model is simple enough. In many real-world cases it\u2019s not so straightforward: high-level torch operations can have complicated fake-kernel implementations or operator decompositions that complicate where and what guards are emitted. In such cases the best way to dig deeper and investigate is to follow the logs\u2019 suggestion, and re-run with environment variable TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"...\", to further attribute the guard of interest. Dim.AUTO is just one of the available options for interacting with dynamic_shapes; as of writing this 2 other options are available: Dim.DYNAMIC, and Dim.STATIC. Dim.STATIC simply marks a dimension static, while Dim.DYNAMIC is similar to Dim.AUTO in all ways except one: it raises an error when specializing to a constant; this is designed to maintain dynamism. See for example what happens when a static guard is emitted on a dynamically-marked dimension: dynamic_shapes[\"w\"] = (Dim.AUTO, Dim.DYNAMIC) try: export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) except Exception: tb.print_exc() I0917 20:30:34.160000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.161000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s15\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.162000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s21\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.162000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.164000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L[\u0027x\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s77\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.165000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s17\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.166000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s94\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.168000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s68\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.173000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.173000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.174000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.175000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.176000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.177000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.177000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.178000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.179000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.180000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.182000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.182000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s77, s94)\" I0917 20:30:34.183000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[2, int_oo] V0917 20:30:34.185000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.191000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s21, 5)\" V0917 20:30:34.192000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update) I0917 20:30:34.192000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5] V0917 20:30:34.205000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known] V0917 20:30:34.206000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.208000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s17*s77, s68)\" V0917 20:30:34.209000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[4, int_oo] (update) I0917 20:30:34.210000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[4, int_oo] I0917 20:30:34.215000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.215000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[0] s15 None V0917 20:30:34.216000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[1] 5 RelaxedUnspecConstraint(warn_only=False) V0917 20:30:34.426000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[0] 5 None V0917 20:30:34.427000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[1] 1 None V0917 20:30:34.427000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].storage_offset() 0 None V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] s77 None V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 1 None V0917 20:30:34.428000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] s17 None V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[1] s77 None V0917 20:30:34.429000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] s77 None V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[1] 1 None V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:34.430000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].size()[0] s17*s77 None V0917 20:30:34.431000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].stride()[0] 1 None V0917 20:30:34.431000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].storage_offset() 0 None Traceback (most recent call last): File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1798, in _export_to_aten_ir_make_fx produce_guards_callback(gm) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1944, in _produce_guards_callback return produce_guards_and_solve_constraints( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 549, in produce_guards_and_solve_constraints raise constraint_violation_error File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 514, in produce_guards_and_solve_constraints shape_env.produce_guards( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5200, in produce_guards return self.produce_guards_verbose(*args, **kwargs, langs=(\"python\",))[0].exprs File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5932, in produce_guards_verbose raise ConstraintViolationError( torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (L[\u0027w\u0027].size()[1])! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked L[\u0027w\u0027].size()[1] as dynamic but your code specialized it to be a constant (5). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 418, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 269, in forward x1 = self.l(w) # [6, 3] File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward return F.linear(input, self.weight, self.bias) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::linear::call(at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"RegisterCompositeImplicitAutograd_0.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026), \u0026at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear\u003e, at::Tensor, c10::guts::typelist::typelist\u003cat::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"??\", line 0, in at::native::linear(at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026) File \"??\", line 0, in at::_ops::addmm::call(at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"\", line 0, in c10::impl::BoxedKernelWrapper\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026), void\u003e::call(c10::BoxedKernel const\u0026, c10::OperatorHandle const\u0026, c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_0.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::addmm\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_0.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::addmm::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2601, in _dispatch_impl decomposition_table[func](*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 309, in _fn result = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 90, in inner r = f(*tree_map(increase_prec, args), **tree_map(increase_prec, kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 1462, in addmm out = alpha * torch.mm(mat1, mat2) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_torch_functions_1.cpp\", line 0, in torch::autograd::THPVariable_mm(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::mm::call(at::Tensor const\u0026, at::Tensor const\u0026) File \"\", line 0, in c10::impl::BoxedKernelWrapper\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026), void\u003e::call(c10::BoxedKernel const\u0026, c10::OperatorHandle const\u0026, c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2717, in _dispatch_impl r = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 309, in _fn result = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 2417, in meta_mm torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 418, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1800, in _export_to_aten_ir_make_fx raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e)) # noqa: B904 torch._dynamo.exc.UserError: Constraints violated (L[\u0027w\u0027].size()[1])! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked L[\u0027w\u0027].size()[1] as dynamic but your code specialized it to be a constant (5). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 418, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 269, in forward x1 = self.l(w) # [6, 3] File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 125, in forward return F.linear(input, self.weight, self.bias) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_nn_functions.cpp\", line 0, in torch::autograd::THPVariable_linear(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::linear::call(at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"RegisterCompositeImplicitAutograd_0.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026), \u0026at::(anonymous namespace)::(anonymous namespace)::wrapper_CompositeImplicitAutograd__linear\u003e, at::Tensor, c10::guts::typelist::typelist\u003cat::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"??\", line 0, in at::native::linear(at::Tensor const\u0026, at::Tensor const\u0026, std::optional\u003cat::Tensor\u003e const\u0026) File \"??\", line 0, in at::_ops::addmm::call(at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"\", line 0, in c10::impl::BoxedKernelWrapper\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026), void\u003e::call(c10::BoxedKernel const\u0026, c10::OperatorHandle const\u0026, c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_0.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::addmm\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_0.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::addmm(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::addmm::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2601, in _dispatch_impl decomposition_table[func](*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 309, in _fn result = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 90, in inner r = f(*tree_map(increase_prec, args), **tree_map(increase_prec, kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_decomp/decompositions.py\", line 1462, in addmm out = alpha * torch.mm(mat1, mat2) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"python_torch_functions_1.cpp\", line 0, in torch::autograd::THPVariable_mm(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::mm::call(at::Tensor const\u0026, at::Tensor const\u0026) File \"\", line 0, in c10::impl::BoxedKernelWrapper\u003cat::Tensor (at::Tensor const\u0026, at::Tensor const\u0026), void\u003e::call(c10::BoxedKernel const\u0026, c10::OperatorHandle const\u0026, c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2717, in _dispatch_impl r = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_prims_common/wrappers.py\", line 309, in _fn result = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 2417, in meta_mm torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. Static guards also aren\u2019t always inherent to the model; they can also come from user specifications. In fact, a common pitfall leading to shape specializations is when the user specifies conflicting markers for equivalent dimensions; one dynamic and another static. The same error type is raised when this is the case for x.shape[0] and y.shape[1]: dynamic_shapes[\"w\"] = (Dim.AUTO, Dim.AUTO) dynamic_shapes[\"x\"] = (Dim.STATIC,) dynamic_shapes[\"y\"] = (Dim.AUTO, Dim.DYNAMIC) try: export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) except Exception: tb.print_exc() I0917 20:30:34.500000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.502000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s15\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.503000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s21\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.503000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.506000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s17\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.507000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s94\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.509000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s68\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.515000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.516000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.516000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.518000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.519000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.519000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.520000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.521000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.526000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s94, 4) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s94, 4)\" V0917 20:30:34.527000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 4] (update) I0917 20:30:34.528000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = 4 (range_refined_to_singleton) VR[4, 4] I0917 20:30:34.537000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s21, 5)\" V0917 20:30:34.537000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update) I0917 20:30:34.538000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5] V0917 20:30:34.540000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.557000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(4*s17, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(4*s17, s68)\" V0917 20:30:34.558000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[8, int_oo] (update) I0917 20:30:34.561000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = 4*s17 (solve) VR[8, int_oo] I0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[0] s15 None V0917 20:30:34.566000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[1] 5 None V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[0] 5 None V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[1] 1 None V0917 20:30:34.567000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].storage_offset() 0 None V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] 4 None V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 1 None V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.568000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] s17 None V0917 20:30:34.569000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[1] 4 RelaxedUnspecConstraint(warn_only=False) V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 4 None V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[1] 1 None V0917 20:30:34.604000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:34.605000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].size()[0] 4*s17 None V0917 20:30:34.605000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].stride()[0] 1 None V0917 20:30:34.606000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].storage_offset() 0 None Traceback (most recent call last): File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1798, in _export_to_aten_ir_make_fx produce_guards_callback(gm) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1944, in _produce_guards_callback return produce_guards_and_solve_constraints( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 549, in produce_guards_and_solve_constraints raise constraint_violation_error File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 514, in produce_guards_and_solve_constraints shape_env.produce_guards( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5200, in produce_guards return self.produce_guards_verbose(*args, **kwargs, langs=(\"python\",))[0].exprs File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5932, in produce_guards_verbose raise ConstraintViolationError( torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (L[\u0027y\u0027].size()[1])! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked L[\u0027y\u0027].size()[1] as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 431, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 268, in forward x0 = x + y # [8, 4] File \"??\", line 0, in PyNumber_Add File \"??\", line 0, in _Py_c_pow File \"??\", line 0, in PyThread_start_new_thread File \"??\", line 0, in _PyType_LookupId File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_\u003c\u0026torch::autograd::THPVariable_add\u003e(_object*, _object*, _object*) File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::add_Tensor::call(at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_2.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::add_Tensor\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_2.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2581, in _dispatch_impl return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 962, in fast_binary_impl final_shape = infer_size(final_shape, shape) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 922, in infer_size torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 431, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1800, in _export_to_aten_ir_make_fx raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e)) # noqa: B904 torch._dynamo.exc.UserError: Constraints violated (L[\u0027y\u0027].size()[1])! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked L[\u0027y\u0027].size()[1] as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 431, in \u003cmodule\u003e export(model, (w, x, y, z), dynamic_shapes=dynamic_shapes) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 268, in forward x0 = x + y # [8, 4] File \"??\", line 0, in PyNumber_Add File \"??\", line 0, in _Py_c_pow File \"??\", line 0, in PyThread_start_new_thread File \"??\", line 0, in _PyType_LookupId File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_\u003c\u0026torch::autograd::THPVariable_add\u003e(_object*, _object*, _object*) File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::add_Tensor::call(at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_2.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::add_Tensor\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_2.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2581, in _dispatch_impl return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 962, in fast_binary_impl final_shape = infer_size(final_shape, shape) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 922, in infer_size torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. Here you might ask why export \u201cspecializes\u201d, i.e. why we resolve this static/dynamic conflict by going with the static route. The answer is because of the symbolic shapes system described above, of symbols and guards. When x.shape[0] is marked static, we don\u2019t allocate a symbol, and compile treating this shape as a concrete integer 4. A symbol is allocated for y.shape[1], and so we finally emit the guard s3 == 4, leading to specialization. One feature of export is that during tracing, statements like asserts, torch._check(), and if/else conditions will also emit guards. See what happens when we augment the existing model with such statements: class DynamicModel(torch.nn.Module): def __init__(self): super().__init__() self.l = torch.nn.Linear(5, 3) def forward(self, w, x, y, z): assert w.shape[0] \u003c= 512 torch._check(x.shape[0] \u003e= 4) if w.shape[0] == x.shape[0] + 2: x0 = x + y x1 = self.l(w) x2 = x0.flatten() x3 = x2 + z return x1, x3 else: return w dynamic_shapes = { \"w\": (Dim.AUTO, Dim.AUTO), \"x\": (Dim.AUTO,), \"y\": (Dim.AUTO, Dim.AUTO), \"z\": (Dim.AUTO,), } try: ep = export(DynamicModel(), (w, x, y, z), dynamic_shapes=dynamic_shapes) except Exception: tb.print_exc() I0917 20:30:34.662000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.664000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s15 = 6 for L[\u0027w\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s15\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.665000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s21 = 5 for L[\u0027w\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s21\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.665000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.667000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 4 for L[\u0027x\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s77\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.669000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 8 for L[\u0027y\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s17\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.669000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s94\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.671000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s68 = 32 for L[\u0027z\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s68\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.676000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.677000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.677000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.679000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.679000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.680000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.681000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.682000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.683000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.683000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.689000 31631 torch/fx/experimental/symbolic_shapes.py:7197] eval s15 \u003c= 512 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:450 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"s15 \u003c= 512\" V0917 20:30:34.689000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s15 = VR[2, 512] (update) I0917 20:30:34.693000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert s77 \u003e= 4 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:451 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"s77 \u003e= 4\" V0917 20:30:34.694000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s77 = VR[4, int_oo] (update) I0917 20:30:34.698000 31631 torch/fx/experimental/symbolic_shapes.py:7197] eval Eq(s15, s77 + 2) [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:452 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s15, s77 + 2)\" V0917 20:30:34.701000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s77 = VR[4, 510] (update) V0917 20:30:34.702000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s15 = VR[6, 512] (update) I0917 20:30:34.703000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s15 = s77 + 2 (solve) VR[6, 512] V0917 20:30:34.705000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.707000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s77, s94)\" V0917 20:30:34.708000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 510] (update) I0917 20:30:34.708000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s77 (solve) VR[4, 510] V0917 20:30:34.712000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.718000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s21, 5) [guard added] (_meta_registrations.py:2417 in meta_mm), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s21, 5)\" V0917 20:30:34.719000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s21 = VR[5, 5] (update) I0917 20:30:34.720000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s21 = 5 (range_refined_to_singleton) VR[5, 5] V0917 20:30:34.734000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(Eq(s17*s77, 1)) == False [statically known] V0917 20:30:34.736000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.745000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s17*s77, s68) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s17*s77, s68)\" V0917 20:30:34.746000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s68 = VR[8, int_oo] (update) I0917 20:30:34.747000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s68 = s17*s77 (solve) VR[8, int_oo] I0917 20:30:34.752000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[0] s77 + 2 None V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].size()[1] 5 None V0917 20:30:34.753000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[0] 5 None V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].stride()[1] 1 None V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027w\u0027].storage_offset() 0 None V0917 20:30:34.754000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] s77 None V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 1 None V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] s17 None V0917 20:30:34.755000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[1] s77 None V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] s77 None V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[1] 1 None V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:34.756000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].size()[0] s17*s77 None V0917 20:30:34.757000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].stride()[0] 1 None V0917 20:30:34.757000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027z\u0027].storage_offset() 0 None V0917 20:30:34.769000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert s77 \u003e= 4 == True [statically known] V0917 20:30:34.770000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] V0917 20:30:34.777000 31631 torch/fx/experimental/symbolic_shapes.py:7461] eval 5 [trivial] Each of these statements emits an additional guard, and the exported program shows the changes; s0 is eliminated in favor of s2 + 2, and s2 now contains lower and upper bounds, reflected in range_constraints. For the if/else condition, you might ask why the True branch was taken, and why it wasn\u2019t the w.shape[0] != x.shape[0] + 2 guard that got emitted from tracing. The answer is that export is guided by the sample inputs provided by tracing, and specializes on the branches taken. If different sample input shapes were provided that fail the if condition, export would trace and emit guards corresponding to the else branch. Additionally, you might ask why we traced only the if branch, and if it\u2019s possible to maintain control-flow in your program and keep both branches alive. For that, refer to rewriting your model code following the Control Flow Ops section above. 0/1 specialization# Since we\u2019re talking about guards and specializations, it\u2019s a good time to talk about the 0/1 specialization issue we brought up earlier. The bottom line is that export will specialize on sample input dimensions with value 0 or 1, because these shapes have trace-time properties that don\u2019t generalize to other shapes. For example, size 1 tensors can broadcast while other sizes fail; and size 0 \u2026 . This just means that you should specify 0/1 sample inputs when you\u2019d like your program to hardcode them, and non-0/1 sample inputs when dynamic behavior is desirable. See what happens at runtime when we export this linear layer: ep = export( torch.nn.Linear(4, 3), (torch.randn(1, 4),), dynamic_shapes={ \"input\": (Dim.AUTO, Dim.STATIC), }, ) try: ep.module()(torch.randn(2, 4)) except Exception: tb.print_exc() I0917 20:30:34.782000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.793000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027input\u0027].size()[0] 1 None V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027input\u0027].size()[1] 4 None V0917 20:30:34.794000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027input\u0027].stride()[0] 4 None V0917 20:30:34.795000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027input\u0027].stride()[1] 1 None V0917 20:30:34.795000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027input\u0027].storage_offset() 0 None W0917 20:30:34.797000 31631 torch/_export/non_strict_utils.py:580] dimension inputs[\u0027input\u0027].shape[0] 0/1 specialized; Dim.AUTO was specified along with a sample input with hint = 1. Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 500, in \u003cmodule\u003e ep.module()(torch.randn(2, 4)) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 848, in call_wrapped return self._wrapped_call(self, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 424, in __call__ raise e File \"/usr/local/lib/python3.10/dist-packages/torch/fx/graph_module.py\", line 411, in __call__ return super(self.cls, obj).__call__(*args, **kwargs) # type: ignore[misc] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1879, in _call_impl return inner() File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1806, in inner args_kwargs_result = hook(self, args, kwargs) # type: ignore[misc] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_unlift.py\", line 83, in _check_input_constraints_pre_hook _check_input_constraints_for_graph( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py\", line 426, in _check_input_constraints_for_graph _check_symint( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/utils.py\", line 390, in _check_symint raise RuntimeError( RuntimeError: Expected input at *args[0].shape[0] to be equal to 1, but got 2. If you meant for this dimension to be dynamic, please re-export and specify dynamic_shapes (e.g. with Dim.DYNAMIC) Named Dims# So far we\u2019ve only been talking about 3 ways to specify dynamic shapes: Dim.AUTO, Dim.DYNAMIC, and Dim.STATIC. The attraction of these is the low-friction user experience; all the guards emitted during model tracing are adhered to, and dynamic behavior like min/max ranges, relations, and static/dynamic dimensions are automatically figured out underneath export. The dynamic shapes subsystem essentially acts as a \u201cdiscovery\u201d process, summarizing these guards and presenting what export believes is the overall dynamic behavior of the program. The drawback of this design appears once the user has stronger expectations or beliefs about the dynamic behavior of these models - maybe there is a strong desire on dynamism and specializations on particular dimensions are to be avoided at all costs, or maybe we just want to catch changes in dynamic behavior with changes to the original model code, or possibly underlying decompositions or meta-kernels. These changes won\u2019t be detected and the export() call will most likely succeed, unless tests are in place that check the resulting ExportedProgram representation. For such cases, our stance is to recommend the \u201ctraditional\u201d way of specifying dynamic shapes, which longer-term users of export might be familiar with: named Dims: dx = Dim(\"dx\", min=4, max=256) dh = Dim(\"dh\", max=512) dynamic_shapes = { \"x\": (dx, None), \"y\": (2 * dx, dh), } This style of dynamic shapes allows the user to specify what symbols are allocated for input dimensions, min/max bounds on those symbols, and places restrictions on the dynamic behavior of the ExportedProgram produced; ConstraintViolation errors will be raised if model tracing emits guards that conflict with the relations or static/dynamic specifications given. For example, in the above specification, the following is asserted: x.shape[0] is to have range [4, 256], and related to y.shape[0] by y.shape[0] == 2 * x.shape[0]. x.shape[1] is static. y.shape[1] has range [2, 512], and is unrelated to any other dimension. In this design, we allow relations between dimensions to be specified with univariate linear expressions: A * dim + B can be specified for any dimension. This allows users to specify more complex constraints like integer divisibility for dynamic dimensions: dx = Dim(\"dx\", min=4, max=512) dynamic_shapes = { \"x\": (4 * dx, None) # x.shape[0] has range [16, 2048], and is divisible by 4. } Constraint violations, suggested fixes# One common issue with this specification style (before Dim.AUTO was introduced), is that the specification would often be mismatched with what was produced by model tracing. That would lead to ConstraintViolation errors and export suggested fixes - see for example with this model \u0026 specification, where the model inherently requires equality between dimensions 0 of x and y, and requires dimension 1 to be static. class Foo(torch.nn.Module): def forward(self, x, y): w = x + y return w + torch.ones(4) dx, dy, d1 = torch.export.dims(\"dx\", \"dy\", \"d1\") try: ep = export( Foo(), (torch.randn(6, 4), torch.randn(6, 4)), dynamic_shapes={ \"x\": (dx, d1), \"y\": (dy, d1), }, ) except Exception: tb.print_exc() I0917 20:30:34.805000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.806000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s77 = 6 for L[\u0027x\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s77\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.808000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s27 = 4 for L[\u0027x\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s27\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.809000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.812000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s17 = 6 for L[\u0027y\u0027].size()[0] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s17\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" I0917 20:30:34.812000 31631 torch/fx/experimental/symbolic_shapes.py:5110] create_symbol s94 = 4 for L[\u0027y\u0027].size()[1] [2, int_oo] (_export/non_strict_utils.py:229 in fakify), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s94\" or to suppress this message run with TORCHDYNAMO_EXTENDED_ADVICE=\"0\" V0917 20:30:34.819000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.820000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.821000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.823000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.823000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.824000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] V0917 20:30:34.826000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:34.828000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s27, s94) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s27, s94)\" I0917 20:30:34.829000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = s27 (solve) VR[2, int_oo] I0917 20:30:34.832000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s77, s17) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s77, s17)\" I0917 20:30:34.833000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s77 = s17 (solve) VR[2, int_oo] V0917 20:30:34.836000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == False [statically known] I0917 20:30:34.845000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert Eq(s27, 4) [guard added] (_subclasses/fake_impls.py:922 in infer_size), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"Eq(s27, 4)\" V0917 20:30:34.846000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s27 = VR[4, 4] (update) I0917 20:30:34.847000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s27 = 4 (range_refined_to_singleton) VR[4, 4] I0917 20:30:34.852000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.852000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range s94 = VR[4, 4] (update) I0917 20:30:34.853000 31631 torch/fx/experimental/symbolic_shapes.py:6776] set_replacement s94 = 4 (find) VR[4, 4] V0917 20:30:34.853000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] s17 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo]) V0917 20:30:34.854000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[1] 4 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo]) V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 4 None V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[1] 1 None V0917 20:30:34.872000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.873000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] s17 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo]) V0917 20:30:34.873000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[1] 4 StrictMinMaxConstraint(warn_only=False, vr=VR[0, int_oo]) V0917 20:30:34.882000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 4 None V0917 20:30:34.883000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[1] 1 None V0917 20:30:34.883000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None Traceback (most recent call last): File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1798, in _export_to_aten_ir_make_fx produce_guards_callback(gm) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1944, in _produce_guards_callback return produce_guards_and_solve_constraints( File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 549, in produce_guards_and_solve_constraints raise constraint_violation_error File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 514, in produce_guards_and_solve_constraints shape_env.produce_guards( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5200, in produce_guards return self.produce_guards_verbose(*args, **kwargs, langs=(\"python\",))[0].exprs File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5932, in produce_guards_verbose raise ConstraintViolationError( torch.fx.experimental.symbolic_shapes.ConstraintViolationError: Constraints violated (d1, dy)! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked d1 as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 557, in \u003cmodule\u003e ep = export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 553, in forward return w + torch.ones(4) File \"??\", line 0, in PyNumber_Add File \"??\", line 0, in _Py_c_pow File \"??\", line 0, in PyThread_start_new_thread File \"??\", line 0, in _PyType_LookupId File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_\u003c\u0026torch::autograd::THPVariable_add\u003e(_object*, _object*, _object*) File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::add_Tensor::call(at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_2.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::add_Tensor\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_2.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2581, in _dispatch_impl return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 962, in fast_binary_impl final_shape = infer_size(final_shape, shape) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 922, in infer_size torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() - You marked d1 as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 557, in \u003cmodule\u003e ep = export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1798, in _export_to_aten_ir_make_fx produce_guards_callback(gm) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1944, in _produce_guards_callback return produce_guards_and_solve_constraints( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 514, in produce_guards_and_solve_constraints shape_env.produce_guards( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5200, in produce_guards return self.produce_guards_verbose(*args, **kwargs, langs=(\"python\",))[0].exprs File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5405, in produce_guards_verbose expr1, expr2 = get_expression(src1), get_expression(src2) # type: ignore[] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5399, in get_expression return symint.node.expr File \"??\", line 0, in PyObject_GetAttr File \"??\", line 0, in _PyObject_GenericGetAttrWithDict File \"??\", line 0, in PyObject_IsTrue File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 189, in expr return self.shape_env.replace(self._expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 2539, in wrapper return fn_cache(self, *args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyErr_FormatFromCause File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6324, in replace r = self._find(s) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 2539, in wrapper return fn_cache(self, *args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyErr_FormatFromCause File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6809, in _find self._set_replacement(a, replaced, \"find\") File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() - The values of dy = L[\u0027y\u0027].size()[0] and dx = L[\u0027x\u0027].size()[0] must always be equal. Suggested fixes: d1 = 4 dy = dx During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 557, in \u003cmodule\u003e ep = export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1800, in _export_to_aten_ir_make_fx raise UserError(UserErrorType.CONSTRAINT_VIOLATION, str(e)) # noqa: B904 torch._dynamo.exc.UserError: Constraints violated (d1, dy)! For more information, run with TORCH_LOGS=\"+dynamic\". - You marked d1 as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 557, in \u003cmodule\u003e ep = export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 553, in forward return w + torch.ones(4) File \"??\", line 0, in PyNumber_Add File \"??\", line 0, in _Py_c_pow File \"??\", line 0, in PyThread_start_new_thread File \"??\", line 0, in _PyType_LookupId File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in _object* torch::autograd::TypeError_to_NotImplemented_\u003c\u0026torch::autograd::THPVariable_add\u003e(_object*, _object*, _object*) File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"\", line 0, in torch::handle_torch_function(torch::PythonArgs\u0026, _object*, _object*, _object*, _object*, char const*, char const*) File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"??\", line 0, in _PyObject_GetDictPtr File \"python_variable_methods.cpp\", line 0, in torch::autograd::THPVariable_add(_object*, _object*, _object*) File \"??\", line 0, in at::_ops::add_Tensor::call(at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"init.cpp\", line 0, in pybind11::cpp_function::initialize\u003ctorch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}, pybind11::object, pybind11::args const\u0026, pybind11::kwargs const\u0026\u003e(torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}\u0026\u0026, pybind11::object (*)(pybind11::args const\u0026, pybind11::kwargs const\u0026))::{lambda(pybind11::detail::function_call\u0026)#1}::_FUN(pybind11::detail::function_call\u0026) File \"init.cpp\", line 0, in torch::jit::initJITBindings(_object*)::{lambda(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026)#2}::operator()(std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026, std::__cxx11::basic_string\u003cchar, std::char_traits\u003cchar\u003e, std::allocator\u003cchar\u003e \u003e const\u0026) const::{lambda(pybind11::args const\u0026, pybind11::kwargs const\u0026)#1}::operator()(pybind11::args const\u0026, pybind11::kwargs const\u0026) const File \"??\", line 0, in torch::jit::_get_operation_for_overload_or_packet(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, c10::Symbol, pybind11::args const\u0026, pybind11::kwargs const\u0026, bool, std::optional\u003cc10::DispatchKey\u003e) File \"??\", line 0, in torch::jit::invokeOperatorFromPython(std::vector\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e, std::allocator\u003cstd::shared_ptr\u003ctorch::jit::Operator\u003e \u003e \u003e const\u0026, pybind11::args const\u0026, pybind11::kwargs const\u0026, std::optional\u003cc10::DispatchKey\u003e) File \"register_c10_ops.cpp\", line 0, in c10::Dispatcher::callBoxed(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const [clone .isra.0] File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in void c10::BoxedKernel::make_boxed_function\u003c\u0026(anonymous namespace)::pythonTLSSnapshotFallback\u003e(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"VariableType_2.cpp\", line 0, in c10::impl::make_boxed_from_unboxed_functor\u003cc10::impl::detail::WrapFunctionIntoFunctor_\u003cc10::CompileTimeFunctionPointer\u003cat::Tensor (c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026), \u0026torch::autograd::VariableType::(anonymous namespace)::add_Tensor\u003e, at::Tensor, c10::guts::typelist::typelist\u003cc10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026\u003e \u003e, false\u003e::call(c10::OperatorKernel*, c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"VariableType_2.cpp\", line 0, in torch::autograd::VariableType::(anonymous namespace)::add_Tensor(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"??\", line 0, in at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const\u0026, at::Tensor const\u0026, c10::Scalar const\u0026) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::python_dispatcher(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"\", line 0, in c10::OperatorHandle::callBoxedForDispatchKey(c10::DispatchKey, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e\u0026) const File \"PythonFallbackKernel.cpp\", line 0, in (anonymous namespace)::pythonFallback(c10::OperatorHandle const\u0026, c10::DispatchKeySet, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) File \"PyInterpreter.cpp\", line 0, in torch::detail::(anonymous namespace)::ConcretePyInterpreterVTable::dispatch(c10::OperatorHandle const\u0026, std::vector\u003cc10::IValue, std::allocator\u003cc10::IValue\u003e \u003e*) const File \"??\", line 0, in torch::handle_torch_function_no_python_arg_parser(c10::ArrayRef\u003c_object*\u003e, _object*, _object*, char const*, _object*, char const*, torch::TorchFunctionName) File \"??\", line 0, in PyObject_CallMethod File \"??\", line 0, in PyModule_AddObjectRef File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2581, in _dispatch_impl return maybe_propagate_real_tensors(fast_impl(self, *args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 962, in fast_binary_impl final_shape = infer_size(final_shape, shape) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 922, in infer_size torch._check( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1684, in _check _check_with(RuntimeError, cond, message) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1647, in _check_with if expect_true(cond): File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 1702, in expect_true return a.node.expect_true( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 559, in expect_true return self.shape_env.guard_or_defer_runtime_assert( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7730, in guard_or_defer_runtime_assert self._maybe_guard_rel(expr) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyCodec_EncodeText File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6868, in _maybe_guard_rel self._refine_ranges(expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7819, in _refine_ranges self._set_replacement( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() - You marked d1 as dynamic but your code specialized it to be a constant (4). If you\u0027re using mark_dynamic, either remove it or use maybe_mark_dynamic. If you\u0027re using Dim.DYNAMIC, replace it with either Dim.STATIC or Dim.AUTO. Framework stack: File \"??\", line 0, in _start File \"??\", line 0, in __libc_start_main File \"??\", line 0, in __libc_init_first File \"??\", line 0, in Py_BytesMain File \"??\", line 0, in Py_RunMain File \"??\", line 0, in _PyRun_AnyFileObject File \"??\", line 0, in _PyRun_SimpleFileObject File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyInit__collections File \"??\", line 0, in PyUnicode_Tailmatch File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e sys.exit(main()) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main return make_main(argv) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main return make_mode.run_make_mode(argv[1:]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode return make.run_generic_build(args[0]) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build return build_main(args + opts) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main app = Sphinx(args.sourcedir, args.confdir, args.outputdir, File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ self._init_builder() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder self.events.emit(\u0027builder-inited\u0027) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit results.append(listener.handler(self.app, *args)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst ) = generate_dir_rst( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst results = parallel( File \"??\", line 0, in PyUnicode_Decode File \"??\", line 0, in _PyLong_FromByteArray File \"??\", line 0, in PyObject_SelfIter File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 85, in wrapper p.start() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start self._popen = self._Popen(self) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen return _default_context.get_context().Process._Popen(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen return Popen(process_obj) File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in _PyStack_AsDict File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ self._launch(process_obj) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch code = process_obj._bootstrap(parent_sentinel=child_r) File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap self.run() File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run self._target(*self._args, **self._kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/conf.py\", line 73, in call_fn result = func(*args, **kwargs) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst output_blocks, time_elapsed = execute_script( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script execute_code_block( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block is_last_expr, mem_max = _exec_and_get_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory mem_max, _ = call_memory( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop return 0.0, func() File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyInit__datetime File \"??\", line 0, in _PyObject_Call_Prepend File \"??\", line 0, in _PyObject_FastCallDictTstate File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ exec(self.code, self.fake_main.__dict__) File \"??\", line 0, in PyCell_New File \"??\", line 0, in PyFrozenSet_New File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in PyEval_EvalCode File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 557, in \u003cmodule\u003e ep = export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1798, in _export_to_aten_ir_make_fx produce_guards_callback(gm) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1944, in _produce_guards_callback return produce_guards_and_solve_constraints( File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 514, in produce_guards_and_solve_constraints shape_env.produce_guards( File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5200, in produce_guards return self.produce_guards_verbose(*args, **kwargs, langs=(\"python\",))[0].exprs File \"??\", line 0, in PyObject_Call File \"??\", line 0, in PyMethod_New File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5405, in produce_guards_verbose expr1, expr2 = get_expression(src1), get_expression(src2) # type: ignore[] File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 5399, in get_expression return symint.node.expr File \"??\", line 0, in PyObject_GetAttr File \"??\", line 0, in _PyObject_GenericGetAttrWithDict File \"??\", line 0, in PyObject_IsTrue File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 189, in expr return self.shape_env.replace(self._expr) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 2539, in wrapper return fn_cache(self, *args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyErr_FormatFromCause File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6324, in replace r = self._find(s) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 2539, in wrapper return fn_cache(self, *args, **kwargs) File \"??\", line 0, in PyObject_Call File \"??\", line 0, in _PyErr_FormatFromCause File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6809, in _find self._set_replacement(a, replaced, \"find\") File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 6768, in _set_replacement CapturedTraceback.extract(cpp=True) File \"??\", line 0, in _PyFunction_Vectorcall File \"??\", line 0, in _PyEval_EvalFrameDefault File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_traceback.py\", line 212, in extract torch._C._profiler.gather_traceback(python=True, script=script, cpp=cpp), File \"??\", line 0, in _PyObject_MakeTpCall File \"??\", line 0, in PyObject_CallFunctionObjArgs File \"\", line 0, in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) File \"\", line 0, in pybind11::cpp_function::initialize\u003cstd::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e, bool, bool, bool, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::arg_v, pybind11::arg_v, pybind11::arg_v\u003e(std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*\u0026)(bool, bool, bool), std::shared_ptr\u003ctorch::CapturedTraceback\u003e (*)(bool, bool, bool), pybind11::name const\u0026, pybind11::scope const\u0026, pybind11::sibling const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026, pybind11::arg_v const\u0026)::{lambda(pybind11::detail::function_call\u0026)#3}::operator()(pybind11::detail::function_call\u0026) const File \"??\", line 0, in torch::CapturedTraceback::gather(bool, bool, bool) File \"??\", line 0, in torch::unwind::unwind() - The values of dy = L[\u0027y\u0027].size()[0] and dx = L[\u0027x\u0027].size()[0] must always be equal. Suggested fixes: d1 = 4 dy = dx The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. The expectation with suggested fixes is that the user can interactively copy-paste the changes into their dynamic shapes specification, and successfully export afterwards. Lastly, there\u2019s couple nice-to-knows about the options for specification: None is a good option for static behavior: - dynamic_shapes=None (default) exports with the entire model being static. - specifying None at an input-level exports with all tensor dimensions static, and is also required for non-tensor inputs. - specifying None at a dimension-level specializes that dimension, though this is deprecated in favor of Dim.STATIC. specifying per-dimension integer values also produces static behavior, and will additionally check that the provided sample input matches the specification. These options are combined in the inputs \u0026 dynamic shapes spec below: inputs = ( torch.randn(4, 4), torch.randn(3, 3), 16, False, ) dynamic_shapes = { \"tensor_0\": (Dim.AUTO, None), \"tensor_1\": None, \"int_val\": None, \"bool_val\": None, } Data-dependent errors# While trying to export models, you have may have encountered errors like \u201cCould not guard on data-dependent expression\u201d, or Could not extract specialized integer from data-dependent expression\u201d. These errors exist because torch.export() compiles programs using FakeTensors, which symbolically represent their real tensor counterparts. While these have equivalent symbolic properties (e.g. sizes, strides, dtypes), they diverge in that FakeTensors do not contain any data values. While this avoids unnecessary memory usage and expensive computation, it does mean that export may be unable to out-of-the-box compile parts of user code where compilation relies on data values. In short, if the compiler requires a concrete, data-dependent value in order to proceed, it will error out, complaining that the value is not available. Data-dependent values appear in many places, and common sources are calls like item(), tolist(), or torch.unbind() that extract scalar values from tensors. How are these values represented in the exported program? In the Constraints/Dynamic Shapes section, we talked about allocating symbols to represent dynamic input dimensions. The same happens here: we allocate symbols for every data-dependent value that appears in the program. The important distinction is that these are \u201cunbacked\u201d symbols, in contrast to the \u201cbacked\u201d symbols allocated for input dimensions. The \u201cbacked/unbacked\u201d nomenclature refers to the presence/absence of a \u201chint\u201d for the symbol: a concrete value backing the symbol, that can inform the compiler on how to proceed. In the input shape symbol case (backed symbols), these hints are simply the sample input shapes provided, which explains why control-flow branching is determined by the sample input properties. For data-dependent values, the symbols are taken from FakeTensor \u201cdata\u201d during tracing, and so the compiler doesn\u2019t know the actual values (hints) that these symbols would take on. Let\u2019s see how these show up in exported programs: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() b = y.tolist() return b + [a] inps = ( torch.tensor(1), torch.tensor([2, 3]), ) ep = export(Foo(), inps) print(ep) I0917 20:30:34.965000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.970000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:34.970000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] I0917 20:30:34.974000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u1 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:34.974000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u1] I0917 20:30:34.976000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u2 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:34.976000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u2] I0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:34.978000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] 2 None V0917 20:30:34.979000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 1 None V0917 20:30:34.979000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"i64[]\", y: \"i64[2]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:618 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(x); x = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:619 in forward, code: b = y.tolist() unbind = torch.ops.aten.unbind.int(y); y = None getitem: \"i64[]\" = unbind[0] getitem_1: \"i64[]\" = unbind[1]; unbind = None item_1: \"Sym(u1)\" = torch.ops.aten.item.default(getitem); getitem = None item_2: \"Sym(u2)\" = torch.ops.aten.item.default(getitem_1); getitem_1 = None return (item_1, item_2, item) Graph signature: # inputs x: USER_INPUT y: USER_INPUT # outputs item_1: USER_OUTPUT item_2: USER_OUTPUT item: USER_OUTPUT Range constraints: {u0: VR[-int_oo, int_oo], u1: VR[-int_oo, int_oo], u2: VR[-int_oo, int_oo]} The result is that 3 unbacked symbols (notice they\u2019re prefixed with \u201cu\u201d, instead of the usual \u201cs\u201d for input shape/backed symbols) are allocated and returned: 1 for the item() call, and 1 for each of the elements of y with the tolist() call. Note from the range constraints field that these take on ranges of [-int_oo, int_oo], not the default [0, int_oo] range allocated to input shape symbols, since we have no information on what these values are - they don\u2019t represent sizes, so don\u2019t necessarily have positive values. Guards, torch._check()# But the case above is easy to export, because the concrete values of these symbols aren\u2019t used in any compiler decision-making; all that\u2019s relevant is that the return values are unbacked symbols. The data-dependent errors highlighted in this section are cases like the following, where data-dependent guards are encountered: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() if a // 2 \u003e= 5: return y + 2 else: return y * 5 Here we actually need the \u201chint\u201d, or the concrete value of a for the compiler to decide whether to trace return y + 2 or return y * 5 as the output. Because we trace with FakeTensors, we don\u2019t know what a // 2 \u003e= 5 actually evaluates to, and export errors out with \u201cCould not guard on data-dependent expression u0 // 2 \u003e= 5 (unhinted)\u201d. So how do we export this toy model? Unlike torch.compile(), export requires full graph compilation, and we can\u2019t just graph break on this. Here are some basic options: Manual specialization: we could intervene by selecting the branch to trace, either by removing the control-flow code to contain only the specialized branch, or using torch.compiler.is_compiling() to guard what\u2019s traced at compile-time. torch.cond(): we could rewrite the control-flow code to use torch.cond() so we don\u2019t specialize on a branch. While these options are valid, they have their pitfalls. Option 1 sometimes requires drastic, invasive rewrites of the model code to specialize, and torch.cond() is not a comprehensive system for handling data-dependent errors. As we will see, there are data-dependent errors that do not involve control-flow. The generally recommended approach is to start with torch._check() calls. While these give the impression of purely being assert statements, they are in fact a system of informing the compiler on properties of symbols. While a torch._check() call does act as an assertion at runtime, when traced at compile-time, the checked expression is sent to the symbolic shapes subsystem for reasoning, and any symbol properties that follow from the expression being true, are stored as symbol properties (provided it\u2019s smart enough to infer those properties). So even if unbacked symbols don\u2019t have hints, if we\u2019re able to communicate properties that are generally true for these symbols via torch._check() calls, we can potentially bypass data-dependent guards without rewriting the offending model code. For example in the model above, inserting torch._check(a \u003e= 10) would tell the compiler that y + 2 can always be returned, and torch._check(a == 4) tells it to return y * 5. See what happens when we re-export this model. class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() torch._check(a \u003e= 10) torch._check(a \u003c= 60) if a // 2 \u003e= 5: return y + 2 else: return y * 5 inps = ( torch.tensor(32), torch.randn(4), ) ep = export(Foo(), inps) print(ep) I0917 20:30:34.985000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:34.989000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:34.990000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] I0917 20:30:34.992000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 \u003e= 10 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:673 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"u0 \u003e= 10\" V0917 20:30:34.992000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[10, int_oo] (update) I0917 20:30:34.997000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 \u003c= 60 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:674 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"u0 \u003c= 60\" V0917 20:30:34.997000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[10, 60] (update) V0917 20:30:35.002000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known] I0917 20:30:35.005000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] 4 None V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 1 None V0917 20:30:35.006000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:35.008000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003e= 10 == True [statically known] V0917 20:30:35.009000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003c= 60 == True [statically known] ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"i64[]\", y: \"f32[4]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:672 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(x); x = None ge_2: \"Sym(u0 \u003e= 10)\" = item \u003e= 10 _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_2, \"Runtime assertion failed for expression u0 \u003e= 10 on node \u0027ge_2\u0027\"); ge_2 = _assert_scalar_default = None le_1: \"Sym(u0 \u003c= 60)\" = item \u003c= 60; item = None _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le_1, \"Runtime assertion failed for expression u0 \u003c= 60 on node \u0027le_1\u0027\"); le_1 = _assert_scalar_default_1 = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:676 in forward, code: return y + 2 add: \"f32[4]\" = torch.ops.aten.add.Tensor(y, 2); y = None return (add,) Graph signature: # inputs x: USER_INPUT y: USER_INPUT # outputs add: USER_OUTPUT Range constraints: {u0: VR[10, 60]} Export succeeds, and note from the range constraints field that u0 takes on a range of [10, 60]. So what information do torch._check() calls actually communicate? This varies as the symbolic shapes subsystem gets smarter, but at a fundamental level, these are generally true: Equality with non-data-dependent expressions: torch._check() calls that communicate equalities like u0 == s0 + 4 or u0 == 5. Range refinement: calls that provide lower or upper bounds for symbols, like the above. Some basic reasoning around more complicated expressions: inserting torch._check(a \u003c 4) will typically tell the compiler that a \u003e= 4 is false. Checks on complex expressions like torch._check(a ** 2 - 3 * a \u003c= 10) will typically get you past identical guards. As mentioned previously, torch._check() calls have applicability outside of data-dependent control flow. For example, here\u2019s a model where torch._check() insertion prevails while manual specialization \u0026 torch.cond() do not: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() return y[a] inps = ( torch.tensor(32), torch.randn(60), ) try: export(Foo(), inps) except Exception: tb.print_exc() I0917 20:30:35.014000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.020000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:35.020000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] Data dependent variable \u0027u0\u0027 allocated at: V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] sys.exit(main()) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_main(argv) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_mode.run_make_mode(argv[1:]) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make.run_generic_build(args[0]) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return build_main(args + opts) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] app = Sphinx(args.sourcedir, args.confdir, args.outputdir, V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._init_builder() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self.events.emit(\u0027builder-inited\u0027) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] results.append(listener.handler(self.app, *args)) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ) = generate_dir_rst( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] results = parallel( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/conf.py\", line 85, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] p.start() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._popen = self._Popen(self) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _default_context.get_context().Process._Popen(process_obj) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Popen(process_obj) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._launch(process_obj) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] code = process_obj._bootstrap(parent_sentinel=child_r) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self.run() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._target(*self._args, **self._kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/conf.py\", line 73, in call_fn V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] result = func(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] output_blocks, time_elapsed = execute_script( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] execute_code_block( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] is_last_expr, mem_max = _exec_and_get_memory( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] mem_max, _ = call_memory( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return 0.0, func() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] exec(self.code, self.fake_main.__dict__) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 709, in \u003cmodule\u003e V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] export(Foo(), inps) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _export( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = _export_for_training( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] export_artifact = export_func( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] aten_export_artifact = _to_aten_func( # type: ignore[operator] V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm, graph_signature = transform(_make_fx_helper)( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm = make_fx( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_fx_tracer.trace(f, *args) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._trace_inner(f, *args) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] t = dispatch_trace( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return disable_fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] res = super().trace(root, concrete_args) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] (self.create_arg(fn(*args)),), V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = f(*tensors) # type:ignore[call-arg] V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return tuple(flat_fn(*args)) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] tree_out = fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = mod(*args[params_len:], **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.call_module(mod, forward, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Tracer.call_module(self, m, forward, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ret_val = forward(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _orig_module_call(mod, *args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._call_impl(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return forward_call(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] tree_out = mod(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.call_module(mod, forward, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Tracer.call_module(self, m, forward, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ret_val = forward(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _orig_module_call(mod, *args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._call_impl(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return forward_call(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 701, in forward V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] a = x.item() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return torch._library.utils.handle_dispatch_mode( V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return proxy_call(self, func, self.pre_dispatch, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = func(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._op(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.dispatch(func, types, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._cached_dispatch_impl(func, types, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1474, in _cached_dispatch_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._dispatch_impl(func, types, args, kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2687, in _dispatch_impl V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] op_impl_out = op_impl(self, func, *args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 163, in dispatch_to_op_implementations_dict V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return op_implementations_dict[func](fake_mode, func, *args, **kwargs) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 425, in local_scalar_dense V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] r = fake_mode.shape_env.create_unbacked_symint() V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return retlog(fn(*args, **kwargs)) V0917 20:30:35.023000 31631 torch/fx/experimental/symbolic_shapes.py:6519] E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] failed while attempting to run meta for aten.select.int E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] Traceback (most recent call last): E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2717, in _dispatch_impl E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] r = func(*args, **kwargs) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return self._op(*args, **kwargs) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 5545, in meta_select E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] guard_size_oblivious(-index \u003e size) or guard_size_oblivious(index \u003e= size) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 473, in guard_size_oblivious E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return expr.node.guard_size_oblivious(\"\", 0) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 596, in guard_size_oblivious E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] r = self.evaluate(size_oblivious=True) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 512, in evaluate E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return self.shape_env.evaluate_sym_node(self, size_oblivious) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7223, in evaluate_sym_node E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return self.evaluate_expr( E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7323, in evaluate_expr E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return self._inner_evaluate_expr( E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return retlog(fn(*args, **kwargs)) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7346, in _inner_evaluate_expr E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] return self._evaluate_expr( E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7570, in _evaluate_expr E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] raise self._make_data_dependent_error( E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression -u0 \u003e 60 (unhinted: -u0 \u003e 60). (Size-like symbols: none) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] Caused by: (_meta_registrations.py:5545 in meta_select) E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For more information, run with TORCH_LOGS=\"dynamic\" E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\" E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] E0917 20:30:35.032000 31631 torch/_subclasses/fake_tensor.py:2721] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 def forward(self, arg0_1: \"i64[]\", arg1_1: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:701 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(arg0_1); arg0_1 = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:702 in forward, code: return y[a] select = torch.ops.aten.select.int(arg1_1, 0, item); arg1_1 = item = select = None def forward(self, arg0_1: \"i64[]\", arg1_1: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:701 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(arg0_1); arg0_1 = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:702 in forward, code: return y[a] select = torch.ops.aten.select.int(arg1_1, 0, item); arg1_1 = item = select = None Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 709, in \u003cmodule\u003e export(Foo(), inps) File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 702, in forward return y[a] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ return func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1026, in run t = _method(t, *_args) File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler return torch._library.utils.handle_dispatch_mode( File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ return proxy_call(self, func, self.pre_dispatch, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call out = func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ return self.dispatch(func, types, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch return self._cached_dispatch_impl(func, types, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1487, in _cached_dispatch_impl output = self._dispatch_impl(func, types, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2717, in _dispatch_impl r = func(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ return self._op(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_meta_registrations.py\", line 5545, in meta_select guard_size_oblivious(-index \u003e size) or guard_size_oblivious(index \u003e= size) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 473, in guard_size_oblivious return expr.node.guard_size_oblivious(\"\", 0) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 596, in guard_size_oblivious r = self.evaluate(size_oblivious=True) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 512, in evaluate return self.shape_env.evaluate_sym_node(self, size_oblivious) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7223, in evaluate_sym_node return self.evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7323, in evaluate_expr return self._inner_evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7346, in _inner_evaluate_expr return self._evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7570, in _evaluate_expr raise self._make_data_dependent_error( torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not guard on data-dependent expression -u0 \u003e 60 (unhinted: -u0 \u003e 60). (Size-like symbols: none) Caused by: (_meta_registrations.py:5545 in meta_select) For more information, run with TORCH_LOGS=\"dynamic\" For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\" If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 The following call raised this error: File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 702, in forward return y[a] To fix the error, insert one of the following checks before this call: 1. torch._check((-1)*a \u003e 60) 2. torch._check((-1)*a \u003c= 60) (These suggested fixes were derived by replacing `u0` with a in -u0 \u003e 60 and its negation.) The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. Here is a scenario where torch._check() insertion is required simply to prevent an operation from failing. The export call will fail with \u201cCould not guard on data-dependent expression -u0 \u003e 60\u201d, implying that the compiler doesn\u2019t know if this is a valid indexing operation - if the value of x is out-of-bounds for y or not. Here, manual specialization is too prohibitive, and torch.cond() has no place. Instead, informing the compiler of u0\u2019s range is sufficient: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() torch._check(a \u003e= 0) torch._check(a \u003c y.shape[0]) return y[a] inps = ( torch.tensor(32), torch.randn(60), ) ep = export(Foo(), inps) print(ep) I0917 20:30:35.046000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.051000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:35.052000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] I0917 20:30:35.053000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 \u003e= 0 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:722 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"u0 \u003e= 0\" V0917 20:30:35.054000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, int_oo] (update) I0917 20:30:35.057000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 \u003c 60 [guard added] (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:723 in forward), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"u0 \u003c 60\" V0917 20:30:35.057000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, 59] (update) V0917 20:30:35.060000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(-u0 \u003e 60) == False [statically known] V0917 20:30:35.060000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval size_oblivious(u0 \u003e= 60) == False [statically known] V0917 20:30:35.061000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known] V0917 20:30:35.062000 31631 torch/fx/experimental/symbolic_shapes.py:7475] eval False == True [statically known] I0917 20:30:35.064000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:35.064000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] 60 None V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 1 None V0917 20:30:35.065000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:35.066000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003e= 0 == True [statically known] V0917 20:30:35.068000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003c= 59 == True [statically known] V0917 20:30:35.069000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003c 60 == True [statically known] ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"i64[]\", y: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:721 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(x); x = None ge_1: \"Sym(u0 \u003e= 0)\" = item \u003e= 0 _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_1, \"Runtime assertion failed for expression u0 \u003e= 0 on node \u0027ge_1\u0027\"); ge_1 = _assert_scalar_default = None le: \"Sym(u0 \u003c= 59)\" = item \u003c= 59 _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le, \"Runtime assertion failed for expression u0 \u003c= 59 on node \u0027le\u0027\"); le = _assert_scalar_default_1 = None # lt_1: \"Sym(u0 \u003c 60)\" = item \u003c 60 _assert_scalar_default_2 = torch.ops.aten._assert_scalar.default(lt_1, \"Runtime assertion failed for expression u0 \u003c 60 on node \u0027lt_1\u0027\"); lt_1 = _assert_scalar_default_2 = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:724 in forward, code: return y[a] select: \"f32[]\" = torch.ops.aten.select.int(y, 0, item); y = item = None return (select,) Graph signature: # inputs x: USER_INPUT y: USER_INPUT # outputs select: USER_OUTPUT Range constraints: {u0: VR[0, 59]} Specialized values# Another category of data-dependent error happens when the program attempts to extract a concrete data-dependent integer/float value while tracing. This looks something like \u201cCould not extract specialized integer from data-dependent expression\u201d, and is analogous to the previous class of errors - if these occur when attempting to evaluate concrete integer/float values, data-dependent guard errors arise with evaluating concrete boolean values. This error typically occurs when there is an explicit or implicit int() cast on a data-dependent expression. For example, this list comprehension has a range() call that implicitly does an int() cast on the size of the list: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() b = torch.cat([y for y in range(a)], dim=0) return b + int(a) inps = ( torch.tensor(32), torch.randn(60), ) try: export(Foo(), inps, strict=False) except Exception: tb.print_exc() I0917 20:30:35.075000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.081000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:35.082000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] Data dependent variable \u0027u0\u0027 allocated at: V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/bin/sphinx-build\", line 7, in \u003cmodule\u003e V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] sys.exit(main()) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 339, in main V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_main(argv) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 213, in make_main V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_mode.run_make_mode(argv[1:]) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 181, in run_make_mode V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make.run_generic_build(args[0]) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/make_mode.py\", line 169, in run_generic_build V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return build_main(args + opts) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/cmd/build.py\", line 293, in build_main V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] app = Sphinx(args.sourcedir, args.confdir, args.outputdir, V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 272, in __init__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._init_builder() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/application.py\", line 343, in _init_builder V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self.events.emit(\u0027builder-inited\u0027) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx/events.py\", line 97, in emit V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] results.append(listener.handler(self.app, *args)) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_gallery.py\", line 757, in generate_gallery_rst V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ) = generate_dir_rst( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 606, in generate_dir_rst V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] results = parallel( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 607, in \u003cgenexpr\u003e V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] p_fun(fname, target_dir, src_dir, gallery_conf) for fname in iterator V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/conf.py\", line 85, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] p.start() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 121, in start V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._popen = self._Popen(self) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _default_context.get_context().Process._Popen(process_obj) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Popen(process_obj) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._launch(process_obj) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] code = process_obj._bootstrap(parent_sentinel=child_r) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self.run() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] self._target(*self._args, **self._kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/conf.py\", line 73, in call_fn V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] result = func(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1374, in generate_file_rst V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] output_blocks, time_elapsed = execute_script( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1192, in execute_script V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] execute_code_block( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1048, in execute_code_block V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] is_last_expr, mem_max = _exec_and_get_memory( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 876, in _exec_and_get_memory V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] mem_max, _ = call_memory( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 1725, in _sg_call_memory_noop V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return 0.0, func() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/sphinx_gallery/gen_rst.py\", line 794, in __call__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] exec(self.code, self.fake_main.__dict__) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 756, in \u003cmodule\u003e V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] export(Foo(), inps, strict=False) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _export( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = _export_for_training( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ep = fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] export_artifact = export_func( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] aten_export_artifact = _to_aten_func( # type: ignore[operator] V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm, graph_signature = transform(_make_fx_helper)( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] gm = make_fx( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return make_fx_tracer.trace(f, *args) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._trace_inner(f, *args) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] t = dispatch_trace( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return disable_fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] res = super().trace(root, concrete_args) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] (self.create_arg(fn(*args)),), V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = f(*tensors) # type:ignore[call-arg] V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return tuple(flat_fn(*args)) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] tree_out = fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = mod(*args[params_len:], **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.call_module(mod, forward, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Tracer.call_module(self, m, forward, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ret_val = forward(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _orig_module_call(mod, *args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._call_impl(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return forward_call(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] tree_out = mod(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.call_module(mod, forward, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return Tracer.call_module(self, m, forward, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] ret_val = forward(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return _orig_module_call(mod, *args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._call_impl(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return forward_call(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 747, in forward V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] a = x.item() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1360, in __torch_function__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1407, in __torch_function__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_export/non_strict_utils.py\", line 1051, in __torch_function__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return func(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 950, in handler V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return torch._library.utils.handle_dispatch_mode( V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_library/utils.py\", line 296, in handle_dispatch_mode V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return curr_mode.__torch_dispatch__(op_overload, overload_types, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1462, in __torch_dispatch__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return proxy_call(self, func, self.pre_dispatch, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 914, in proxy_call V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] out = func(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_ops.py\", line 829, in __call__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._op(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_stats.py\", line 28, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return fn(*args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1352, in __torch_dispatch__ V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self.dispatch(func, types, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2058, in dispatch V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._cached_dispatch_impl(func, types, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 1474, in _cached_dispatch_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return self._dispatch_impl(func, types, args, kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\", line 2687, in _dispatch_impl V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] op_impl_out = op_impl(self, func, *args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 163, in dispatch_to_op_implementations_dict V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return op_implementations_dict[func](fake_mode, func, *args, **kwargs) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_impls.py\", line 425, in local_scalar_dense V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] r = fake_mode.shape_env.create_unbacked_symint() V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] return retlog(fn(*args, **kwargs)) V0917 20:30:35.083000 31631 torch/fx/experimental/symbolic_shapes.py:6519] def forward(self, arg0_1: \"i64[]\", arg1_1: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:747 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(arg0_1); arg0_1 = item = None def forward(self, arg0_1: \"i64[]\", arg1_1: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:747 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(arg0_1); arg0_1 = item = None Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 756, in \u003cmodule\u003e export(Foo(), inps, strict=False) File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 319, in export raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/__init__.py\", line 286, in export return _export( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2176, in _export ep = _export_for_training( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1164, in wrapper raise e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1130, in wrapper ep = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/exported_program.py\", line 123, in wrapper return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 2037, in _export_for_training export_artifact = export_func( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1979, in _non_strict_export aten_export_artifact = _to_aten_func( # type: ignore[operator] File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1770, in _export_to_aten_ir_make_fx gm, graph_signature = transform(_make_fx_helper)( File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1900, in _aot_export_non_strict gm, sig = aot_export(wrapped_mod, args, kwargs=kwargs, **flags) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1685, in _make_fx_helper gm = make_fx( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2318, in wrapped return make_fx_tracer.trace(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2250, in trace return self._trace_inner(f, *args) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 2221, in _trace_inner t = dispatch_trace( File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 53, in inner return disable_fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1254, in dispatch_trace graph = tracer.trace(root, concrete_args) # type: ignore[arg-type] File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1835, in trace res = super().trace(root, concrete_args) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 929, in _fn return fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 850, in trace (self.create_arg(fn(*args)),), File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1312, in wrapped out = f(*tensors) # type:ignore[call-arg] File \"\u003cstring\u003e\", line 1, in \u003clambda\u003e File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1589, in wrapped_fn return tuple(flat_fn(*args)) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/utils.py\", line 184, in flat_fn tree_out = fn(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/traced_function_transforms.py\", line 906, in functional_call out = mod(*args[params_len:], **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/export/_trace.py\", line 1884, in forward tree_out = mod(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 825, in module_call_wrapper return self.call_module(mod, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/proxy_tensor.py\", line 1905, in call_module return Tracer.call_module(self, m, forward, args, kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 542, in call_module ret_val = forward(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/_symbolic_trace.py\", line 818, in forward return _orig_module_call(mod, *args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl return self._call_impl(*args, **kwargs) File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl return forward_call(*args, **kwargs) File \"/var/lib/workspace/intermediate_source/torch_export_tutorial.py\", line 748, in forward b = torch.cat([y for y in range(a)], dim=0) File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 438, in __index__ return self.node.int_() File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 468, in int_ return self.guard_int(\"\", 0) # NB: uses Python backtrace File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 518, in guard_int r = self.evaluate() File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/sym_node.py\", line 512, in evaluate return self.shape_env.evaluate_sym_node(self, size_oblivious) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7223, in evaluate_sym_node return self.evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7323, in evaluate_expr return self._inner_evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/recording.py\", line 272, in wrapper return retlog(fn(*args, **kwargs)) File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7346, in _inner_evaluate_expr return self._evaluate_expr( File \"/usr/local/lib/python3.10/dist-packages/torch/fx/experimental/symbolic_shapes.py\", line 7570, in _evaluate_expr raise self._make_data_dependent_error( torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode: Could not extract specialized integer from data-dependent expression u0 (unhinted: u0). (Size-like symbols: none) Caused by: (ar/lib/workspace/intermediate_source/torch_export_tutorial.py:748 in forward) For more information, run with TORCH_LOGS=\"dynamic\" For extended logs when we create symbols, also add TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"u0\" If you suspect the guard was triggered from C++, add TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 For more debugging help, see https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit?usp=sharing For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 The error above occurred when calling torch.export.export. If you would like to view some more information about this error, and get a list of all other errors that may occur in your export call, you can replace your `export()` call with `draft_export()`. For these errors, some basic options you have are: Avoid unnecessary int() cast calls, in this case the int(a) in the return statement. Use torch._check() calls; unfortunately all you may be able to do in this case is specialize (with torch._check(a == 60)). Rewrite the offending code at a higher level. For example, the list comprehension is semantically a repeat() op, which doesn\u2019t involve an int() cast. The following rewrite avoids data-dependent errors: class Foo(torch.nn.Module): def forward(self, x, y): a = x.item() b = y.unsqueeze(0).repeat(a, 1) return b + a inps = ( torch.tensor(32), torch.randn(60), ) ep = export(Foo(), inps, strict=False) print(ep) I0917 20:30:35.101000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.106000 31631 torch/fx/experimental/symbolic_shapes.py:4776] create_unbacked_symint u0 [-int_oo, int_oo] (_subclasses/fake_impls.py:425 in local_scalar_dense) I0917 20:30:35.106000 31631 torch/fx/experimental/symbolic_shapes.py:1287] compute_unbacked_bindings [u0] I0917 20:30:35.110000 31631 torch/fx/experimental/symbolic_shapes.py:7197] runtime_assert u0 \u003e= 0 [guard added] (_meta_registrations.py:4247 in meta_repeat), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED=\"u0 \u003e= 0\" V0917 20:30:35.110000 31631 torch/fx/experimental/symbolic_shapes.py:6606] _update_var_to_range u0 = VR[0, int_oo] (update) V0917 20:30:35.111000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003e= 0 == True [statically known] I0917 20:30:35.114000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate Eq(u0, 0) due to data dependency, it was assumed to be False with no runtime assertions (utils/_stats.py:28 in wrapper) I0917 20:30:35.114000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 I0917 20:30:35.120000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate 60*u0 \u003c 2 due to data dependency, it was assumed to be False with no runtime assertions (_prims_common/__init__.py:279 in is_contiguous) I0917 20:30:35.120000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 I0917 20:30:35.121000 31631 torch/fx/experimental/symbolic_shapes.py:7369] could not evaluate Eq(u0, 1) due to data dependency, it was assumed to be False with no runtime assertions (_prims_common/__init__.py:285 in is_contiguous) I0917 20:30:35.121000 31631 torch/fx/experimental/symbolic_shapes.py:7369] For C++ stack trace, run with TORCHDYNAMO_EXTENDED_DEBUG_CPP=1 V0917 20:30:35.123000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert True == True [statically known] I0917 20:30:35.128000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:35.128000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].size()[0] 60 None V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].stride()[0] 1 None V0917 20:30:35.129000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027y\u0027].storage_offset() 0 None V0917 20:30:35.130000 31631 torch/fx/experimental/symbolic_shapes.py:7694] runtime_assert u0 \u003e= 0 == True [statically known] ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"i64[]\", y: \"f32[60]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:769 in forward, code: a = x.item() item: \"Sym(u0)\" = torch.ops.aten.item.default(x); x = None # sym_constrain_range_for_size_default = torch.ops.aten.sym_constrain_range_for_size.default(item); sym_constrain_range_for_size_default = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:769 in forward, code: a = x.item() ge: \"Sym(u0 \u003e= 0)\" = item \u003e= 0 _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge, \"Runtime assertion failed for expression u0 \u003e= 0 on node \u0027ge\u0027\"); ge = _assert_scalar_default = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:770 in forward, code: b = y.unsqueeze(0).repeat(a, 1) unsqueeze: \"f32[1, 60]\" = torch.ops.aten.unsqueeze.default(y, 0); y = None repeat: \"f32[u0, 60]\" = torch.ops.aten.repeat.default(unsqueeze, [item, 1]); unsqueeze = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:771 in forward, code: return b + a add: \"f32[u0, 60]\" = torch.ops.aten.add.Tensor(repeat, item); repeat = item = None return (add,) Graph signature: # inputs x: USER_INPUT y: USER_INPUT # outputs add: USER_OUTPUT Range constraints: {u0: VR[0, int_oo]} Data-dependent errors can be much more involved, and there are many more options in your toolkit to deal with them: torch._check_is_size(), guard_size_oblivious(), or real-tensor tracing, as starters. For more in-depth guides, please refer to the Export Programming Model, or Dealing with GuardOnDataDependentSymNode errors. Custom Ops# torch.export can export PyTorch programs with custom operators. Please refer to this page on how to author a custom operator in either C++ or Python. The following is an example of registering a custom operator in python to be used by torch.export. The important thing to note is that the custom op must have a FakeTensor kernel. @torch.library.custom_op(\"my_custom_library::custom_op\", mutates_args={}) def custom_op(x: torch.Tensor) -\u003e torch.Tensor: print(\"custom_op called!\") return torch.relu(x) @custom_op.register_fake def custom_op_meta(x): # Returns an empty tensor with the same shape as the expected output return torch.empty_like(x) Here is an example of exporting a program with the custom op. class CustomOpExample(torch.nn.Module): def forward(self, x): x = torch.sin(x) x = torch.ops.my_custom_library.custom_op(x) x = torch.cos(x) return x exported_custom_op_example = export(CustomOpExample(), (torch.randn(3, 3),)) print(exported_custom_op_example) print(exported_custom_op_example.module()(torch.randn(3, 3))) I0917 20:30:35.206000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.216000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:35.216000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] 3 None V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[1] 3 None V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 3 None V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[1] 1 None V0917 20:30:35.217000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None ExportedProgram: class GraphModule(torch.nn.Module): def forward(self, x: \"f32[3, 3]\"): # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:812 in forward, code: x = torch.sin(x) sin: \"f32[3, 3]\" = torch.ops.aten.sin.default(x); x = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:813 in forward, code: x = torch.ops.my_custom_library.custom_op(x) custom_op: \"f32[3, 3]\" = torch.ops.my_custom_library.custom_op.default(sin); sin = None # File: /var/lib/workspace/intermediate_source/torch_export_tutorial.py:814 in forward, code: x = torch.cos(x) cos: \"f32[3, 3]\" = torch.ops.aten.cos.default(custom_op); custom_op = None return (cos,) Graph signature: # inputs x: USER_INPUT # outputs cos: USER_OUTPUT Range constraints: {} custom_op called! tensor([[1.0000, 0.6898, 1.0000], [0.7006, 0.9948, 0.9682], [1.0000, 0.9950, 1.0000]]) Note that in the ExportedProgram, the custom operator is included in the graph. IR/Decompositions# The graph produced by torch.export returns a graph containing only ATen operators, which are the basic unit of computation in PyTorch. As there are over 3000 ATen operators, export provides a way to narrow down the operator set used in the graph based on certain characteristics, creating different IRs. By default, export produces the most generic IR which contains all ATen operators, including both functional and non-functional operators. A functional operator is one that does not contain any mutations or aliasing of the inputs. You can find a list of all ATen operators here and you can inspect if an operator is functional by checking op._schema.is_mutable, for example: print(torch.ops.aten.add.Tensor._schema.is_mutable) print(torch.ops.aten.add_.Tensor._schema.is_mutable) False True This generic IR can be used to train in eager PyTorch Autograd. This IR can be more explicitly reached through the API torch.export.export_for_training, which was introduced in PyTorch 2.5, but calling torch.export.export should produce the same graph as of PyTorch 2.6. class DecompExample(torch.nn.Module): def __init__(self) -\u003e None: super().__init__() self.conv = torch.nn.Conv2d(1, 3, 1, 1) self.bn = torch.nn.BatchNorm2d(3) def forward(self, x): x = self.conv(x) x = self.bn(x) return (x,) ep_for_training = torch.export.export_for_training(DecompExample(), (torch.randn(1, 1, 3, 3),)) print(ep_for_training.graph) I0917 20:30:35.227000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:35.257000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] 1 None V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[1] 1 None V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[2] 3 None V0917 20:30:35.258000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[3] 3 None V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 9 None V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[1] 9 None V0917 20:30:35.259000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[2] 3 None V0917 20:30:35.260000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[3] 1 None V0917 20:30:35.260000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None graph(): %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight] %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias] %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight] %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias] %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean] %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var] %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked] %x : [num_users=1] = placeholder[target=x] %conv2d : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%x, %p_conv_weight, %p_conv_bias), kwargs = {}) %add_ : [num_users=0] = call_function[target=torch.ops.aten.add_.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {}) %batch_norm : [num_users=1] = call_function[target=torch.ops.aten.batch_norm.default](args = (%conv2d, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05, True), kwargs = {}) return (batch_norm,) We can then lower this exported program to an operator set which only contains functional ATen operators through the API run_decompositions, which decomposes the ATen operators into the ones specified in the decomposition table, and functionalizes the graph. By specifying an empty set, we\u2019re only performing functionalization, and does not do any additional decompositions. This results in an IR which contains ~2000 operators (instead of the 3000 operators above), and is ideal for inference cases. ep_for_inference = ep_for_training.run_decompositions(decomp_table={}) print(ep_for_inference.graph) graph(): %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight] %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias] %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight] %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias] %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean] %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var] %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked] %x : [num_users=1] = placeholder[target=x] %conv2d : [num_users=1] = call_function[target=torch.ops.aten.conv2d.default](args = (%x, %p_conv_weight, %p_conv_bias), kwargs = {}) %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {}) %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%conv2d, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {}) %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {}) %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {}) %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {}) return (getitem_3, getitem_4, add, getitem) As we can see, the previously mutable operator, torch.ops.aten.add_.default has now been replaced with torch.ops.aten.add.default, a l operator. We can also further lower this exported program to an operator set which only contains the Core ATen Operator Set, which is a collection of only ~180 operators. This IR is optimal for backends who do not want to reimplement all ATen operators. from torch.export import default_decompositions core_aten_decomp_table = default_decompositions() core_aten_ep = ep_for_training.run_decompositions(decomp_table=core_aten_decomp_table) print(core_aten_ep.graph) graph(): %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight] %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias] %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight] %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias] %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean] %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var] %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked] %x : [num_users=1] = placeholder[target=x] %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%x, %p_conv_weight, %p_conv_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {}) %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {}) %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%convolution, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {}) %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {}) %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {}) %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {}) return (getitem_3, getitem_4, add, getitem) We now see that torch.ops.aten.conv2d.default has been decomposed into torch.ops.aten.convolution.default. This is because convolution is a more \u201ccore\u201d operator, as operations like conv1d and conv2d can be implemented using the same op. We can also specify our own decomposition behaviors: my_decomp_table = torch.export.default_decompositions() def my_awesome_custom_conv2d_function(x, weight, bias, stride=[1, 1], padding=[0, 0], dilation=[1, 1], groups=1): return 2 * torch.ops.aten.convolution(x, weight, bias, stride, padding, dilation, False, [0, 0], groups) my_decomp_table[torch.ops.aten.conv2d.default] = my_awesome_custom_conv2d_function my_ep = ep_for_training.run_decompositions(my_decomp_table) print(my_ep.graph) graph(): %p_conv_weight : [num_users=1] = placeholder[target=p_conv_weight] %p_conv_bias : [num_users=1] = placeholder[target=p_conv_bias] %p_bn_weight : [num_users=1] = placeholder[target=p_bn_weight] %p_bn_bias : [num_users=1] = placeholder[target=p_bn_bias] %b_bn_running_mean : [num_users=1] = placeholder[target=b_bn_running_mean] %b_bn_running_var : [num_users=1] = placeholder[target=b_bn_running_var] %b_bn_num_batches_tracked : [num_users=1] = placeholder[target=b_bn_num_batches_tracked] %x : [num_users=1] = placeholder[target=x] %convolution : [num_users=1] = call_function[target=torch.ops.aten.convolution.default](args = (%x, %p_conv_weight, %p_conv_bias, [1, 1], [0, 0], [1, 1], False, [0, 0], 1), kwargs = {}) %mul : [num_users=1] = call_function[target=torch.ops.aten.mul.Tensor](args = (%convolution, 2), kwargs = {}) %add : [num_users=1] = call_function[target=torch.ops.aten.add.Tensor](args = (%b_bn_num_batches_tracked, 1), kwargs = {}) %_native_batch_norm_legit_functional : [num_users=3] = call_function[target=torch.ops.aten._native_batch_norm_legit_functional.default](args = (%mul, %p_bn_weight, %p_bn_bias, %b_bn_running_mean, %b_bn_running_var, True, 0.1, 1e-05), kwargs = {}) %getitem : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 0), kwargs = {}) %getitem_3 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 3), kwargs = {}) %getitem_4 : [num_users=1] = call_function[target=operator.getitem](args = (%_native_batch_norm_legit_functional, 4), kwargs = {}) return (getitem_3, getitem_4, add, getitem) Notice that instead of torch.ops.aten.conv2d.default being decomposed into torch.ops.aten.convolution.default, it is now decomposed into torch.ops.aten.convolution.default and torch.ops.aten.mul.Tensor, which matches our custom decomposition rule. ExportDB# torch.export will only ever export a single computation graph from a PyTorch program. Because of this requirement, there will be Python or PyTorch features that are not compatible with torch.export, which will require users to rewrite parts of their model code. We have seen examples of this earlier in the tutorial \u2013 for example, rewriting if-statements using cond. ExportDB is the standard reference that documents supported and unsupported Python/PyTorch features for torch.export. It is essentially a list a program samples, each of which represents the usage of one particular Python/PyTorch feature and its interaction with torch.export. Examples are also tagged by category so that they can be more easily searched. For example, let\u2019s use ExportDB to get a better understanding of how the predicate works in the cond operator. We can look at the example called cond_predicate, which has a torch.cond tag. The example code looks like: def cond_predicate(x): \"\"\" The conditional statement (aka predicate) passed to ``cond()`` must be one of the following: - ``torch.Tensor`` with a single element - boolean expression NOTE: If the `pred` is test on a dim with batch size \u003c 2, it will be specialized. \"\"\" pred = x.dim() \u003e 2 and x.shape[2] \u003e 10 return cond(pred, lambda x: x.cos(), lambda y: y.sin(), [x]) More generally, ExportDB can be used as a reference when one of the following occurs: Before attempting torch.export, you know ahead of time that your model uses some tricky Python/PyTorch features and you want to know if torch.export covers that feature. When attempting torch.export, there is a failure and it\u2019s unclear how to work around it. ExportDB is not exhaustive, but is intended to cover all use cases found in typical PyTorch code. Feel free to reach out if there is an important Python/PyTorch feature that should be added to ExportDB or supported by torch.export. Running the Exported Program# As torch.export is only a graph capturing mechanism, calling the artifact produced by torch.export eagerly will be equivalent to running the eager module. To optimize the execution of the Exported Program, we can pass this exported artifact to backends such as Inductor through torch.compile, AOTInductor, or TensorRT. class M(torch.nn.Module): def __init__(self): super().__init__() self.linear = torch.nn.Linear(3, 3) def forward(self, x): x = self.linear(x) return x inp = torch.randn(2, 3, device=\"cuda\") m = M().to(device=\"cuda\") ep = torch.export.export(m, (inp,)) # Run it eagerly res = ep.module()(inp) print(res) # Run it with torch.compile res = torch.compile(ep.module(), backend=\"inductor\")(inp) print(res) I0917 20:30:36.192000 31631 torch/fx/experimental/symbolic_shapes.py:3767] create_env I0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5238] produce_guards V0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[0] 2 None V0917 20:30:36.205000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].size()[1] 3 None V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[0] 3 None V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].stride()[1] 1 None V0917 20:30:36.206000 31631 torch/fx/experimental/symbolic_shapes.py:5458] track_symint L[\u0027x\u0027].storage_offset() 0 None tensor([[-0.0818, 0.3067, 0.4360], [-0.0191, 0.2972, 0.4662]], device=\u0027cuda:0\u0027, grad_fn=\u003cAddmmBackward0\u003e) I0917 20:30:37.613000 31631 torch/fx/experimental/symbolic_shapes.py:3767] [2/0] create_env /usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py:282: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision(\u0027high\u0027)` for better performance. I0917 20:30:38.330000 31631 torch/fx/experimental/symbolic_shapes.py:5238] [2/0] produce_guards I0917 20:30:38.339000 31631 torch/fx/experimental/symbolic_shapes.py:5238] [2/0] produce_guards V0917 20:30:38.339000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027x\u0027].size()[0] 2 None V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027x\u0027].size()[1] 3 None V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027x\u0027].stride()[0] 3 None V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027x\u0027].stride()[1] 1 None V0917 20:30:38.340000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027x\u0027].storage_offset() 0 None V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].size()[0] 3 None V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].size()[1] 3 None V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].stride()[0] 3 None V0917 20:30:38.341000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].stride()[1] 1 None V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].storage_offset() 0 None V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].size()[0] 3 None V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].stride()[0] 1 None V0917 20:30:38.342000 31631 torch/fx/experimental/symbolic_shapes.py:5458] [2/0] track_symint L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].storage_offset() 0 None V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027x\u0027].size()[0] == 2 V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027x\u0027].size()[1] == 3 V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027x\u0027].stride()[0] == 3 V0917 20:30:38.343000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027x\u0027].stride()[1] == 1 V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027x\u0027].storage_offset() == 0 V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].size()[0] == 3 V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].size()[1] == 3 V0917 20:30:38.344000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].stride()[0] == 3 V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].stride()[1] == 1 V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027weight\u0027].storage_offset() == 0 V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].size()[0] == 3 V0917 20:30:38.345000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].stride()[0] == 1 V0917 20:30:38.346000 31631 torch/fx/experimental/symbolic_shapes.py:5679] [2/0] Skipping guard L[\u0027self\u0027]._modules[\u0027linear\u0027]._parameters[\u0027bias\u0027].storage_offset() == 0 tensor([[-0.0818, 0.3067, 0.4360], [-0.0191, 0.2972, 0.4662]], device=\u0027cuda:0\u0027, grad_fn=\u003cCompiledFunctionBackward\u003e) import torch._inductor # Note: these APIs are subject to change # Compile the exported program to a PT2 archive using ``AOTInductor`` with torch.no_grad(): pt2_path = torch._inductor.aoti_compile_and_package(ep) # Load and run the .so file in Python. # To load and run it in a C++ environment, see: # https://pytorch.org/docs/main/torch.compiler_aot_inductor.html aoti_compiled = torch._inductor.aoti_load_package(pt2_path) res = aoti_compiled(inp) Conclusion# We introduced torch.export, the new PyTorch 2.X way to export single computation graphs from PyTorch programs. In particular, we demonstrate several code modifications and considerations (control flow ops, constraints, etc.) that need to be made in order to export a graph. Total running time of the script: (0 minutes 5.199 seconds) Download Jupyter notebook: torch_export_tutorial.ipynb Download Python source code: torch_export_tutorial.py Download zipped: torch_export_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/torch_export_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>