
<!DOCTYPE html>

<html data-content_root="../" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="2022-07-20T23:02:43+00:00" property="article:modified_time"/>
<title>Introduction to torch.compile — PyTorch Tutorials 2.9.0+cu128 documentation</title>
<script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
<!-- Loaded before other Sphinx assets -->
<link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" rel="preload" type="font/woff2"/>
<link href="../_static/pygments.css?v=536c50fe" rel="stylesheet" type="text/css"/>
<link href="../_static/css/theme.css?v=047068a3" rel="stylesheet" type="text/css"/>
<link href="../_static/copybutton.css?v=76b2166b" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery.css?v=d2d258e8" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-binder.css?v=f4aeca0c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-dataframe.css?v=2082cf3c" rel="stylesheet" type="text/css"/>
<link href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<link href="../_static/katex-math.css?v=91adb8b6" rel="stylesheet" type="text/css"/>
<link href="../_static/sphinx-design.min.css?v=95c83b7e" rel="stylesheet" type="text/css"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" rel="stylesheet" type="text/css"/>
<!-- Pre-loaded scripts that we'll load fully later -->
<link as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<link as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" rel="preload"/>
<script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/documentation_options.js?v=c2809cec"></script>
<script src="../_static/doctools.js?v=888ff710"></script>
<script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
<script src="../_static/clipboard.min.js?v=a7894cd8"></script>
<script src="../_static/copybutton.js?v=f281be69"></script>
<script src="../_static/katex.min.js?v=be8ff15f"></script>
<script src="../_static/auto-render.min.js?v=ad136472"></script>
<script src="../_static/katex_autorenderer.js?v=bebc588a"></script>
<script src="../_static/design-tabs.js?v=f930bc37"></script>
<script>DOCUMENTATION_OPTIONS.pagename = 'intermediate/torch_compile_tutorial';</script>
<link href="https://docs.pytorch.org/tutorials/intermediate/torch_compile_tutorial.html" rel="canonical"/>
<link href="../genindex.html" rel="index" title="Index"/>
<link href="../search.html" rel="search" title="Search"/>
<link href="torch_compile_full_example.html" rel="next" title="torch.compile End-to-End Tutorial"/>
<link href="../compilers_index.html" rel="prev" title="Compilers"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/2.3.1/list.min.js"></script>
<script>
  if (window.location.hostname === 'docs.pytorch.org' || window.location.hostname === 'docs-preview.pytorch.org') {
    const script = document.createElement('script');
    script.src = 'https://cmp.osano.com/16A0DbT9yDNIaQkvZ/31b1b91a-e0b6-47ea-bde2-7f2bd13dbe5c/osano.js?variant=one';
    document.head.appendChild(script);
  }
</script>
<script>
  // Cookie banner for non-LF projects
  document.addEventListener('DOMContentLoaded', function () {
    // Hide cookie banner on local environments and LF owned docs
    if (window.location.hostname === 'localhost' ||
      window.location.hostname === '0.0.0.0' ||
      window.location.hostname === '127.0.0.1' ||
      window.location.hostname === 'docs.pytorch.org' ||
      window.location.hostname === 'docs-preview.pytorch.org' ||
      window.location.hostname.startsWith('192.168.')) {
      const banner = document.querySelector('.cookie-banner-wrapper');
      if (banner) {
        banner.style.display = 'none';
      }
    }
  });
</script>
<!-- Conditional CSS for header and footer height adjustment -->
<link crossorigin="anonymous" href="../_static/css/theme.css" rel="stylesheet" type="text/css"/>
<script src="../_static/js/theme.js" type="text/javascript"></script>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400&amp;display=swap" rel="stylesheet"/>
<meta content="../_static/img/pytorch_seo.png" property="og:image"/>
<link crossorigin="anonymous" href="../_static/webfonts/all.min.css" rel="stylesheet"/>
<meta content="default-src * 'unsafe-inline' 'unsafe-eval' data: blob:; style-src * 'unsafe-inline'; script-src * 'unsafe-inline' 'unsafe-eval' blob:;" http-equiv="Content-Security-Policy"/>
<meta content="tutorials" name="pytorch_project"/>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe height="0" src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS" style="display:none;visibility:hidden" width="0"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Google Tag Manager -->
<script>(function (w, d, s, l, i) {
    w[l] = w[l] || []; w[l].push({
      'gtm.start':
        new Date().getTime(), event: 'gtm.js'
    }); var f = d.getElementsByTagName(s)[0],
      j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    j.onload = function () {
      window.dispatchEvent(new Event('gtm_loaded'));
      console.log('GTM loaded successfully');
    };
  })(window, document, 'script', 'dataLayer', 'GTM-T8XT4PS');
</script>
<!-- End Google Tag Manager -->
<!-- Facebook Pixel Code -->
<script>
  !function (f, b, e, v, n, t, s) {
    if (f.fbq) return; n = f.fbq = function () {
      n.callMethod ?
        n.callMethod.apply(n, arguments) : n.queue.push(arguments)
    };
    if (!f._fbq) f._fbq = n; n.push = n; n.loaded = !0; n.version = '2.0';
    n.queue = []; t = b.createElement(e); t.async = !0;
    t.src = v; s = b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t, s)
  }(window, document, 'script',
    'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');
</script>
<script>
  document.documentElement.setAttribute('data-version', 'v2.9.0+cu128');
</script>
<noscript>
<img height="1" src="https://www.facebook.com/tr?id=243028289693773&amp;ev=PageView&amp;noscript=1" width="1"/>
</noscript>
<script>
  function gtag() {
    window.dataLayer.push(arguments);
  }
</script>
<!-- End Facebook Pixel Code -->
<!-- Repository configuration for tutorials -->
<script>
  // Define repository configuration for tutorial buttons using existing html_context variables
  // Only injected when tutorial buttons are shown AND github variables are defined
  // If either condition is false, JavaScript will fallback to default PyTorch tutorial links
  window.repoConfig = {
    github_repo: "pytorch/tutorials",
    github_branch: "main",
    colab_repo: "pytorch/tutorials",
    colab_branch: ""
  };
</script>
<!-- Script to Fix scrolling -->
<script>
  document.addEventListener('DOMContentLoaded', function () {
    // Fix anchor scrolling
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const targetId = this.getAttribute('href').substring(1);
        const targetElement = document.getElementById(targetId);

        if (targetElement) {
          const headerHeight =
            (document.querySelector('.header-holder') ? document.querySelector('.header-holder').offsetHeight : 0) +
            (document.querySelector('.bd-header') ? document.querySelector('.bd-header').offsetHeight : 0) + 20;

          const targetPosition = targetElement.getBoundingClientRect().top + window.pageYOffset - headerHeight;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });

          // Update URL hash without scrolling
          history.pushState(null, null, '#' + targetId);
        }
      });
    });
  });
</script>
<script async="" src="https://cse.google.com/cse.js?cx=e65585f8c3ea1440e"></script>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
<meta content="Jul 20, 2022" name="docbuild:last-update"/>
</head>
<body class="pytorch-body" data-feedback-url="https://github.com/pytorch/tutorials">
<div class="container-fluid header-holder tutorials-header" id="header-holder">
<div class="header-container-wrapper">
<div class="header-container">
<a aria-label="PyTorch" class="header-logo" href="https://pytorch.org/"></a>
<div class="main-menu">
<ul>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Learn</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/get-started/locally">
<span class="dropdown-title">Get Started</span>
</a>
<a class="nav-dropdown-item" href="https://docs.pytorch.org/tutorials">
<span class="dropdown-title">Tutorials</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
<span class="dropdown-title">Learn the Basics</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
<span class="dropdown-title">PyTorch Recipes</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
<span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/webinars/">
<span class="dropdown-title">Webinars</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Community</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
<span class="dropdown-title">Landscape</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/join-ecosystem">
<span class="dropdown-title">Join the Ecosystem</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-hub/">
<span class="dropdown-title">Community Hub</span>
</a>
<a class="nav-dropdown-item" href="https://discuss.pytorch.org/">
<span class="dropdown-title">Forums</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/resources">
<span class="dropdown-title">Developer Resources</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contributor-awards/">
<span class="dropdown-title">Contributor Awards</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/community-events/">
<span class="dropdown-title">Community Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/programs/ambassadors/">
<span class="dropdown-title">PyTorch Ambassadors</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Projects</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/projects/pytorch/">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/vllm/">
<span class="dropdown-title">vLLM</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/deepspeed/">
<span class="dropdown-title">DeepSpeed</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/projects/host-your-project/">
<span class="dropdown-title">Host Your Project</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span> Docs</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://docs.pytorch.org/docs/stable/index.html">
<span class="dropdown-title">PyTorch</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/domains">
<span class="dropdown-title">Domains</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>Blogs &amp; News</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/blog/">
<span class="dropdown-title">Blog</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/announcements">
<span class="dropdown-title">Announcements</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/case-studies/">
<span class="dropdown-title">Case Studies</span>
<a class="nav-dropdown-item" href="https://pytorch.org/events">
<span class="dropdown-title">Events</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
<span class="dropdown-title">Newsletter</span>
</a>
</a></div>
</div></li>
<li class="main-menu-item">
<div class="resources-dropdown" data-toggle="resources-dropdown" id="resourcesDropdownButton">
<a class="with-down-arrow">
<span>About</span>
</a>
<div class="resources-dropdown-menu">
<a class="nav-dropdown-item" href="https://pytorch.org/foundation">
<span class="dropdown-title">PyTorch Foundation</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/members">
<span class="dropdown-title">Members</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
<span class="dropdown-title">Governing Board</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/tac">
<span class="dropdown-title">Technical Advisory Council</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/credits">
<span class="dropdown-title">Cloud Credit Program</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/staff">
<span class="dropdown-title">Staff</span>
</a>
<a class="nav-dropdown-item" href="https://pytorch.org/contact">
<span class="dropdown-title">Contact</span>
</a>
</div>
</div>
</li>
<li class="main-menu-item">
<div class="no-dropdown main-menu-button">
<a data-cta="join" href="https://pytorch.org/join">
                JOIN
              </a>
</div>
</li>
</ul>
</div>
<a class="main-menu-open-button" data-behavior="open-mobile-menu" href="#">
<i class="fa-solid fa-ellipsis"></i>
</a>
</div>
</div>
</div>
<!-- Begin Mobile Menu -->
<div class="mobile-main-menu">
<div class="container-fluid">
<div class="header-container-wrapper">
<div class="mobile-main-menu-header-container">
<a class="main-menu-close-button" data-behavior="close-mobile-menu" href="#">
</a>
</div>
</div>
</div>
<div class="mobile-main-menu-links-container">
<div class="main-menu">
<ul>
<li class="resources-mobile-menu-title">
<a>Learn</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/get-started/locally">Get Started</a>
</li>
<li>
<a href="https://docs.pytorch.org/tutorials">Tutorials</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
</li>
<li>
<a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
</li>
<li>
<a href="https://pytorch.org/webinars/">Webinars</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Community</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://landscape.pytorch.org/">Landscape</a>
</li>
<li>
<a href="https://pytorch.org/join-ecosystem">Join the Ecosystem</a>
</li>
<li>
<a href="https://pytorch.org/community-hub/">Community Hub</a>
</li>
<li>
<a href="https://discuss.pytorch.org/">Forums</a>
</li>
<li>
<a href="https://pytorch.org/resources">Developer Resources</a>
</li>
<li>
<a href="https://pytorch.org/contributor-awards/">Contributor Awards</a>
</li>
<li>
<a href="https://pytorch.org/community-events/">Community Events</a>
</li>
<li>
<a href="https://pytorch.org/programs/ambassadors/">PyTorch Ambassadors</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Projects</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/projects/pytorch/">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/projects/vllm/">vLLM</a>
</li>
<li>
<a href="https://pytorch.org/projects/deepspeed/">DeepSpeed</a>
</li>
<li>
<a href="https://pytorch.org/projects/host-your-project/">Host Your Project</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Docs</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://docs.pytorch.org/docs/stable/index.html">PyTorch</a>
</li>
<li>
<a href="https://pytorch.org/domains">Domains</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>Blog &amp; News</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/blog/">Blog</a>
</li>
<li>
<a href="https://pytorch.org/announcements">Announcements</a>
</li>
<li>
<a href="https://pytorch.org/case-studies/">Case Studies</a>
</li>
<li>
<a href="https://pytorch.org/events">Events</a>
</li>
<li>
<a href="https://pytorch.org/newsletter">Newsletter</a>
</li>
</ul>
<li class="resources-mobile-menu-title">
<a>About</a>
</li>
<ul class="resources-mobile-menu-items">
<li>
<a href="https://pytorch.org/foundation">PyTorch Foundation</a>
</li>
<li>
<a href="https://pytorch.org/members">Members</a>
</li>
<li>
<a href="https://pytorch.org/governing-board">Governing Board</a>
</li>
<li>
<a href="https://pytorch.org/tac">Technical Advisory Council</a>
</li>
<li>
<a href="https://pytorch.org/credits">Cloud Credit Program</a>
</li>
<li>
<a href="https://pytorch.org/staff">Staff</a>
</li>
<li>
<a href="https://pytorch.org/contact">Contact</a>
</li>
</ul>
</ul>
</div>
</div>
</div>
<!-- End Mobile Menu -->
<body data-bs-root-margin="0px 0px -60%" data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-default-mode="" data-offset="180">
<div class="skip-link d-print-none" id="pst-skip-link"><a href="#main-content">Skip to main content</a></div>
<div id="pst-scroll-pixel-helper"></div>
<button class="btn rounded-pill" id="pst-back-to-top" type="button">
<i class="fa-solid fa-arrow-up"></i>Back to top</button>
<input class="sidebar-toggle" id="pst-primary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
<input class="sidebar-toggle" id="pst-secondary-sidebar-checkbox" type="checkbox"/>
<label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
<div class="search-button__wrapper">
<div class="search-button__overlay"></div>
<div class="search-button__search-container">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
</div>
<div class="pst-async-banner-revealer d-none">
<aside aria-label="Version warning" class="d-none d-print-none" id="bd-header-version-warning"></aside>
</div>
<header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
<button aria-label="Site navigation" class="pst-navbar-icon sidebar-toggle primary-toggle">
<span class="fa-solid fa-bars"></span>
</button>
<div class="navbar-header-items__start">
<div class="navbar-item">
<a class="version" href="../index.html">v2.9.0+cu128</a>
</div>
</div>
<div class="navbar-header-items">
<div class="me-auto navbar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="navbar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<button aria-label="On this page" class="pst-navbar-icon sidebar-toggle secondary-toggle">
<span class="fa-solid fa-outdent"></span>
</button>
</div>
</header>
<div class="bd-container">
<div class="bd-container__inner bd-page-width">
<div class="bd-sidebar-primary bd-sidebar">
<div class="sidebar-header-items sidebar-primary__section">
<div class="sidebar-header-items__center">
<div class="navbar-item">
<nav>
<ul class="bd-navbar-elements navbar-nav">
<li class="nav-item">
<a class="nav-link nav-internal" href="../intro.html">
    Intro
  </a>
</li>
<li class="nav-item current active">
<a class="nav-link nav-internal" href="../compilers_index.html">
    Compilers
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../domains.html">
    Domains
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../distributed.html">
    Distributed
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../deep-dive.html">
    Deep Dive
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../extension.html">
    Extension
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../ecosystem.html">
    Ecosystem
  </a>
</li>
<li class="nav-item">
<a class="nav-link nav-internal" href="../recipes_index.html">
    Recipes
  </a>
</li>
</ul>
</nav></div>
</div>
<div class="sidebar-header-items__end">
<div class="navbar-item">
<form action="../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="fa-solid fa-magnifying-glass"></i>
<input aria-label="Search the docs ..." autocapitalize="off" autocomplete="off" autocorrect="off" class="form-control" id="search-input" name="q" placeholder="Search the docs ..." spellcheck="false" type="search"/>
<span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
</div>
<div class="navbar-item">
<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
<div class="navbar-item"><ul aria-label="Icon Links" class="navbar-icon-links">
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://x.com/PyTorch" rel="noopener" target="_blank" title="X"><i aria-hidden="true" class="fa-brands fa-x-twitter fa-lg"></i>
<span class="sr-only">X</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://github.com/pytorch/tutorials" rel="noopener" target="_blank" title="GitHub"><i aria-hidden="true" class="fa-brands fa-github fa-lg"></i>
<span class="sr-only">GitHub</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://dev-discuss.pytorch.org/" rel="noopener" target="_blank" title="Discourse"><i aria-hidden="true" class="fa-brands fa-discourse fa-lg"></i>
<span class="sr-only">Discourse</span></a>
</li>
<li class="nav-item">
<a class="nav-link pst-navbar-icon" data-bs-placement="bottom" data-bs-toggle="tooltip" href="https://pypi.org/project/torch/" rel="noopener" target="_blank" title="PyPi"><i aria-hidden="true" class="fa-brands fa-python fa-lg"></i>
<span class="sr-only">PyPi</span></a>
</li>
</ul></div>
</div>
</div>
<div class="sidebar-primary-items__start sidebar-primary__section">
<div class="sidebar-primary-item">
<nav aria-label="Section Navigation" class="bd-docs-nav bd-links">
<p aria-level="1" class="bd-links__title" role="heading">Section Navigation</p>
<div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_compile_full_example.html"><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> End-to-End Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiled_autograd_tutorial.html">Compiled Autograd: Capturing a larger backward graph for <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compiler_set_stance_tutorial.html">Dynamic Compilation Control with <code class="docutils literal notranslate"><span class="pre">torch.compiler.set_stance</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/compiling_optimizer.html">(beta) Compiling the optimizer with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/compiling_optimizer_lr_scheduler.html">(beta) Running the compiled optimizer with an LR Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_compile_caching_tutorial.html">Compile Time Caching in <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">torch.export</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="torch_export_tutorial.html">torch.export Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_aoti_python.html"><code class="docutils literal notranslate"><span class="pre">torch.export</span></code> AOTInductor Tutorial for Python runtime (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recipes/torch_export_challenges_solutions.html">Demonstration of torch.export flow, common challenges and the solutions to address them</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ONNX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/export_simple_model_to_onnx_tutorial.html">Export a PyTorch model to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/onnx_registry_tutorial.html">Extending the ONNX Exporter Operator Support</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../beginner/onnx/export_control_flow_model_to_onnx_tutorial.html">Export a model with control flow to ONNX</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="simple">
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="torch_compile_conv_bn_fuser.html">Building a Convolution/Batch Norm fuser with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
</div>
</nav></div>
</div>
<div class="sidebar-primary-items__end sidebar-primary__section">
</div>
<div id="rtd-footer-container"></div>
</div>
<main class="bd-main" id="main-content" role="main">
<div class="bd-content">
<div class="bd-article-container">
<div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
<div class="header-article-items__start">
<div class="header-article-item">
<nav aria-label="Breadcrumb" class="d-print-none">
<ul class="bd-breadcrumbs">
<li class="breadcrumb-item breadcrumb-home">
<a aria-label="Home" class="nav-link" href="../index.html">
<i class="fa-solid fa-home"></i>
</a>
</li>
<li class="breadcrumb-item"><a class="nav-link" href="../compilers_index.html">Compilers</a></li>
<li aria-current="page" class="breadcrumb-item active">Introduction...</li>
</ul>
</nav>
</div>
</div>
<div class="header-article-items__end">
<div class="header-article-item">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="searchbox"></div>
<article class="bd-article" id="pytorch-article">
<!-- Hidden breadcrumb schema for SEO only -->
<div itemscope="" itemtype="https://schema.org/BreadcrumbList" style="display:none;">
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<link href="../compilers_index.html" itemprop="item"/>
<meta content="Compilers" itemprop="name"/>
<meta content="1" itemprop="position"/>
</div>
<div itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
<meta content="Introduction to &lt;code class=" docutils="" itemprop="name" literal="" notranslate"=""/><span class="pre">torch.compile</span>"&gt;
        <meta content="2" itemprop="position"/>
</div>
</div>
<script>
      if ((window.location.href.indexOf("/unstable/") != -1) && (window.location.href.indexOf("/unstable/unstable_index") < 1)) {
        var div = '<div class="prototype-banner"><i class="fa fa-flask" aria-hidden="true"></i> <strong>Unstable feature:</strong> Not typically available in binary distributions like PyPI. Early stage for feedback and testing.</div>'
        document.addEventListener('DOMContentLoaded', function () {
          document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div);
        });
      }
    </script>
<div class="pytorch-call-to-action-links">
<div id="tutorial-type">intermediate/torch_compile_tutorial</div>
<a data-behavior="call-to-action-event" data-response="Run in Google Colab" id="colab-link" target="_blank">
<div id="google-colab-link">
<img class="call-to-action-img" src="../_static/img/pytorch-colab.svg"/>
<div class="call-to-action-desktop-view">Run in Google Colab</div>
<div class="call-to-action-mobile-view">Colab</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="Download Notebook" id="notebook-link">
<div id="download-notebook-link">
<img class="call-to-action-notebook-img" src="../_static/img/pytorch-download.svg"/>
<div class="call-to-action-desktop-view">Download Notebook</div>
<div class="call-to-action-mobile-view">Notebook</div>
</div>
</a>
<a data-behavior="call-to-action-event" data-response="View on Github" id="github-link" target="_blank">
<div id="github-view-link">
<img class="call-to-action-img" src="../_static/img/pytorch-github.svg"/>
<div class="call-to-action-desktop-view">View on GitHub</div>
<div class="call-to-action-mobile-view">GitHub</div>
</div>
</a>
</div>
<div id="searchbox"></div>
<article class="bd-article">
<div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-intermediate-torch-compile-tutorial-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="introduction-to-torch-compile">
<span id="sphx-glr-intermediate-torch-compile-tutorial-py"></span><h1>Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code><a class="headerlink" href="#introduction-to-torch-compile" title="Link to this heading">#</a></h1><p class="date-info-last-verified" style="color: #6c6c6d; font-size: small;">Created On: Mar 15, 2023 | Last Updated: Oct 15, 2025 | Last Verified: Nov 05, 2024</p>
<p><strong>Author:</strong> William Wen</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is the new way to speed up your PyTorch code!
<code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> makes PyTorch code run faster by
JIT-compiling PyTorch code into optimized kernels,
while requiring minimal code changes.</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> accomplishes this by tracing through
your Python code, looking for PyTorch operations.
Code that is difficult to trace will result a
<strong>graph break</strong>, which are lost optimization opportunities, rather
than errors or silent incorrectness.</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is available in PyTorch 2.0 and later.</p>
<p>This introduction covers basic <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> usage
and demonstrates the advantages of <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> over
our previous PyTorch compiler solution,
<a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a>.</p>
<p>For an end-to-end example on a real model, check out our <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_compile_full_example.html">end-to-end torch.compile tutorial</a>.</p>
<p>To troubleshoot issues and to gain a deeper understanding of how to apply <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> to your code, check out <a class="reference external" href="https://docs.pytorch.org/docs/main/compile/programming_model.html">the torch.compile programming model</a>.</p>
<p><strong>Contents</strong></p>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#basic-usage" id="id1">Basic Usage</a></p></li>
<li><p><a class="reference internal" href="#demonstrating-speedups" id="id2">Demonstrating Speedups</a></p></li>
<li><p><a class="reference internal" href="#benefits-over-torchscript" id="id3">Benefits over TorchScript</a></p></li>
<li><p><a class="reference internal" href="#graph-breaks" id="id4">Graph Breaks</a></p></li>
<li><p><a class="reference internal" href="#troubleshooting" id="id5">Troubleshooting</a></p></li>
<li><p><a class="reference internal" href="#conclusion" id="id6">Conclusion</a></p></li>
</ul>
</nav>
<p><strong>Required pip dependencies for this tutorial</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span> <span class="pre">&gt;=</span> <span class="pre">2.0</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scipy</span></code></p></li>
</ul>
<p><strong>System requirements</strong>
- A C++ compiler, such as <code class="docutils literal notranslate"><span class="pre">g++</span></code>
- Python development package (<code class="docutils literal notranslate"><span class="pre">python-devel</span></code>/<code class="docutils literal notranslate"><span class="pre">python-dev</span></code>)</p>
<section id="basic-usage">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Basic Usage</a><a class="headerlink" href="#basic-usage" title="Link to this heading">#</a></h2>
<p>We turn on some logging to help us to see what <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is doing
under the hood in this tutorial.
The following code will print out the PyTorch ops that <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> traced.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>


<a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">graph_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is a decorator that takes an arbitrary Python function.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">foo</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>


<span class="n">opt_foo1</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foo</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">opt_foo1</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span>
<span class="k">def</span><span class="w"> </span><span class="nf">opt_foo2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>


<span class="nb">print</span><span class="p">(</span><span class="n">opt_foo2</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_1_57703c6c_17e9_44be_adf9_87ae8a7f015f =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[3, 3][3, 1]cpu", L_y_: "f32[3, 3][3, 1]cpu"):
        l_x_ = L_x_
        l_y_ = L_y_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:74 in foo, code: a = torch.sin(x)
        a: "f32[3, 3][3, 1]cpu" = torch.sin(l_x_);  l_x_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:75 in foo, code: b = torch.cos(y)
        b: "f32[3, 3][3, 1]cpu" = torch.cos(l_y_);  l_y_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:76 in foo, code: return a + b
        add: "f32[3, 3][3, 1]cpu" = a + b;  a = b = None
        return (add,)


tensor([[ 0.0663,  1.8726,  1.0057],
        [-0.3487,  0.3188,  0.9310],
        [ 1.8560,  0.4513, -0.4614]])
TRACED GRAPH
 ===== __compiled_fn_3_12712180_e493_4bc2_8b8e_dcdfd783faaa =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[3, 3][3, 1]cpu", L_y_: "f32[3, 3][3, 1]cpu"):
        l_x_ = L_x_
        l_y_ = L_y_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:85 in opt_foo2, code: a = torch.sin(x)
        a: "f32[3, 3][3, 1]cpu" = torch.sin(l_x_);  l_x_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:86 in opt_foo2, code: b = torch.cos(y)
        b: "f32[3, 3][3, 1]cpu" = torch.cos(l_y_);  l_y_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:87 in opt_foo2, code: return a + b
        add: "f32[3, 3][3, 1]cpu" = a + b;  a = b = None
        return (add,)


tensor([[ 0.2038,  0.5530,  0.2229],
        [-0.3382,  0.5160, -0.0161],
        [ 1.7310,  1.3559,  1.2261]])
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is applied recursively, so nested function calls
within the top-level compiled function will also be compiled.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">inner</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.sin.html#torch.sin" title="torch.sin"><span class="n">torch</span><span class="o">.</span><span class="n">sin</span></a><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span>
<span class="k">def</span><span class="w"> </span><span class="nf">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">inner</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cos.html#torch.cos" title="torch.cos"><span class="n">torch</span><span class="o">.</span><span class="n">cos</span></a><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>


<span class="nb">print</span><span class="p">(</span><span class="n">outer</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_5_03c189a8_83d7_41cc_a42b_e8e8d534d682 =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[3, 3][3, 1]cpu", L_y_: "f32[3, 3][3, 1]cpu"):
        l_x_ = L_x_
        l_y_ = L_y_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:98 in inner, code: return torch.sin(x)
        a: "f32[3, 3][3, 1]cpu" = torch.sin(l_x_);  l_x_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:104 in outer, code: b = torch.cos(y)
        b: "f32[3, 3][3, 1]cpu" = torch.cos(l_y_);  l_y_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:105 in outer, code: return a + b
        add: "f32[3, 3][3, 1]cpu" = a + b;  a = b = None
        return (add,)


tensor([[ 1.2845, -0.0892, -0.2115],
        [ 1.3537, -0.0816, -0.0732],
        [-0.3591,  1.5748,  0.7948]])
</pre></div>
</div>
<p>We can also optimize <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> instances by either calling
its <code class="docutils literal notranslate"><span class="pre">.compile()</span></code> method or by directly <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>-ing the module.
This is equivalent to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>-ing the module’s <code class="docutils literal notranslate"><span class="pre">__call__</span></code> method
(which indirectly calls <code class="docutils literal notranslate"><span class="pre">forward</span></code>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">t</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">MyModule</span><span class="p">(</span><a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span></a><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="torch.nn.Linear"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lin</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">mod1</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">MyModule</span></a><span class="p">()</span>
<a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.compile" title="torch.nn.Module.compile"><span class="n">mod1</span><span class="o">.</span><span class="n">compile</span></a><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mod1</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>

<span class="n">mod2</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><span class="n">MyModule</span></a><span class="p">()</span>
<span class="n">mod2</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">mod2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mod2</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_7_d919aa2b_ce68_443d_ab75_c1f3ad8968a4 =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_self_modules_lin_parameters_weight_: "f32[3, 3][3, 1]cpu", L_self_modules_lin_parameters_bias_: "f32[3][1]cpu", L_x_: "f32[3, 3][3, 1]cpu"):
        l_self_modules_lin_parameters_weight_ = L_self_modules_lin_parameters_weight_
        l_self_modules_lin_parameters_bias_ = L_self_modules_lin_parameters_bias_
        l_x_ = L_x_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:126 in forward, code: return torch.nn.functional.relu(self.lin(x))
        linear: "f32[3, 3][3, 1]cpu" = torch._C._nn.linear(l_x_, l_self_modules_lin_parameters_weight_, l_self_modules_lin_parameters_bias_);  l_x_ = l_self_modules_lin_parameters_weight_ = l_self_modules_lin_parameters_bias_ = None
        relu: "f32[3, 3][3, 1]cpu" = torch.nn.functional.relu(linear);  linear = None
        return (relu,)


tensor([[0.4863, 0.2575, 0.5411],
        [0.1428, 0.0000, 0.3762],
        [0.4444, 0.5583, 0.7902]], grad_fn=&lt;CompiledFunctionBackward&gt;)
tensor([[0.0000, 0.0000, 1.4330],
        [0.0000, 0.0000, 0.0536],
        [0.0000, 0.0000, 0.1456]], grad_fn=&lt;CompiledFunctionBackward&gt;)
</pre></div>
</div>
</section>
<section id="demonstrating-speedups">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Demonstrating Speedups</a><a class="headerlink" href="#demonstrating-speedups" title="Link to this heading">#</a></h2>
<p>Now let’s demonstrate how <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> speeds up a simple PyTorch example.
For a demonstration on a more complex model, see our <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_compile_full_example.html">end-to-end torch.compile tutorial</a>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">foo3</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">z</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-nn-functional sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.functional.relu.html#torch.nn.functional.relu" title="torch.nn.functional.relu"><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">z</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="k">return</span> <span class="n">u</span>


<span class="n">opt_foo3</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">foo3</span><span class="p">)</span>


<span class="c1"># Returns the result of running `fn()` and the time it took for `fn()` to run,</span>
<span class="c1"># in seconds. We use CUDA events and synchronization for the most accurate</span>
<span class="c1"># measurements.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">timed</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="n">start</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.Event.html#torch.cuda.Event" title="torch.cuda.Event"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span></a><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-class" href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.Event.html#torch.cuda.Event" title="torch.cuda.Event"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span></a><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">start</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">fn</span><span class="p">()</span>
    <span class="n">end</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
    <a class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.cuda.synchronize.html#torch.cuda.synchronize" title="torch.cuda.synchronize"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span></a><span class="p">()</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">end</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1024</span>


<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"compile:"</span><span class="p">,</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">opt_foo3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">))[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"eager:"</span><span class="p">,</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">foo3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">))[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_9_08a72ca3_c6ee_45c6_a198_0e8c99e7092d =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[4096, 4096][4096, 1]cuda:0"):
        l_x_ = L_x_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:147 in foo3, code: y = x + 1
        y: "f32[4096, 4096][4096, 1]cuda:0" = l_x_ + 1;  l_x_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:148 in foo3, code: z = torch.nn.functional.relu(y)
        z: "f32[4096, 4096][4096, 1]cuda:0" = torch.nn.functional.relu(y);  y = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:149 in foo3, code: u = z * 2
        u: "f32[4096, 4096][4096, 1]cuda:0" = z * 2;  z = None
        return (u,)


compile: 0.40412646532058716
eager: 0.02964000031352043
</pre></div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> appears to take a lot longer to complete
compared to eager. This is because <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> takes extra time to compile
the model on the first few executions.
<code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> re-uses compiled code whever possible,
so if we run our optimized model several more times, we should
see a significant improvement compared to eager.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># turn off logging for now to prevent spam</span>
<a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">graph_code</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">eager_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">_</span></a><span class="p">,</span> <span class="n">eager_time</span> <span class="o">=</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">foo3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">))</span>
    <span class="n">eager_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eager_time</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"eager time </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">eager_time</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"~"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">compile_times</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">_</span></a><span class="p">,</span> <span class="n">compile_time</span> <span class="o">=</span> <span class="n">timed</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">opt_foo3</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp</span></a><span class="p">))</span>
    <span class="n">compile_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compile_time</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"compile time </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">compile_time</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"~"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">eager_med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">eager_times</span><span class="p">)</span>
<span class="n">compile_med</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">compile_times</span><span class="p">)</span>
<span class="n">speedup</span> <span class="o">=</span> <span class="n">eager_med</span> <span class="o">/</span> <span class="n">compile_med</span>
<span class="k">assert</span> <span class="n">speedup</span> <span class="o">&gt;</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">"(eval) eager median: </span><span class="si">{</span><span class="n">eager_med</span><span class="si">}</span><span class="s2">, compile median: </span><span class="si">{</span><span class="n">compile_med</span><span class="si">}</span><span class="s2">, speedup: </span><span class="si">{</span><span class="n">speedup</span><span class="si">}</span><span class="s2">x"</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"~"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>eager time 0: 0.00088900001719594
eager time 1: 0.0008459999808110297
eager time 2: 0.0008459999808110297
eager time 3: 0.0008479999960400164
eager time 4: 0.000846999988425523
eager time 5: 0.0008420000085607171
eager time 6: 0.0008420000085607171
eager time 7: 0.0008509375038556755
eager time 8: 0.0008399999933317304
eager time 9: 0.0008440000237897038
~~~~~~~~~~
compile time 0: 0.0005019999807700515
compile time 1: 0.0003699999942909926
compile time 2: 0.00036100001307204366
compile time 3: 0.0003539999888744205
compile time 4: 0.00035700001171790063
compile time 5: 0.0003530000103637576
compile time 6: 0.0003530000103637576
compile time 7: 0.0003499999875202775
compile time 8: 0.0003539999888744205
compile time 9: 0.0003530000103637576
~~~~~~~~~~
(eval) eager median: 0.0008459999808110297, compile median: 0.0003539999888744205, speedup: 2.389830529376495x
~~~~~~~~~~
</pre></div>
</div>
<p>And indeed, we can see that running our model with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>
results in a significant speedup. Speedup mainly comes from reducing Python overhead and
GPU read/writes, and so the observed speedup may vary on factors such as model
architecture and batch size. For example, if a model’s architecture is simple
and the amount of data is large, then the bottleneck would be
GPU compute and the observed speedup may be less significant.</p>
<p>To see speedups on a real model, check out our <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_compile_full_example.html">end-to-end torch.compile tutorial</a>.</p>
</section>
<section id="benefits-over-torchscript">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">Benefits over TorchScript</a><a class="headerlink" href="#benefits-over-torchscript" title="Link to this heading">#</a></h2>
<p>Why should we use <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> over TorchScript? Primarily, the
advantage of <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> lies in its ability to handle
arbitrary Python code with minimal changes to existing code.</p>
<p>Compare to TorchScript, which has a tracing mode (<code class="docutils literal notranslate"><span class="pre">torch.jit.trace</span></code>) and
a scripting mode (<code class="docutils literal notranslate"><span class="pre">torch.jit.script</span></code>). Tracing mode is susceptible to
silent incorrectness, while scripting mode requires significant code changes
and will raise errors on unsupported Python code.</p>
<p>For example, TorchScript tracing silently fails on data-dependent control flow
(the <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">x.sum()</span> <span class="pre">&lt;</span> <span class="pre">0:</span></code> line below)
because only the actual control flow path is traced.
In comparison, <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> is able to correctly handle it.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">f1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">y</span>
    <span class="k">return</span> <span class="n">y</span>


<span class="c1"># Test that `fn1` and `fn2` return the same result, given the same arguments `args`.</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_fns</span><span class="p">(</span><span class="n">fn1</span><span class="p">,</span> <span class="n">fn2</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="n">fn1</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="n">fn2</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="k">return</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose" title="torch.allclose"><span class="n">torch</span><span class="o">.</span><span class="n">allclose</span></a><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">)</span>


<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<a class="sphx-glr-backref-module-torch-jit-torch-jit sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.torch.jit.ScriptFunction"><span class="n">traced_f1</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace" title="torch.jit.trace"><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span></a><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"traced 1, 1:"</span><span class="p">,</span> <span class="n">test_fns</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-jit-torch-jit sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.torch.jit.ScriptFunction"><span class="n">traced_f1</span></a><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"traced 1, 2:"</span><span class="p">,</span> <span class="n">test_fns</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <a class="sphx-glr-backref-module-torch-jit-torch-jit sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.torch.jit.ScriptFunction"><span class="n">traced_f1</span></a><span class="p">,</span> <span class="p">(</span><span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)))</span>

<span class="n">compile_f1</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"compile 1, 1:"</span><span class="p">,</span> <span class="n">test_fns</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">compile_f1</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"compile 1, 2:"</span><span class="p">,</span> <span class="n">test_fns</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">compile_f1</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"~"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/var/lib/workspace/intermediate_source/torch_compile_tutorial.py:239: TracerWarning:

Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!

traced 1, 1: True
traced 1, 2: False
compile 1, 1: True
compile 1, 2: True
~~~~~~~~~~
</pre></div>
</div>
<p>TorchScript scripting can handle data-dependent control flow,
but it can require major code changes and will raise errors when unsupported Python
is used.</p>
<p>In the example below, we forget TorchScript type annotations and we receive
a TorchScript error because the input type for argument <code class="docutils literal notranslate"><span class="pre">y</span></code>, an <code class="docutils literal notranslate"><span class="pre">int</span></code>,
does not match with the default argument type, <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>.
In comparison, <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> works without requiring any type annotations.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">traceback</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tb</span>

<a class="sphx-glr-backref-module-torch-_logging sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch._logging.set_logs.html#torch._logging.set_logs" title="torch._logging.set_logs"><span class="n">torch</span><span class="o">.</span><span class="n">_logging</span><span class="o">.</span><span class="n">set_logs</span></a><span class="p">(</span><span class="n">graph_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">f2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>


<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a> <span class="o">=</span> <span class="mi">3</span>

<a class="sphx-glr-backref-module-torch-jit-torch-jit sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.torch.jit.ScriptFunction"><span class="n">script_f2</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch-jit sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script" title="torch.jit.script"><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span></a><span class="p">(</span><span class="n">f2</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <a class="sphx-glr-backref-module-torch-jit-torch-jit sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction" title="torch.jit.torch.jit.ScriptFunction"><span class="n">script_f2</span></a><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>

<span class="n">compile_f2</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">f2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"compile 2:"</span><span class="p">,</span> <span class="n">test_fns</span><span class="p">(</span><span class="n">f2</span><span class="p">,</span> <span class="n">compile_f2</span><span class="p">,</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"~"</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_compile_tutorial.py", line 288, in &lt;module&gt;
    script_f2(inp1, inp2)
RuntimeError: f2() Expected a value of type 'Tensor (inferred)' for argument 'y' but instead found type 'int'.
Inferred 'y' to be of type 'Tensor' because it was not annotated with an explicit type.
Position: 1
Value: 3
Declaration: f2(Tensor x, Tensor y) -&gt; Tensor
Cast error details: Unable to cast 3 to Tensor
TRACED GRAPH
 ===== __compiled_fn_18_60f88fab_6a3d_4dcc_a2ea_16a1899bfb1f =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[5, 5][5, 1]cpu"):
        l_x_ = L_x_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:280 in f2, code: return x + y
        add: "f32[5, 5][5, 1]cpu" = l_x_ + 3;  l_x_ = None
        return (add,)


compile 2: True
~~~~~~~~~~
</pre></div>
</div>
</section>
<section id="graph-breaks">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Graph Breaks</a><a class="headerlink" href="#graph-breaks" title="Link to this heading">#</a></h2>
<p>The graph break is one of the most fundamental concepts within <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>.
It allows <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> to handle arbitrary Python code by interrupting
compilation, running the unsupported code, then resuming compilation.
The term “graph break” comes from the fact that <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> attempts
to capture and optimize the PyTorch operation graph. When unsupported Python code is encountered,
then this graph must be “broken”.
Graph breaks result in lost optimization opportunities, which may still be undesirable,
but this is better than silent incorrectness or a hard crash.</p>
<p>Let’s look at a data-dependent control flow example to better see how graph breaks work.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">bar</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.abs.html#torch.abs" title="torch.abs"><span class="n">torch</span><span class="o">.</span><span class="n">abs</span></a><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">b</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span>


<span class="n">opt_bar</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">bar</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.ones.html#torch.ones" title="torch.ones"><span class="n">torch</span><span class="o">.</span><span class="n">ones</span></a><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">opt_bar</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
<span class="n">opt_bar</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_20_d5309909_d209_4382_9b82_0ba74ced4ca8 =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_a_: "f32[10][1]cpu", L_b_: "f32[10][1]cpu"):
        l_a_ = L_a_
        l_b_ = L_b_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:312 in bar, code: x = a / (torch.abs(a) + 1)
        abs_1: "f32[10][1]cpu" = torch.abs(l_a_)
        add: "f32[10][1]cpu" = abs_1 + 1;  abs_1 = None
        x: "f32[10][1]cpu" = l_a_ / add;  l_a_ = add = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:313 in bar, code: if b.sum() &lt; 0:
        sum_1: "f32[][]cpu" = l_b_.sum();  l_b_ = None
        lt: "b8[][]cpu" = sum_1 &lt; 0;  sum_1 = None
        return (lt, x)


TRACED GRAPH
 ===== __compiled_fn_24_24e667b5_a8e5_442d_b94a_a878f1114d23 =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[10][1]cpu", L_b_: "f32[10][1]cpu"):
        l_x_ = L_x_
        l_b_ = L_b_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b
        mul: "f32[10][1]cpu" = l_x_ * l_b_;  l_x_ = l_b_ = None
        return (mul,)


TRACED GRAPH
 ===== __compiled_fn_26_d1830df0_39a5_4379_96f3_af6c112110cd =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_b_: "f32[10][1]cpu", L_x_: "f32[10][1]cpu"):
        l_b_ = L_b_
        l_x_ = L_x_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:314 in torch_dynamo_resume_in_bar_at_313, code: b = b * -1
        b: "f32[10][1]cpu" = l_b_ * -1;  l_b_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b
        mul_1: "f32[10][1]cpu" = l_x_ * b;  l_x_ = b = None
        return (mul_1,)



tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000])
</pre></div>
</div>
<p>The first time we run <code class="docutils literal notranslate"><span class="pre">bar</span></code>, we see that <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> traced 2 graphs
corresponding to the following code (noting that <code class="docutils literal notranslate"><span class="pre">b.sum()</span> <span class="pre">&lt;</span> <span class="pre">0</span></code> is False):</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">/</span> <span class="pre">(torch.abs(a)</span> <span class="pre">+</span> <span class="pre">1);</span> <span class="pre">b.sum()</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">return</span> <span class="pre">x</span> <span class="pre">*</span> <span class="pre">b</span></code></p></li>
</ol>
<p>The second time we run <code class="docutils literal notranslate"><span class="pre">bar</span></code>, we take the other branch of the if statement
and we get 1 traced graph corresponding to the code <code class="docutils literal notranslate"><span class="pre">b</span> <span class="pre">=</span> <span class="pre">b</span> <span class="pre">*</span> <span class="pre">-1;</span> <span class="pre">return</span> <span class="pre">x</span> <span class="pre">*</span> <span class="pre">b</span></code>.
We do not see a graph of <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">/</span> <span class="pre">(torch.abs(a)</span> <span class="pre">+</span> <span class="pre">1)</span></code> outputted the second time
since <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> cached this graph from the first run and re-used it.</p>
<p>Let’s investigate by example how TorchDynamo would step through <code class="docutils literal notranslate"><span class="pre">bar</span></code>.
If <code class="docutils literal notranslate"><span class="pre">b.sum()</span> <span class="pre">&lt;</span> <span class="pre">0</span></code>, then TorchDynamo would run graph 1, let
Python determine the result of the conditional, then run
graph 2. On the other hand, if <code class="docutils literal notranslate"><span class="pre">not</span> <span class="pre">b.sum()</span> <span class="pre">&lt;</span> <span class="pre">0</span></code>, then TorchDynamo
would run graph 1, let Python determine the result of the conditional, then
run graph 3.</p>
<p>We can see all graph breaks by using <code class="docutils literal notranslate"><span class="pre">torch._logging.set_logs(graph_breaks=True)</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset to clear the torch.compile cache</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">opt_bar</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
<span class="n">opt_bar</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_28_e75c1c8c_4795_4a16_8d6f_90d489a9e78e =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_a_: "f32[10][1]cpu", L_b_: "f32[10][1]cpu"):
        l_a_ = L_a_
        l_b_ = L_b_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:312 in bar, code: x = a / (torch.abs(a) + 1)
        abs_1: "f32[10][1]cpu" = torch.abs(l_a_)
        add: "f32[10][1]cpu" = abs_1 + 1;  abs_1 = None
        x: "f32[10][1]cpu" = l_a_ / add;  l_a_ = add = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:313 in bar, code: if b.sum() &lt; 0:
        sum_1: "f32[][]cpu" = l_b_.sum();  l_b_ = None
        lt: "b8[][]cpu" = sum_1 &lt; 0;  sum_1 = None
        return (lt, x)


TRACED GRAPH
 ===== __compiled_fn_32_e26b0760_f8cc_414d_a852_6092ac007ca7 =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_x_: "f32[10][1]cpu", L_b_: "f32[10][1]cpu"):
        l_x_ = L_x_
        l_b_ = L_b_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b
        mul: "f32[10][1]cpu" = l_x_ * l_b_;  l_x_ = l_b_ = None
        return (mul,)


TRACED GRAPH
 ===== __compiled_fn_34_2b406644_b833_40a0_96ec_c1f387d13c7f =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_b_: "f32[10][1]cpu", L_x_: "f32[10][1]cpu"):
        l_b_ = L_b_
        l_x_ = L_x_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:314 in torch_dynamo_resume_in_bar_at_313, code: b = b * -1
        b: "f32[10][1]cpu" = l_b_ * -1;  l_b_ = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b
        mul_1: "f32[10][1]cpu" = l_x_ * b;  l_x_ = b = None
        return (mul_1,)



tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,
        0.5000])
</pre></div>
</div>
<p>In order to maximize speedup, graph breaks should be limited.
We can force TorchDynamo to raise an error upon the first graph
break encountered by using <code class="docutils literal notranslate"><span class="pre">fullgraph=True</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset to clear the torch.compile cache</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_dynamo</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="n">opt_bar_fullgraph</span> <span class="o">=</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">bar</span><span class="p">,</span> <span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">opt_bar_fullgraph</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">print_exc</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File "/var/lib/workspace/intermediate_source/torch_compile_tutorial.py", line 360, in &lt;module&gt;
    opt_bar_fullgraph(torch.randn(10), torch.randn(10))
  File "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py", line 841, in compile_wrapper
    raise e.with_traceback(None) from e.__cause__  # User compiler error
torch._dynamo.exc.Unsupported: Data-dependent branching
  Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() &gt; 0:`). Dynamo does not support tracing dynamic control flow.
  Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround.
  Hint: Use `torch.cond` to express dynamic control flow.

  Developer debug context: attempted to jump with TensorVariable()

 For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0170.html

from user code:
   File "/var/lib/workspace/intermediate_source/torch_compile_tutorial.py", line 313, in bar
    if b.sum() &lt; 0:

Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS="+dynamo"
</pre></div>
</div>
<p>In our example above, we can work around this graph break by replacing
the if statement with a <code class="docutils literal notranslate"><span class="pre">torch.cond</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functorch.experimental.control_flow</span><span class="w"> </span><span class="kn">import</span> <span class="n">cond</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">fullgraph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">bar_fixed</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function" href="https://docs.pytorch.org/docs/stable/generated/torch.abs.html#torch.abs" title="torch.abs"><span class="n">torch</span><span class="o">.</span><span class="n">abs</span></a><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">true_branch</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">false_branch</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="c1"># NOTE: torch.cond doesn't allow aliased outputs</span>
        <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">cond</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">true_branch</span><span class="p">,</span> <span class="n">false_branch</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">b</span>


<span class="n">bar_fixed</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
<span class="n">bar_fixed</span><span class="p">(</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp1</span></a><span class="p">,</span> <span class="o">-</span><a class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor"><span class="n">inp2</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>TRACED GRAPH
 ===== __compiled_fn_37_6c5f108a_d951_495b_a538_024359c8fc5a =====
 /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
    def forward(self, L_a_: "f32[10][1]cpu", L_b_: "f32[10][1]cpu"):
        l_a_ = L_a_
        l_b_ = L_b_

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:373 in bar_fixed, code: x = a / (torch.abs(a) + 1)
        abs_1: "f32[10][1]cpu" = torch.abs(l_a_)
        add: "f32[10][1]cpu" = abs_1 + 1;  abs_1 = None
        x: "f32[10][1]cpu" = l_a_ / add;  l_a_ = add = x = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:382 in bar_fixed, code: x = cond(b.sum() &lt; 0, true_branch, false_branch, (b,))
        sum_1: "f32[][]cpu" = l_b_.sum()
        lt: "b8[][]cpu" = sum_1 &lt; 0;  sum_1 = None

         # File: /usr/local/lib/python3.10/dist-packages/torch/_higher_order_ops/cond.py:186 in cond, code: return cond_op(pred, true_fn, false_fn, operands)
        cond_true_0 = self.cond_true_0
        cond_false_0 = self.cond_false_0
        cond = torch.ops.higher_order.cond(lt, cond_true_0, cond_false_0, (l_b_,));  lt = cond_true_0 = cond_false_0 = None
        x_1: "f32[10][1]cpu" = cond[0];  cond = None

         # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:383 in bar_fixed, code: return x * b
        mul: "f32[10][1]cpu" = x_1 * l_b_;  x_1 = l_b_ = None
        return (mul,)

    class cond_true_0(torch.nn.Module):
        def forward(self, l_b_: "f32[10][1]cpu"):
            l_b__1 = l_b_

             # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:376 in true_branch, code: return y * -1
            mul: "f32[10][1]cpu" = l_b__1 * -1;  l_b__1 = None
            return (mul,)

    class cond_false_0(torch.nn.Module):
        def forward(self, l_b_: "f32[10][1]cpu"):
            l_b__1 = l_b_

             # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:380 in false_branch, code: return y.clone()
            clone: "f32[10][1]cpu" = l_b__1.clone();  l_b__1 = None
            return (clone,)



tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])
</pre></div>
</div>
<p>In order to serialize graphs or to run graphs on different (i.e. Python-less)
environments, consider using <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> instead (from PyTorch 2.1+).
One important restriction is that <code class="docutils literal notranslate"><span class="pre">torch.export</span></code> does not support graph breaks. Please check
<a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_export_tutorial.html">the torch.export tutorial</a>
for more details on <code class="docutils literal notranslate"><span class="pre">torch.export</span></code>.</p>
<p>Check out our <a class="reference external" href="https://docs.pytorch.org/docs/main/compile/programming_model.graph_breaks_index.html">section on graph breaks in the torch.compile programming model</a>
for tips on how to work around graph breaks.</p>
</section>
<section id="troubleshooting">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Troubleshooting</a><a class="headerlink" href="#troubleshooting" title="Link to this heading">#</a></h2>
<p>Is <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> failing to speed up your model? Is compile time unreasonably long?
Is your code recompiling excessively? Are you having difficulties dealing with graph breaks?
Are you looking for tips on how to best use <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>?
Or maybe you simply want to learn more about the inner workings of <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code>?</p>
<p>Check out <a class="reference external" href="https://docs.pytorch.org/docs/main/compile/programming_model.html">the torch.compile programming model</a>.</p>
</section>
<section id="conclusion">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Conclusion</a><a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this tutorial, we introduced <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> by covering
basic usage, demonstrating speedups over eager mode, comparing to TorchScript,
and briefly describing graph breaks.</p>
<p>For an end-to-end example on a real model, check out our <a class="reference external" href="https://pytorch.org/tutorials/intermediate/torch_compile_full_example.html">end-to-end torch.compile tutorial</a>.</p>
<p>To troubleshoot issues and to gain a deeper understanding of how to apply <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> to your code, check out <a class="reference external" href="https://docs.pytorch.org/docs/main/compile/programming_model.html">the torch.compile programming model</a>.</p>
<p>We hope that you will give <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> a try!</p>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 16.527 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-intermediate-torch-compile-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/96ad88eb476f41a5403dcdade086afb8/torch_compile_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">torch_compile_tutorial.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6b019e0b5f84b568fcca1120bd28e230/torch_compile_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">torch_compile_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../_downloads/2802fa0f38eb25e527bdd4d098be787f/torch_compile_tutorial.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">torch_compile_tutorial.zip</span></code></a></p>
</div>
</div>
</section>
</section>
</article>
</article>
<footer class="bd-footer-article">
<div class="footer-article-items footer-article__inner">
<div class="footer-article-item">
<div class="feedback">
<div class="rating">
    Rate this Page
    <div class="stars">
<span class="star" data-behavior="tutorial-rating" data-count="1" data-value="1">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="2" data-value="2">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="3" data-value="3">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="4" data-value="4">★</span>
<span class="star" data-behavior="tutorial-rating" data-count="5" data-value="5">★</span>
</div>
</div>
<div class="feedback-send">
<button class="feedback-btn" data-bs-placement="bottom" data-bs-title="Create a GitHub Issue" data-bs-toggle="tooltip" data-gtm="feedback-btn-click" onclick="openGitHubIssue()">Send Feedback
    </button>
</div>
</div>
<div class="prev-next-area">
<a class="left-prev" href="../compilers_index.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Compilers</p>
</div>
</a>
<a class="right-next" href="torch_compile_full_example.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> End-to-End Tutorial</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
<div class="footer-info">
<p class="copyright">
    
      
        © Copyright 2024, PyTorch.
      
      <br/>
</p>
<p class="theme-version">
    Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
  </p>
</div>
</div>
</div>
</footer>
<footer class="prev-next-footer d-print-none">
<div class="prev-next-area">
<a class="left-prev" href="../compilers_index.html" title="previous page">
<i class="fa-solid fa-angle-left"></i>
<div class="prev-next-info">
<p class="prev-next-subtitle">previous</p>
<p class="prev-next-title">Compilers</p>
</div>
</a>
<a class="right-next" href="torch_compile_full_example.html" title="next page">
<div class="prev-next-info">
<p class="prev-next-subtitle">next</p>
<p class="prev-next-title"><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> End-to-End Tutorial</p>
</div>
<i class="fa-solid fa-angle-right"></i>
</a>
</div>
</footer>
</div>
<div class="bd-sidebar-secondary bd-toc">
<div class="sidebar-secondary-items sidebar-secondary__inner">
<div class="sidebar-secondary-item">
<div class="page-toc tocsection onthispage" id="pst-page-navigation-heading-2">
<i class="fa-solid fa-list"></i> On this page
  </div>
<nav aria-labelledby="pst-page-navigation-heading-2" class="bd-toc-nav page-toc">
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-usage">Basic Usage</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstrating-speedups">Demonstrating Speedups</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#benefits-over-torchscript">Benefits over TorchScript</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#graph-breaks">Graph Breaks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#troubleshooting">Troubleshooting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
</ul>
</nav></div>
<div class="sidebar-secondary-item">
<div class="sidebar-heading">PyTorch Libraries</div>
<ul style="list-style-type: none; padding: 0; padding-bottom: 80px;">
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/ao" style="color: var(--pst-color-text-muted)">torchao</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchrec" style="color: var(--pst-color-text-muted)">torchrec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchft" style="color: var(--pst-color-text-muted)">torchft</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/torchcodec" style="color: var(--pst-color-text-muted)">TorchCodec</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/vision" style="color: var(--pst-color-text-muted)">torchvision</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/executorch" style="color: var(--pst-color-text-muted)">ExecuTorch</a></li>
<li><a class="nav-link nav-external" href="https://docs.pytorch.org/xla" style="color: var(--pst-color-text-muted)">PyTorch on XLA Devices</a></li>
</ul>
</div>
</div>
</div>
</div>
<footer class="bd-footer-content">
</footer>
</main>
</div>
</div>
<!-- Scripts loaded after <body> so the DOM is not blocked -->
<script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>
<div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
<div class="container">
<div class="row">
<div class="col-md-4">
<h2>Docs</h2>
<p>Access comprehensive developer documentation for PyTorch</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/docs/stable/index.html">View Docs</a>
</div>
<div class="col-md-4">
<h2>Tutorials</h2>
<p>Get in-depth tutorials for beginners and advanced developers</p>
<a class="with-right-arrow" href="https://docs.pytorch.org/tutorials">View Tutorials</a>
</div>
<div class="col-md-4">
<h2>Resources</h2>
<p>Find development resources and get your questions answered</p>
<a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
</div>
</div>
</div>
</div>
<footer class="site-footer">
<div class="container footer-container">
<div class="newsletter" id="newsletter">
<p class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and
        the latest news</p>
<script charset="utf-8" src="//js.hsforms.net/forms/embed/v2.js" type="text/javascript"></script>
<script>
        hbspt.forms.create({
          region: "na1",
          portalId: "8112310",
          formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
        });
      </script>
<p class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its
        projects regarding their events, training, research, developments, and related announcements. I understand that
        I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
</div>
<div class="lf-grid">
<ul class="social-links">
<li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
<svg aria-label="Facebook" viewbox="-0.51 -0.26 26.45 26.45" xmlns="http://www.w3.org/2000/svg">
<path d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
<svg aria-label="X" viewbox="0 0 300 300" xmlns="http://www.w3.org/2000/svg">
<path d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
<svg aria-label="YouTube" viewbox="0.21 0.27 34.45 25.07" xmlns="http://www.w3.org/2000/svg">
<path d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z" fill="currentColor"></path>
</svg>
</a></li>
<li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
<svg aria-label="LinkedIn" viewbox="-10.23 -10.23 531.96 531.96" xmlns="http://www.w3.org/2000/svg">
<rect fill="currentColor" height="512" rx="0" width="512"></rect>
<circle cx="142" cy="138" fill="#000" r="37"></circle>
<path d="M244 194v198M142 194v198" stroke="#000" stroke-width="66"></path>
<path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32" fill="#000"></path>
</svg>
</a></li>
<li><a href="https://pytorch.slack.com" target="_blank" title="PyTorch Slack">
<svg aria-label="Slack" viewbox="0.16 -0.03 21.19 21.19" xmlns="http://www.w3.org/2000/svg">
<path d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z" fill="currentColor">
</path>
</svg>
</a></li>
<li><a href="https://pytorch.org/wechat" title="PyTorch on WeChat">
<svg aria-label="WeChat" viewbox="0.14 -0.17 38.02 33.02" xmlns="http://www.w3.org/2000/svg">
<path d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z" fill="currentColor">
</path>
<path d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z" fill="currentColor">
</path>
</svg>
</a></li>
</ul>
</div>
<div class="privacy-policy">
<div class="copyright">
<p>
          © PyTorch. Copyright © The Linux Foundation®. All rights reserved. The Linux Foundation has registered
          trademarks and uses trademarks. For more information, including terms of use, privacy policy, and trademark
          usage, please see our <a href="https://www.linuxfoundation.org/legal/policies">Policies</a> page. <a href="https://www.linuxfoundation.org/trademark-usage">Trademark Usage</a>. <a href="http://www.linuxfoundation.org/privacy">Privacy Policy</a>.
        </p>
</div>
</div>
</div>
</footer>
<div class="cookie-banner-wrapper">
<div class="container">
<p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
<img class="close-button" src="../_static/img/pytorch-x.svg"/>
</div>
</div>
<footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
<div class="footer-items__start">
<div class="footer-item">
<p class="copyright">
    
      © Copyright 2024, PyTorch.
      <br/>
</p>
</div>
<div class="footer-item">
<p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
</p>
</div>
</div>
<div class="footer-items__end">
<div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
</div>
</div>
</footer>
<script type="application/ld+json">
    {
       "@context": "https://schema.org",
       "@type": "Article",
       "name": "Introduction to torch.compile",
       "headline": "Introduction to torch.compile",
       "description": "PyTorch Documentation. Explore PyTorch, an open-source machine learning library that accelerates the path from research prototyping to production deployment. Discover tutorials, API references, and guides to help you build and deploy deep learning models efficiently.",
       "url": "/intermediate/torch_compile_tutorial.html",
       "articleBody": "Note Go to the end to download the full example code. Introduction to torch.compile# Author: William Wen torch.compile is the new way to speed up your PyTorch code! torch.compile makes PyTorch code run faster by JIT-compiling PyTorch code into optimized kernels, while requiring minimal code changes. torch.compile accomplishes this by tracing through your Python code, looking for PyTorch operations. Code that is difficult to trace will result a graph break, which are lost optimization opportunities, rather than errors or silent incorrectness. torch.compile is available in PyTorch 2.0 and later. This introduction covers basic torch.compile usage and demonstrates the advantages of torch.compile over our previous PyTorch compiler solution, TorchScript. For an end-to-end example on a real model, check out our end-to-end torch.compile tutorial. To troubleshoot issues and to gain a deeper understanding of how to apply torch.compile to your code, check out the torch.compile programming model. Contents Basic Usage Demonstrating Speedups Benefits over TorchScript Graph Breaks Troubleshooting Conclusion Required pip dependencies for this tutorial torch \u003e= 2.0 numpy scipy System requirements - A C++ compiler, such as g++ - Python development package (python-devel/python-dev) Basic Usage# We turn on some logging to help us to see what torch.compile is doing under the hood in this tutorial. The following code will print out the PyTorch ops that torch.compile traced. import torch torch._logging.set_logs(graph_code=True) torch.compile is a decorator that takes an arbitrary Python function. def foo(x, y): a = torch.sin(x) b = torch.cos(y) return a + b opt_foo1 = torch.compile(foo) print(opt_foo1(torch.randn(3, 3), torch.randn(3, 3))) @torch.compile def opt_foo2(x, y): a = torch.sin(x) b = torch.cos(y) return a + b print(opt_foo2(torch.randn(3, 3), torch.randn(3, 3))) TRACED GRAPH ===== __compiled_fn_1_57703c6c_17e9_44be_adf9_87ae8a7f015f ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"): l_x_ = L_x_ l_y_ = L_y_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:74 in foo, code: a = torch.sin(x) a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_); l_x_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:75 in foo, code: b = torch.cos(y) b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_); l_y_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:76 in foo, code: return a + b add: \"f32[3, 3][3, 1]cpu\" = a + b; a = b = None return (add,) tensor([[ 0.0663, 1.8726, 1.0057], [-0.3487, 0.3188, 0.9310], [ 1.8560, 0.4513, -0.4614]]) TRACED GRAPH ===== __compiled_fn_3_12712180_e493_4bc2_8b8e_dcdfd783faaa ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"): l_x_ = L_x_ l_y_ = L_y_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:85 in opt_foo2, code: a = torch.sin(x) a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_); l_x_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:86 in opt_foo2, code: b = torch.cos(y) b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_); l_y_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:87 in opt_foo2, code: return a + b add: \"f32[3, 3][3, 1]cpu\" = a + b; a = b = None return (add,) tensor([[ 0.2038, 0.5530, 0.2229], [-0.3382, 0.5160, -0.0161], [ 1.7310, 1.3559, 1.2261]]) torch.compile is applied recursively, so nested function calls within the top-level compiled function will also be compiled. def inner(x): return torch.sin(x) @torch.compile def outer(x, y): a = inner(x) b = torch.cos(y) return a + b print(outer(torch.randn(3, 3), torch.randn(3, 3))) TRACED GRAPH ===== __compiled_fn_5_03c189a8_83d7_41cc_a42b_e8e8d534d682 ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"): l_x_ = L_x_ l_y_ = L_y_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:98 in inner, code: return torch.sin(x) a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_); l_x_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:104 in outer, code: b = torch.cos(y) b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_); l_y_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:105 in outer, code: return a + b add: \"f32[3, 3][3, 1]cpu\" = a + b; a = b = None return (add,) tensor([[ 1.2845, -0.0892, -0.2115], [ 1.3537, -0.0816, -0.0732], [-0.3591, 1.5748, 0.7948]]) We can also optimize torch.nn.Module instances by either calling its .compile() method or by directly torch.compile-ing the module. This is equivalent to torch.compile-ing the module\u2019s __call__ method (which indirectly calls forward). t = torch.randn(10, 100) class MyModule(torch.nn.Module): def __init__(self): super().__init__() self.lin = torch.nn.Linear(3, 3) def forward(self, x): return torch.nn.functional.relu(self.lin(x)) mod1 = MyModule() mod1.compile() print(mod1(torch.randn(3, 3))) mod2 = MyModule() mod2 = torch.compile(mod2) print(mod2(torch.randn(3, 3))) TRACED GRAPH ===== __compiled_fn_7_d919aa2b_ce68_443d_ab75_c1f3ad8968a4 ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_self_modules_lin_parameters_weight_: \"f32[3, 3][3, 1]cpu\", L_self_modules_lin_parameters_bias_: \"f32[3][1]cpu\", L_x_: \"f32[3, 3][3, 1]cpu\"): l_self_modules_lin_parameters_weight_ = L_self_modules_lin_parameters_weight_ l_self_modules_lin_parameters_bias_ = L_self_modules_lin_parameters_bias_ l_x_ = L_x_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:126 in forward, code: return torch.nn.functional.relu(self.lin(x)) linear: \"f32[3, 3][3, 1]cpu\" = torch._C._nn.linear(l_x_, l_self_modules_lin_parameters_weight_, l_self_modules_lin_parameters_bias_); l_x_ = l_self_modules_lin_parameters_weight_ = l_self_modules_lin_parameters_bias_ = None relu: \"f32[3, 3][3, 1]cpu\" = torch.nn.functional.relu(linear); linear = None return (relu,) tensor([[0.4863, 0.2575, 0.5411], [0.1428, 0.0000, 0.3762], [0.4444, 0.5583, 0.7902]], grad_fn=\u003cCompiledFunctionBackward\u003e) tensor([[0.0000, 0.0000, 1.4330], [0.0000, 0.0000, 0.0536], [0.0000, 0.0000, 0.1456]], grad_fn=\u003cCompiledFunctionBackward\u003e) Demonstrating Speedups# Now let\u2019s demonstrate how torch.compile speeds up a simple PyTorch example. For a demonstration on a more complex model, see our end-to-end torch.compile tutorial. def foo3(x): y = x + 1 z = torch.nn.functional.relu(y) u = z * 2 return u opt_foo3 = torch.compile(foo3) # Returns the result of running `fn()` and the time it took for `fn()` to run, # in seconds. We use CUDA events and synchronization for the most accurate # measurements. def timed(fn): start = torch.cuda.Event(enable_timing=True) end = torch.cuda.Event(enable_timing=True) start.record() result = fn() end.record() torch.cuda.synchronize() return result, start.elapsed_time(end) / 1024 inp = torch.randn(4096, 4096).cuda() print(\"compile:\", timed(lambda: opt_foo3(inp))[1]) print(\"eager:\", timed(lambda: foo3(inp))[1]) TRACED GRAPH ===== __compiled_fn_9_08a72ca3_c6ee_45c6_a198_0e8c99e7092d ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[4096, 4096][4096, 1]cuda:0\"): l_x_ = L_x_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:147 in foo3, code: y = x + 1 y: \"f32[4096, 4096][4096, 1]cuda:0\" = l_x_ + 1; l_x_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:148 in foo3, code: z = torch.nn.functional.relu(y) z: \"f32[4096, 4096][4096, 1]cuda:0\" = torch.nn.functional.relu(y); y = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:149 in foo3, code: u = z * 2 u: \"f32[4096, 4096][4096, 1]cuda:0\" = z * 2; z = None return (u,) compile: 0.40412646532058716 eager: 0.02964000031352043 Notice that torch.compile appears to take a lot longer to complete compared to eager. This is because torch.compile takes extra time to compile the model on the first few executions. torch.compile re-uses compiled code whever possible, so if we run our optimized model several more times, we should see a significant improvement compared to eager. # turn off logging for now to prevent spam torch._logging.set_logs(graph_code=False) eager_times = [] for i in range(10): _, eager_time = timed(lambda: foo3(inp)) eager_times.append(eager_time) print(f\"eager time {i}: {eager_time}\") print(\"~\" * 10) compile_times = [] for i in range(10): _, compile_time = timed(lambda: opt_foo3(inp)) compile_times.append(compile_time) print(f\"compile time {i}: {compile_time}\") print(\"~\" * 10) import numpy as np eager_med = np.median(eager_times) compile_med = np.median(compile_times) speedup = eager_med / compile_med assert speedup \u003e 1 print( f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\" ) print(\"~\" * 10) eager time 0: 0.00088900001719594 eager time 1: 0.0008459999808110297 eager time 2: 0.0008459999808110297 eager time 3: 0.0008479999960400164 eager time 4: 0.000846999988425523 eager time 5: 0.0008420000085607171 eager time 6: 0.0008420000085607171 eager time 7: 0.0008509375038556755 eager time 8: 0.0008399999933317304 eager time 9: 0.0008440000237897038 ~~~~~~~~~~ compile time 0: 0.0005019999807700515 compile time 1: 0.0003699999942909926 compile time 2: 0.00036100001307204366 compile time 3: 0.0003539999888744205 compile time 4: 0.00035700001171790063 compile time 5: 0.0003530000103637576 compile time 6: 0.0003530000103637576 compile time 7: 0.0003499999875202775 compile time 8: 0.0003539999888744205 compile time 9: 0.0003530000103637576 ~~~~~~~~~~ (eval) eager median: 0.0008459999808110297, compile median: 0.0003539999888744205, speedup: 2.389830529376495x ~~~~~~~~~~ And indeed, we can see that running our model with torch.compile results in a significant speedup. Speedup mainly comes from reducing Python overhead and GPU read/writes, and so the observed speedup may vary on factors such as model architecture and batch size. For example, if a model\u2019s architecture is simple and the amount of data is large, then the bottleneck would be GPU compute and the observed speedup may be less significant. To see speedups on a real model, check out our end-to-end torch.compile tutorial. Benefits over TorchScript# Why should we use torch.compile over TorchScript? Primarily, the advantage of torch.compile lies in its ability to handle arbitrary Python code with minimal changes to existing code. Compare to TorchScript, which has a tracing mode (torch.jit.trace) and a scripting mode (torch.jit.script). Tracing mode is susceptible to silent incorrectness, while scripting mode requires significant code changes and will raise errors on unsupported Python code. For example, TorchScript tracing silently fails on data-dependent control flow (the if x.sum() \u003c 0: line below) because only the actual control flow path is traced. In comparison, torch.compile is able to correctly handle it. def f1(x, y): if x.sum() \u003c 0: return -y return y # Test that `fn1` and `fn2` return the same result, given the same arguments `args`. def test_fns(fn1, fn2, args): out1 = fn1(*args) out2 = fn2(*args) return torch.allclose(out1, out2) inp1 = torch.randn(5, 5) inp2 = torch.randn(5, 5) traced_f1 = torch.jit.trace(f1, (inp1, inp2)) print(\"traced 1, 1:\", test_fns(f1, traced_f1, (inp1, inp2))) print(\"traced 1, 2:\", test_fns(f1, traced_f1, (-inp1, inp2))) compile_f1 = torch.compile(f1) print(\"compile 1, 1:\", test_fns(f1, compile_f1, (inp1, inp2))) print(\"compile 1, 2:\", test_fns(f1, compile_f1, (-inp1, inp2))) print(\"~\" * 10) /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:239: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can\u0027t record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! traced 1, 1: True traced 1, 2: False compile 1, 1: True compile 1, 2: True ~~~~~~~~~~ TorchScript scripting can handle data-dependent control flow, but it can require major code changes and will raise errors when unsupported Python is used. In the example below, we forget TorchScript type annotations and we receive a TorchScript error because the input type for argument y, an int, does not match with the default argument type, torch.Tensor. In comparison, torch.compile works without requiring any type annotations. import traceback as tb torch._logging.set_logs(graph_code=True) def f2(x, y): return x + y inp1 = torch.randn(5, 5) inp2 = 3 script_f2 = torch.jit.script(f2) try: script_f2(inp1, inp2) except: tb.print_exc() compile_f2 = torch.compile(f2) print(\"compile 2:\", test_fns(f2, compile_f2, (inp1, inp2))) print(\"~\" * 10) Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_compile_tutorial.py\", line 288, in \u003cmodule\u003e script_f2(inp1, inp2) RuntimeError: f2() Expected a value of type \u0027Tensor (inferred)\u0027 for argument \u0027y\u0027 but instead found type \u0027int\u0027. Inferred \u0027y\u0027 to be of type \u0027Tensor\u0027 because it was not annotated with an explicit type. Position: 1 Value: 3 Declaration: f2(Tensor x, Tensor y) -\u003e Tensor Cast error details: Unable to cast 3 to Tensor TRACED GRAPH ===== __compiled_fn_18_60f88fab_6a3d_4dcc_a2ea_16a1899bfb1f ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[5, 5][5, 1]cpu\"): l_x_ = L_x_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:280 in f2, code: return x + y add: \"f32[5, 5][5, 1]cpu\" = l_x_ + 3; l_x_ = None return (add,) compile 2: True ~~~~~~~~~~ Graph Breaks# The graph break is one of the most fundamental concepts within torch.compile. It allows torch.compile to handle arbitrary Python code by interrupting compilation, running the unsupported code, then resuming compilation. The term \u201cgraph break\u201d comes from the fact that torch.compile attempts to capture and optimize the PyTorch operation graph. When unsupported Python code is encountered, then this graph must be \u201cbroken\u201d. Graph breaks result in lost optimization opportunities, which may still be undesirable, but this is better than silent incorrectness or a hard crash. Let\u2019s look at a data-dependent control flow example to better see how graph breaks work. def bar(a, b): x = a / (torch.abs(a) + 1) if b.sum() \u003c 0: b = b * -1 return x * b opt_bar = torch.compile(bar) inp1 = torch.ones(10) inp2 = torch.ones(10) opt_bar(inp1, inp2) opt_bar(inp1, -inp2) TRACED GRAPH ===== __compiled_fn_20_d5309909_d209_4382_9b82_0ba74ced4ca8 ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"): l_a_ = L_a_ l_b_ = L_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:312 in bar, code: x = a / (torch.abs(a) + 1) abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_) add: \"f32[10][1]cpu\" = abs_1 + 1; abs_1 = None x: \"f32[10][1]cpu\" = l_a_ / add; l_a_ = add = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:313 in bar, code: if b.sum() \u003c 0: sum_1: \"f32[][]cpu\" = l_b_.sum(); l_b_ = None lt: \"b8[][]cpu\" = sum_1 \u003c 0; sum_1 = None return (lt, x) TRACED GRAPH ===== __compiled_fn_24_24e667b5_a8e5_442d_b94a_a878f1114d23 ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"): l_x_ = L_x_ l_b_ = L_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b mul: \"f32[10][1]cpu\" = l_x_ * l_b_; l_x_ = l_b_ = None return (mul,) TRACED GRAPH ===== __compiled_fn_26_d1830df0_39a5_4379_96f3_af6c112110cd ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_b_: \"f32[10][1]cpu\", L_x_: \"f32[10][1]cpu\"): l_b_ = L_b_ l_x_ = L_x_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:314 in torch_dynamo_resume_in_bar_at_313, code: b = b * -1 b: \"f32[10][1]cpu\" = l_b_ * -1; l_b_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b mul_1: \"f32[10][1]cpu\" = l_x_ * b; l_x_ = b = None return (mul_1,) tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]) The first time we run bar, we see that torch.compile traced 2 graphs corresponding to the following code (noting that b.sum() \u003c 0 is False): x = a / (torch.abs(a) + 1); b.sum() return x * b The second time we run bar, we take the other branch of the if statement and we get 1 traced graph corresponding to the code b = b * -1; return x * b. We do not see a graph of x = a / (torch.abs(a) + 1) outputted the second time since torch.compile cached this graph from the first run and re-used it. Let\u2019s investigate by example how TorchDynamo would step through bar. If b.sum() \u003c 0, then TorchDynamo would run graph 1, let Python determine the result of the conditional, then run graph 2. On the other hand, if not b.sum() \u003c 0, then TorchDynamo would run graph 1, let Python determine the result of the conditional, then run graph 3. We can see all graph breaks by using torch._logging.set_logs(graph_breaks=True). # Reset to clear the torch.compile cache torch._dynamo.reset() opt_bar(inp1, inp2) opt_bar(inp1, -inp2) TRACED GRAPH ===== __compiled_fn_28_e75c1c8c_4795_4a16_8d6f_90d489a9e78e ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"): l_a_ = L_a_ l_b_ = L_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:312 in bar, code: x = a / (torch.abs(a) + 1) abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_) add: \"f32[10][1]cpu\" = abs_1 + 1; abs_1 = None x: \"f32[10][1]cpu\" = l_a_ / add; l_a_ = add = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:313 in bar, code: if b.sum() \u003c 0: sum_1: \"f32[][]cpu\" = l_b_.sum(); l_b_ = None lt: \"b8[][]cpu\" = sum_1 \u003c 0; sum_1 = None return (lt, x) TRACED GRAPH ===== __compiled_fn_32_e26b0760_f8cc_414d_a852_6092ac007ca7 ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_x_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"): l_x_ = L_x_ l_b_ = L_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b mul: \"f32[10][1]cpu\" = l_x_ * l_b_; l_x_ = l_b_ = None return (mul,) TRACED GRAPH ===== __compiled_fn_34_2b406644_b833_40a0_96ec_c1f387d13c7f ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_b_: \"f32[10][1]cpu\", L_x_: \"f32[10][1]cpu\"): l_b_ = L_b_ l_x_ = L_x_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:314 in torch_dynamo_resume_in_bar_at_313, code: b = b * -1 b: \"f32[10][1]cpu\" = l_b_ * -1; l_b_ = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:315 in torch_dynamo_resume_in_bar_at_313, code: return x * b mul_1: \"f32[10][1]cpu\" = l_x_ * b; l_x_ = b = None return (mul_1,) tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]) In order to maximize speedup, graph breaks should be limited. We can force TorchDynamo to raise an error upon the first graph break encountered by using fullgraph=True: # Reset to clear the torch.compile cache torch._dynamo.reset() opt_bar_fullgraph = torch.compile(bar, fullgraph=True) try: opt_bar_fullgraph(torch.randn(10), torch.randn(10)) except: tb.print_exc() Traceback (most recent call last): File \"/var/lib/workspace/intermediate_source/torch_compile_tutorial.py\", line 360, in \u003cmodule\u003e opt_bar_fullgraph(torch.randn(10), torch.randn(10)) File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 841, in compile_wrapper raise e.with_traceback(None) from e.__cause__ # User compiler error torch._dynamo.exc.Unsupported: Data-dependent branching Explanation: Detected data-dependent branching (e.g. `if my_tensor.sum() \u003e 0:`). Dynamo does not support tracing dynamic control flow. Hint: This graph break is fundamental - it is unlikely that Dynamo will ever be able to trace through your code. Consider finding a workaround. Hint: Use `torch.cond` to express dynamic control flow. Developer debug context: attempted to jump with TensorVariable() For more details about this graph break, please visit: https://meta-pytorch.github.io/compile-graph-break-site/gb/gb0170.html from user code: File \"/var/lib/workspace/intermediate_source/torch_compile_tutorial.py\", line 313, in bar if b.sum() \u003c 0: Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you\u0027re reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\" In our example above, we can work around this graph break by replacing the if statement with a torch.cond: from functorch.experimental.control_flow import cond @torch.compile(fullgraph=True) def bar_fixed(a, b): x = a / (torch.abs(a) + 1) def true_branch(y): return y * -1 def false_branch(y): # NOTE: torch.cond doesn\u0027t allow aliased outputs return y.clone() x = cond(b.sum() \u003c 0, true_branch, false_branch, (b,)) return x * b bar_fixed(inp1, inp2) bar_fixed(inp1, -inp2) TRACED GRAPH ===== __compiled_fn_37_6c5f108a_d951_495b_a538_024359c8fc5a ===== /usr/local/lib/python3.10/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, L_a_: \"f32[10][1]cpu\", L_b_: \"f32[10][1]cpu\"): l_a_ = L_a_ l_b_ = L_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:373 in bar_fixed, code: x = a / (torch.abs(a) + 1) abs_1: \"f32[10][1]cpu\" = torch.abs(l_a_) add: \"f32[10][1]cpu\" = abs_1 + 1; abs_1 = None x: \"f32[10][1]cpu\" = l_a_ / add; l_a_ = add = x = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:382 in bar_fixed, code: x = cond(b.sum() \u003c 0, true_branch, false_branch, (b,)) sum_1: \"f32[][]cpu\" = l_b_.sum() lt: \"b8[][]cpu\" = sum_1 \u003c 0; sum_1 = None # File: /usr/local/lib/python3.10/dist-packages/torch/_higher_order_ops/cond.py:186 in cond, code: return cond_op(pred, true_fn, false_fn, operands) cond_true_0 = self.cond_true_0 cond_false_0 = self.cond_false_0 cond = torch.ops.higher_order.cond(lt, cond_true_0, cond_false_0, (l_b_,)); lt = cond_true_0 = cond_false_0 = None x_1: \"f32[10][1]cpu\" = cond[0]; cond = None # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:383 in bar_fixed, code: return x * b mul: \"f32[10][1]cpu\" = x_1 * l_b_; x_1 = l_b_ = None return (mul,) class cond_true_0(torch.nn.Module): def forward(self, l_b_: \"f32[10][1]cpu\"): l_b__1 = l_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:376 in true_branch, code: return y * -1 mul: \"f32[10][1]cpu\" = l_b__1 * -1; l_b__1 = None return (mul,) class cond_false_0(torch.nn.Module): def forward(self, l_b_: \"f32[10][1]cpu\"): l_b__1 = l_b_ # File: /var/lib/workspace/intermediate_source/torch_compile_tutorial.py:380 in false_branch, code: return y.clone() clone: \"f32[10][1]cpu\" = l_b__1.clone(); l_b__1 = None return (clone,) tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]) In order to serialize graphs or to run graphs on different (i.e. Python-less) environments, consider using torch.export instead (from PyTorch 2.1+). One important restriction is that torch.export does not support graph breaks. Please check the torch.export tutorial for more details on torch.export. Check out our section on graph breaks in the torch.compile programming model for tips on how to work around graph breaks. Troubleshooting# Is torch.compile failing to speed up your model? Is compile time unreasonably long? Is your code recompiling excessively? Are you having difficulties dealing with graph breaks? Are you looking for tips on how to best use torch.compile? Or maybe you simply want to learn more about the inner workings of torch.compile? Check out the torch.compile programming model. Conclusion# In this tutorial, we introduced torch.compile by covering basic usage, demonstrating speedups over eager mode, comparing to TorchScript, and briefly describing graph breaks. For an end-to-end example on a real model, check out our end-to-end torch.compile tutorial. To troubleshoot issues and to gain a deeper understanding of how to apply torch.compile to your code, check out the torch.compile programming model. We hope that you will give torch.compile a try! Total running time of the script: (0 minutes 16.527 seconds) Download Jupyter notebook: torch_compile_tutorial.ipynb Download Python source code: torch_compile_tutorial.py Download zipped: torch_compile_tutorial.zip",
       "author": {
         "@type": "Organization",
         "name": "PyTorch Contributors",
         "url": "https://pytorch.org"
       },
       "image": "../_static/img/pytorch_seo.png",
       "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/intermediate/torch_compile_tutorial.html"
       },
       "datePublished": "2023-01-01T00:00:00Z",
       "dateModified": "2023-01-01T00:00:00Z"
     }
 </script>
<script>
    // Tutorials Call to action event tracking
    $("[data-behavior='call-to-action-event']").on('click', function () {
      fbq('trackCustom', "Download", {
        tutorialTitle: $('h1:first').text(),
        downloadLink: this.href,
        tutorialLink: window.location.href,
        downloadTitle: $(this).attr("data-response")
      });
      if (typeof gtag === 'function') {
        gtag('event', 'click', {
          'event_category': $(this).attr("data-response"),
          'event_label': $("h1").first().text(),
          'tutorial_link': window.location.href
        });
      }
    });
  </script>
</body>
</body></html>